
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v4,09/36] nds32: Cache and TLB routines - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v4,09/36] nds32: Cache and TLB routines</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 18, 2017, 6:46 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;0916d15bd615ddcee8b1bc35fad043a9eb03d749.1513577007.git.green.hu@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10118395/mbox/"
   >mbox</a>
|
   <a href="/patch/10118395/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10118395/">/patch/10118395/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E53FE603FA for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 18 Dec 2017 07:26:35 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D3B28288B1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 18 Dec 2017 07:26:35 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id C826C28D8D; Mon, 18 Dec 2017 07:26:35 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D4D6228C06
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 18 Dec 2017 07:26:33 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1758043AbdLRH02 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 18 Dec 2017 02:26:28 -0500
Received: from mail-pl0-f68.google.com ([209.85.160.68]:41330 &quot;EHLO
	mail-pl0-f68.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S932709AbdLRHMi (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 18 Dec 2017 02:12:38 -0500
Received: by mail-pl0-f68.google.com with SMTP id g2so4318909pli.8;
	Sun, 17 Dec 2017 23:12:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:in-reply-to:references;
	bh=OZ6uNLo0/O2NKR4VsQwZ35vXzEsPUVmjEcCI1CxR0hY=;
	b=br7pbT5jS1T/FkfL2mbkahzquiNky2NlklLWKuuIPIXQYNmqKW7yowh+JPLe+8EfUP
	UVo+bHjgXbrhdMhe+wtgv9ZKS28RT5fucOJIUgNmWWBBQtIrCf+r5w9SRS4WmnItCCSK
	t9fpDt82axfcaBmJloMWt0kmQbTQwU+nzucWrVAPqm9C+NnQF3xMTvxxe38MNy1LuSvY
	wKRmH1sZ8w0fdR0GK3+0KozILN1nsZEDQMI0ROG01Knt3GYlB+7th4aqWurwiXHSR1PP
	UO4aweGLxGwtjZ7Kywsnu0n6GYUzNrCJk/KYqux7Xr1ubhf91OOXBieBG+Z2ASMUX3xL
	aP7g==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:in-reply-to:references;
	bh=OZ6uNLo0/O2NKR4VsQwZ35vXzEsPUVmjEcCI1CxR0hY=;
	b=VPDEWEJNy0smpCTiPpP5hIXUddp037NqcOfAtskz5B3QLRhqD7rb3BELXGZs6AygAJ
	6BDlNbeN1cWDr3fyflWJ4AhJxpETz0n0zVEyVPDE5HYWJernkljXmVh4l7cT4Ev2VBNI
	cfO9rB1FINy9jvT2L8AkIBTdee/dciyNesSixBkJYtxdnE//807Tzd/xULOLpzBCus9t
	axJ83nCW1UieuVu8/B7JURgctPzCyaqDMq4T30Ns0C8w2YyFYW5hcR/3M0QdakDZxRA7
	3MmOfd62vCTpnjnjIO7AMluaNZ3OeqVt+7wanjiX9n+HYb67aY5lhLnugG+NfbnHlho+
	kp4A==
X-Gm-Message-State: AKGB3mI270AOJc1RVSNNs0IkUpqzy8d/2Lb9IrJ8N3v9QjOaNxOQvw2g
	uPnYq3XpppXB2J7aJzALixo=
X-Google-Smtp-Source: ACJfBotA1tL3l7Y1HfuqKEhUGAeMrw3FYIUTTdG8scAXkgKo8Ff6FYyqyIGewWgQtquFe+L/MZfBwg==
X-Received: by 10.84.141.164 with SMTP id 33mr17216083plv.375.1513581157443; 
	Sun, 17 Dec 2017 23:12:37 -0800 (PST)
Received: from app09.andestech.com ([118.163.51.199])
	by smtp.gmail.com with ESMTPSA id
	q24sm24013551pfk.168.2017.12.17.23.12.33
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Sun, 17 Dec 2017 23:12:36 -0800 (PST)
From: Greentime Hu &lt;green.hu@gmail.com&gt;
To: greentime@andestech.com, linux-kernel@vger.kernel.org,
	arnd@arndb.de, linux-arch@vger.kernel.org, tglx@linutronix.de,
	jason@lakedaemon.net, marc.zyngier@arm.com, robh+dt@kernel.org,
	netdev@vger.kernel.org, deanbo422@gmail.com,
	devicetree@vger.kernel.org, viro@zeniv.linux.org.uk,
	dhowells@redhat.com, will.deacon@arm.com,
	daniel.lezcano@linaro.org, linux-serial@vger.kernel.org,
	geert.uytterhoeven@gmail.com, linus.walleij@linaro.org,
	mark.rutland@arm.com, greg@kroah.com, ren_guo@c-sky.com,
	pombredanne@nexb.com
Cc: green.hu@gmail.com, Vincent Chen &lt;vincentc@andestech.com&gt;
Subject: [PATCH v4 09/36] nds32: Cache and TLB routines
Date: Mon, 18 Dec 2017 14:46:21 +0800
Message-Id: &lt;0916d15bd615ddcee8b1bc35fad043a9eb03d749.1513577007.git.green.hu@gmail.com&gt;
X-Mailer: git-send-email 1.7.9.5
In-Reply-To: &lt;cover.1513577007.git.green.hu@gmail.com&gt;
References: &lt;cover.1513577007.git.green.hu@gmail.com&gt;
In-Reply-To: &lt;cover.1513577007.git.green.hu@gmail.com&gt;
References: &lt;cover.1513577007.git.green.hu@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Dec. 18, 2017, 6:46 a.m.</div>
<pre class="content">
<span class="from">From: Greentime Hu &lt;greentime@andestech.com&gt;</span>

This patch contains cache and TLB maintenance functions.
<span class="signed-off-by">
Signed-off-by: Vincent Chen &lt;vincentc@andestech.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Greentime Hu &lt;greentime@andestech.com&gt;</span>
---
 arch/nds32/include/asm/cache.h         |   12 +
 arch/nds32/include/asm/cache_info.h    |   13 +
 arch/nds32/include/asm/cacheflush.h    |   44 +++
 arch/nds32/include/asm/mmu_context.h   |   68 ++++
 arch/nds32/include/asm/proc-fns.h      |   44 +++
 arch/nds32/include/asm/tlb.h           |   28 ++
 arch/nds32/include/asm/tlbflush.h      |   47 +++
 arch/nds32/include/uapi/asm/cachectl.h |   14 +
 arch/nds32/kernel/cacheinfo.c          |   49 +++
 arch/nds32/mm/cacheflush.c             |  322 +++++++++++++++++++
 arch/nds32/mm/proc.c                   |  540 ++++++++++++++++++++++++++++++++
 arch/nds32/mm/tlb.c                    |   50 +++
 12 files changed, 1231 insertions(+)
 create mode 100644 arch/nds32/include/asm/cache.h
 create mode 100644 arch/nds32/include/asm/cache_info.h
 create mode 100644 arch/nds32/include/asm/cacheflush.h
 create mode 100644 arch/nds32/include/asm/mmu_context.h
 create mode 100644 arch/nds32/include/asm/proc-fns.h
 create mode 100644 arch/nds32/include/asm/tlb.h
 create mode 100644 arch/nds32/include/asm/tlbflush.h
 create mode 100644 arch/nds32/include/uapi/asm/cachectl.h
 create mode 100644 arch/nds32/kernel/cacheinfo.c
 create mode 100644 arch/nds32/mm/cacheflush.c
 create mode 100644 arch/nds32/mm/proc.c
 create mode 100644 arch/nds32/mm/tlb.c
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/nds32/include/asm/cache.h b/arch/nds32/include/asm/cache.h</span>
new file mode 100644
<span class="p_header">index 0000000..347db48</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cache.h</span>
<span class="p_chunk">@@ -0,0 +1,12 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_CACHE_H__</span>
<span class="p_add">+#define __NDS32_CACHE_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#define L1_CACHE_BYTES	32</span>
<span class="p_add">+#define L1_CACHE_SHIFT	5</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_DMA_MINALIGN   L1_CACHE_BYTES</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __NDS32_CACHE_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/cache_info.h b/arch/nds32/include/asm/cache_info.h</span>
new file mode 100644
<span class="p_header">index 0000000..38ec458</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cache_info.h</span>
<span class="p_chunk">@@ -0,0 +1,13 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+struct cache_info {</span>
<span class="p_add">+	unsigned char ways;</span>
<span class="p_add">+	unsigned char line_size;</span>
<span class="p_add">+	unsigned short sets;</span>
<span class="p_add">+	unsigned short size;</span>
<span class="p_add">+#if defined(CONFIG_CPU_CACHE_ALIASING)</span>
<span class="p_add">+	unsigned short aliasing_num;</span>
<span class="p_add">+	unsigned int aliasing_mask;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+};</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/cacheflush.h b/arch/nds32/include/asm/cacheflush.h</span>
new file mode 100644
<span class="p_header">index 0000000..7b9b20a</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cacheflush.h</span>
<span class="p_chunk">@@ -0,0 +1,44 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_CACHEFLUSH_H__</span>
<span class="p_add">+#define __NDS32_CACHEFLUSH_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define PG_dcache_dirty PG_arch_1</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CPU_CACHE_ALIASING</span>
<span class="p_add">+void flush_cache_mm(struct mm_struct *mm);</span>
<span class="p_add">+void flush_cache_dup_mm(struct mm_struct *mm);</span>
<span class="p_add">+void flush_cache_range(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_cache_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, unsigned long pfn);</span>
<span class="p_add">+void flush_cache_kmaps(void);</span>
<span class="p_add">+void flush_cache_vmap(unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_cache_vunmap(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1</span>
<span class="p_add">+void flush_dcache_page(struct page *page);</span>
<span class="p_add">+void copy_to_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+		       unsigned long vaddr, void *dst, void *src, int len);</span>
<span class="p_add">+void copy_from_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+			 unsigned long vaddr, void *dst, void *src, int len);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_HAS_FLUSH_ANON_PAGE</span>
<span class="p_add">+void flush_anon_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		     struct page *page, unsigned long vaddr);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE</span>
<span class="p_add">+void flush_kernel_dcache_page(struct page *page);</span>
<span class="p_add">+void flush_icache_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_icache_page(struct vm_area_struct *vma, struct page *page);</span>
<span class="p_add">+#define flush_dcache_mmap_lock(mapping)   spin_lock_irq(&amp;(mapping)-&gt;tree_lock)</span>
<span class="p_add">+#define flush_dcache_mmap_unlock(mapping) spin_unlock_irq(&amp;(mapping)-&gt;tree_lock)</span>
<span class="p_add">+</span>
<span class="p_add">+#else</span>
<span class="p_add">+#include &lt;asm-generic/cacheflush.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __NDS32_CACHEFLUSH_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/mmu_context.h b/arch/nds32/include/asm/mmu_context.h</span>
new file mode 100644
<span class="p_header">index 0000000..fd7d13c</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -0,0 +1,68 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASM_NDS32_MMU_CONTEXT_H</span>
<span class="p_add">+#define __ASM_NDS32_MMU_CONTEXT_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm-generic/mm_hooks.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int</span>
<span class="p_add">+init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mm-&gt;context.id = 0;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define destroy_context(mm)	do { } while(0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define CID_BITS	9</span>
<span class="p_add">+extern spinlock_t cid_lock;</span>
<span class="p_add">+extern unsigned int cpu_last_cid;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __new_context(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cid;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	cid = cpu_last_cid;</span>
<span class="p_add">+	cpu_last_cid += 1 &lt;&lt; TLB_MISC_offCID;</span>
<span class="p_add">+	if (cpu_last_cid == 0)</span>
<span class="p_add">+		cpu_last_cid = 1 &lt;&lt; TLB_MISC_offCID &lt;&lt; CID_BITS;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((cid &amp; TLB_MISC_mskCID) == 0)</span>
<span class="p_add">+		flush_tlb_all();</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	mm-&gt;context.id = cid;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void check_context(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely</span>
<span class="p_add">+	    ((mm-&gt;context.id ^ cpu_last_cid) &gt;&gt; TLB_MISC_offCID &gt;&gt; CID_BITS))</span>
<span class="p_add">+		__new_context(mm);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
<span class="p_add">+			     struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cpu = smp_processor_id();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!cpumask_test_and_set_cpu(cpu, mm_cpumask(next)) || prev != next) {</span>
<span class="p_add">+		check_context(next);</span>
<span class="p_add">+		cpu_switch_mm(next);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define deactivate_mm(tsk,mm)	do { } while (0)</span>
<span class="p_add">+#define activate_mm(prev,next)	switch_mm(prev, next, NULL)</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/proc-fns.h b/arch/nds32/include/asm/proc-fns.h</span>
new file mode 100644
<span class="p_header">index 0000000..bedc4f5</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/proc-fns.h</span>
<span class="p_chunk">@@ -0,0 +1,44 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_PROCFNS_H__</span>
<span class="p_add">+#define __NDS32_PROCFNS_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef __KERNEL__</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct mm_struct;</span>
<span class="p_add">+struct vm_area_struct;</span>
<span class="p_add">+extern void cpu_proc_init(void);</span>
<span class="p_add">+extern void cpu_proc_fin(void);</span>
<span class="p_add">+extern void cpu_do_idle(void);</span>
<span class="p_add">+extern void cpu_reset(unsigned long reset);</span>
<span class="p_add">+extern void cpu_switch_mm(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_dcache_inval_all(void);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_all(void);</span>
<span class="p_add">+extern void cpu_dcache_inval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_wb_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dcache_wb_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_icache_inval_all(void);</span>
<span class="p_add">+extern void cpu_icache_inval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_icache_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_cache_wbinval_page(unsigned long page, int flushi);</span>
<span class="p_add">+extern void cpu_cache_wbinval_range(unsigned long start,</span>
<span class="p_add">+				    unsigned long end, int flushi);</span>
<span class="p_add">+extern void cpu_cache_wbinval_range_check(struct vm_area_struct *vma,</span>
<span class="p_add">+					  unsigned long start,</span>
<span class="p_add">+					  unsigned long end, bool flushi,</span>
<span class="p_add">+					  bool wbd);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_dma_wb_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dma_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dma_wbinval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __KERNEL__ */</span>
<span class="p_add">+#endif /* __NDS32_PROCFNS_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/tlb.h b/arch/nds32/include/asm/tlb.h</span>
new file mode 100644
<span class="p_header">index 0000000..b35ae5e</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/tlb.h</span>
<span class="p_chunk">@@ -0,0 +1,28 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASMNDS32_TLB_H</span>
<span class="p_add">+#define __ASMNDS32_TLB_H</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_start_vma(tlb,vma)						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (!tlb-&gt;fullmm)					\</span>
<span class="p_add">+			flush_cache_range(vma, vma-&gt;vm_start, vma-&gt;vm_end); \</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_end_vma(tlb,vma)				\</span>
<span class="p_add">+	do { 						\</span>
<span class="p_add">+		if(!tlb-&gt;fullmm)			\</span>
<span class="p_add">+			flush_tlb_range(vma, vma-&gt;vm_start, vma-&gt;vm_end); \</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define __tlb_remove_tlb_entry(tlb, pte, addr) do { } while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_flush(tlb)	flush_tlb_mm((tlb)-&gt;mm)</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm-generic/tlb.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define __pte_free_tlb(tlb, pte, addr)	pte_free((tlb)-&gt;mm, pte)</span>
<span class="p_add">+#define __pmd_free_tlb(tlb, pmd, addr)	pmd_free((tln)-&gt;mm, pmd)</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/tlbflush.h b/arch/nds32/include/asm/tlbflush.h</span>
new file mode 100644
<span class="p_header">index 0000000..9b411f4</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -0,0 +1,47 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef _ASMNDS32_TLBFLUSH_H</span>
<span class="p_add">+#define _ASMNDS32_TLBFLUSH_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_flua();</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_flua();</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_kernel_range(unsigned long start,</span>
<span class="p_add">+						unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		__nds32__tlbop_inv(start);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_range(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long start, unsigned long end);</span>
<span class="p_add">+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+#define flush_tlb_all		local_flush_tlb_all</span>
<span class="p_add">+#define flush_tlb_mm		local_flush_tlb_mm</span>
<span class="p_add">+#define flush_tlb_range		local_flush_tlb_range</span>
<span class="p_add">+#define flush_tlb_page		local_flush_tlb_page</span>
<span class="p_add">+#define flush_tlb_kernel_range	local_flush_tlb_kernel_range</span>
<span class="p_add">+</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long address, pte_t * pte);</span>
<span class="p_add">+void tlb_migrate_finish(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/uapi/asm/cachectl.h b/arch/nds32/include/uapi/asm/cachectl.h</span>
new file mode 100644
<span class="p_header">index 0000000..4cdca9b</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/uapi/asm/cachectl.h</span>
<span class="p_chunk">@@ -0,0 +1,14 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 1994, 1995, 1996 by Ralf Baechle</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+#ifndef	_ASM_CACHECTL</span>
<span class="p_add">+#define	_ASM_CACHECTL</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Options for cacheflush system call</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define	ICACHE	0		/* flush instruction cache        */</span>
<span class="p_add">+#define	DCACHE	1		/* writeback and flush data cache */</span>
<span class="p_add">+#define	BCACHE	2		/* flush instruction cache + writeback and flush data cache */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ASM_CACHECTL */</span>
<span class="p_header">diff --git a/arch/nds32/kernel/cacheinfo.c b/arch/nds32/kernel/cacheinfo.c</span>
new file mode 100644
<span class="p_header">index 0000000..0a7bc69</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/kernel/cacheinfo.c</span>
<span class="p_chunk">@@ -0,0 +1,49 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/bitops.h&gt;</span>
<span class="p_add">+#include &lt;linux/cacheinfo.h&gt;</span>
<span class="p_add">+#include &lt;linux/cpu.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static void ci_leaf_init(struct cacheinfo *this_leaf,</span>
<span class="p_add">+			 enum cache_type type, unsigned int level)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char cache_type = (type &amp; CACHE_TYPE_INST ? ICACHE : DCACHE);</span>
<span class="p_add">+</span>
<span class="p_add">+	this_leaf-&gt;level = level;</span>
<span class="p_add">+	this_leaf-&gt;type = type;</span>
<span class="p_add">+	this_leaf-&gt;coherency_line_size = CACHE_LINE_SIZE(cache_type);</span>
<span class="p_add">+	this_leaf-&gt;number_of_sets = CACHE_SET(cache_type);;</span>
<span class="p_add">+	this_leaf-&gt;ways_of_associativity = CACHE_WAY(cache_type);</span>
<span class="p_add">+	this_leaf-&gt;size = this_leaf-&gt;number_of_sets *</span>
<span class="p_add">+	    this_leaf-&gt;coherency_line_size * this_leaf-&gt;ways_of_associativity;</span>
<span class="p_add">+#if defined(CONFIG_CPU_DCACHE_WRITETHROUGH)</span>
<span class="p_add">+	this_leaf-&gt;attributes = CACHE_WRITE_THROUGH;</span>
<span class="p_add">+#else</span>
<span class="p_add">+	this_leaf-&gt;attributes = CACHE_WRITE_BACK;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int init_cache_level(unsigned int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Only 1 level and I/D cache seperate. */</span>
<span class="p_add">+	this_cpu_ci-&gt;num_levels = 1;</span>
<span class="p_add">+	this_cpu_ci-&gt;num_leaves = 2;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int populate_cache_leaves(unsigned int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int level, idx;</span>
<span class="p_add">+	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);</span>
<span class="p_add">+	struct cacheinfo *this_leaf = this_cpu_ci-&gt;info_list;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (idx = 0, level = 1; level &lt;= this_cpu_ci-&gt;num_levels &amp;&amp;</span>
<span class="p_add">+	     idx &lt; this_cpu_ci-&gt;num_leaves; idx++, level++) {</span>
<span class="p_add">+		ci_leaf_init(this_leaf++, CACHE_TYPE_DATA, level);</span>
<span class="p_add">+		ci_leaf_init(this_leaf++, CACHE_TYPE_INST, level);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/cacheflush.c b/arch/nds32/mm/cacheflush.c</span>
new file mode 100644
<span class="p_header">index 0000000..6eb786a</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/cacheflush.c</span>
<span class="p_chunk">@@ -0,0 +1,322 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/fs.h&gt;</span>
<span class="p_add">+#include &lt;linux/pagemap.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm/shmparam.h&gt;</span>
<span class="p_add">+#include &lt;asm/cache_info.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct cache_info L1_cache_info[2];</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef CONFIG_CPU_CACHE_ALIASING</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		      pte_t * pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long pfn = pte_pfn(*pte);</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pfn_valid(pfn))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm == current-&gt;active_mm) {</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		__nds32__mtsr_dsb(addr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+		__nds32__tlbop_rwr(*pte);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	page = pfn_to_page(pfn);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((test_and_clear_bit(PG_dcache_dirty, &amp;page-&gt;flags)) ||</span>
<span class="p_add">+	    (vma-&gt;vm_flags &amp; VM_EXEC)) {</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!PageHighMem(page)) {</span>
<span class="p_add">+			cpu_cache_wbinval_page((unsigned long)</span>
<span class="p_add">+					       page_address(page),</span>
<span class="p_add">+					       vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			unsigned long kaddr = (unsigned long)kmap_atomic(page);</span>
<span class="p_add">+			cpu_cache_wbinval_page(kaddr, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+			kunmap_atomic((void *)kaddr);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#else</span>
<span class="p_add">+extern pte_t va_present(struct mm_struct *mm, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long aliasing(unsigned long addr, unsigned long page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return ((addr &amp; PAGE_MASK) ^ page) &amp; (SHMLBA - 1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kremap0(unsigned long uaddr, unsigned long pa)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BASE_ADDR0 0xffffc000</span>
<span class="p_add">+	kaddr = BASE_ADDR0 | (uaddr &amp; L1_cache_info[DCACHE].aliasing_mask);</span>
<span class="p_add">+	pte = (pa | PAGE_KERNEL);</span>
<span class="p_add">+	__nds32__mtsr_dsb(kaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwlk(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return kaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kunmap01(unsigned long kaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_unlk(kaddr);</span>
<span class="p_add">+	__nds32__tlbop_inv(kaddr);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kremap1(unsigned long uaddr, unsigned long pa)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BASE_ADDR1 0xffff8000</span>
<span class="p_add">+	kaddr = BASE_ADDR1 | (uaddr &amp; L1_cache_info[DCACHE].aliasing_mask);</span>
<span class="p_add">+	pte = (pa | PAGE_KERNEL);</span>
<span class="p_add">+	__nds32__mtsr_dsb(kaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwlk(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return kaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_dup_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_range(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; 8 * PAGE_SIZE) {</span>
<span class="p_add">+		cpu_dcache_wbinval_all();</span>
<span class="p_add">+		if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+			cpu_icache_inval_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, start))</span>
<span class="p_add">+			cpu_cache_wbinval_page(start, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+	return;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(addr, pfn &lt;&lt; PAGE_SHIFT);</span>
<span class="p_add">+	cpu_cache_wbinval_page(vto, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_vmap(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_vunmap(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_user_highpage(struct page *to, struct page *from,</span>
<span class="p_add">+			unsigned long vaddr, struct vm_area_struct *vma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, vfrom, flags, kto, kfrom, pfrom, pto;</span>
<span class="p_add">+	kto = ((unsigned long)page_address(to) &amp; PAGE_MASK);</span>
<span class="p_add">+	kfrom = ((unsigned long)page_address(from) &amp; PAGE_MASK);</span>
<span class="p_add">+	pto = page_to_phys(to);</span>
<span class="p_add">+	pfrom = page_to_phys(from);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (aliasing(vaddr, (unsigned long)kfrom))</span>
<span class="p_add">+		cpu_dcache_wb_page((unsigned long)kfrom);</span>
<span class="p_add">+	if (aliasing(vaddr, (unsigned long)kto))</span>
<span class="p_add">+		cpu_dcache_inval_page((unsigned long)kto);</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, pto);</span>
<span class="p_add">+	vfrom = kremap1(vaddr, pfrom);</span>
<span class="p_add">+	copy_page((void *)vto, (void *)vfrom);</span>
<span class="p_add">+	kunmap01(vfrom);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(copy_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void clear_user_highpage(struct page *page, unsigned long vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags, kto;</span>
<span class="p_add">+</span>
<span class="p_add">+	kto = ((unsigned long)page_address(page) &amp; PAGE_MASK);</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (aliasing(kto, vaddr) &amp;&amp; kto != 0) {</span>
<span class="p_add">+		cpu_dcache_inval_page(kto);</span>
<span class="p_add">+		cpu_icache_inval_page(kto);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	clear_page((void *)vto);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(clear_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct address_space *mapping;</span>
<span class="p_add">+</span>
<span class="p_add">+	mapping = page_mapping(page);</span>
<span class="p_add">+	if (mapping &amp;&amp; !mapping_mapped(mapping))</span>
<span class="p_add">+		set_bit(PG_dcache_dirty, &amp;page-&gt;flags);</span>
<span class="p_add">+	else {</span>
<span class="p_add">+		int i, pc;</span>
<span class="p_add">+		unsigned long vto, kaddr, flags;</span>
<span class="p_add">+		kaddr = (unsigned long)page_address(page);</span>
<span class="p_add">+		cpu_dcache_wbinval_page(kaddr);</span>
<span class="p_add">+		pc = CACHE_SET(DCACHE) * CACHE_LINE_SIZE(DCACHE) / PAGE_SIZE;</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		for (i = 0; i &lt; pc; i++) {</span>
<span class="p_add">+			vto =</span>
<span class="p_add">+			    kremap0(kaddr + i * PAGE_SIZE, page_to_phys(page));</span>
<span class="p_add">+			cpu_dcache_wbinval_page(vto);</span>
<span class="p_add">+			kunmap01(vto);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_to_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+		       unsigned long vaddr, void *dst, void *src, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, start, end, vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	dst = (void *)(vto | (vaddr &amp; (PAGE_SIZE - 1)));</span>
<span class="p_add">+	memcpy(dst, src, len);</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_EXEC) {</span>
<span class="p_add">+		line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+		start = (unsigned long)dst &amp; ~(line_size - 1);</span>
<span class="p_add">+		end =</span>
<span class="p_add">+		    ((unsigned long)dst + len + line_size - 1) &amp; ~(line_size -</span>
<span class="p_add">+								   1);</span>
<span class="p_add">+		cpu_cache_wbinval_range(start, end, 1);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_from_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+			 unsigned long vaddr, void *dst, void *src, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	src = (void *)(vto | (vaddr &amp; (PAGE_SIZE - 1)));</span>
<span class="p_add">+	memcpy(dst, src, len);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_anon_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		     struct page *page, unsigned long vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	if (!PageAnon(page))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm != current-&gt;active_mm)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+		cpu_icache_inval_page(vaddr &amp; PAGE_MASK);</span>
<span class="p_add">+	cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_kernel_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_cache_wbinval_range(start, end, 1);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_page(struct vm_area_struct *vma, struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_cache_wbinval_page((unsigned long)page_address(page),</span>
<span class="p_add">+			       vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		      pte_t * pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	unsigned long pfn = pte_pfn(*pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pfn_valid(pfn))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm == current-&gt;active_mm) {</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		__nds32__mtsr_dsb(addr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+		__nds32__tlbop_rwr(*pte);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	page = pfn_to_page(pfn);</span>
<span class="p_add">+	if (test_and_clear_bit(PG_dcache_dirty, &amp;page-&gt;flags) ||</span>
<span class="p_add">+	    (vma-&gt;vm_flags &amp; VM_EXEC)) {</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/mm/proc.c b/arch/nds32/mm/proc.c</span>
new file mode 100644
<span class="p_header">index 0000000..5b05c11</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/proc.c</span>
<span class="p_chunk">@@ -0,0 +1,540 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;asm/nds32.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/l2_cache.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/cache_info.h&gt;</span>
<span class="p_add">+extern struct cache_info L1_cache_info[2];</span>
<span class="p_add">+</span>
<span class="p_add">+int va_kernel_present(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *ptep, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pmd_offset(pgd_offset_k(addr), addr);</span>
<span class="p_add">+	if (!pmd_none(*pmd)) {</span>
<span class="p_add">+		ptep = pte_offset_map(pmd, addr);</span>
<span class="p_add">+		pte = *ptep;</span>
<span class="p_add">+		if (pte_present(pte))</span>
<span class="p_add">+			return pte;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t va_present(struct mm_struct * mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *ptep, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	if (!pgd_none(*pgd)) {</span>
<span class="p_add">+		pud = pud_offset(pgd, addr);</span>
<span class="p_add">+		if (!pud_none(*pud)) {</span>
<span class="p_add">+			pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+			if (!pmd_none(*pmd)) {</span>
<span class="p_add">+				ptep = pte_offset_map(pmd, addr);</span>
<span class="p_add">+				pte = *ptep;</span>
<span class="p_add">+				if (pte_present(pte))</span>
<span class="p_add">+					return pte;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int va_readable(struct pt_regs *regs, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (user_mode(regs)) {</span>
<span class="p_add">+		/* user mode */</span>
<span class="p_add">+		pte = va_present(mm, addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_read(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* superuser mode is always readable, so we can only</span>
<span class="p_add">+		 * check it is present or not*/</span>
<span class="p_add">+		return (! !va_kernel_present(addr));</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int va_writable(struct pt_regs *regs, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (user_mode(regs)) {</span>
<span class="p_add">+		/* user mode */</span>
<span class="p_add">+		pte = va_present(mm, addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_write(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* superuser mode */</span>
<span class="p_add">+		pte = va_kernel_present(addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_kernel_write(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * All</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_icache_inval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long end, line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+	end =</span>
<span class="p_add">+	    line_size * L1_cache_info[ICACHE].ways * L1_cache_info[ICACHE].sets;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end &gt; 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+static inline dcache_wb_all_level(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, cmd;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+	/* Section 1: Ensure the section 2 &amp; 3 program code execution after */</span>
<span class="p_add">+	__nds32__cctlidx_read(NDS32_CCTL_L1D_IX_RWD,0);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Section 2: Confirm the writeback all level is done in CPU and L2C */</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+	cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+	L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Section 3: Writeback whole L2 cache */</span>
<span class="p_add">+	cmd = CCTL_ALL_CMD | CCTL_CMD_L2_IX_WB;</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+	L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_inval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__cctl_l1d_invalall();</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wb_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base)</span>
<span class="p_add">+		dcache_wb_all_level();</span>
<span class="p_add">+	else</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+#else</span>
<span class="p_add">+	__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wbinval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	cpu_dcache_wb_all();</span>
<span class="p_add">+	cpu_dcache_inval_all();</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Page</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_icache_inval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_inval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wb_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wbinval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_cache_wbinval_page(unsigned long page, int flushi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_page(page);</span>
<span class="p_add">+	if (flushi)</span>
<span class="p_add">+		cpu_icache_inval_page(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Range</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_icache_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wb_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_cache_wbinval_range(unsigned long start, unsigned long end, int flushi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, align_start, align_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	align_start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	align_end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+	cpu_dcache_wbinval_range(align_start, align_end);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (flushi) {</span>
<span class="p_add">+		line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+		align_start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+		align_end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+		cpu_icache_inval_range(align_start, align_end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_cache_wbinval_range_check(struct vm_area_struct *vma,</span>
<span class="p_add">+				   unsigned long start, unsigned long end,</span>
<span class="p_add">+				   bool flushi, bool wbd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, t_start, t_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!flushi &amp;&amp; !wbd)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; (8 * PAGE_SIZE)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			cpu_dcache_wbinval_all();</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			cpu_icache_inval_all();</span>
<span class="p_add">+		__nds32__msync_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	t_start = (start + PAGE_SIZE) &amp; PAGE_MASK;</span>
<span class="p_add">+	t_end = ((end - 1) &amp; PAGE_MASK);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((start &amp; PAGE_MASK) == t_end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, start)) {</span>
<span class="p_add">+			if (wbd)</span>
<span class="p_add">+				cpu_dcache_wbinval_range(start, end);</span>
<span class="p_add">+			if (flushi)</span>
<span class="p_add">+				cpu_icache_inval_range(start, end);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		__nds32__msync_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va_present(vma-&gt;vm_mm, start)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			cpu_dcache_wbinval_range(start, t_start);</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			cpu_icache_inval_range(start, t_start);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va_present(vma-&gt;vm_mm, end - 1)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			cpu_dcache_wbinval_range(t_end, end);</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			cpu_icache_inval_range(t_end, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	while (t_start &lt; t_end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, t_start)) {</span>
<span class="p_add">+			if (wbd)</span>
<span class="p_add">+				cpu_dcache_wbinval_page(t_start);</span>
<span class="p_add">+			if (flushi)</span>
<span class="p_add">+				cpu_icache_inval_page(t_start);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		t_start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+static inline void cpu_l2cache_op(unsigned long start, unsigned long end, unsigned long op)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base) {</span>
<span class="p_add">+		unsigned long p_start = __pa(start);</span>
<span class="p_add">+		unsigned long p_end = __pa(end);</span>
<span class="p_add">+		unsigned long cmd;</span>
<span class="p_add">+		unsigned long line_size;</span>
<span class="p_add">+		/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+		line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+		p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+		p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+		cmd =</span>
<span class="p_add">+		    (p_start &amp; ~(line_size - 1)) | op |</span>
<span class="p_add">+		    CCTL_SINGLE_CMD;</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			cmd += line_size;</span>
<span class="p_add">+			p_start += line_size;</span>
<span class="p_add">+		} while (p_end &gt; p_start);</span>
<span class="p_add">+		cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+		L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * DMA</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_dma_wb_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wb_range(start, end);</span>
<span class="p_add">+	cpu_l2cache_op(start, end, CCTL_CMD_L2_PA_WB);</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dma_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long old_start = start;</span>
<span class="p_add">+	unsigned long old_end = end;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (start != old_start) {</span>
<span class="p_add">+		cpu_dcache_wbinval_range(start, start + line_size);</span>
<span class="p_add">+		cpu_l2cache_op(start, start + line_size, CCTL_CMD_L2_PA_WBINVAL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (end != old_end) {</span>
<span class="p_add">+		cpu_dcache_wbinval_range(end - line_size, end);</span>
<span class="p_add">+		cpu_l2cache_op(end - line_size, end, CCTL_CMD_L2_PA_WBINVAL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	cpu_dcache_inval_range(start, end);</span>
<span class="p_add">+	cpu_l2cache_op(start, end, CCTL_CMD_L2_PA_INVAL);</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dma_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_range(start, end);</span>
<span class="p_add">+	cpu_l2cache_op(start, end, CCTL_CMD_L2_PA_WBINVAL);</span>
<span class="p_add">+	__nds32__msync_all();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_proc_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_proc_fin(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_do_idle(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__standby_no_wake_grant();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_reset(unsigned long reset)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 tmp;</span>
<span class="p_add">+	GIE_DISABLE();</span>
<span class="p_add">+	tmp = __nds32__mfsr(NDS32_SR_CACHE_CTL);</span>
<span class="p_add">+	tmp &amp;= ~(CACHE_CTL_mskIC_EN | CACHE_CTL_mskDC_EN);</span>
<span class="p_add">+	__nds32__mtsr_isb(tmp, NDS32_SR_CACHE_CTL);</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+</span>
<span class="p_add">+	__asm__ __volatile__(&quot;jr.toff %0\n\t&quot;::&quot;r&quot;(reset));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_switch_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long cid;</span>
<span class="p_add">+	cid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	cid = (cid &amp; ~TLB_MISC_mskCID) | mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(cid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	__nds32__mtsr_isb(__pa(mm-&gt;pgd), NDS32_SR_L1_PPTB);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/tlb.c b/arch/nds32/mm/tlb.c</span>
new file mode 100644
<span class="p_header">index 0000000..dd41f5e</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/tlb.c</span>
<span class="p_chunk">@@ -0,0 +1,50 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock_types.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;asm/nds32.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned int cpu_last_cid = { TLB_MISC_mskCID + (2 &lt;&lt; TLB_MISC_offCID) };</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_SPINLOCK(cid_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_range(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, ocid, ncid;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; 0x400000) {</span>
<span class="p_add">+		__nds32__tlbop_flua();</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	ocid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	ncid = (ocid &amp; ~TLB_MISC_mskCID) | vma-&gt;vm_mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(ncid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		__nds32__tlbop_inv(start);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__mtsr_dsb(ocid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, ocid, ncid;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	ocid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	ncid = (ocid &amp; ~TLB_MISC_mskCID) | vma-&gt;vm_mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(ncid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	__nds32__tlbop_inv(addr);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	__nds32__mtsr_dsb(ocid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



