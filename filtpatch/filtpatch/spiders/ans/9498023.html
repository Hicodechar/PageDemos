
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v3] sparc64: Add support for Application Data Integrity (ADI) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v3] sparc64: Add support for Application Data Integrity (ADI)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 4, 2017, 10:46 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1483569999-13543-1-git-send-email-khalid.aziz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9498023/mbox/"
   >mbox</a>
|
   <a href="/patch/9498023/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9498023/">/patch/9498023/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	D0F3D606A9 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  4 Jan 2017 22:51:06 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 986FD267EC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  4 Jan 2017 22:51:06 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 88887281D2; Wed,  4 Jan 2017 22:51:06 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	UNPARSEABLE_RELAY autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 846D4267EC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  4 Jan 2017 22:51:03 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S969163AbdADWu5 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 4 Jan 2017 17:50:57 -0500
Received: from userp1040.oracle.com ([156.151.31.81]:24911 &quot;EHLO
	userp1040.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S934035AbdADWus (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 4 Jan 2017 17:50:48 -0500
Received: from aserv0022.oracle.com (aserv0022.oracle.com [141.146.126.234])
	by userp1040.oracle.com (Sentrion-MTA-4.3.2/Sentrion-MTA-4.3.2)
	with ESMTP id v04MlgL7003265
	(version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Wed, 4 Jan 2017 22:47:43 GMT
Received: from userv0121.oracle.com (userv0121.oracle.com [156.151.31.72])
	by aserv0022.oracle.com (8.14.4/8.14.4) with ESMTP id v04MleVf012580
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Wed, 4 Jan 2017 22:47:40 GMT
Received: from abhmp0008.oracle.com (abhmp0008.oracle.com [141.146.116.14])
	by userv0121.oracle.com (8.14.4/8.13.8) with ESMTP id
	v04MlXAf028793; Wed, 4 Jan 2017 22:47:33 GMT
Received: from concerto.us.oracle.com (/10.159.111.188)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Wed, 04 Jan 2017 14:47:32 -0800
From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;
To: davem@davemloft.net, corbet@lwn.net, arnd@arndb.de,
	akpm@linux-foundation.org
Cc: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;, hpa@zytor.com,
	viro@zeniv.linux.org.uk, nitin.m.gupta@oracle.com,
	chris.hyser@oracle.com, tushar.n.dave@oracle.com,
	sowmini.varadhan@oracle.com, mike.kravetz@oracle.com,
	adam.buchbinder@gmail.com, minchan@kernel.org, hughd@google.com,
	kirill.shutemov@linux.intel.com, keescook@chromium.org,
	allen.pais@oracle.com, aryabinin@virtuozzo.com,
	atish.patra@oracle.com, joe@perches.com, pmladek@suse.com,
	jslaby@suse.cz, cmetcalf@mellanox.com,
	paul.gortmaker@windriver.com, mhocko@suse.com, jmarchan@redhat.com,
	dave.hansen@linux.intel.com, lstoakes@gmail.com,
	0x7f454c46@gmail.com, vbabka@suse.cz, tglx@linutronix.de,
	mingo@redhat.com, dan.j.williams@intel.com, iamjoonsoo.kim@lge.com,
	mgorman@techsingularity.net, vdavydov.dev@gmail.com,
	hannes@cmpxchg.org, namit@vmware.com, linux-doc@vger.kernel.org,
	linux-kernel@vger.kernel.org, sparclinux@vger.kernel.org,
	linux-arch@vger.kernel.org, x86@kernel.org, linux-mm@kvack.org,
	Khalid Aziz &lt;khalid@gonehiking.org&gt;
Subject: [RFC PATCH v3] sparc64: Add support for Application Data Integrity
	(ADI)
Date: Wed,  4 Jan 2017 15:46:39 -0700
Message-Id: &lt;1483569999-13543-1-git-send-email-khalid.aziz@oracle.com&gt;
X-Mailer: git-send-email 2.7.4
X-Source-IP: aserv0022.oracle.com [141.146.126.234]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 4, 2017, 10:46 p.m.</div>
<pre class="content">
ADI is a new feature supported on sparc M7 and newer processors to allow
hardware to catch rogue accesses to memory. ADI is supported for data
fetches only and not instruction fetches. An app can enable ADI on its
data pages, set version tags on them and use versioned addresses to
access the data pages. Upper bits of the address contain the version
tag. On M7 processors, upper four bits (bits 63-60) contain the version
tag. If a rogue app attempts to access ADI enabled data pages, its
access is blocked and processor generates an exception.

This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable
MCD (Memory Corruption Detection) on selected memory ranges, enable
TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI
version tags on page swap out/in.  It also adds handlers for all traps
related to MCD. ADI is not enabled by default for any task. A task must
explicitly enable ADI on a memory range and set version tag for ADI to
be effective for the task.
<span class="signed-off-by">
Signed-off-by: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Cc: Khalid Aziz &lt;khalid@gonehiking.org&gt;
---
v2:
	- Fixed a build error

v3:
	- Removed CONFIG_SPARC_ADI
	- Replaced prctl commands with mprotect
	- Added auxiliary vectors for ADI parameters
	- Enabled ADI for swappable pages

 Documentation/sparc/adi.txt             | 239 ++++++++++++++++++++++++++++++++
 arch/sparc/include/asm/adi.h            |   6 +
 arch/sparc/include/asm/adi_64.h         |  46 ++++++
 arch/sparc/include/asm/elf_64.h         |   8 ++
 arch/sparc/include/asm/hugetlb.h        |  13 ++
 arch/sparc/include/asm/hypervisor.h     |   2 +
 arch/sparc/include/asm/mman.h           |  40 +++++-
 arch/sparc/include/asm/mmu_64.h         |   2 +
 arch/sparc/include/asm/mmu_context_64.h |  32 +++++
 arch/sparc/include/asm/pgtable_64.h     |  97 ++++++++++++-
 arch/sparc/include/asm/ttable.h         |  10 ++
 arch/sparc/include/asm/uaccess_64.h     | 120 +++++++++++++++-
 arch/sparc/include/uapi/asm/asi.h       |   5 +
 arch/sparc/include/uapi/asm/auxvec.h    |   8 ++
 arch/sparc/include/uapi/asm/mman.h      |   2 +
 arch/sparc/include/uapi/asm/pstate.h    |  10 ++
 arch/sparc/kernel/Makefile              |   1 +
 arch/sparc/kernel/adi_64.c              |  93 +++++++++++++
 arch/sparc/kernel/entry.h               |   3 +
 arch/sparc/kernel/head_64.S             |   1 +
 arch/sparc/kernel/mdesc.c               |   4 +
 arch/sparc/kernel/process_64.c          |  21 +++
 arch/sparc/kernel/sun4v_mcd.S           |  16 +++
 arch/sparc/kernel/traps_64.c            | 142 ++++++++++++++++++-
 arch/sparc/kernel/ttable_64.S           |   6 +-
 arch/sparc/mm/gup.c                     |  37 +++++
 arch/sparc/mm/tlb.c                     |  28 ++++
 arch/x86/kernel/signal_compat.c         |   2 +-
 include/asm-generic/pgtable.h           |   5 +
 include/linux/mm.h                      |   2 +
 include/uapi/asm-generic/siginfo.h      |   5 +-
 mm/memory.c                             |   2 +-
 mm/rmap.c                               |   4 +-
 33 files changed, 993 insertions(+), 19 deletions(-)
 create mode 100644 Documentation/sparc/adi.txt
 create mode 100644 arch/sparc/include/asm/adi.h
 create mode 100644 arch/sparc/include/asm/adi_64.h
 create mode 100644 arch/sparc/kernel/adi_64.c
 create mode 100644 arch/sparc/kernel/sun4v_mcd.S
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 4, 2017, 11:27 p.m.</div>
<pre class="content">
On 01/04/2017 02:46 PM, Khalid Aziz wrote:
<span class="quote">&gt; This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable</span>
<span class="quote">&gt; MCD (Memory Corruption Detection) on selected memory ranges, enable</span>
<span class="quote">&gt; TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI</span>
<span class="quote">&gt; version tags on page swap out/in. </span>

I&#39;m a bit confused why we need all the mechanics with set_swp_pte_at().
For pkeys, for instance, all of the PTEs under a given VMA share a pkey.
 When swapping something in, we just get the pkey out of the VMA and
populate the PTE.

ADI doesn&#39;t seem to have a similar restriction.  The feature is turned
on or off at a VMA granularity, but we do not (or can enforce that all
pages under a given VMA must share a tag.

But this leads to an interesting question: is the tag associated with
the (populated?) pte, or the virtual address?  Can you have tags
associated with non-present addresses?  What&#39;s the mechanism that clears
the tags at munmap() or MADV_FREE time?

Is the tag storage a precious resource?  Can it be exhausted?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 4, 2017, 11:31 p.m.</div>
<pre class="content">
One other high-level comment:  It would be nice to see the
arch-independent and x86 portions broken out and explained in their own
right, even if they&#39;re small patches.  It&#39;s a bit cruel to make us
scroll through a thousand lines of sparc code to see the bits
interesting to us.

It would also be really nice to see a high-level breakdown explaining
what you had to modify, especially since this affects all of the system
calls that take a PROT_* argument.  The sample code is nice, but it&#39;s no
substitute for writing it down.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 4, 2017, 11:35 p.m.</div>
<pre class="content">
On 01/04/2017 03:27 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 02:46 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable</span>
<span class="quote">&gt;&gt; MCD (Memory Corruption Detection) on selected memory ranges, enable</span>
<span class="quote">&gt;&gt; TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI</span>
<span class="quote">&gt;&gt; version tags on page swap out/in.</span>
<span class="quote">&gt; I&#39;m a bit confused why we need all the mechanics with set_swp_pte_at().</span>
<span class="quote">&gt; For pkeys, for instance, all of the PTEs under a given VMA share a pkey.</span>
<span class="quote">&gt;   When swapping something in, we just get the pkey out of the VMA and</span>
<span class="quote">&gt; populate the PTE.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; ADI doesn&#39;t seem to have a similar restriction.  The feature is turned</span>
<span class="quote">&gt; on or off at a VMA granularity, but we do not (or can enforce that all</span>
<span class="quote">&gt; pages under a given VMA must share a tag.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; But this leads to an interesting question: is the tag associated with</span>
<span class="quote">&gt; the (populated?) pte, or the virtual address?  Can you have tags</span>
<span class="quote">&gt; associated with non-present addresses?  What&#39;s the mechanism that clears</span>
<span class="quote">&gt; the tags at munmap() or MADV_FREE time?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Is the tag storage a precious resource?  Can it be exhausted?</span>


Tags are stored in physical memory, so there is no &quot;tag storage&quot; that 
can be exhausted.

Tags are not cleared at all when memory is freed, but rather, lazily 
(and automatically) cleared when memory is allocated.


Rob
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 4, 2017, 11:40 p.m.</div>
<pre class="content">
On 01/04/2017 03:35 PM, Rob Gardner wrote:
<span class="quote">&gt; Tags are not cleared at all when memory is freed, but rather, lazily</span>
<span class="quote">&gt; (and automatically) cleared when memory is allocated.</span>

What does &quot;allocated&quot; mean in this context?  Physical or virtual? What
does this do, for instance?

	ptr = malloc(PAGE_SIZE);
	set_tag(ptr, 14);
	madvise(ptr, PAGE_SIZE, MADV_FREE);
	printf(&quot;tag: %d\n&quot;, get_tag(ptr));
	free(ptr);
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 4, 2017, 11:43 p.m.</div>
<pre class="content">
On 01/04/2017 04:27 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 02:46 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable</span>
<span class="quote">&gt;&gt; MCD (Memory Corruption Detection) on selected memory ranges, enable</span>
<span class="quote">&gt;&gt; TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI</span>
<span class="quote">&gt;&gt; version tags on page swap out/in.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I&#39;m a bit confused why we need all the mechanics with set_swp_pte_at().</span>
<span class="quote">&gt; For pkeys, for instance, all of the PTEs under a given VMA share a pkey.</span>
<span class="quote">&gt;  When swapping something in, we just get the pkey out of the VMA and</span>
<span class="quote">&gt; populate the PTE.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; ADI doesn&#39;t seem to have a similar restriction.  The feature is turned</span>
<span class="quote">&gt; on or off at a VMA granularity, but we do not (or can enforce that all</span>
<span class="quote">&gt; pages under a given VMA must share a tag.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; But this leads to an interesting question: is the tag associated with</span>
<span class="quote">&gt; the (populated?) pte, or the virtual address?  Can you have tags</span>
<span class="quote">&gt; associated with non-present addresses?  What&#39;s the mechanism that clears</span>
<span class="quote">&gt; the tags at munmap() or MADV_FREE time?</span>

Hi Dave,

Tag is associated with virtual address and all pages in a singular VMA 
do not share the same tag. When a page is swapped out, we need to save 
the tag that was set on it so we can restore it when we bring the page 
back in. When MMU translates a vitrtual address into physical address, 
it expects to see the same tag set on the physical page as is set in the 
VA before it will allow access. Tags are cleared on a page by 
NG4clear_page() and NG4clear_user_page() when a page is allocated to a task.
<span class="quote">
&gt;</span>
<span class="quote">&gt; Is the tag storage a precious resource?  Can it be exhausted?</span>

There is a metadata area in RAM that stores the tags and it has enough 
space to cover all the tags for the RAM size.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 4, 2017, 11:44 p.m.</div>
<pre class="content">
On 01/04/2017 03:40 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 03:35 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt; Tags are not cleared at all when memory is freed, but rather, lazily</span>
<span class="quote">&gt;&gt; (and automatically) cleared when memory is allocated.</span>
<span class="quote">&gt; What does &quot;allocated&quot; mean in this context?  Physical or virtual? What</span>
<span class="quote">&gt; does this do, for instance?</span>

The first time a virtual page is touched by a process after the malloc, 
the kernel does clear_user_page() or something similar, which zeroes the 
memory. At the same time, the memory tags are cleared.

Rob
<span class="quote">

&gt;</span>
<span class="quote">&gt; 	ptr = malloc(PAGE_SIZE);</span>
<span class="quote">&gt; 	set_tag(ptr, 14);</span>
<span class="quote">&gt; 	madvise(ptr, PAGE_SIZE, MADV_FREE);</span>
<span class="quote">&gt; 	printf(&quot;tag: %d\n&quot;, get_tag(ptr));</span>
<span class="quote">&gt; 	free(ptr);</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe from this list: send the line &quot;unsubscribe sparclinux&quot; in</span>
<span class="quote">&gt; the body of a message to majordomo@vger.kernel.org</span>
<span class="quote">&gt; More majordomo info at  http://vger.kernel.org/majordomo-info.html</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 4, 2017, 11:46 p.m.</div>
<pre class="content">
On 01/04/2017 04:31 PM, Dave Hansen wrote:
<span class="quote">&gt; One other high-level comment:  It would be nice to see the</span>
<span class="quote">&gt; arch-independent and x86 portions broken out and explained in their own</span>
<span class="quote">&gt; right, even if they&#39;re small patches.  It&#39;s a bit cruel to make us</span>
<span class="quote">&gt; scroll through a thousand lines of sparc code to see the bits</span>
<span class="quote">&gt; interesting to us.</span>

Sure, that is very reasonable. I will do that.
<span class="quote">
&gt;</span>
<span class="quote">&gt; It would also be really nice to see a high-level breakdown explaining</span>
<span class="quote">&gt; what you had to modify, especially since this affects all of the system</span>
<span class="quote">&gt; calls that take a PROT_* argument.  The sample code is nice, but it&#39;s no</span>
<span class="quote">&gt; substitute for writing it down.</span>

I will expand the explanation in Documentation/sparc/adi.txt.

Thanks!

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 4, 2017, 11:49 p.m.</div>
<pre class="content">
On 01/04/2017 03:44 PM, Rob Gardner wrote:
<span class="quote">&gt; On 01/04/2017 03:40 PM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt; On 01/04/2017 03:35 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt;&gt; Tags are not cleared at all when memory is freed, but rather, lazily</span>
<span class="quote">&gt;&gt;&gt; (and automatically) cleared when memory is allocated.</span>
<span class="quote">&gt;&gt; What does &quot;allocated&quot; mean in this context?  Physical or virtual? What</span>
<span class="quote">&gt;&gt; does this do, for instance?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The first time a virtual page is touched by a process after the malloc,</span>
<span class="quote">&gt; the kernel does clear_user_page() or something similar, which zeroes the</span>
<span class="quote">&gt; memory. At the same time, the memory tags are cleared.</span>

OK, so the tags can&#39;t survive a MADV_FREE.  That&#39;s definitely something
for apps to understand that use MADV_FREE as a substitute for memset().
It also means that tags can&#39;t be set for physically unallocated memory.

Neither of those are deal killers, but it would be nice to document it.

How does this all work with large pages?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 4, 2017, 11:50 p.m.</div>
<pre class="content">
On 01/04/2017 03:46 PM, Khalid Aziz wrote:
<span class="quote">&gt;&gt; It would also be really nice to see a high-level breakdown explaining</span>
<span class="quote">&gt;&gt; what you had to modify, especially since this affects all of the system</span>
<span class="quote">&gt;&gt; calls that take a PROT_* argument.  The sample code is nice, but it&#39;s no</span>
<span class="quote">&gt;&gt; substitute for writing it down.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I will expand the explanation in Documentation/sparc/adi.txt.</span>

I think (partially) duplicating that in a cover letter would also be
nice.  The documentation is a bit buried in the 1,000 lines of code.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 4, 2017, 11:56 p.m.</div>
<pre class="content">
On 01/04/2017 03:49 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 03:44 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt; On 01/04/2017 03:40 PM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt; On 01/04/2017 03:35 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; Tags are not cleared at all when memory is freed, but rather, lazily</span>
<span class="quote">&gt;&gt;&gt;&gt; (and automatically) cleared when memory is allocated.</span>
<span class="quote">&gt;&gt;&gt; What does &quot;allocated&quot; mean in this context?  Physical or virtual? What</span>
<span class="quote">&gt;&gt;&gt; does this do, for instance?</span>
<span class="quote">&gt;&gt; The first time a virtual page is touched by a process after the malloc,</span>
<span class="quote">&gt;&gt; the kernel does clear_user_page() or something similar, which zeroes the</span>
<span class="quote">&gt;&gt; memory. At the same time, the memory tags are cleared.</span>
<span class="quote">&gt; OK, so the tags can&#39;t survive a MADV_FREE.  That&#39;s definitely something</span>
<span class="quote">&gt; for apps to understand that use MADV_FREE as a substitute for memset().</span>
<span class="quote">&gt; It also means that tags can&#39;t be set for physically unallocated memory.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Neither of those are deal killers, but it would be nice to document it.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; How does this all work with large pages?</span>

It all works completely with large pages.

Rob
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 4, 2017, 11:58 p.m.</div>
<pre class="content">
On 01/04/2017 04:49 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 03:44 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt; On 01/04/2017 03:40 PM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt; On 01/04/2017 03:35 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; Tags are not cleared at all when memory is freed, but rather, lazily</span>
<span class="quote">&gt;&gt;&gt;&gt; (and automatically) cleared when memory is allocated.</span>
<span class="quote">&gt;&gt;&gt; What does &quot;allocated&quot; mean in this context?  Physical or virtual? What</span>
<span class="quote">&gt;&gt;&gt; does this do, for instance?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The first time a virtual page is touched by a process after the malloc,</span>
<span class="quote">&gt;&gt; the kernel does clear_user_page() or something similar, which zeroes the</span>
<span class="quote">&gt;&gt; memory. At the same time, the memory tags are cleared.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; OK, so the tags can&#39;t survive a MADV_FREE.  That&#39;s definitely something</span>
<span class="quote">&gt; for apps to understand that use MADV_FREE as a substitute for memset().</span>
<span class="quote">&gt; It also means that tags can&#39;t be set for physically unallocated memory.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Neither of those are deal killers, but it would be nice to document it.</span>

This can go into the adi.txt doc file.
<span class="quote">
&gt;</span>
<span class="quote">&gt; How does this all work with large pages?</span>

It works with large pages the same way as normal sized pages. The TTE 
for a large page also will have the mcd bit set in it and tags are set 
and referenced the same way.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 5, 2017, 12:01 a.m.</div>
<pre class="content">
On 01/04/2017 03:58 PM, Khalid Aziz wrote:
<span class="quote">&gt;&gt; How does this all work with large pages?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It works with large pages the same way as normal sized pages. The TTE</span>
<span class="quote">&gt; for a large page also will have the mcd bit set in it and tags are set</span>
<span class="quote">&gt; and referenced the same way.</span>

But does the user setting the tags need to know what the page size is?

What if two different small pages have different tags and khugepaged
comes along and tries to collapse them?  Will the page be split if a
user attempts to set two different tags inside two different small-page
portions of a single THP?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 5, 2017, 12:05 a.m.</div>
<pre class="content">
On 01/04/2017 04:01 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 03:58 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt; How does this all work with large pages?</span>
<span class="quote">&gt;&gt; It works with large pages the same way as normal sized pages. The TTE</span>
<span class="quote">&gt;&gt; for a large page also will have the mcd bit set in it and tags are set</span>
<span class="quote">&gt;&gt; and referenced the same way.</span>
<span class="quote">&gt; But does the user setting the tags need to know what the page size is?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What if two different small pages have different tags and khugepaged</span>
<span class="quote">&gt; comes along and tries to collapse them?  Will the page be split if a</span>
<span class="quote">&gt; user attempts to set two different tags inside two different small-page</span>
<span class="quote">&gt; portions of a single THP?</span>

The MCD tags operate at a resolution of cache lines (64 bytes). Page 
sizes don&#39;t matter except that each virtual page must have a bit set in 
its TTE to allow MCD to be enabled on the page. Any page can have many 
different tags, one for each cache line.

Rob
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 5, 2017, 12:14 a.m.</div>
<pre class="content">
On 01/04/2017 04:05 PM, Rob Gardner wrote:
<span class="quote">&gt;&gt; What if two different small pages have different tags and khugepaged</span>
<span class="quote">&gt;&gt; comes along and tries to collapse them?  Will the page be split if a</span>
<span class="quote">&gt;&gt; user attempts to set two different tags inside two different small-page</span>
<span class="quote">&gt;&gt; portions of a single THP?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The MCD tags operate at a resolution of cache lines (64 bytes). Page</span>
<span class="quote">&gt; sizes don&#39;t matter except that each virtual page must have a bit set in</span>
<span class="quote">&gt; its TTE to allow MCD to be enabled on the page. Any page can have many</span>
<span class="quote">&gt; different tags, one for each cache line.</span>

Is an &quot;MCD tag&quot; the same thing as a &quot;ADI version tag&quot;?

The thing that confused me here is that we&#39;re taking an entire page of
&quot;ADI version tags&quot; and stuffing them into a swap pte (in
set_swp_pte_at()).  Do we somehow have enough space in a swap pte on
sparc to fit PAGE_SIZE/64 &quot;ADI version tag&quot;s in there?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 5, 2017, 12:26 a.m.</div>
<pre class="content">
On 01/04/2017 05:14 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 04:05 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt;&gt; What if two different small pages have different tags and khugepaged</span>
<span class="quote">&gt;&gt;&gt; comes along and tries to collapse them?  Will the page be split if a</span>
<span class="quote">&gt;&gt;&gt; user attempts to set two different tags inside two different small-page</span>
<span class="quote">&gt;&gt;&gt; portions of a single THP?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The MCD tags operate at a resolution of cache lines (64 bytes). Page</span>
<span class="quote">&gt;&gt; sizes don&#39;t matter except that each virtual page must have a bit set in</span>
<span class="quote">&gt;&gt; its TTE to allow MCD to be enabled on the page. Any page can have many</span>
<span class="quote">&gt;&gt; different tags, one for each cache line.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Is an &quot;MCD tag&quot; the same thing as a &quot;ADI version tag&quot;?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The thing that confused me here is that we&#39;re taking an entire page of</span>
<span class="quote">&gt; &quot;ADI version tags&quot; and stuffing them into a swap pte (in</span>
<span class="quote">&gt; set_swp_pte_at()).  Do we somehow have enough space in a swap pte on</span>
<span class="quote">&gt; sparc to fit PAGE_SIZE/64 &quot;ADI version tag&quot;s in there?</span>

No, we do not have space to stuff PAGE_SIZE/64 version tags in swap pte. 
There is enough space for just one tag per page. DaveM had suggested 
doing this since the usual case is for a task to set one tag per page 
even though MMU does not require it. I have implemented this as first 
pass to start a discussion and get feedback on whether rest of the 
swapping implementation and other changes look right, hence the patch is 
&quot;RFC&quot;. If this all looks good, I can expand swapping support in a 
subsequent patch or iteration of this patch to allocate space in 
mm_context_t possibly to store per cacheline tags. I am open to any 
other ideas on storing this larger number of version tags.

Thanks,
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1608">Jerome Marchand</a> - Jan. 5, 2017, 9:37 a.m.</div>
<pre class="content">
On 01/04/2017 11:46 PM, Khalid Aziz wrote:
<span class="quote">&gt; ADI is a new feature supported on sparc M7 and newer processors to allow</span>
<span class="quote">&gt; hardware to catch rogue accesses to memory. ADI is supported for data</span>
<span class="quote">&gt; fetches only and not instruction fetches. An app can enable ADI on its</span>
<span class="quote">&gt; data pages, set version tags on them and use versioned addresses to</span>
<span class="quote">&gt; access the data pages. Upper bits of the address contain the version</span>
<span class="quote">&gt; tag. On M7 processors, upper four bits (bits 63-60) contain the version</span>
<span class="quote">&gt; tag. If a rogue app attempts to access ADI enabled data pages, its</span>
<span class="quote">&gt; access is blocked and processor generates an exception.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable</span>
<span class="quote">&gt; MCD (Memory Corruption Detection) on selected memory ranges, enable</span>
<span class="quote">&gt; TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI</span>
<span class="quote">&gt; version tags on page swap out/in.  It also adds handlers for all traps</span>
<span class="quote">&gt; related to MCD. ADI is not enabled by default for any task. A task must</span>
<span class="quote">&gt; explicitly enable ADI on a memory range and set version tag for ADI to</span>
<span class="quote">&gt; be effective for the task.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
<span class="quote">&gt; Cc: Khalid Aziz &lt;khalid@gonehiking.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; v2:</span>
<span class="quote">&gt; 	- Fixed a build error</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; v3:</span>
<span class="quote">&gt; 	- Removed CONFIG_SPARC_ADI</span>
<span class="quote">&gt; 	- Replaced prctl commands with mprotect</span>
<span class="quote">&gt; 	- Added auxiliary vectors for ADI parameters</span>
<span class="quote">&gt; 	- Enabled ADI for swappable pages</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  Documentation/sparc/adi.txt             | 239 ++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/sparc/include/asm/adi.h            |   6 +</span>
<span class="quote">&gt;  arch/sparc/include/asm/adi_64.h         |  46 ++++++</span>
<span class="quote">&gt;  arch/sparc/include/asm/elf_64.h         |   8 ++</span>
<span class="quote">&gt;  arch/sparc/include/asm/hugetlb.h        |  13 ++</span>
<span class="quote">&gt;  arch/sparc/include/asm/hypervisor.h     |   2 +</span>
<span class="quote">&gt;  arch/sparc/include/asm/mman.h           |  40 +++++-</span>
<span class="quote">&gt;  arch/sparc/include/asm/mmu_64.h         |   2 +</span>
<span class="quote">&gt;  arch/sparc/include/asm/mmu_context_64.h |  32 +++++</span>
<span class="quote">&gt;  arch/sparc/include/asm/pgtable_64.h     |  97 ++++++++++++-</span>
<span class="quote">&gt;  arch/sparc/include/asm/ttable.h         |  10 ++</span>
<span class="quote">&gt;  arch/sparc/include/asm/uaccess_64.h     | 120 +++++++++++++++-</span>
<span class="quote">&gt;  arch/sparc/include/uapi/asm/asi.h       |   5 +</span>
<span class="quote">&gt;  arch/sparc/include/uapi/asm/auxvec.h    |   8 ++</span>
<span class="quote">&gt;  arch/sparc/include/uapi/asm/mman.h      |   2 +</span>
<span class="quote">&gt;  arch/sparc/include/uapi/asm/pstate.h    |  10 ++</span>
<span class="quote">&gt;  arch/sparc/kernel/Makefile              |   1 +</span>
<span class="quote">&gt;  arch/sparc/kernel/adi_64.c              |  93 +++++++++++++</span>
<span class="quote">&gt;  arch/sparc/kernel/entry.h               |   3 +</span>
<span class="quote">&gt;  arch/sparc/kernel/head_64.S             |   1 +</span>
<span class="quote">&gt;  arch/sparc/kernel/mdesc.c               |   4 +</span>
<span class="quote">&gt;  arch/sparc/kernel/process_64.c          |  21 +++</span>
<span class="quote">&gt;  arch/sparc/kernel/sun4v_mcd.S           |  16 +++</span>
<span class="quote">&gt;  arch/sparc/kernel/traps_64.c            | 142 ++++++++++++++++++-</span>
<span class="quote">&gt;  arch/sparc/kernel/ttable_64.S           |   6 +-</span>
<span class="quote">&gt;  arch/sparc/mm/gup.c                     |  37 +++++</span>
<span class="quote">&gt;  arch/sparc/mm/tlb.c                     |  28 ++++</span>
<span class="quote">&gt;  arch/x86/kernel/signal_compat.c         |   2 +-</span>
<span class="quote">&gt;  include/asm-generic/pgtable.h           |   5 +</span>
<span class="quote">&gt;  include/linux/mm.h                      |   2 +</span>
<span class="quote">&gt;  include/uapi/asm-generic/siginfo.h      |   5 +-</span>
<span class="quote">&gt;  mm/memory.c                             |   2 +-</span>
<span class="quote">&gt;  mm/rmap.c                               |   4 +-</span>

I haven&#39;t actually reviewed the code and looked at why you need
set_swp_pte_at() function, but the code that add the generic version of
this function need to be separated from the rest of the patch. Also,
given the size of this patch, I suspect the rest also need to be broken
into more patches.

Jerome
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 5, 2017, 3:13 p.m.</div>
<pre class="content">
On 01/05/2017 02:37 AM, Jerome Marchand wrote:
<span class="quote">&gt; On 01/04/2017 11:46 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; ADI is a new feature supported on sparc M7 and newer processors to allow</span>
<span class="quote">&gt;&gt; hardware to catch rogue accesses to memory. ADI is supported for data</span>
<span class="quote">&gt;&gt; fetches only and not instruction fetches. An app can enable ADI on its</span>
<span class="quote">&gt;&gt; data pages, set version tags on them and use versioned addresses to</span>
<span class="quote">&gt;&gt; access the data pages. Upper bits of the address contain the version</span>
<span class="quote">&gt;&gt; tag. On M7 processors, upper four bits (bits 63-60) contain the version</span>
<span class="quote">&gt;&gt; tag. If a rogue app attempts to access ADI enabled data pages, its</span>
<span class="quote">&gt;&gt; access is blocked and processor generates an exception.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable</span>
<span class="quote">&gt;&gt; MCD (Memory Corruption Detection) on selected memory ranges, enable</span>
<span class="quote">&gt;&gt; TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI</span>
<span class="quote">&gt;&gt; version tags on page swap out/in.  It also adds handlers for all traps</span>
<span class="quote">&gt;&gt; related to MCD. ADI is not enabled by default for any task. A task must</span>
<span class="quote">&gt;&gt; explicitly enable ADI on a memory range and set version tag for ADI to</span>
<span class="quote">&gt;&gt; be effective for the task.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Khalid Aziz &lt;khalid@gonehiking.org&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt; v2:</span>
<span class="quote">&gt;&gt; 	- Fixed a build error</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; v3:</span>
<span class="quote">&gt;&gt; 	- Removed CONFIG_SPARC_ADI</span>
<span class="quote">&gt;&gt; 	- Replaced prctl commands with mprotect</span>
<span class="quote">&gt;&gt; 	- Added auxiliary vectors for ADI parameters</span>
<span class="quote">&gt;&gt; 	- Enabled ADI for swappable pages</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  Documentation/sparc/adi.txt             | 239 ++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/adi.h            |   6 +</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/adi_64.h         |  46 ++++++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/elf_64.h         |   8 ++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/hugetlb.h        |  13 ++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/hypervisor.h     |   2 +</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/mman.h           |  40 +++++-</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/mmu_64.h         |   2 +</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/mmu_context_64.h |  32 +++++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/pgtable_64.h     |  97 ++++++++++++-</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/ttable.h         |  10 ++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/asm/uaccess_64.h     | 120 +++++++++++++++-</span>
<span class="quote">&gt;&gt;  arch/sparc/include/uapi/asm/asi.h       |   5 +</span>
<span class="quote">&gt;&gt;  arch/sparc/include/uapi/asm/auxvec.h    |   8 ++</span>
<span class="quote">&gt;&gt;  arch/sparc/include/uapi/asm/mman.h      |   2 +</span>
<span class="quote">&gt;&gt;  arch/sparc/include/uapi/asm/pstate.h    |  10 ++</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/Makefile              |   1 +</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/adi_64.c              |  93 +++++++++++++</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/entry.h               |   3 +</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/head_64.S             |   1 +</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/mdesc.c               |   4 +</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/process_64.c          |  21 +++</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/sun4v_mcd.S           |  16 +++</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/traps_64.c            | 142 ++++++++++++++++++-</span>
<span class="quote">&gt;&gt;  arch/sparc/kernel/ttable_64.S           |   6 +-</span>
<span class="quote">&gt;&gt;  arch/sparc/mm/gup.c                     |  37 +++++</span>
<span class="quote">&gt;&gt;  arch/sparc/mm/tlb.c                     |  28 ++++</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/signal_compat.c         |   2 +-</span>
<span class="quote">&gt;&gt;  include/asm-generic/pgtable.h           |   5 +</span>
<span class="quote">&gt;&gt;  include/linux/mm.h                      |   2 +</span>
<span class="quote">&gt;&gt;  include/uapi/asm-generic/siginfo.h      |   5 +-</span>
<span class="quote">&gt;&gt;  mm/memory.c                             |   2 +-</span>
<span class="quote">&gt;&gt;  mm/rmap.c                               |   4 +-</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I haven&#39;t actually reviewed the code and looked at why you need</span>
<span class="quote">&gt; set_swp_pte_at() function, but the code that add the generic version of</span>
<span class="quote">&gt; this function need to be separated from the rest of the patch. Also,</span>
<span class="quote">&gt; given the size of this patch, I suspect the rest also need to be broken</span>
<span class="quote">&gt; into more patches.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Jerome</span>
<span class="quote">&gt;</span>

Sure, I can do that. Code to add new signal codes can be one patch, 
generic changes to swap infrastructure can be another and I can look for 
logical breaks for the rest of the sparc specific code.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 5, 2017, 7:22 p.m.</div>
<pre class="content">
On 01/04/2017 04:26 PM, Khalid Aziz wrote:
...
<span class="quote">&gt; No, we do not have space to stuff PAGE_SIZE/64 version tags in swap pte.</span>
<span class="quote">&gt; There is enough space for just one tag per page. DaveM had suggested</span>
<span class="quote">&gt; doing this since the usual case is for a task to set one tag per page</span>
<span class="quote">&gt; even though MMU does not require it. I have implemented this as first</span>
<span class="quote">&gt; pass to start a discussion and get feedback on whether rest of the</span>
<span class="quote">&gt; swapping implementation and other changes look right, hence the patch is</span>
<span class="quote">&gt; &quot;RFC&quot;. If this all looks good, I can expand swapping support in a</span>
<span class="quote">&gt; subsequent patch or iteration of this patch to allocate space in</span>
<span class="quote">&gt; mm_context_t possibly to store per cacheline tags. I am open to any</span>
<span class="quote">&gt; other ideas on storing this larger number of version tags.</span>

FWIW, This is the kind of thing that would be really useful to point out
to reviewers instead of requiring them to ferret it out of the code.  It
has huge implications for how applications use this feature.

As for where to store the tags...  It&#39;s potentially a *lot* of data, so
I think it&#39;ll be a pain any way you do it.

If you, instead, can live with doing things on a PAGE_SIZE granularity
like pkeys does, you could just store it in the VMA and have the kernel
tag the data at the same time it zeroes the pages.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 5, 2017, 8:30 p.m.</div>
<pre class="content">
On 01/05/2017 12:22 PM, Dave Hansen wrote:
<span class="quote">&gt; On 01/04/2017 04:26 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt;&gt; No, we do not have space to stuff PAGE_SIZE/64 version tags in swap pte.</span>
<span class="quote">&gt;&gt; There is enough space for just one tag per page. DaveM had suggested</span>
<span class="quote">&gt;&gt; doing this since the usual case is for a task to set one tag per page</span>
<span class="quote">&gt;&gt; even though MMU does not require it. I have implemented this as first</span>
<span class="quote">&gt;&gt; pass to start a discussion and get feedback on whether rest of the</span>
<span class="quote">&gt;&gt; swapping implementation and other changes look right, hence the patch is</span>
<span class="quote">&gt;&gt; &quot;RFC&quot;. If this all looks good, I can expand swapping support in a</span>
<span class="quote">&gt;&gt; subsequent patch or iteration of this patch to allocate space in</span>
<span class="quote">&gt;&gt; mm_context_t possibly to store per cacheline tags. I am open to any</span>
<span class="quote">&gt;&gt; other ideas on storing this larger number of version tags.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; FWIW, This is the kind of thing that would be really useful to point out</span>
<span class="quote">&gt; to reviewers instead of requiring them to ferret it out of the code.  It</span>
<span class="quote">&gt; has huge implications for how applications use this feature.</span>

Hi Dave,

Thanks for taking the time to review this. I appreciate your patience. I 
will add more details.
<span class="quote">
&gt;</span>
<span class="quote">&gt; As for where to store the tags...  It&#39;s potentially a *lot* of data, so</span>
<span class="quote">&gt; I think it&#39;ll be a pain any way you do it.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If you, instead, can live with doing things on a PAGE_SIZE granularity</span>
<span class="quote">&gt; like pkeys does, you could just store it in the VMA and have the kernel</span>
<span class="quote">&gt; tag the data at the same time it zeroes the pages.</span>

It is very tempting to restrict tags to PAGE_SIZE granularity since it 
makes code noticeably simpler and that is indeed going to be the 
majority of cases. Sooner or later somebody would want to use multiple 
tags per page though. There can be 128 4-bit tags per 8K page which 
requires 64 bytes of tag storage for each page. This can add up. What I 
am considering doing is store the tag in swp pte if I find only one tag 
on the page. A VMA can cover multiple pages and we have unused bits in 
swp pte. It makes more sense to store the tags in swp pte. If I find 
more than one tag on the page, I can allocate memory, attach it to a 
data structure in mm_context_t and store the tags there. I will need to 
use an rb tree or some other way to keep the data sorted to make it 
quick to retrieve the tags for one of the millions of pages a task might 
have. As I said, it gets complex trying to store tags per cacheline as 
opposed to per page :)

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Jan. 6, 2017, 9:19 a.m.</div>
<pre class="content">
On Thu 05-01-17 13:30:10, Khalid Aziz wrote:
[...]
<span class="quote">&gt; It is very tempting to restrict tags to PAGE_SIZE granularity since it makes</span>
<span class="quote">&gt; code noticeably simpler and that is indeed going to be the majority of</span>
<span class="quote">&gt; cases. Sooner or later somebody would want to use multiple tags per page</span>
<span class="quote">&gt; though.</span>

I didn&#39;t get to read the patch throughly yet but I am really confused by
this statement. The api is mprotect based which makes it ineherently
PAGE_SIZE granular. How do you want to achieve cache line granularity
with this API?

And I would really vote for simplicity first... Subpage granularity
sounds way too tricky...
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 6, 2017, 3:32 p.m.</div>
<pre class="content">
On 01/06/2017 02:19 AM, Michal Hocko wrote:
<span class="quote">&gt; On Thu 05-01-17 13:30:10, Khalid Aziz wrote:</span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;&gt; It is very tempting to restrict tags to PAGE_SIZE granularity since it makes</span>
<span class="quote">&gt;&gt; code noticeably simpler and that is indeed going to be the majority of</span>
<span class="quote">&gt;&gt; cases. Sooner or later somebody would want to use multiple tags per page</span>
<span class="quote">&gt;&gt; though.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I didn&#39;t get to read the patch throughly yet but I am really confused by</span>
<span class="quote">&gt; this statement. The api is mprotect based which makes it ineherently</span>
<span class="quote">&gt; PAGE_SIZE granular. How do you want to achieve cache line granularity</span>
<span class="quote">&gt; with this API?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; And I would really vote for simplicity first... Subpage granularity</span>
<span class="quote">&gt; sounds way too tricky...</span>
<span class="quote">&gt;</span>

Hi Michal,

ADI can be enabled for subsets of a task&#39;s address space. It takes three 
steps to enable ADI completely:

1. Enable the task to use ADI by setting PSTATE.mcde bit. This is the 
master switch for ADI. mprotect() does this in my patch. Granularity for 
this operation is entire address space for the task.

2. Set TTE.mcd bit for each page translation for the pages one wants ADI 
enabled on. mprotect() does this as well in my patch. Granularity for 
this operation is per page.

3. Set version tag for the addresses task wants to enable ADI on using 
&quot;stxa&quot; instruction. This is done entirely in userspace with no 
assistance or intervention needed from the kernel. Granularity for this 
operation is cache line size which is 64 bytes on Sparc M7.

I agree with you on simplicity first. Subpage granularity is complex, 
but the architecture allows for subpage granularity. Maybe the right 
approach is to support this at page granularity first for swappable 
pages and then expand to subpage granularity in a subsequent patch? 
Pages locked in memory can already use subpage granularity with my patch.

Thanks,
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 6, 2017, 3:36 p.m.</div>
<pre class="content">
On 01/06/2017 07:32 AM, Khalid Aziz wrote:
<span class="quote">&gt; I agree with you on simplicity first. Subpage granularity is complex,</span>
<span class="quote">&gt; but the architecture allows for subpage granularity. Maybe the right</span>
<span class="quote">&gt; approach is to support this at page granularity first for swappable</span>
<span class="quote">&gt; pages and then expand to subpage granularity in a subsequent patch?</span>
<span class="quote">&gt; Pages locked in memory can already use subpage granularity with my patch.</span>

What do you mean by &quot;locked in memory&quot;?  mlock()&#39;d memory can still be
migrated around and still requires &quot;swap&quot; ptes, for instance.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 6, 2017, 4:22 p.m.</div>
<pre class="content">
On 01/06/2017 08:36 AM, Dave Hansen wrote:
<span class="quote">&gt; On 01/06/2017 07:32 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; I agree with you on simplicity first. Subpage granularity is complex,</span>
<span class="quote">&gt;&gt; but the architecture allows for subpage granularity. Maybe the right</span>
<span class="quote">&gt;&gt; approach is to support this at page granularity first for swappable</span>
<span class="quote">&gt;&gt; pages and then expand to subpage granularity in a subsequent patch?</span>
<span class="quote">&gt;&gt; Pages locked in memory can already use subpage granularity with my patch.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What do you mean by &quot;locked in memory&quot;?  mlock()&#39;d memory can still be</span>
<span class="quote">&gt; migrated around and still requires &quot;swap&quot; ptes, for instance.</span>

You are right. Page migration can invalidate subpage granularity even 
for locked pages. Is it possible to use cpusets to keep a task and its 
memory locked on a single node? Just wondering if there are limited 
cases where subpage granularity could work without supporting subpage 
granularity for tags in swap. It still sounds like the right thing to do 
is to get a reliable implementation in place with page size granularity 
and then add the complexity of subpage granularity.

Thanks,
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=61891">David Miller</a> - Jan. 6, 2017, 4:25 p.m.</div>
<pre class="content">
<span class="from">From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Date: Fri, 6 Jan 2017 09:22:13 -0700
<span class="quote">
&gt; On 01/06/2017 08:36 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt; On 01/06/2017 07:32 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt; I agree with you on simplicity first. Subpage granularity is complex,</span>
<span class="quote">&gt;&gt;&gt; but the architecture allows for subpage granularity. Maybe the right</span>
<span class="quote">&gt;&gt;&gt; approach is to support this at page granularity first for swappable</span>
<span class="quote">&gt;&gt;&gt; pages and then expand to subpage granularity in a subsequent patch?</span>
<span class="quote">&gt;&gt;&gt; Pages locked in memory can already use subpage granularity with my</span>
<span class="quote">&gt;&gt;&gt; patch.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; What do you mean by &quot;locked in memory&quot;?  mlock()&#39;d memory can still be</span>
<span class="quote">&gt;&gt; migrated around and still requires &quot;swap&quot; ptes, for instance.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You are right. Page migration can invalidate subpage granularity even</span>
<span class="quote">&gt; for locked pages. Is it possible to use cpusets to keep a task and its</span>
<span class="quote">&gt; memory locked on a single node? Just wondering if there are limited</span>
<span class="quote">&gt; cases where subpage granularity could work without supporting subpage</span>
<span class="quote">&gt; granularity for tags in swap. It still sounds like the right thing to</span>
<span class="quote">&gt; do is to get a reliable implementation in place with page size</span>
<span class="quote">&gt; granularity and then add the complexity of subpage granularity.</span>

It sounds to me, in all of this, that if the kernel manages the
movement of the pages, it thus must handle making sure the tags move
around with that page as well.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Jan. 6, 2017, 4:55 p.m.</div>
<pre class="content">
On 01/06/2017 08:22 AM, Khalid Aziz wrote:
<span class="quote">&gt; On 01/06/2017 08:36 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt; On 01/06/2017 07:32 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt; I agree with you on simplicity first. Subpage granularity is complex,</span>
<span class="quote">&gt;&gt;&gt; but the architecture allows for subpage granularity. Maybe the right</span>
<span class="quote">&gt;&gt;&gt; approach is to support this at page granularity first for swappable</span>
<span class="quote">&gt;&gt;&gt; pages and then expand to subpage granularity in a subsequent patch?</span>
<span class="quote">&gt;&gt;&gt; Pages locked in memory can already use subpage granularity with my</span>
<span class="quote">&gt;&gt;&gt; patch.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; What do you mean by &quot;locked in memory&quot;?  mlock()&#39;d memory can still be</span>
<span class="quote">&gt;&gt; migrated around and still requires &quot;swap&quot; ptes, for instance.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You are right. Page migration can invalidate subpage granularity even</span>
<span class="quote">&gt; for locked pages. Is it possible to use cpusets to keep a task and its</span>
<span class="quote">&gt; memory locked on a single node?</span>

It&#39;s going to be hard to impossible to guarantee.  mlock() doesn&#39;t
guarantee that things won&#39;t change physical addresses.  You&#39;d have to
change that guarantee or chase all the things in the kernel that might
change physical addresses (compaction, ksm, etc...).

Actually, that reminds me...  How does your code interface with ksm?  Or
is there no interaction needed since you&#39;re always working on virtual
addresses?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=129">David Miller</a> - Jan. 6, 2017, 5:02 p.m.</div>
<pre class="content">
<span class="from">From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
Date: Fri, 6 Jan 2017 08:55:03 -0800
<span class="quote">
&gt; Actually, that reminds me...  How does your code interface with ksm?  Or</span>
<span class="quote">&gt; is there no interaction needed since you&#39;re always working on virtual</span>
<span class="quote">&gt; addresses?</span>

This reminds me, I consider this feature potentially extremely useful for
kernel debugging.  So I would like to make sure we don&#39;t implement anything
in a way which would preclude that in the long term.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 6, 2017, 5:08 p.m.</div>
<pre class="content">
On 01/06/2017 09:55 AM, Dave Hansen wrote:
<span class="quote">&gt; On 01/06/2017 08:22 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; On 01/06/2017 08:36 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt; On 01/06/2017 07:32 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; I agree with you on simplicity first. Subpage granularity is complex,</span>
<span class="quote">&gt;&gt;&gt;&gt; but the architecture allows for subpage granularity. Maybe the right</span>
<span class="quote">&gt;&gt;&gt;&gt; approach is to support this at page granularity first for swappable</span>
<span class="quote">&gt;&gt;&gt;&gt; pages and then expand to subpage granularity in a subsequent patch?</span>
<span class="quote">&gt;&gt;&gt;&gt; Pages locked in memory can already use subpage granularity with my</span>
<span class="quote">&gt;&gt;&gt;&gt; patch.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; What do you mean by &quot;locked in memory&quot;?  mlock()&#39;d memory can still be</span>
<span class="quote">&gt;&gt;&gt; migrated around and still requires &quot;swap&quot; ptes, for instance.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; You are right. Page migration can invalidate subpage granularity even</span>
<span class="quote">&gt;&gt; for locked pages. Is it possible to use cpusets to keep a task and its</span>
<span class="quote">&gt;&gt; memory locked on a single node?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It&#39;s going to be hard to impossible to guarantee.  mlock() doesn&#39;t</span>
<span class="quote">&gt; guarantee that things won&#39;t change physical addresses.  You&#39;d have to</span>
<span class="quote">&gt; change that guarantee or chase all the things in the kernel that might</span>
<span class="quote">&gt; change physical addresses (compaction, ksm, etc...).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Actually, that reminds me...  How does your code interface with ksm?  Or</span>
<span class="quote">&gt; is there no interaction needed since you&#39;re always working on virtual</span>
<span class="quote">&gt; addresses?</span>
<span class="quote">&gt;</span>

Yes, version tags are interpreted at virtual address level.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 6, 2017, 5:10 p.m.</div>
<pre class="content">
On 01/06/2017 10:02 AM, David Miller wrote:
<span class="quote">&gt; From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt; Date: Fri, 6 Jan 2017 08:55:03 -0800</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; Actually, that reminds me...  How does your code interface with ksm?  Or</span>
<span class="quote">&gt;&gt; is there no interaction needed since you&#39;re always working on virtual</span>
<span class="quote">&gt;&gt; addresses?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This reminds me, I consider this feature potentially extremely useful for</span>
<span class="quote">&gt; kernel debugging.  So I would like to make sure we don&#39;t implement anything</span>
<span class="quote">&gt; in a way which would preclude that in the long term.</span>

I agree and please do point out if I have made any implementation 
decisions that could preclude that.

Thanks,
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 6, 2017, 5:54 p.m.</div>
<pre class="content">
On 01/06/2017 09:10 AM, Khalid Aziz wrote:
<span class="quote">&gt; On 01/06/2017 10:02 AM, David Miller wrote:</span>
<span class="quote">&gt;&gt; From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt;&gt; Date: Fri, 6 Jan 2017 08:55:03 -0800</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Actually, that reminds me...  How does your code interface with </span>
<span class="quote">&gt;&gt;&gt; ksm?  Or</span>
<span class="quote">&gt;&gt;&gt; is there no interaction needed since you&#39;re always working on virtual</span>
<span class="quote">&gt;&gt;&gt; addresses?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This reminds me, I consider this feature potentially extremely useful </span>
<span class="quote">&gt;&gt; for</span>
<span class="quote">&gt;&gt; kernel debugging.  So I would like to make sure we don&#39;t implement </span>
<span class="quote">&gt;&gt; anything</span>
<span class="quote">&gt;&gt; in a way which would preclude that in the long term.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I agree and please do point out if I have made any implementation </span>
<span class="quote">&gt; decisions that could preclude that.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Thanks,</span>
<span class="quote">&gt; Khalid</span>


Khalid, I have already pointed out an implementation decision that 
interferes with the potential for kernel debugging with ADI: lazy 
clearing of version tags.

Details: when memory is &quot;freed&quot; the version tags are left alone, as it 
is an expensive operation to go through the memory and clear the tag for 
each cache line. So this is done lazily whenever memory is &quot;allocated&quot;. 
More specifically, the first time a user process touches freshly 
allocated memory, a fault occurs and the kernel then clears the page. In 
the NG4 and M7 variants of clear_user_page, the block init store ASI is 
used to optimize, and it has the side effect of clearing the ADI tag for 
the cache line. BUT only if pstate.mcde is clear. If pstate.mcde is set, 
then instead of the ADI tag being cleared, the tag is *checked*, and if 
there is a mismatch between the version in the virtual address and the 
version in memory, then you&#39;ll get a trap and panic. Therefore, with 
this design, you cannot have pstate.mcde enabled while in the kernel (in 
general). To solve this you have to check the state of pstate.mcde (or 
just turn it off) before doing any block init store in clear_user_page, 
memset, memcpy, etc.

Rob
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 6, 2017, 6:18 p.m.</div>
<pre class="content">
On 01/06/2017 10:54 AM, Rob Gardner wrote:
<span class="quote">&gt; On 01/06/2017 09:10 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; On 01/06/2017 10:02 AM, David Miller wrote:</span>
<span class="quote">&gt;&gt;&gt; From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt;&gt;&gt; Date: Fri, 6 Jan 2017 08:55:03 -0800</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Actually, that reminds me...  How does your code interface with</span>
<span class="quote">&gt;&gt;&gt;&gt; ksm?  Or</span>
<span class="quote">&gt;&gt;&gt;&gt; is there no interaction needed since you&#39;re always working on virtual</span>
<span class="quote">&gt;&gt;&gt;&gt; addresses?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This reminds me, I consider this feature potentially extremely useful</span>
<span class="quote">&gt;&gt;&gt; for</span>
<span class="quote">&gt;&gt;&gt; kernel debugging.  So I would like to make sure we don&#39;t implement</span>
<span class="quote">&gt;&gt;&gt; anything</span>
<span class="quote">&gt;&gt;&gt; in a way which would preclude that in the long term.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I agree and please do point out if I have made any implementation</span>
<span class="quote">&gt;&gt; decisions that could preclude that.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Thanks,</span>
<span class="quote">&gt;&gt; Khalid</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Khalid, I have already pointed out an implementation decision that</span>
<span class="quote">&gt; interferes with the potential for kernel debugging with ADI: lazy</span>
<span class="quote">&gt; clearing of version tags.</span>

This does not preclude kernel debugging. If kernel debugging ends up 
requiring tags be cleared whenever a page is freed, we can add that code 
as part of kernel debugging support code and enable it conditionally 
only when kernel is being debugged. Forcing every task to incur the 
large cost of clearing tags on every &quot;free&quot; all the time is just not an 
acceptable cost only to support kernel debugging. It should be a dynamic 
switch to be toggled on only when debugging kernel. PSTATE.mcde being 
set is not enough to trigger a trap. It is easy enough to clear TTE.mcd 
before block initialization of a page and avoid a trap due to tag 
mismatch, or just use physical address with block initialization.

We can evaluate all of these options when we get to implementing kernel 
debugging using ADI.

Thanks,
Khalid
<span class="quote">

&gt;</span>
<span class="quote">&gt; Details: when memory is &quot;freed&quot; the version tags are left alone, as it</span>
<span class="quote">&gt; is an expensive operation to go through the memory and clear the tag for</span>
<span class="quote">&gt; each cache line. So this is done lazily whenever memory is &quot;allocated&quot;.</span>
<span class="quote">&gt; More specifically, the first time a user process touches freshly</span>
<span class="quote">&gt; allocated memory, a fault occurs and the kernel then clears the page. In</span>
<span class="quote">&gt; the NG4 and M7 variants of clear_user_page, the block init store ASI is</span>
<span class="quote">&gt; used to optimize, and it has the side effect of clearing the ADI tag for</span>
<span class="quote">&gt; the cache line. BUT only if pstate.mcde is clear. If pstate.mcde is set,</span>
<span class="quote">&gt; then instead of the ADI tag being cleared, the tag is *checked*, and if</span>
<span class="quote">&gt; there is a mismatch between the version in the virtual address and the</span>
<span class="quote">&gt; version in memory, then you&#39;ll get a trap and panic. Therefore, with</span>
<span class="quote">&gt; this design, you cannot have pstate.mcde enabled while in the kernel (in</span>
<span class="quote">&gt; general). To solve this you have to check the state of pstate.mcde (or</span>
<span class="quote">&gt; just turn it off) before doing any block init store in clear_user_page,</span>
<span class="quote">&gt; memset, memcpy, etc.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Rob</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe from this list: send the line &quot;unsubscribe sparclinux&quot; in</span>
<span class="quote">&gt; the body of a message to majordomo@vger.kernel.org</span>
<span class="quote">&gt; More majordomo info at  http://vger.kernel.org/majordomo-info.html</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 6, 2017, 6:28 p.m.</div>
<pre class="content">
On 01/06/2017 10:18 AM, Khalid Aziz wrote:
<span class="quote">&gt; On 01/06/2017 10:54 AM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt; On 01/06/2017 09:10 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt; On 01/06/2017 10:02 AM, David Miller wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Date: Fri, 6 Jan 2017 08:55:03 -0800</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; Actually, that reminds me...  How does your code interface with</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; ksm?  Or</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; is there no interaction needed since you&#39;re always working on virtual</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; addresses?</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; This reminds me, I consider this feature potentially extremely useful</span>
<span class="quote">&gt;&gt;&gt;&gt; for</span>
<span class="quote">&gt;&gt;&gt;&gt; kernel debugging.  So I would like to make sure we don&#39;t implement</span>
<span class="quote">&gt;&gt;&gt;&gt; anything</span>
<span class="quote">&gt;&gt;&gt;&gt; in a way which would preclude that in the long term.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I agree and please do point out if I have made any implementation</span>
<span class="quote">&gt;&gt;&gt; decisions that could preclude that.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Thanks,</span>
<span class="quote">&gt;&gt;&gt; Khalid</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Khalid, I have already pointed out an implementation decision that</span>
<span class="quote">&gt;&gt; interferes with the potential for kernel debugging with ADI: lazy</span>
<span class="quote">&gt;&gt; clearing of version tags.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This does not preclude kernel debugging. If kernel debugging ends up </span>
<span class="quote">&gt; requiring tags be cleared whenever a page is freed, we can add that </span>
<span class="quote">&gt; code as part of kernel debugging support code and enable it </span>
<span class="quote">&gt; conditionally only when kernel is being debugged. Forcing every task </span>
<span class="quote">&gt; to incur the large cost of clearing tags on every &quot;free&quot; all the time </span>
<span class="quote">&gt; is just not an acceptable cost only to support kernel debugging. It </span>
<span class="quote">&gt; should be a dynamic switch to be toggled on only when debugging </span>
<span class="quote">&gt; kernel. PSTATE.mcde being set is not enough to trigger a trap. It is </span>
<span class="quote">&gt; easy enough to clear TTE.mcd before block initialization of a page and </span>
<span class="quote">&gt; avoid a trap due to tag mismatch, or just use physical address with </span>
<span class="quote">&gt; block initialization.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; We can evaluate all of these options when we get to implementing </span>
<span class="quote">&gt; kernel debugging using ADI.</span>

I didn&#39;t say it precludes kernel debugging, just that it interferes, and 
there will be additional work to do if we want kernel debugging 
capability with ADI.

Rob
<span class="quote">


&gt;</span>
<span class="quote">&gt; Thanks,</span>
<span class="quote">&gt; Khalid</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Details: when memory is &quot;freed&quot; the version tags are left alone, as it</span>
<span class="quote">&gt;&gt; is an expensive operation to go through the memory and clear the tag for</span>
<span class="quote">&gt;&gt; each cache line. So this is done lazily whenever memory is &quot;allocated&quot;.</span>
<span class="quote">&gt;&gt; More specifically, the first time a user process touches freshly</span>
<span class="quote">&gt;&gt; allocated memory, a fault occurs and the kernel then clears the page. In</span>
<span class="quote">&gt;&gt; the NG4 and M7 variants of clear_user_page, the block init store ASI is</span>
<span class="quote">&gt;&gt; used to optimize, and it has the side effect of clearing the ADI tag for</span>
<span class="quote">&gt;&gt; the cache line. BUT only if pstate.mcde is clear. If pstate.mcde is set,</span>
<span class="quote">&gt;&gt; then instead of the ADI tag being cleared, the tag is *checked*, and if</span>
<span class="quote">&gt;&gt; there is a mismatch between the version in the virtual address and the</span>
<span class="quote">&gt;&gt; version in memory, then you&#39;ll get a trap and panic. Therefore, with</span>
<span class="quote">&gt;&gt; this design, you cannot have pstate.mcde enabled while in the kernel (in</span>
<span class="quote">&gt;&gt; general). To solve this you have to check the state of pstate.mcde (or</span>
<span class="quote">&gt;&gt; just turn it off) before doing any block init store in clear_user_page,</span>
<span class="quote">&gt;&gt; memset, memcpy, etc.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Rob</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -- </span>
<span class="quote">&gt;&gt; To unsubscribe from this list: send the line &quot;unsubscribe sparclinux&quot; in</span>
<span class="quote">&gt;&gt; the body of a message to majordomo@vger.kernel.org</span>
<span class="quote">&gt;&gt; More majordomo info at http://vger.kernel.org/majordomo-info.html</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; To unsubscribe from this list: send the line &quot;unsubscribe sparclinux&quot; in</span>
<span class="quote">&gt; the body of a message to majordomo@vger.kernel.org</span>
<span class="quote">&gt; More majordomo info at  http://vger.kernel.org/majordomo-info.html</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/sparc/adi.txt b/Documentation/sparc/adi.txt</span>
new file mode 100644
<span class="p_header">index 0000000..18aa6d0</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/Documentation/sparc/adi.txt</span>
<span class="p_chunk">@@ -0,0 +1,239 @@</span> <span class="p_context"></span>
<span class="p_add">+Application Data Integrity (ADI)</span>
<span class="p_add">+================================</span>
<span class="p_add">+</span>
<span class="p_add">+Sparc M7 processor adds the Application Data Integrity (ADI) feature.</span>
<span class="p_add">+ADI allows a task to set version tags on any subset of its address</span>
<span class="p_add">+space. Once ADI is enabled and version tags are set for ranges of</span>
<span class="p_add">+address space of a task, the processor will compare the tag in pointers</span>
<span class="p_add">+to memory in these ranges to the version set by the application</span>
<span class="p_add">+previously. Access to memory is granted only if the tag in given</span>
<span class="p_add">+pointer matches the tag set by the application. In case of mismatch,</span>
<span class="p_add">+processor raises an exception.</span>
<span class="p_add">+</span>
<span class="p_add">+Following steps must be taken by a task to enable ADI fully:</span>
<span class="p_add">+</span>
<span class="p_add">+1. Set the user mode PSTATE.mcde bit</span>
<span class="p_add">+</span>
<span class="p_add">+2. Set TTE.mcd bit on any TLB entries that correspond to the range of</span>
<span class="p_add">+addresses ADI is being enabled on.</span>
<span class="p_add">+</span>
<span class="p_add">+3. Set the version tag for memory addresses.</span>
<span class="p_add">+</span>
<span class="p_add">+ADI is enabled on a set of pages using mprotect() with PROT_ADI flag.</span>
<span class="p_add">+When ADI is enabled on a set of pages by a task for the first time,</span>
<span class="p_add">+kernel sets the PSTATE.mcde bit fot the task. Version tags for memory</span>
<span class="p_add">+addresses are set with an stxa instruction on the addresses using</span>
<span class="p_add">+ASI_MCD_PRIMARY or ASI_MCD_ST_BLKINIT_PRIMARY. Version tags are</span>
<span class="p_add">+specified in bits 63-60 of address and are set on memory the size of ADI</span>
<span class="p_add">+block size.  ADI block size is provided by the hypervisor to the kernel.</span>
<span class="p_add">+Kernel returns the value of ADI block size to userspace using auxiliary</span>
<span class="p_add">+vector along with other ADI info. Following auxiliary vectors are</span>
<span class="p_add">+provided by the kernel:</span>
<span class="p_add">+</span>
<span class="p_add">+	AT_ADI_BLKSZ	ADI block size. This is the granularity and</span>
<span class="p_add">+			alignment, in bytes, of ADI versioning.</span>
<span class="p_add">+	AT_ADI_NBITS	Number of ADI version bits in the VA</span>
<span class="p_add">+	AT_ADI_UEONADI	ADI version of memory containing uncorrectable</span>
<span class="p_add">+			errors will be set to this value</span>
<span class="p_add">+</span>
<span class="p_add">+Version tag values of 0x0 and 0xf are reserved.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+ADI related traps</span>
<span class="p_add">+-----------------</span>
<span class="p_add">+</span>
<span class="p_add">+With ADI enabled, following new traps may occur:</span>
<span class="p_add">+</span>
<span class="p_add">+Disrupting memory corruption</span>
<span class="p_add">+</span>
<span class="p_add">+	When a store accesses a memory localtion that has TTE.mcd=1,</span>
<span class="p_add">+	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="p_add">+	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="p_add">+	the corresponding cacheline, a memory corruption trap occurs. By</span>
<span class="p_add">+	default, it is a disrupting trap and is sent to the hypervisor</span>
<span class="p_add">+	first. Hypervisor creates a sun4v error report and sends a</span>
<span class="p_add">+	resumable error (TT=0x7e) trap to the kernel. The kernel sends</span>
<span class="p_add">+	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="p_add">+	info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ADIDERR;</span>
<span class="p_add">+		siginfo.si_addr = addr; /* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+Precise memory corruption</span>
<span class="p_add">+</span>
<span class="p_add">+	When a store accesses a memory location that has TTE.mcd=1,</span>
<span class="p_add">+	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="p_add">+	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="p_add">+	the corresponding cacheline, a memory corruption trap occurs. If</span>
<span class="p_add">+	MCD precise exception is enabled (MCDPERR=1), a precise</span>
<span class="p_add">+	exception is sent to the kernel with TT=0x1a. The kernel sends</span>
<span class="p_add">+	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="p_add">+	info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ADIPERR;</span>
<span class="p_add">+		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	NOTE: ADI tag mismatch on a load always results in precise trap.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+MCD disabled</span>
<span class="p_add">+</span>
<span class="p_add">+	When a task has not enabled ADI and attempts to set ADI version</span>
<span class="p_add">+	on a memory address, processor sends an MCD disabled trap. This</span>
<span class="p_add">+	trap is handled by hypervisor first and the hypervisor vectors this</span>
<span class="p_add">+	trap through to the kernel as Data Access Exception trap with</span>
<span class="p_add">+	fault type set to 0xa (invalid ASI). When this occurs, the kernel</span>
<span class="p_add">+	sends the task SIGBUS signal with following info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGBUS;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ACCADI;</span>
<span class="p_add">+		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+Sample program to use ADI</span>
<span class="p_add">+-------------------------</span>
<span class="p_add">+</span>
<span class="p_add">+Following sample program is meant to illustrate how to use the ADI</span>
<span class="p_add">+functionality.</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;unistd.h&gt;</span>
<span class="p_add">+#include &lt;stdio.h&gt;</span>
<span class="p_add">+#include &lt;stdlib.h&gt;</span>
<span class="p_add">+#include &lt;elf.h&gt;</span>
<span class="p_add">+#include &lt;sys/ipc.h&gt;</span>
<span class="p_add">+#include &lt;sys/shm.h&gt;</span>
<span class="p_add">+#include &lt;sys/mman.h&gt;</span>
<span class="p_add">+#include &lt;asm/asi.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef AT_ADI_BLKSZ</span>
<span class="p_add">+#define AT_ADI_BLKSZ	34</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifndef AT_ADI_NBITS</span>
<span class="p_add">+#define AT_ADI_NBITS	35</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifndef AT_ADI_UEONADI</span>
<span class="p_add">+#define AT_ADI_UEONADI	36</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef PROT_ADI</span>
<span class="p_add">+#define PROT_ADI	0x10</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define BUFFER_SIZE     32*1024*1024UL</span>
<span class="p_add">+</span>
<span class="p_add">+main(int argc, char* argv[], char* envp[])</span>
<span class="p_add">+{</span>
<span class="p_add">+        unsigned long i, mcde, adi_blksz, adi_nbits, adi_ueonadi;</span>
<span class="p_add">+        char *shmaddr, *tmp_addr, *end, *veraddr, *clraddr;</span>
<span class="p_add">+        int shmid, version;</span>
<span class="p_add">+	Elf64_auxv_t *auxv;</span>
<span class="p_add">+</span>
<span class="p_add">+	adi_blksz = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	while(*envp++ != NULL);</span>
<span class="p_add">+	for (auxv = (Elf64_auxv_t *)envp; auxv-&gt;a_type != AT_NULL; auxv++) {</span>
<span class="p_add">+		switch (auxv-&gt;a_type) {</span>
<span class="p_add">+		case AT_ADI_BLKSZ:</span>
<span class="p_add">+			adi_blksz = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case AT_ADI_NBITS:</span>
<span class="p_add">+			adi_nbits = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case AT_ADI_UEONADI:</span>
<span class="p_add">+			adi_ueonadi = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (adi_blksz == 0) {</span>
<span class="p_add">+		fprintf(stderr, &quot;Oops! ADI is not supported\n&quot;);</span>
<span class="p_add">+		exit(1);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	printf(&quot;ADI capabilities:\n&quot;);</span>
<span class="p_add">+	printf(&quot;\tBlock size = %ld\n&quot;, adi_blksz);</span>
<span class="p_add">+	printf(&quot;\tNumber of bits = %ld\n&quot;, adi_nbits);</span>
<span class="p_add">+	printf(&quot;\tUE on ADI error = %ld\n&quot;, adi_ueonadi);</span>
<span class="p_add">+</span>
<span class="p_add">+        if ((shmid = shmget(2, BUFFER_SIZE,</span>
<span class="p_add">+                                IPC_CREAT | SHM_R | SHM_W)) &lt; 0) {</span>
<span class="p_add">+                perror(&quot;shmget failed&quot;);</span>
<span class="p_add">+                exit(1);</span>
<span class="p_add">+        }</span>
<span class="p_add">+</span>
<span class="p_add">+        shmaddr = shmat(shmid, NULL, 0);</span>
<span class="p_add">+        if (shmaddr == (char *)-1) {</span>
<span class="p_add">+                perror(&quot;shm attach failed&quot;);</span>
<span class="p_add">+                shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+                exit(1);</span>
<span class="p_add">+        }</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE|PROT_ADI)) {</span>
<span class="p_add">+		perror(&quot;mprotect failed&quot;);</span>
<span class="p_add">+		goto err_out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Set the ADI version tag on the shm segment</span>
<span class="p_add">+         */</span>
<span class="p_add">+        version = 10;</span>
<span class="p_add">+        tmp_addr = shmaddr;</span>
<span class="p_add">+        end = shmaddr + BUFFER_SIZE;</span>
<span class="p_add">+        while (tmp_addr &lt; end) {</span>
<span class="p_add">+                asm volatile(</span>
<span class="p_add">+                        &quot;stxa %1, [%0]0x90\n\t&quot;</span>
<span class="p_add">+                        :</span>
<span class="p_add">+                        : &quot;r&quot; (tmp_addr), &quot;r&quot; (version));</span>
<span class="p_add">+                tmp_addr += adi_blksz;</span>
<span class="p_add">+        }</span>
<span class="p_add">+	asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Create a versioned address from the normal address</span>
<span class="p_add">+         */</span>
<span class="p_add">+        tmp_addr = (void *) ((unsigned long)shmaddr &lt;&lt; adi_nbits);</span>
<span class="p_add">+        tmp_addr = (void *) ((unsigned long)tmp_addr &gt;&gt; adi_nbits);</span>
<span class="p_add">+        veraddr = (void *) (((unsigned long)version &lt;&lt; (64-adi_nbits))</span>
<span class="p_add">+                        | (unsigned long)tmp_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+        printf(&quot;Starting the writes:\n&quot;);</span>
<span class="p_add">+        for (i = 0; i &lt; BUFFER_SIZE; i++) {</span>
<span class="p_add">+                veraddr[i] = (char)(i);</span>
<span class="p_add">+                if (!(i % (1024 * 1024)))</span>
<span class="p_add">+                        printf(&quot;.&quot;);</span>
<span class="p_add">+        }</span>
<span class="p_add">+        printf(&quot;\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        printf(&quot;Verifying data...&quot;);</span>
<span class="p_add">+	fflush(stdout);</span>
<span class="p_add">+        for (i = 0; i &lt; BUFFER_SIZE; i++)</span>
<span class="p_add">+                if (veraddr[i] != (char)i)</span>
<span class="p_add">+                        printf(&quot;\nIndex %lu mismatched\n&quot;, i);</span>
<span class="p_add">+        printf(&quot;Done.\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Disable ADI and clean up</span>
<span class="p_add">+         */</span>
<span class="p_add">+	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE)) {</span>
<span class="p_add">+		perror(&quot;mprotect failed&quot;);</span>
<span class="p_add">+		goto err_out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="p_add">+                perror(&quot;Detach failure&quot;);</span>
<span class="p_add">+        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+        exit(0);</span>
<span class="p_add">+</span>
<span class="p_add">+err_out:</span>
<span class="p_add">+        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="p_add">+                perror(&quot;Detach failure&quot;);</span>
<span class="p_add">+        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+        exit(1);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/adi.h b/arch/sparc/include/asm/adi.h</span>
new file mode 100644
<span class="p_header">index 0000000..acad0d0</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/include/asm/adi.h</span>
<span class="p_chunk">@@ -0,0 +1,6 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef ___ASM_SPARC_ADI_H</span>
<span class="p_add">+#define ___ASM_SPARC_ADI_H</span>
<span class="p_add">+#if defined(__sparc__) &amp;&amp; defined(__arch64__)</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/adi_64.h b/arch/sparc/include/asm/adi_64.h</span>
new file mode 100644
<span class="p_header">index 0000000..24fe52f</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/include/asm/adi_64.h</span>
<span class="p_chunk">@@ -0,0 +1,46 @@</span> <span class="p_context"></span>
<span class="p_add">+/* adi_64.h: ADI related data structures</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2016 Khalid Aziz (khalid.aziz@oracle.com)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifndef __ASM_SPARC64_ADI_H</span>
<span class="p_add">+#define __ASM_SPARC64_ADI_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASSEMBLY__</span>
<span class="p_add">+</span>
<span class="p_add">+struct adi_caps {</span>
<span class="p_add">+	__u64 blksz;</span>
<span class="p_add">+	__u64 nbits;</span>
<span class="p_add">+	__u64 ue_on_adi;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct adi_config {</span>
<span class="p_add">+	bool enabled;</span>
<span class="p_add">+	struct adi_caps caps;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct adi_config adi_state;</span>
<span class="p_add">+</span>
<span class="p_add">+extern void mdesc_adi_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool adi_capable(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return adi_state.enabled;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long adi_blksize(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return adi_state.caps.blksz;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long adi_nbits(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return adi_state.caps.nbits;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#endif	/* __ASSEMBLY__ */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif	/* !(__ASM_SPARC64_ADI_H) */</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/elf_64.h b/arch/sparc/include/asm/elf_64.h</span>
<span class="p_header">index 3f2d403..cf00fbc 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/elf_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/elf_64.h</span>
<span class="p_chunk">@@ -210,4 +210,12 @@</span> <span class="p_context"> do {	if ((ex).e_ident[EI_CLASS] == ELFCLASS32)	\</span>
 			(current-&gt;personality &amp; (~PER_MASK)));	\
 } while (0)
 
<span class="p_add">+#define ARCH_DLINFO						\</span>
<span class="p_add">+do {								\</span>
<span class="p_add">+	extern struct adi_config adi_state;			\</span>
<span class="p_add">+	NEW_AUX_ENT(AT_ADI_BLKSZ, adi_state.caps.blksz);	\</span>
<span class="p_add">+	NEW_AUX_ENT(AT_ADI_NBITS, adi_state.caps.nbits);	\</span>
<span class="p_add">+	NEW_AUX_ENT(AT_ADI_UEONADI, adi_state.caps.ue_on_adi);	\</span>
<span class="p_add">+} while (0)</span>
<span class="p_add">+</span>
 #endif /* !(__ASM_SPARC64_ELF_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/hugetlb.h b/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_header">index dcbf985..ac2fe18 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -77,5 +77,18 @@</span> <span class="p_context"> static inline void arch_clear_hugepage_flags(struct page *page)</span>
 void hugetlb_free_pgd_range(struct mmu_gather *tlb, unsigned long addr,
 			    unsigned long end, unsigned long floor,
 			    unsigned long ceiling);
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+static inline pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+			 struct page *page, int writeable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* If this vma has ADI enabled on it, turn on TTE.mcd</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SPARC_ADI)</span>
<span class="p_add">+		return pte_mkmcd(entry);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return pte_mknotmcd(entry);</span>
<span class="p_add">+}</span>
<span class="p_add">+#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="p_add">+#endif</span>
 
 #endif /* _ASM_SPARC64_HUGETLB_H */
<span class="p_header">diff --git a/arch/sparc/include/asm/hypervisor.h b/arch/sparc/include/asm/hypervisor.h</span>
<span class="p_header">index 73cb897..31782f7 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/hypervisor.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/hypervisor.h</span>
<span class="p_chunk">@@ -547,6 +547,8 @@</span> <span class="p_context"> struct hv_fault_status {</span>
 #define HV_FAULT_TYPE_RESV1	13
 #define HV_FAULT_TYPE_UNALIGNED	14
 #define HV_FAULT_TYPE_INV_PGSZ	15
<span class="p_add">+#define HV_FAULT_TYPE_MCD	17</span>
<span class="p_add">+#define HV_FAULT_TYPE_MCD_DIS	18</span>
 /* Values 16 --&gt; -2 are reserved.  */
 #define HV_FAULT_TYPE_MULTIPLE	-1
 
<span class="p_header">diff --git a/arch/sparc/include/asm/mman.h b/arch/sparc/include/asm/mman.h</span>
<span class="p_header">index 59bb593..95d3abc 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mman.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mman.h</span>
<span class="p_chunk">@@ -6,5 +6,43 @@</span> <span class="p_context"></span>
 #ifndef __ASSEMBLY__
 #define arch_mmap_check(addr,len,flags)	sparc_mmap_check(addr,len)
 int sparc_mmap_check(unsigned long addr, unsigned long len);
<span class="p_del">-#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_calc_vm_prot_bits(prot, pkey) sparc_calc_vm_prot_bits(prot)</span>
<span class="p_add">+static inline unsigned long sparc_calc_vm_prot_bits(unsigned long prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (prot &amp; PROT_ADI) {</span>
<span class="p_add">+		struct pt_regs *regs;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!current-&gt;mm-&gt;context.adi) {</span>
<span class="p_add">+			regs = task_pt_regs(current);</span>
<span class="p_add">+			regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="p_add">+			current-&gt;mm-&gt;context.adi = true;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return VM_SPARC_ADI;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_vm_get_page_prot(vm_flags) sparc_vm_get_page_prot(vm_flags)</span>
<span class="p_add">+static inline pgprot_t sparc_vm_get_page_prot(unsigned long vm_flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (vm_flags &amp; VM_SPARC_ADI) ? __pgprot(_PAGE_MCD_4V) : __pgprot(0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_validate_prot(prot) sparc_validate_prot(prot)</span>
<span class="p_add">+static inline int sparc_validate_prot(unsigned long prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM | PROT_ADI))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if ((prot &amp; PROT_ADI) &amp;&amp; !adi_capable())</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	return 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif /* CONFIG_SPARC64 */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __ASSEMBLY__ */</span>
 #endif /* __SPARC_MMAN_H__ */
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">index f7de0db..85adfd8 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_chunk">@@ -96,6 +96,8 @@</span> <span class="p_context"> typedef struct {</span>
 	unsigned long		thp_pte_count;
 	struct tsb_config	tsb_block[MM_NUM_TSBS];
 	struct hv_tsb_descr	tsb_descr[MM_NUM_TSBS];
<span class="p_add">+	bool			adi;</span>
<span class="p_add">+	unsigned long		mcdper;</span>
 } mm_context_t;
 
 #endif /* !__ASSEMBLY__ */
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index b84be67..79f3c7a 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -7,6 +7,7 @@</span> <span class="p_context"></span>
 
 #include &lt;linux/spinlock.h&gt;
 #include &lt;asm/spitfire.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 #include &lt;asm-generic/mm_hooks.h&gt;
 
 static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
<span class="p_chunk">@@ -79,6 +80,21 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 	if (unlikely(mm == &amp;init_mm))
 		return;
 
<span class="p_add">+	/* Save the current state of MCDPER register for the process we are</span>
<span class="p_add">+	 * switching from</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;.word 0xa1438000\n\t&quot;	/* rd  %mcdper, %l0 */</span>
<span class="p_add">+			&quot;mov %%l0, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;l0&quot;);</span>
<span class="p_add">+		old_mm-&gt;context.mcdper = tmp_mcdper;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);
 	ctx_valid = CTX_VALID(mm-&gt;context);
 	if (!ctx_valid)
<span class="p_chunk">@@ -127,6 +143,22 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 		__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),
 			       SECONDARY_CONTEXT);
 	}
<span class="p_add">+</span>
<span class="p_add">+	/* Restore the state of MCDPER register for the process we are</span>
<span class="p_add">+	 * switching to</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		tmp_mcdper = mm-&gt;context.mcdper;</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;mov %0, %%l1\n\t&quot;</span>
<span class="p_add">+			&quot;.word 0x9d800011\n\t&quot;	/* wr  %g0, %l1, %mcdper */</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;ir&quot; (tmp_mcdper)</span>
<span class="p_add">+			: &quot;l1&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);
 }
 
<span class="p_header">diff --git a/arch/sparc/include/asm/pgtable_64.h b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_header">index 1fb317f..c543a33 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_chunk">@@ -17,6 +17,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/types.h&gt;
 #include &lt;asm/spitfire.h&gt;
 #include &lt;asm/asi.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 #include &lt;asm/page.h&gt;
 #include &lt;asm/processor.h&gt;
 
<span class="p_chunk">@@ -162,6 +163,9 @@</span> <span class="p_context"> bool kern_addr_valid(unsigned long addr);</span>
 #define _PAGE_E_4V	  _AC(0x0000000000000800,UL) /* side-Effect          */
 #define _PAGE_CP_4V	  _AC(0x0000000000000400,UL) /* Cacheable in P-Cache */
 #define _PAGE_CV_4V	  _AC(0x0000000000000200,UL) /* Cacheable in V-Cache */
<span class="p_add">+/* Bit 9 is used to enable MCD corruption detection instead on M7</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define _PAGE_MCD_4V	  _AC(0x0000000000000200,UL) /* Memory Corruption    */</span>
 #define _PAGE_P_4V	  _AC(0x0000000000000100,UL) /* Privileged Page      */
 #define _PAGE_EXEC_4V	  _AC(0x0000000000000080,UL) /* Executable Page      */
 #define _PAGE_W_4V	  _AC(0x0000000000000040,UL) /* Writable             */
<span class="p_chunk">@@ -562,6 +566,18 @@</span> <span class="p_context"> static inline pte_t pte_mkspecial(pte_t pte)</span>
 	return pte;
 }
 
<span class="p_add">+static inline pte_t pte_mkmcd(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_val(pte) |= _PAGE_MCD_4V;</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pte_t pte_mknotmcd(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_val(pte) &amp;= ~_PAGE_MCD_4V;</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline unsigned long pte_young(pte_t pte)
 {
 	unsigned long mask;
<span class="p_chunk">@@ -919,6 +935,10 @@</span> <span class="p_context"> static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
 #define pte_clear_not_present_full(mm,addr,ptep,fullmm)	\
 	__set_pte_at((mm), (addr), (ptep), __pte(0UL), (fullmm))
 
<span class="p_add">+#define __HAVE_ARCH_PTEP_CLEAR_FLUSH</span>
<span class="p_add">+pte_t ptep_clear_flush(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		       pte_t *ptep);</span>
<span class="p_add">+</span>
 #ifdef DCACHE_ALIASING_POSSIBLE
 #define __HAVE_ARCH_MOVE_PTE
 #define move_pte(pte, prot, old_addr, new_addr)				\
<span class="p_chunk">@@ -962,9 +982,14 @@</span> <span class="p_context"> void pgtable_trans_huge_deposit(struct mm_struct *mm, pmd_t *pmdp,</span>
 pgtable_t pgtable_trans_huge_withdraw(struct mm_struct *mm, pmd_t *pmdp);
 #endif
 
<span class="p_del">-/* Encode and de-code a swap entry */</span>
<span class="p_add">+/* Encode and de-code a swap entry. Upper bits of offset are used to</span>
<span class="p_add">+ * store the ADI version tag for pages that have ADI enabled and tags set</span>
<span class="p_add">+ */</span>
 #define __swp_type(entry)	(((entry).val &gt;&gt; PAGE_SHIFT) &amp; 0xffUL)
<span class="p_del">-#define __swp_offset(entry)	((entry).val &gt;&gt; (PAGE_SHIFT + 8UL))</span>
<span class="p_add">+#define __swp_offset(entry)		\</span>
<span class="p_add">+	((((entry).val &lt;&lt; adi_nbits()) &gt;&gt; adi_nbits()) &gt;&gt; (PAGE_SHIFT + 8UL))</span>
<span class="p_add">+#define __swp_aditag(entry)		\</span>
<span class="p_add">+	((entry).val &gt;&gt; (sizeof(unsigned long)-adi_nbits()))</span>
 #define __swp_entry(type, offset)	\
 	( (swp_entry_t) \
 	  { \
<span class="p_chunk">@@ -987,6 +1012,74 @@</span> <span class="p_context"> int page_in_phys_avail(unsigned long paddr);</span>
 int remap_pfn_range(struct vm_area_struct *, unsigned long, unsigned long,
 		    unsigned long, pgprot_t);
 
<span class="p_add">+static inline void set_swp_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			     pte_t *ptep, pte_t pte, pte_t oldpte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t orig = *ptep;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pte_none(pte) &amp;&amp; !pte_present(pte)) {</span>
<span class="p_add">+		if (pte_val(oldpte) &amp; _PAGE_MCD_4V) {</span>
<span class="p_add">+			unsigned long version, paddr;</span>
<span class="p_add">+</span>
<span class="p_add">+			paddr = pte_val(oldpte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+			asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+				     : &quot;=r&quot; (version)</span>
<span class="p_add">+				     : &quot;r&quot; (paddr), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+			if (version) {</span>
<span class="p_add">+				swp_entry_t tmp;</span>
<span class="p_add">+				pgoff_t swap_off;</span>
<span class="p_add">+				unsigned long swap_type, shift_size;</span>
<span class="p_add">+</span>
<span class="p_add">+				/* Save ADI version tag in the top bits</span>
<span class="p_add">+				 * of swap offset</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				tmp = __pte_to_swp_entry(pte);</span>
<span class="p_add">+				swap_off = __swp_offset(tmp);</span>
<span class="p_add">+				swap_type = __swp_type(tmp);</span>
<span class="p_add">+				shift_size = PAGE_SHIFT + 8UL + adi_nbits();</span>
<span class="p_add">+				swap_off = (swap_off &lt;&lt; shift_size)&gt;&gt;shift_size;</span>
<span class="p_add">+				swap_off = (version &lt;&lt; (sizeof(unsigned long) -</span>
<span class="p_add">+						        shift_size)) | swap_off;</span>
<span class="p_add">+				tmp = __swp_entry(swap_type, swap_off);</span>
<span class="p_add">+				pte = __swp_entry_to_pte(tmp);</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+		*ptep = pte;</span>
<span class="p_add">+		maybe_tlb_batch_add(mm, addr, ptep, orig, 0);</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		if (pte_val(pte) &amp; _PAGE_MCD_4V) {</span>
<span class="p_add">+			swp_entry_t tmp;</span>
<span class="p_add">+			pgoff_t swap_off;</span>
<span class="p_add">+			unsigned long swap_type, version;</span>
<span class="p_add">+</span>
<span class="p_add">+			*ptep = pte;</span>
<span class="p_add">+			maybe_tlb_batch_add(mm, addr, ptep, orig, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+			/* Check if the swapped out page has an ADI version</span>
<span class="p_add">+			 * saved in the swap offset. If yes, restore</span>
<span class="p_add">+			 * version tag to the newly allocated page</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			tmp = __pte_to_swp_entry(oldpte);</span>
<span class="p_add">+			swap_off = __swp_offset(tmp);</span>
<span class="p_add">+			swap_type = __swp_type(tmp);</span>
<span class="p_add">+			version = __swp_aditag(tmp);</span>
<span class="p_add">+			if (version) {</span>
<span class="p_add">+				unsigned long i, paddr;</span>
<span class="p_add">+</span>
<span class="p_add">+				paddr = pte_val(pte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+				for (i = paddr; i &lt; (paddr+PAGE_SIZE);</span>
<span class="p_add">+						i += adi_blksize())</span>
<span class="p_add">+					asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="p_add">+						:</span>
<span class="p_add">+						: &quot;r&quot; (version), &quot;r&quot; (i),</span>
<span class="p_add">+						  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+			}</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			*ptep = pte;</span>
<span class="p_add">+			maybe_tlb_batch_add(mm, addr, ptep, orig, 0);</span>
<span class="p_add">+		}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int io_remap_pfn_range(struct vm_area_struct *vma,
 				     unsigned long from, unsigned long pfn,
 				     unsigned long size, pgprot_t prot)
<span class="p_header">diff --git a/arch/sparc/include/asm/ttable.h b/arch/sparc/include/asm/ttable.h</span>
<span class="p_header">index 781b9f1..77cc073 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/ttable.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/ttable.h</span>
<span class="p_chunk">@@ -212,6 +212,16 @@</span> <span class="p_context"></span>
 	nop;						\
 	nop;
 
<span class="p_add">+#define SUN4V_MCD_PRECISE				\</span>
<span class="p_add">+	ldxa	[%g0] ASI_SCRATCHPAD, %g2;		\</span>
<span class="p_add">+	ldx	[%g2 + HV_FAULT_D_ADDR_OFFSET], %g4;	\</span>
<span class="p_add">+	ldx	[%g2 + HV_FAULT_D_CTX_OFFSET], %g5;	\</span>
<span class="p_add">+	ba,pt	%xcc, etrap;				\</span>
<span class="p_add">+	rd	%pc, %g7;				\</span>
<span class="p_add">+	ba,pt	%xcc, sun4v_mcd_detect_precise;		\</span>
<span class="p_add">+	nop;						\</span>
<span class="p_add">+	nop;</span>
<span class="p_add">+</span>
 /* Before touching these macros, you owe it to yourself to go and
  * see how arch/sparc64/kernel/winfixup.S works... -DaveM
  *
<span class="p_header">diff --git a/arch/sparc/include/asm/uaccess_64.h b/arch/sparc/include/asm/uaccess_64.h</span>
<span class="p_header">index 5373136..6bfe818 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/uaccess_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/uaccess_64.h</span>
<span class="p_chunk">@@ -10,8 +10,10 @@</span> <span class="p_context"></span>
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/string.h&gt;
 #include &lt;linux/thread_info.h&gt;
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
 #include &lt;asm/asi.h&gt;
 #include &lt;asm/spitfire.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 #include &lt;asm-generic/uaccess-unaligned.h&gt;
 #include &lt;asm/extable_64.h&gt;
 #endif
<span class="p_chunk">@@ -72,6 +74,31 @@</span> <span class="p_context"> static inline bool __chk_range_not_ok(unsigned long addr, unsigned long size, un</span>
 	__chk_range_not_ok((unsigned long __force)(addr), size, limit); \
 })
 
<span class="p_add">+static inline void enable_adi(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If userspace is using ADI, it could potentially pass a pointer</span>
<span class="p_add">+	 * with version tag embedded in it. To maintain the ADI security,</span>
<span class="p_add">+	 * we must enable PSTATE.mcde. Userspace would have already set</span>
<span class="p_add">+	 * TTE.mcd in an earlier call to kernel and set the version tag</span>
<span class="p_add">+	 * for the address being dereferenced. Setting PSTATE.mcde would</span>
<span class="p_add">+	 * ensure any access to userspace data through a system call</span>
<span class="p_add">+	 * honors ADI and does not allow a rogue app to bypass ADI by</span>
<span class="p_add">+	 * using system calls. Also to ensure the right exception,</span>
<span class="p_add">+	 * precise or disrupting, is delivered to the userspace, update</span>
<span class="p_add">+	 * PMCDPER to match MCDPER</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__asm__ __volatile__(</span>
<span class="p_add">+		&quot;rdpr %%pstate, %%g1\n\t&quot;</span>
<span class="p_add">+		&quot;or %%g1, %0, %%g1\n\t&quot;</span>
<span class="p_add">+		&quot;wrpr %%g1, %%g0, %%pstate\n\t&quot;</span>
<span class="p_add">+		&quot;.word 0x83438000\n\t&quot;	/* rd %mcdper, %g1 */</span>
<span class="p_add">+		&quot;.word 0xaf900001\n\t&quot;	/* wrpr  %g0, %g1, %pmcdper */</span>
<span class="p_add">+		:</span>
<span class="p_add">+		: &quot;i&quot; (PSTATE_MCDE)</span>
<span class="p_add">+		: &quot;g1&quot;);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int __access_ok(const void __user * addr, unsigned long size)
 {
 	return 1;
<span class="p_chunk">@@ -112,7 +139,9 @@</span> <span class="p_context"> struct __large_struct { unsigned long buf[100]; };</span>
 #define __m(x) ((struct __large_struct *)(x))
 
 #define __put_user_nocheck(data, addr, size) ({			\
<span class="p_del">-	register int __pu_ret;					\</span>
<span class="p_add">+	register int __pu_ret, __adi_status;				\</span>
<span class="p_add">+	if ((__adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))	\</span>
<span class="p_add">+		enable_adi();					\</span>
 	switch (size) {						\
 	case 1: __put_user_asm(data, b, addr, __pu_ret); break;	\
 	case 2: __put_user_asm(data, h, addr, __pu_ret); break;	\
<span class="p_chunk">@@ -120,6 +149,9 @@</span> <span class="p_context"> struct __large_struct { unsigned long buf[100]; };</span>
 	case 8: __put_user_asm(data, x, addr, __pu_ret); break;	\
 	default: __pu_ret = __put_user_bad(); break;		\
 	}							\
<span class="p_add">+	if (__adi_status)					\</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */			\</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);	\</span>
 	__pu_ret;						\
 })
 
<span class="p_chunk">@@ -146,8 +178,10 @@</span> <span class="p_context"> __asm__ __volatile__(							\</span>
 int __put_user_bad(void);
 
 #define __get_user_nocheck(data, addr, size, type) ({			     \
<span class="p_del">-	register int __gu_ret;						     \</span>
<span class="p_add">+	register int __gu_ret, __adi_status;				     \</span>
 	register unsigned long __gu_val;				     \
<span class="p_add">+	if ((__adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))	     \</span>
<span class="p_add">+		enable_adi();						     \</span>
 	switch (size) {							     \
 		case 1: __get_user_asm(__gu_val, ub, addr, __gu_ret); break; \
 		case 2: __get_user_asm(__gu_val, uh, addr, __gu_ret); break; \
<span class="p_chunk">@@ -159,6 +193,9 @@</span> <span class="p_context"> int __put_user_bad(void);</span>
 			break;						     \
 	} 								     \
 	data = (__force type) __gu_val;					     \
<span class="p_add">+	if (__adi_status)						     \</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */				     \</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);		     \</span>
 	 __gu_ret;							     \
 })
 
<span class="p_chunk">@@ -185,15 +222,53 @@</span> <span class="p_context"> __asm__ __volatile__(							\</span>
 
 int __get_user_bad(void);
 
<span class="p_add">+/* When kernel access userspace memory, it must honor ADI setting</span>
<span class="p_add">+ * to ensure ADI protection continues across system calls. Kernel</span>
<span class="p_add">+ * must set PSTATE.mcde bit. It must also update PMCDPER register</span>
<span class="p_add">+ * to reflect MCDPER register so the kind of exception generated</span>
<span class="p_add">+ * in case of ADI version tag mismatch, is what the userspace is</span>
<span class="p_add">+ * expecting. PMCDPER exists only on the processors that support</span>
<span class="p_add">+ * ADI and must be accessed conditionally to avoid illegal</span>
<span class="p_add">+ * instruction trap.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define user_access_begin()						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)		\</span>
<span class="p_add">+			enable_adi();					\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define user_access_end()						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (adi_capable())					\</span>
<span class="p_add">+			/* wrpr  %g0, %pmcdper */			\</span>
<span class="p_add">+			__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);	\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define unsafe_get_user(x, ptr, err)		\</span>
<span class="p_add">+		do { if (unlikely(__get_user(x, ptr))) goto err; } while (0)</span>
<span class="p_add">+#define unsafe_put_user(x, ptr, err)		\</span>
<span class="p_add">+		do { if (unlikely(__put_user(x, ptr))) goto err; } while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 unsigned long __must_check ___copy_from_user(void *to,
 					     const void __user *from,
 					     unsigned long size);
 static inline unsigned long __must_check
 copy_from_user(void *to, const void __user *from, unsigned long size)
 {
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
 	check_object_size(to, size, false);
 
<span class="p_del">-	return ___copy_from_user(to, from, size);</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ___copy_from_user(to, from, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
 #define __copy_from_user copy_from_user
 
<span class="p_chunk">@@ -203,9 +278,18 @@</span> <span class="p_context"> unsigned long __must_check ___copy_to_user(void __user *to,</span>
 static inline unsigned long __must_check
 copy_to_user(void __user *to, const void *from, unsigned long size)
 {
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
 	check_object_size(from, size, true);
 
<span class="p_del">-	return ___copy_to_user(to, from, size);</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ___copy_to_user(to, from, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+	return ret;</span>
 }
 #define __copy_to_user copy_to_user
 
<span class="p_chunk">@@ -215,13 +299,37 @@</span> <span class="p_context"> unsigned long __must_check ___copy_in_user(void __user *to,</span>
 static inline unsigned long __must_check
 copy_in_user(void __user *to, void __user *from, unsigned long size)
 {
<span class="p_del">-	return ___copy_in_user(to, from, size);</span>
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ___copy_in_user(to, from, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
 #define __copy_in_user copy_in_user
 
 unsigned long __must_check __clear_user(void __user *, unsigned long);
 
<span class="p_del">-#define clear_user __clear_user</span>
<span class="p_add">+static inline unsigned long __must_check</span>
<span class="p_add">+___clear_user(void __user *uaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+	ret = __clear_user(uaddr, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define clear_user ___clear_user</span>
 
 __must_check long strlen_user(const char __user *str);
 __must_check long strnlen_user(const char __user *str, long n);
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/asi.h b/arch/sparc/include/uapi/asm/asi.h</span>
<span class="p_header">index 7ad7203d..2bcdaa5 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/asi.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/asi.h</span>
<span class="p_chunk">@@ -144,6 +144,8 @@</span> <span class="p_context"></span>
  * ASIs, &quot;(4V)&quot; designates SUN4V specific ASIs.  &quot;(NG4)&quot; designates SPARC-T4
  * and later ASIs.
  */
<span class="p_add">+#define ASI_MCD_PRIV_PRIMARY	0x02 /* (NG7) Privileged MCD version VA	*/</span>
<span class="p_add">+#define ASI_MCD_REAL		0x05 /* (NG7) Privileged MCD version PA	*/</span>
 #define ASI_PHYS_USE_EC		0x14 /* PADDR, E-cachable		*/
 #define ASI_PHYS_BYPASS_EC_E	0x15 /* PADDR, E-bit			*/
 #define ASI_BLK_AIUP_4V		0x16 /* (4V) Prim, user, block ld/st	*/
<span class="p_chunk">@@ -244,6 +246,9 @@</span> <span class="p_context"></span>
 #define ASI_UDBL_CONTROL_R	0x7f /* External UDB control regs rd low*/
 #define ASI_INTR_R		0x7f /* IRQ vector dispatch read	*/
 #define ASI_INTR_DATAN_R	0x7f /* (III) In irq vector data reg N	*/
<span class="p_add">+#define ASI_MCD_PRIMARY		0x90 /* (NG7) MCD version load/store	*/</span>
<span class="p_add">+#define ASI_MCD_ST_BLKINIT_PRIMARY	\</span>
<span class="p_add">+				0x92 /* (NG7) MCD store BLKINIT primary	*/</span>
 #define ASI_PIC			0xb0 /* (NG4) PIC registers		*/
 #define ASI_PST8_P		0xc0 /* Primary, 8 8-bit, partial	*/
 #define ASI_PST8_S		0xc1 /* Secondary, 8 8-bit, partial	*/
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/auxvec.h b/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="p_header">index ad6f360..6fe1249 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="p_chunk">@@ -1,4 +1,12 @@</span> <span class="p_context"></span>
 #ifndef __ASMSPARC_AUXVEC_H
 #define __ASMSPARC_AUXVEC_H
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+#define AT_ADI_BLKSZ	34</span>
<span class="p_add">+#define AT_ADI_NBITS	35</span>
<span class="p_add">+#define AT_ADI_UEONADI	36</span>
<span class="p_add">+</span>
<span class="p_add">+#define AT_VECTOR_SIZE_ARCH	3</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif /* !(__ASMSPARC_AUXVEC_H) */
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/mman.h b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_header">index 9765896..a72c033 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_chunk">@@ -5,6 +5,8 @@</span> <span class="p_context"></span>
 
 /* SunOS&#39;ified... */
 
<span class="p_add">+#define PROT_ADI	0x10		/* ADI enabled */</span>
<span class="p_add">+</span>
 #define MAP_RENAME      MAP_ANONYMOUS   /* In SunOS terminology */
 #define MAP_NORESERVE   0x40            /* don&#39;t reserve swap pages */
 #define MAP_INHERIT     0x80            /* SunOS doesn&#39;t do this, but... */
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/pstate.h b/arch/sparc/include/uapi/asm/pstate.h</span>
<span class="p_header">index cf832e1..d0521db 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/pstate.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/pstate.h</span>
<span class="p_chunk">@@ -10,7 +10,12 @@</span> <span class="p_context"></span>
  * -----------------------------------------------------------------------
  *  63  12  11   10    9     8    7   6   5     4     3     2     1    0
  */
<span class="p_add">+/* IG on V9 conflicts with MCDE on M7. PSTATE_MCDE will only be used on</span>
<span class="p_add">+ * processors that support ADI which do not use IG, hence there is no</span>
<span class="p_add">+ * functional conflict</span>
<span class="p_add">+ */</span>
 #define PSTATE_IG   _AC(0x0000000000000800,UL) /* Interrupt Globals.	*/
<span class="p_add">+#define PSTATE_MCDE _AC(0x0000000000000800,UL) /* MCD Enable		*/</span>
 #define PSTATE_MG   _AC(0x0000000000000400,UL) /* MMU Globals.		*/
 #define PSTATE_CLE  _AC(0x0000000000000200,UL) /* Current Little Endian.*/
 #define PSTATE_TLE  _AC(0x0000000000000100,UL) /* Trap Little Endian.	*/
<span class="p_chunk">@@ -47,7 +52,12 @@</span> <span class="p_context"></span>
 #define TSTATE_ASI	_AC(0x00000000ff000000,UL) /* AddrSpace ID.	*/
 #define TSTATE_PIL	_AC(0x0000000000f00000,UL) /* %pil (Linux traps)*/
 #define TSTATE_PSTATE	_AC(0x00000000000fff00,UL) /* PSTATE.		*/
<span class="p_add">+/* IG on V9 conflicts with MCDE on M7. TSTATE_MCDE will only be used on</span>
<span class="p_add">+ * processors that support ADI which do not support IG, hence there is</span>
<span class="p_add">+ * no functional conflict</span>
<span class="p_add">+ */</span>
 #define TSTATE_IG	_AC(0x0000000000080000,UL) /* Interrupt Globals.*/
<span class="p_add">+#define TSTATE_MCDE	_AC(0x0000000000080000,UL) /* MCD enable.       */</span>
 #define TSTATE_MG	_AC(0x0000000000040000,UL) /* MMU Globals.	*/
 #define TSTATE_CLE	_AC(0x0000000000020000,UL) /* CurrLittleEndian.	*/
 #define TSTATE_TLE	_AC(0x0000000000010000,UL) /* TrapLittleEndian.	*/
<span class="p_header">diff --git a/arch/sparc/kernel/Makefile b/arch/sparc/kernel/Makefile</span>
<span class="p_header">index fa3c02d..c9c4e76 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/Makefile</span>
<span class="p_header">+++ b/arch/sparc/kernel/Makefile</span>
<span class="p_chunk">@@ -67,6 +67,7 @@</span> <span class="p_context"> obj-$(CONFIG_SPARC64)   += visemul.o</span>
 obj-$(CONFIG_SPARC64)   += hvapi.o
 obj-$(CONFIG_SPARC64)   += sstate.o
 obj-$(CONFIG_SPARC64)   += mdesc.o
<span class="p_add">+obj-$(CONFIG_SPARC64)   += adi_64.o</span>
 obj-$(CONFIG_SPARC64)	+= pcr.o
 obj-$(CONFIG_SPARC64)	+= nmi.o
 obj-$(CONFIG_SPARC64_SMP) += cpumap.o
<span class="p_header">diff --git a/arch/sparc/kernel/adi_64.c b/arch/sparc/kernel/adi_64.c</span>
new file mode 100644
<span class="p_header">index 0000000..aba1960</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/kernel/adi_64.c</span>
<span class="p_chunk">@@ -0,0 +1,93 @@</span> <span class="p_context"></span>
<span class="p_add">+/* adi_64.c: support for ADI (Application Data Integrity) feature on</span>
<span class="p_add">+ * sparc m7 and newer processors. This feature is also known as</span>
<span class="p_add">+ * SSM (Silicon Secured Memory).</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2016 Khalid Aziz (khalid.aziz@oracle.com)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &lt;linux/init.h&gt;</span>
<span class="p_add">+#include &lt;asm/mdesc.h&gt;</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct adi_config adi_state;</span>
<span class="p_add">+</span>
<span class="p_add">+/* mdesc_adi_init() : Parse machine description provided by the</span>
<span class="p_add">+ *	hypervisor to detect ADI capabilities</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Hypervisor reports ADI capabilities of platform in &quot;hwcap-list&quot; property</span>
<span class="p_add">+ * for &quot;cpu&quot; node. If the platform supports ADI, &quot;hwcap-list&quot; property</span>
<span class="p_add">+ * contains the keyword &quot;adp&quot;. If the platform supports ADI, &quot;platform&quot;</span>
<span class="p_add">+ * node will contain &quot;adp-blksz&quot;, &quot;adp-nbits&quot; and &quot;ue-on-adp&quot; properties</span>
<span class="p_add">+ * to describe the ADI capabilities.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init mdesc_adi_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mdesc_handle *hp = mdesc_grab();</span>
<span class="p_add">+	const char *prop;</span>
<span class="p_add">+	u64 pn, *val;</span>
<span class="p_add">+	int len;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!hp)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	pn = mdesc_node_by_name(hp, MDESC_NODE_NULL, &quot;cpu&quot;);</span>
<span class="p_add">+	if (pn == MDESC_NODE_NULL)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	prop = mdesc_get_property(hp, pn, &quot;hwcap-list&quot;, &amp;len);</span>
<span class="p_add">+	if (!prop)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Look for &quot;adp&quot; keyword in hwcap-list which would indicate</span>
<span class="p_add">+	 * ADI support</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	adi_state.enabled = false;</span>
<span class="p_add">+	while (len) {</span>
<span class="p_add">+		int plen;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!strcmp(prop, &quot;adp&quot;)) {</span>
<span class="p_add">+			adi_state.enabled = true;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		plen = strlen(prop) + 1;</span>
<span class="p_add">+		prop += plen;</span>
<span class="p_add">+		len -= plen;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!adi_state.enabled)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Find the ADI properties in &quot;platform&quot; node. If all ADI</span>
<span class="p_add">+	 * properties are not found, ADI support is incomplete and</span>
<span class="p_add">+	 * do not enable ADI in the kernel.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pn = mdesc_node_by_name(hp, MDESC_NODE_NULL, &quot;platform&quot;);</span>
<span class="p_add">+	if (pn == MDESC_NODE_NULL)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = (u64 *) mdesc_get_property(hp, pn, &quot;adp-blksz&quot;, &amp;len);</span>
<span class="p_add">+	if (!val)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+	adi_state.caps.blksz = *val;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = (u64 *) mdesc_get_property(hp, pn, &quot;adp-nbits&quot;, &amp;len);</span>
<span class="p_add">+	if (!val)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+	adi_state.caps.nbits = *val;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = (u64 *) mdesc_get_property(hp, pn, &quot;ue-on-adp&quot;, &amp;len);</span>
<span class="p_add">+	if (!val)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+	adi_state.caps.ue_on_adi = *val;</span>
<span class="p_add">+</span>
<span class="p_add">+	mdesc_release(hp);</span>
<span class="p_add">+	return;</span>
<span class="p_add">+</span>
<span class="p_add">+adi_not_found:</span>
<span class="p_add">+	adi_state.enabled = false;</span>
<span class="p_add">+	if (hp)</span>
<span class="p_add">+		mdesc_release(hp);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/sparc/kernel/entry.h b/arch/sparc/kernel/entry.h</span>
<span class="p_header">index 0f67942..2078468 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/entry.h</span>
<span class="p_header">+++ b/arch/sparc/kernel/entry.h</span>
<span class="p_chunk">@@ -159,6 +159,9 @@</span> <span class="p_context"> void sun4v_resum_overflow(struct pt_regs *regs);</span>
 void sun4v_nonresum_error(struct pt_regs *regs,
 			  unsigned long offset);
 void sun4v_nonresum_overflow(struct pt_regs *regs);
<span class="p_add">+void sun4v_mem_corrupt_detect_precise(struct pt_regs *regs,</span>
<span class="p_add">+				      unsigned long addr,</span>
<span class="p_add">+				      unsigned long context);</span>
 
 extern unsigned long sun4v_err_itlb_vaddr;
 extern unsigned long sun4v_err_itlb_ctx;
<span class="p_header">diff --git a/arch/sparc/kernel/head_64.S b/arch/sparc/kernel/head_64.S</span>
<span class="p_header">index 6aa3da1..818f869 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/head_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/head_64.S</span>
<span class="p_chunk">@@ -873,6 +873,7 @@</span> <span class="p_context"> sparc64_boot_end:</span>
 #include &quot;helpers.S&quot;
 #include &quot;hvcalls.S&quot;
 #include &quot;sun4v_tlb_miss.S&quot;
<span class="p_add">+#include &quot;sun4v_mcd.S&quot;</span>
 #include &quot;sun4v_ivec.S&quot;
 #include &quot;ktlb.S&quot;
 #include &quot;tsb.S&quot;
<span class="p_header">diff --git a/arch/sparc/kernel/mdesc.c b/arch/sparc/kernel/mdesc.c</span>
<span class="p_header">index 8a6982d..68b03bf 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/mdesc.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/mdesc.c</span>
<span class="p_chunk">@@ -20,6 +20,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/uaccess.h&gt;
 #include &lt;asm/oplib.h&gt;
 #include &lt;asm/smp.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 
 /* Unlike the OBP device tree, the machine description is a full-on
  * DAG.  An arbitrary number of ARCs are possible from one
<span class="p_chunk">@@ -1104,5 +1105,8 @@</span> <span class="p_context"> void __init sun4v_mdesc_init(void)</span>
 
 	cur_mdesc = hp;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	mdesc_adi_init();</span>
<span class="p_add">+#endif</span>
 	report_platform_properties();
 }
<span class="p_header">diff --git a/arch/sparc/kernel/process_64.c b/arch/sparc/kernel/process_64.c</span>
<span class="p_header">index 47ff558..740cecb 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/process_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/process_64.c</span>
<span class="p_chunk">@@ -680,6 +680,27 @@</span> <span class="p_context"> int copy_thread(unsigned long clone_flags, unsigned long sp,</span>
 	return 0;
 }
 
<span class="p_add">+/* Update the state of MCDPER register in current task&#39;s mm context before</span>
<span class="p_add">+ * dup so the dup&#39;d task will inherit flags in this register correctly.</span>
<span class="p_add">+ * Current task may have updated flags since it started running.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (adi_capable() &amp;&amp; src-&gt;mm) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;.word 0x83438000\n\t&quot;	/* rd %mcdper, %g1 */</span>
<span class="p_add">+			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+		src-&gt;mm-&gt;context.mcdper = tmp_mcdper;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	*dst = *src;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 typedef struct {
 	union {
 		unsigned int	pr_regs[32];
<span class="p_header">diff --git a/arch/sparc/kernel/sun4v_mcd.S b/arch/sparc/kernel/sun4v_mcd.S</span>
new file mode 100644
<span class="p_header">index 0000000..a36e337</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/kernel/sun4v_mcd.S</span>
<span class="p_chunk">@@ -0,0 +1,16 @@</span> <span class="p_context"></span>
<span class="p_add">+/* sun4v_mcd.S: Sun4v memory corruption detected precise exception handler</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2015 Bob Picco &lt;bob.picco@oracle.com&gt;</span>
<span class="p_add">+ * Copyright (C) 2015 Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="p_add">+ */</span>
<span class="p_add">+	.text</span>
<span class="p_add">+	.align 32</span>
<span class="p_add">+</span>
<span class="p_add">+sun4v_mcd_detect_precise:</span>
<span class="p_add">+	or	%l4, %g0, %o1</span>
<span class="p_add">+	or 	%l5, %g0, %o2</span>
<span class="p_add">+	call	sun4v_mem_corrupt_detect_precise</span>
<span class="p_add">+	add	%sp, PTREGS_OFF, %o0</span>
<span class="p_add">+	ba,a,pt	%xcc, rtrap</span>
<span class="p_header">diff --git a/arch/sparc/kernel/traps_64.c b/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">index 4094a51..576937c 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/traps_64.c</span>
<span class="p_chunk">@@ -44,6 +44,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/memctrl.h&gt;
 #include &lt;asm/cacheflush.h&gt;
 #include &lt;asm/setup.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 
 #include &quot;entry.h&quot;
 #include &quot;kernel.h&quot;
<span class="p_chunk">@@ -351,12 +352,31 @@</span> <span class="p_context"> void sun4v_data_access_exception(struct pt_regs *regs, unsigned long addr, unsig</span>
 		regs-&gt;tpc &amp;= 0xffffffff;
 		regs-&gt;tnpc &amp;= 0xffffffff;
 	}
<span class="p_del">-	info.si_signo = SIGSEGV;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* MCD (Memory Corruption Detection) disabled trap (TT=0x19) in HV</span>
<span class="p_add">+	 * is vectored thorugh data access exception trap with fault type</span>
<span class="p_add">+	 * set to HV_FAULT_TYPE_MCD_DIS. Check for MCD disabled trap</span>
<span class="p_add">+	 */</span>
 	info.si_errno = 0;
<span class="p_del">-	info.si_code = SEGV_MAPERR;</span>
 	info.si_addr = (void __user *) addr;
 	info.si_trapno = 0;
<span class="p_del">-	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+	switch (type) {</span>
<span class="p_add">+	case HV_FAULT_TYPE_INV_ASI:</span>
<span class="p_add">+		info.si_signo = SIGILL;</span>
<span class="p_add">+		info.si_code = ILL_ILLADR;</span>
<span class="p_add">+		force_sig_info(SIGILL, &amp;info, current);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case HV_FAULT_TYPE_MCD_DIS:</span>
<span class="p_add">+		info.si_signo = SIGSEGV;</span>
<span class="p_add">+		info.si_code = SEGV_ACCADI;</span>
<span class="p_add">+		force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		info.si_signo = SIGSEGV;</span>
<span class="p_add">+		info.si_code = SEGV_MAPERR;</span>
<span class="p_add">+		force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
 }
 
 void sun4v_data_access_exception_tl1(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)
<span class="p_chunk">@@ -1801,6 +1821,7 @@</span> <span class="p_context"> struct sun4v_error_entry {</span>
 #define SUN4V_ERR_ATTRS_ASI		0x00000080
 #define SUN4V_ERR_ATTRS_PRIV_REG	0x00000100
 #define SUN4V_ERR_ATTRS_SPSTATE_MSK	0x00000600
<span class="p_add">+#define SUN4V_ERR_ATTRS_MCD		0x00000800</span>
 #define SUN4V_ERR_ATTRS_SPSTATE_SHFT	9
 #define SUN4V_ERR_ATTRS_MODE_MSK	0x03000000
 #define SUN4V_ERR_ATTRS_MODE_SHFT	24
<span class="p_chunk">@@ -1998,6 +2019,54 @@</span> <span class="p_context"> static void sun4v_log_error(struct pt_regs *regs, struct sun4v_error_entry *ent,</span>
 	}
 }
 
<span class="p_add">+/* Handle memory corruption detected error which is vectored in</span>
<span class="p_add">+ * through resumable error trap.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void do_mcd_err(struct pt_regs *regs, struct sun4v_error_entry ent)</span>
<span class="p_add">+{</span>
<span class="p_add">+	siginfo_t info;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (notify_die(DIE_TRAP, &quot;MCD error&quot;, regs,</span>
<span class="p_add">+		       0, 0x34, SIGSEGV) == NOTIFY_STOP)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (regs-&gt;tstate &amp; TSTATE_PRIV) {</span>
<span class="p_add">+		/* MCD exception could happen because the task was running</span>
<span class="p_add">+		 * a system call with MCD enabled and passed a non-versioned</span>
<span class="p_add">+		 * pointer or pointer with bad version tag to  the system</span>
<span class="p_add">+		 * call. In such cases, hypervisor places the address of</span>
<span class="p_add">+		 * offending instruction in the resumable error report. This</span>
<span class="p_add">+		 * is a deferred error, so the read/write that caused the trap</span>
<span class="p_add">+		 * was potentially retired long time back and we may have</span>
<span class="p_add">+		 * no choice but to send SIGSEGV to the process.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		const struct exception_table_entry *entry;</span>
<span class="p_add">+</span>
<span class="p_add">+		entry = search_exception_tables(regs-&gt;tpc);</span>
<span class="p_add">+		if (entry) {</span>
<span class="p_add">+			/* Looks like a bad syscall parameter */</span>
<span class="p_add">+#ifdef DEBUG_EXCEPTIONS</span>
<span class="p_add">+			pr_emerg(&quot;Exception: PC&lt;%016lx&gt; faddr&lt;UNKNOWN&gt;\n&quot;,</span>
<span class="p_add">+				 regs-&gt;tpc);</span>
<span class="p_add">+			pr_emerg(&quot;EX_TABLE: insn&lt;%016lx&gt; fixup&lt;%016lx&gt;\n&quot;,</span>
<span class="p_add">+				 ent.err_raddr, entry-&gt;fixup);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+			regs-&gt;tpc = entry-&gt;fixup;</span>
<span class="p_add">+			regs-&gt;tnpc = regs-&gt;tpc + 4;</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Send SIGSEGV to the userspace process with the right code</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	info.si_signo = SIGSEGV;</span>
<span class="p_add">+	info.si_errno = 0;</span>
<span class="p_add">+	info.si_code = SEGV_ADIDERR;</span>
<span class="p_add">+	info.si_addr = (void __user *)ent.err_raddr;</span>
<span class="p_add">+	info.si_trapno = 0;</span>
<span class="p_add">+	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* We run with %pil set to PIL_NORMAL_MAX and PSTATE_IE enabled in %pstate.
  * Log the event and clear the first word of the entry.
  */
<span class="p_chunk">@@ -2035,6 +2104,14 @@</span> <span class="p_context"> void sun4v_resum_error(struct pt_regs *regs, unsigned long offset)</span>
 		goto out;
 	}
 
<span class="p_add">+	/* If this is a memory corruption detected error, call the</span>
<span class="p_add">+	 * handler</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (local_copy.err_attrs &amp; SUN4V_ERR_ATTRS_MCD) {</span>
<span class="p_add">+		do_mcd_err(regs, local_copy);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	sun4v_log_error(regs, &amp;local_copy, cpu,
 			KERN_ERR &quot;RESUMABLE ERROR&quot;,
 			&amp;sun4v_resum_oflow_cnt);
<span class="p_chunk">@@ -2531,6 +2608,65 @@</span> <span class="p_context"> void sun4v_do_mna(struct pt_regs *regs, unsigned long addr, unsigned long type_c</span>
 	force_sig_info(SIGBUS, &amp;info, current);
 }
 
<span class="p_add">+/* sun4v_mem_corrupt_detect_precise() - Handle precise exception on an ADI</span>
<span class="p_add">+ * tag mismatch.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * ADI version tag mismatch on a load from memory always results in a</span>
<span class="p_add">+ * precise exception. Tag mismatch on a store to memory will result in</span>
<span class="p_add">+ * precise exception if MCDPER or PMCDPER is set to 1.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void sun4v_mem_corrupt_detect_precise(struct pt_regs *regs, unsigned long addr,</span>
<span class="p_add">+				      unsigned long context)</span>
<span class="p_add">+{</span>
<span class="p_add">+	siginfo_t info;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!adi_capable()) {</span>
<span class="p_add">+		bad_trap(regs, 0x1a);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (notify_die(DIE_TRAP, &quot;memory corruption precise exception&quot;, regs,</span>
<span class="p_add">+		       0, 0x8, SIGSEGV) == NOTIFY_STOP)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (regs-&gt;tstate &amp; TSTATE_PRIV) {</span>
<span class="p_add">+		/* MCD exception could happen because the task was running</span>
<span class="p_add">+		 * a system call with MCD enabled and passed a non-versioned</span>
<span class="p_add">+		 * pointer or pointer with bad version tag to  the system</span>
<span class="p_add">+		 * call.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		const struct exception_table_entry *entry;</span>
<span class="p_add">+</span>
<span class="p_add">+		entry = search_exception_tables(regs-&gt;tpc);</span>
<span class="p_add">+		if (entry) {</span>
<span class="p_add">+			/* Looks like a bad syscall parameter */</span>
<span class="p_add">+#ifdef DEBUG_EXCEPTIONS</span>
<span class="p_add">+			pr_emerg(&quot;Exception: PC&lt;%016lx&gt; faddr&lt;UNKNOWN&gt;\n&quot;,</span>
<span class="p_add">+				 regs-&gt;tpc);</span>
<span class="p_add">+			pr_emerg(&quot;EX_TABLE: insn&lt;%016lx&gt; fixup&lt;%016lx&gt;\n&quot;,</span>
<span class="p_add">+				 regs-&gt;tpc, entry-&gt;fixup);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+			regs-&gt;tpc = entry-&gt;fixup;</span>
<span class="p_add">+			regs-&gt;tnpc = regs-&gt;tpc + 4;</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		pr_emerg(&quot;sun4v_mem_corrupt_detect_precise: ADDR[%016lx] &quot;</span>
<span class="p_add">+			&quot;CTX[%lx], going.\n&quot;, addr, context);</span>
<span class="p_add">+		die_if_kernel(&quot;MCD precise&quot;, regs);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (test_thread_flag(TIF_32BIT)) {</span>
<span class="p_add">+		regs-&gt;tpc &amp;= 0xffffffff;</span>
<span class="p_add">+		regs-&gt;tnpc &amp;= 0xffffffff;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	info.si_signo = SIGSEGV;</span>
<span class="p_add">+	info.si_code = SEGV_ADIPERR;</span>
<span class="p_add">+	info.si_errno = 0;</span>
<span class="p_add">+	info.si_addr = (void __user *) addr;</span>
<span class="p_add">+	info.si_trapno = 0;</span>
<span class="p_add">+	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void do_privop(struct pt_regs *regs)
 {
 	enum ctx_state prev_state = exception_enter();
<span class="p_header">diff --git a/arch/sparc/kernel/ttable_64.S b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">index c6dfdaa..2343bf0 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_chunk">@@ -25,8 +25,10 @@</span> <span class="p_context"> tl0_ill:	membar #Sync</span>
 		TRAP_7INSNS(do_illegal_instruction)
 tl0_privop:	TRAP(do_privop)
 tl0_resv012:	BTRAP(0x12) BTRAP(0x13) BTRAP(0x14) BTRAP(0x15) BTRAP(0x16) BTRAP(0x17)
<span class="p_del">-tl0_resv018:	BTRAP(0x18) BTRAP(0x19) BTRAP(0x1a) BTRAP(0x1b) BTRAP(0x1c) BTRAP(0x1d)</span>
<span class="p_del">-tl0_resv01e:	BTRAP(0x1e) BTRAP(0x1f)</span>
<span class="p_add">+tl0_resv018:	BTRAP(0x18) BTRAP(0x19)</span>
<span class="p_add">+tl0_mcd:	SUN4V_MCD_PRECISE</span>
<span class="p_add">+tl0_resv01b:	BTRAP(0x1b)</span>
<span class="p_add">+tl0_resv01c:	BTRAP(0x1c) BTRAP(0x1d)	BTRAP(0x1e) BTRAP(0x1f)</span>
 tl0_fpdis:	TRAP_NOSAVE(do_fpdis)
 tl0_fpieee:	TRAP_SAVEFPU(do_fpieee)
 tl0_fpother:	TRAP_NOSAVE(do_fpother_check_fitos)
<span class="p_header">diff --git a/arch/sparc/mm/gup.c b/arch/sparc/mm/gup.c</span>
<span class="p_header">index cd0e32b..579f7ae 100644</span>
<span class="p_header">--- a/arch/sparc/mm/gup.c</span>
<span class="p_header">+++ b/arch/sparc/mm/gup.c</span>
<span class="p_chunk">@@ -11,6 +11,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/pagemap.h&gt;
 #include &lt;linux/rwsem.h&gt;
 #include &lt;asm/pgtable.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 
 /*
  * The performance critical leaf functions are made noinline otherwise gcc
<span class="p_chunk">@@ -157,6 +158,24 @@</span> <span class="p_context"> int __get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
 	pgd_t *pgdp;
 	int nr = 0;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		long addr = start;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If userspace has passed a versioned address, kernel</span>
<span class="p_add">+		 * will not find it in the VMAs since it does not store</span>
<span class="p_add">+		 * the version tags in the list of VMAs. Storing version</span>
<span class="p_add">+		 * tags in list of VMAs is impractical since they can be</span>
<span class="p_add">+		 * changed any time from userspace without dropping into</span>
<span class="p_add">+		 * kernel. Any address search in VMAs will be done with</span>
<span class="p_add">+		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="p_add">+		 * are dropped here by sign extending the last bit before</span>
<span class="p_add">+		 * ADI bits. IOMMU does not implement version tags.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="p_add">+		start = addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
 	start &amp;= PAGE_MASK;
 	addr = start;
 	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;
<span class="p_chunk">@@ -187,6 +206,24 @@</span> <span class="p_context"> int get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
 	pgd_t *pgdp;
 	int nr = 0;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		long addr = start;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If userspace has passed a versioned address, kernel</span>
<span class="p_add">+		 * will not find it in the VMAs since it does not store</span>
<span class="p_add">+		 * the version tags in the list of VMAs. Storing version</span>
<span class="p_add">+		 * tags in list of VMAs is impractical since they can be</span>
<span class="p_add">+		 * changed any time from userspace without dropping into</span>
<span class="p_add">+		 * kernel. Any address search in VMAs will be done with</span>
<span class="p_add">+		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="p_add">+		 * are dropped here by sign extending the last bit before</span>
<span class="p_add">+		 * ADI bits. IOMMU does not implements version tags,</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="p_add">+		start = addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
 	start &amp;= PAGE_MASK;
 	addr = start;
 	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;
<span class="p_header">diff --git a/arch/sparc/mm/tlb.c b/arch/sparc/mm/tlb.c</span>
<span class="p_header">index c56a195..557f2c38 100644</span>
<span class="p_header">--- a/arch/sparc/mm/tlb.c</span>
<span class="p_header">+++ b/arch/sparc/mm/tlb.c</span>
<span class="p_chunk">@@ -15,6 +15,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/cacheflush.h&gt;
 #include &lt;asm/mmu_context.h&gt;
 #include &lt;asm/tlb.h&gt;
<span class="p_add">+#include &lt;asm/asi.h&gt;</span>
 
 /* Heavily inspired by the ppc64 code.  */
 
<span class="p_chunk">@@ -142,6 +143,33 @@</span> <span class="p_context"> void tlb_batch_add(struct mm_struct *mm, unsigned long vaddr,</span>
 		tlb_batch_add_one(mm, vaddr, pte_exec(orig), huge);
 }
 
<span class="p_add">+pte_t ptep_clear_flush(struct vm_area_struct *vma, unsigned long address,</span>
<span class="p_add">+		       pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = (vma)-&gt;vm_mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = *ptep;</span>
<span class="p_add">+	/* If we are getting ready to swap out a page with ADI enabled</span>
<span class="p_add">+	 * and version tags set, save the version tags so we can restore</span>
<span class="p_add">+	 * them when page is swapped back in.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (pte_val(pte) &amp; _PAGE_MCD_4V) {</span>
<span class="p_add">+		unsigned long version, paddr;</span>
<span class="p_add">+</span>
<span class="p_add">+		paddr = pte_val(pte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+		asm volatile(</span>
<span class="p_add">+			&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (version)</span>
<span class="p_add">+			: &quot;r&quot; (paddr), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = ptep_get_and_clear(mm, address, ptep);</span>
<span class="p_add">+	if (pte_accessible(mm, pte))</span>
<span class="p_add">+		flush_tlb_page(vma, address);</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 static void tlb_batch_pmd_scan(struct mm_struct *mm, unsigned long vaddr,
 			       pmd_t pmd)
<span class="p_header">diff --git a/arch/x86/kernel/signal_compat.c b/arch/x86/kernel/signal_compat.c</span>
<span class="p_header">index ec1f756..d1e860c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/signal_compat.c</span>
<span class="p_header">+++ b/arch/x86/kernel/signal_compat.c</span>
<span class="p_chunk">@@ -26,7 +26,7 @@</span> <span class="p_context"> static inline void signal_compat_build_tests(void)</span>
 	 */
 	BUILD_BUG_ON(NSIGILL  != 8);
 	BUILD_BUG_ON(NSIGFPE  != 8);
<span class="p_del">-	BUILD_BUG_ON(NSIGSEGV != 4);</span>
<span class="p_add">+	BUILD_BUG_ON(NSIGSEGV != 7);</span>
 	BUILD_BUG_ON(NSIGBUS  != 5);
 	BUILD_BUG_ON(NSIGTRAP != 4);
 	BUILD_BUG_ON(NSIGCHLD != 6);
<span class="p_header">diff --git a/include/asm-generic/pgtable.h b/include/asm-generic/pgtable.h</span>
<span class="p_header">index c4f8fd2..5043e5a 100644</span>
<span class="p_header">--- a/include/asm-generic/pgtable.h</span>
<span class="p_header">+++ b/include/asm-generic/pgtable.h</span>
<span class="p_chunk">@@ -294,6 +294,11 @@</span> <span class="p_context"> static inline int pmd_same(pmd_t pmd_a, pmd_t pmd_b)</span>
 # define pte_accessible(mm, pte)	((void)(pte), 1)
 #endif
 
<span class="p_add">+#ifndef set_swp_pte_at</span>
<span class="p_add">+#define set_swp_pte_at(mm, addr, ptep, pte, oldpte)	\</span>
<span class="p_add">+		set_pte_at(mm, addr, ptep, pte)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #ifndef flush_tlb_fix_spurious_fault
 #define flush_tlb_fix_spurious_fault(vma, address) flush_tlb_page(vma, address)
 #endif
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index a92c8d7..5c894a5 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -225,6 +225,8 @@</span> <span class="p_context"> extern unsigned int kobjsize(const void *objp);</span>
 # define VM_GROWSUP	VM_ARCH_1
 #elif defined(CONFIG_IA64)
 # define VM_GROWSUP	VM_ARCH_1
<span class="p_add">+#elif defined(CONFIG_SPARC64)</span>
<span class="p_add">+# define VM_SPARC_ADI	VM_ARCH_1	/* Uses ADI tag for access control */</span>
 #elif !defined(CONFIG_MMU)
 # define VM_MAPPED_COPY	VM_ARCH_1	/* T if mapped copy of data (nommu mmap) */
 #endif
<span class="p_header">diff --git a/include/uapi/asm-generic/siginfo.h b/include/uapi/asm-generic/siginfo.h</span>
<span class="p_header">index 1abaf62..2446864 100644</span>
<span class="p_header">--- a/include/uapi/asm-generic/siginfo.h</span>
<span class="p_header">+++ b/include/uapi/asm-generic/siginfo.h</span>
<span class="p_chunk">@@ -213,7 +213,10 @@</span> <span class="p_context"> typedef struct siginfo {</span>
 #define SEGV_ACCERR	(__SI_FAULT|2)	/* invalid permissions for mapped object */
 #define SEGV_BNDERR	(__SI_FAULT|3)  /* failed address bound checks */
 #define SEGV_PKUERR	(__SI_FAULT|4)  /* failed protection key checks */
<span class="p_del">-#define NSIGSEGV	4</span>
<span class="p_add">+#define SEGV_ACCADI	(__SI_FAULT|5)	/* ADI not enabled for mapped object */</span>
<span class="p_add">+#define SEGV_ADIDERR	(__SI_FAULT|6)	/* Disrupting MCD error */</span>
<span class="p_add">+#define SEGV_ADIPERR	(__SI_FAULT|7)	/* Precise MCD exception */</span>
<span class="p_add">+#define NSIGSEGV	7</span>
 
 /*
  * SIGBUS si_codes
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index e18c57b..1cc3b55 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -2642,7 +2642,7 @@</span> <span class="p_context"> int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
 	flush_icache_page(vma, page);
 	if (pte_swp_soft_dirty(orig_pte))
 		pte = pte_mksoft_dirty(pte);
<span class="p_del">-	set_pte_at(vma-&gt;vm_mm, fe-&gt;address, fe-&gt;pte, pte);</span>
<span class="p_add">+	set_swp_pte_at(vma-&gt;vm_mm, fe-&gt;address, fe-&gt;pte, pte, orig_pte);</span>
 	if (page == swapcache) {
 		do_page_add_anon_rmap(page, vma, fe-&gt;address, exclusive);
 		mem_cgroup_commit_charge(page, memcg, true, false);
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index 1ef3640..d58cb94 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -1539,7 +1539,7 @@</span> <span class="p_context"> static int try_to_unmap_one(struct page *page, struct vm_area_struct *vma,</span>
 		swp_pte = swp_entry_to_pte(entry);
 		if (pte_soft_dirty(pteval))
 			swp_pte = pte_swp_mksoft_dirty(swp_pte);
<span class="p_del">-		set_pte_at(mm, address, pte, swp_pte);</span>
<span class="p_add">+		set_swp_pte_at(mm, address, pte, swp_pte, pteval);</span>
 	} else if (PageAnon(page)) {
 		swp_entry_t entry = { .val = page_private(page) };
 		pte_t swp_pte;
<span class="p_chunk">@@ -1572,7 +1572,7 @@</span> <span class="p_context"> static int try_to_unmap_one(struct page *page, struct vm_area_struct *vma,</span>
 		swp_pte = swp_entry_to_pte(entry);
 		if (pte_soft_dirty(pteval))
 			swp_pte = pte_swp_mksoft_dirty(swp_pte);
<span class="p_del">-		set_pte_at(mm, address, pte, swp_pte);</span>
<span class="p_add">+		set_swp_pte_at(mm, address, pte, swp_pte, pteval);</span>
 	} else
 		dec_mm_counter(mm, mm_counter_file(page));
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



