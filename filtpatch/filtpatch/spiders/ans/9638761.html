
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.9.17 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.9.17</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 22, 2017, 1:06 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170322130617.GB32110@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9638761/mbox/"
   >mbox</a>
|
   <a href="/patch/9638761/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9638761/">/patch/9638761/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A81E860327 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Mar 2017 13:07:37 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 87E7E281F9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Mar 2017 13:07:37 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7A0D928459; Wed, 22 Mar 2017 13:07:37 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id BE709281F9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Mar 2017 13:07:28 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S934612AbdCVNH0 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 22 Mar 2017 09:07:26 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:46934 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1759558AbdCVNGj (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 22 Mar 2017 09:06:39 -0400
Received: from localhost (LFbn-1-12060-104.w90-92.abo.wanadoo.fr
	[90.92.122.104])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 0BD9CBD5;
	Wed, 22 Mar 2017 13:06:30 +0000 (UTC)
Date: Wed, 22 Mar 2017 14:06:17 +0100
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.9.17
Message-ID: &lt;20170322130617.GB32110@kroah.com&gt;
References: &lt;20170322130609.GA32110@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170322130609.GA32110@kroah.com&gt;
User-Agent: Mutt/1.8.0 (2017-02-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - March 22, 2017, 1:06 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/arm64/silicon-errata.txt b/Documentation/arm64/silicon-errata.txt</span>
<span class="p_header">index 405da11fc3e4..d11af52427b4 100644</span>
<span class="p_header">--- a/Documentation/arm64/silicon-errata.txt</span>
<span class="p_header">+++ b/Documentation/arm64/silicon-errata.txt</span>
<span class="p_chunk">@@ -42,24 +42,26 @@</span> <span class="p_context"> file acts as a registry of software workarounds in the Linux Kernel and</span>
 will be updated when new workarounds are committed and backported to
 stable kernels.
 
<span class="p_del">-| Implementor    | Component       | Erratum ID      | Kconfig                 |</span>
<span class="p_del">-+----------------+-----------------+-----------------+-------------------------+</span>
<span class="p_del">-| ARM            | Cortex-A53      | #826319         | ARM64_ERRATUM_826319    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #827319         | ARM64_ERRATUM_827319    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #824069         | ARM64_ERRATUM_824069    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #819472         | ARM64_ERRATUM_819472    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #845719         | ARM64_ERRATUM_845719    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #843419         | ARM64_ERRATUM_843419    |</span>
<span class="p_del">-| ARM            | Cortex-A57      | #832075         | ARM64_ERRATUM_832075    |</span>
<span class="p_del">-| ARM            | Cortex-A57      | #852523         | N/A                     |</span>
<span class="p_del">-| ARM            | Cortex-A57      | #834220         | ARM64_ERRATUM_834220    |</span>
<span class="p_del">-| ARM            | Cortex-A72      | #853709         | N/A                     |</span>
<span class="p_del">-| ARM            | MMU-500         | #841119,#826419 | N/A                     |</span>
<span class="p_del">-|                |                 |                 |                         |</span>
<span class="p_del">-| Cavium         | ThunderX ITS    | #22375, #24313  | CAVIUM_ERRATUM_22375    |</span>
<span class="p_del">-| Cavium         | ThunderX ITS    | #23144          | CAVIUM_ERRATUM_23144    |</span>
<span class="p_del">-| Cavium         | ThunderX GICv3  | #23154          | CAVIUM_ERRATUM_23154    |</span>
<span class="p_del">-| Cavium         | ThunderX Core   | #27456          | CAVIUM_ERRATUM_27456    |</span>
<span class="p_del">-| Cavium         | ThunderX SMMUv2 | #27704          | N/A		       |</span>
<span class="p_del">-|                |                 |                 |                         |</span>
<span class="p_del">-| Freescale/NXP  | LS2080A/LS1043A | A-008585        | FSL_ERRATUM_A008585     |</span>
<span class="p_add">+| Implementor    | Component       | Erratum ID      | Kconfig                     |</span>
<span class="p_add">++----------------+-----------------+-----------------+-----------------------------+</span>
<span class="p_add">+| ARM            | Cortex-A53      | #826319         | ARM64_ERRATUM_826319        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #827319         | ARM64_ERRATUM_827319        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #824069         | ARM64_ERRATUM_824069        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #819472         | ARM64_ERRATUM_819472        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #845719         | ARM64_ERRATUM_845719        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #843419         | ARM64_ERRATUM_843419        |</span>
<span class="p_add">+| ARM            | Cortex-A57      | #832075         | ARM64_ERRATUM_832075        |</span>
<span class="p_add">+| ARM            | Cortex-A57      | #852523         | N/A                         |</span>
<span class="p_add">+| ARM            | Cortex-A57      | #834220         | ARM64_ERRATUM_834220        |</span>
<span class="p_add">+| ARM            | Cortex-A72      | #853709         | N/A                         |</span>
<span class="p_add">+| ARM            | MMU-500         | #841119,#826419 | N/A                         |</span>
<span class="p_add">+|                |                 |                 |                             |</span>
<span class="p_add">+| Cavium         | ThunderX ITS    | #22375, #24313  | CAVIUM_ERRATUM_22375        |</span>
<span class="p_add">+| Cavium         | ThunderX ITS    | #23144          | CAVIUM_ERRATUM_23144        |</span>
<span class="p_add">+| Cavium         | ThunderX GICv3  | #23154          | CAVIUM_ERRATUM_23154        |</span>
<span class="p_add">+| Cavium         | ThunderX Core   | #27456          | CAVIUM_ERRATUM_27456        |</span>
<span class="p_add">+| Cavium         | ThunderX SMMUv2 | #27704          | N/A                         |</span>
<span class="p_add">+|                |                 |                 |                             |</span>
<span class="p_add">+| Freescale/NXP  | LS2080A/LS1043A | A-008585        | FSL_ERRATUM_A008585         |</span>
<span class="p_add">+|                |                 |                 |                             |</span>
<span class="p_add">+| Qualcomm Tech. | QDF2400 ITS     | E0065           | QCOM_QDF2400_ERRATUM_0065   |</span>
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 4e0f962eb434..004f90a4e613 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 9
<span class="p_del">-SUBLEVEL = 16</span>
<span class="p_add">+SUBLEVEL = 17</span>
 EXTRAVERSION =
 NAME = Roaring Lionus
 
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 969ef880d234..cf57a7799a0f 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -474,6 +474,16 @@</span> <span class="p_context"> config CAVIUM_ERRATUM_27456</span>
 
 	  If unsure, say Y.
 
<span class="p_add">+config QCOM_QDF2400_ERRATUM_0065</span>
<span class="p_add">+	bool &quot;QDF2400 E0065: Incorrect GITS_TYPER.ITT_Entry_size&quot;</span>
<span class="p_add">+	default y</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  On Qualcomm Datacenter Technologies QDF2400 SoC, ITS hardware reports</span>
<span class="p_add">+	  ITE size incorrectly. The GITS_TYPER.ITT_Entry_size field should have</span>
<span class="p_add">+	  been indicated as 16Bytes (0xf), not 8Bytes (0x7).</span>
<span class="p_add">+</span>
<span class="p_add">+	  If unsure, say Y.</span>
<span class="p_add">+</span>
 endmenu
 
 
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">index 88e2f2b938f0..55889d057757 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -17,14 +17,62 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/kvm_hyp.h&gt;
 
<span class="p_add">+static void __hyp_text __tlb_switch_to_guest_vhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 val;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * With VHE enabled, we have HCR_EL2.{E2H,TGE} = {1,1}, and</span>
<span class="p_add">+	 * most TLB operations target EL2/EL0. In order to affect the</span>
<span class="p_add">+	 * guest TLBs (EL1/EL0), we need to change one of these two</span>
<span class="p_add">+	 * bits. Changing E2H is impossible (goodbye TTBR1_EL2), so</span>
<span class="p_add">+	 * let&#39;s flip TGE before executing the TLB operation.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_add">+	val = read_sysreg(hcr_el2);</span>
<span class="p_add">+	val &amp;= ~HCR_TGE;</span>
<span class="p_add">+	write_sysreg(val, hcr_el2);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __tlb_switch_to_guest_nvhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__tlb_switch_to_guest,</span>
<span class="p_add">+			    __tlb_switch_to_guest_nvhe,</span>
<span class="p_add">+			    __tlb_switch_to_guest_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __tlb_switch_to_host_vhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We&#39;re done with the TLB operation, let&#39;s restore the host&#39;s</span>
<span class="p_add">+	 * view of HCR_EL2.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	write_sysreg(HCR_HOST_VHE_FLAGS, hcr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __tlb_switch_to_host_nvhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__tlb_switch_to_host,</span>
<span class="p_add">+			    __tlb_switch_to_host_nvhe,</span>
<span class="p_add">+			    __tlb_switch_to_host_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
 void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa)
 {
 	dsb(ishst);
 
 	/* Switch to requested VMID */
 	kvm = kern_hyp_va(kvm);
<span class="p_del">-	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_del">-	isb();</span>
<span class="p_add">+	__tlb_switch_to_guest()(kvm);</span>
 
 	/*
 	 * We could do so much better if we had the VA as well.
<span class="p_chunk">@@ -45,7 +93,7 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa)</span>
 	dsb(ish);
 	isb();
 
<span class="p_del">-	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	__tlb_switch_to_host()(kvm);</span>
 }
 
 void __hyp_text __kvm_tlb_flush_vmid(struct kvm *kvm)
<span class="p_chunk">@@ -54,14 +102,13 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid(struct kvm *kvm)</span>
 
 	/* Switch to requested VMID */
 	kvm = kern_hyp_va(kvm);
<span class="p_del">-	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_del">-	isb();</span>
<span class="p_add">+	__tlb_switch_to_guest()(kvm);</span>
 
 	asm volatile(&quot;tlbi vmalls12e1is&quot; : : );
 	dsb(ish);
 	isb();
 
<span class="p_del">-	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	__tlb_switch_to_host()(kvm);</span>
 }
 
 void __hyp_text __kvm_tlb_flush_local_vmid(struct kvm_vcpu *vcpu)
<span class="p_chunk">@@ -69,14 +116,13 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_local_vmid(struct kvm_vcpu *vcpu)</span>
 	struct kvm *kvm = kern_hyp_va(kern_hyp_va(vcpu)-&gt;kvm);
 
 	/* Switch to requested VMID */
<span class="p_del">-	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_del">-	isb();</span>
<span class="p_add">+	__tlb_switch_to_guest()(kvm);</span>
 
 	asm volatile(&quot;tlbi vmalle1&quot; : : );
 	dsb(nsh);
 	isb();
 
<span class="p_del">-	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	__tlb_switch_to_host()(kvm);</span>
 }
 
 void __hyp_text __kvm_flush_vm_context(void)
<span class="p_header">diff --git a/arch/powerpc/crypto/crc32c-vpmsum_glue.c b/arch/powerpc/crypto/crc32c-vpmsum_glue.c</span>
<span class="p_header">index 9fa046d56eba..411994551afc 100644</span>
<span class="p_header">--- a/arch/powerpc/crypto/crc32c-vpmsum_glue.c</span>
<span class="p_header">+++ b/arch/powerpc/crypto/crc32c-vpmsum_glue.c</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"> static int crc32c_vpmsum_cra_init(struct crypto_tfm *tfm)</span>
 {
 	u32 *key = crypto_tfm_ctx(tfm);
 
<span class="p_del">-	*key = 0;</span>
<span class="p_add">+	*key = ~0;</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu_context.h b/arch/powerpc/include/asm/mmu_context.h</span>
<span class="p_header">index 5c451140660a..b9e3f0aca261 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -19,16 +19,18 @@</span> <span class="p_context"> extern void destroy_context(struct mm_struct *mm);</span>
 struct mm_iommu_table_group_mem_t;
 
 extern int isolate_lru_page(struct page *page);	/* from internal.h */
<span class="p_del">-extern bool mm_iommu_preregistered(void);</span>
<span class="p_del">-extern long mm_iommu_get(unsigned long ua, unsigned long entries,</span>
<span class="p_add">+extern bool mm_iommu_preregistered(struct mm_struct *mm);</span>
<span class="p_add">+extern long mm_iommu_get(struct mm_struct *mm,</span>
<span class="p_add">+		unsigned long ua, unsigned long entries,</span>
 		struct mm_iommu_table_group_mem_t **pmem);
<span class="p_del">-extern long mm_iommu_put(struct mm_iommu_table_group_mem_t *mem);</span>
<span class="p_del">-extern void mm_iommu_init(mm_context_t *ctx);</span>
<span class="p_del">-extern void mm_iommu_cleanup(mm_context_t *ctx);</span>
<span class="p_del">-extern struct mm_iommu_table_group_mem_t *mm_iommu_lookup(unsigned long ua,</span>
<span class="p_del">-		unsigned long size);</span>
<span class="p_del">-extern struct mm_iommu_table_group_mem_t *mm_iommu_find(unsigned long ua,</span>
<span class="p_del">-		unsigned long entries);</span>
<span class="p_add">+extern long mm_iommu_put(struct mm_struct *mm,</span>
<span class="p_add">+		struct mm_iommu_table_group_mem_t *mem);</span>
<span class="p_add">+extern void mm_iommu_init(struct mm_struct *mm);</span>
<span class="p_add">+extern void mm_iommu_cleanup(struct mm_struct *mm);</span>
<span class="p_add">+extern struct mm_iommu_table_group_mem_t *mm_iommu_lookup(struct mm_struct *mm,</span>
<span class="p_add">+		unsigned long ua, unsigned long size);</span>
<span class="p_add">+extern struct mm_iommu_table_group_mem_t *mm_iommu_find(struct mm_struct *mm,</span>
<span class="p_add">+		unsigned long ua, unsigned long entries);</span>
 extern long mm_iommu_ua_to_hpa(struct mm_iommu_table_group_mem_t *mem,
 		unsigned long ua, unsigned long *hpa);
 extern long mm_iommu_mapped_inc(struct mm_iommu_table_group_mem_t *mem);
<span class="p_header">diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c</span>
<span class="p_header">index 270ee30abdcf..f516ac508ae3 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/setup-common.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="p_chunk">@@ -915,7 +915,7 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 	init_mm.context.pte_frag = NULL;
 #endif
 #ifdef CONFIG_SPAPR_TCE_IOMMU
<span class="p_del">-	mm_iommu_init(&amp;init_mm.context);</span>
<span class="p_add">+	mm_iommu_init(&amp;init_mm);</span>
 #endif
 	irqstack_early_init();
 	exc_lvl_early_init();
<span class="p_header">diff --git a/arch/powerpc/mm/mmu_context_book3s64.c b/arch/powerpc/mm/mmu_context_book3s64.c</span>
<span class="p_header">index b114f8b93ec9..73bf6e14c3aa 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/mmu_context_book3s64.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/mmu_context_book3s64.c</span>
<span class="p_chunk">@@ -115,7 +115,7 @@</span> <span class="p_context"> int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
 	mm-&gt;context.pte_frag = NULL;
 #endif
 #ifdef CONFIG_SPAPR_TCE_IOMMU
<span class="p_del">-	mm_iommu_init(&amp;mm-&gt;context);</span>
<span class="p_add">+	mm_iommu_init(mm);</span>
 #endif
 	return 0;
 }
<span class="p_chunk">@@ -156,13 +156,11 @@</span> <span class="p_context"> static inline void destroy_pagetable_page(struct mm_struct *mm)</span>
 }
 #endif
 
<span class="p_del">-</span>
 void destroy_context(struct mm_struct *mm)
 {
 #ifdef CONFIG_SPAPR_TCE_IOMMU
<span class="p_del">-	mm_iommu_cleanup(&amp;mm-&gt;context);</span>
<span class="p_add">+	WARN_ON_ONCE(!list_empty(&amp;mm-&gt;context.iommu_group_mem_list));</span>
 #endif
<span class="p_del">-</span>
 #ifdef CONFIG_PPC_ICSWX
 	drop_cop(mm-&gt;context.acop, mm);
 	kfree(mm-&gt;context.cop_lockp);
<span class="p_header">diff --git a/arch/powerpc/mm/mmu_context_iommu.c b/arch/powerpc/mm/mmu_context_iommu.c</span>
<span class="p_header">index e0f1c33601dd..7de7124ac91b 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/mmu_context_iommu.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/mmu_context_iommu.c</span>
<span class="p_chunk">@@ -56,7 +56,7 @@</span> <span class="p_context"> static long mm_iommu_adjust_locked_vm(struct mm_struct *mm,</span>
 	}
 
 	pr_debug(&quot;[%d] RLIMIT_MEMLOCK HASH64 %c%ld %ld/%ld\n&quot;,
<span class="p_del">-			current-&gt;pid,</span>
<span class="p_add">+			current ? current-&gt;pid : 0,</span>
 			incr ? &#39;+&#39; : &#39;-&#39;,
 			npages &lt;&lt; PAGE_SHIFT,
 			mm-&gt;locked_vm &lt;&lt; PAGE_SHIFT,
<span class="p_chunk">@@ -66,12 +66,9 @@</span> <span class="p_context"> static long mm_iommu_adjust_locked_vm(struct mm_struct *mm,</span>
 	return ret;
 }
 
<span class="p_del">-bool mm_iommu_preregistered(void)</span>
<span class="p_add">+bool mm_iommu_preregistered(struct mm_struct *mm)</span>
 {
<span class="p_del">-	if (!current || !current-&gt;mm)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	return !list_empty(&amp;current-&gt;mm-&gt;context.iommu_group_mem_list);</span>
<span class="p_add">+	return !list_empty(&amp;mm-&gt;context.iommu_group_mem_list);</span>
 }
 EXPORT_SYMBOL_GPL(mm_iommu_preregistered);
 
<span class="p_chunk">@@ -124,19 +121,16 @@</span> <span class="p_context"> static int mm_iommu_move_page_from_cma(struct page *page)</span>
 	return 0;
 }
 
<span class="p_del">-long mm_iommu_get(unsigned long ua, unsigned long entries,</span>
<span class="p_add">+long mm_iommu_get(struct mm_struct *mm, unsigned long ua, unsigned long entries,</span>
 		struct mm_iommu_table_group_mem_t **pmem)
 {
 	struct mm_iommu_table_group_mem_t *mem;
 	long i, j, ret = 0, locked_entries = 0;
 	struct page *page = NULL;
 
<span class="p_del">-	if (!current || !current-&gt;mm)</span>
<span class="p_del">-		return -ESRCH; /* process exited */</span>
<span class="p_del">-</span>
 	mutex_lock(&amp;mem_list_mutex);
 
<span class="p_del">-	list_for_each_entry_rcu(mem, &amp;current-&gt;mm-&gt;context.iommu_group_mem_list,</span>
<span class="p_add">+	list_for_each_entry_rcu(mem, &amp;mm-&gt;context.iommu_group_mem_list,</span>
 			next) {
 		if ((mem-&gt;ua == ua) &amp;&amp; (mem-&gt;entries == entries)) {
 			++mem-&gt;used;
<span class="p_chunk">@@ -154,7 +148,7 @@</span> <span class="p_context"> long mm_iommu_get(unsigned long ua, unsigned long entries,</span>
 
 	}
 
<span class="p_del">-	ret = mm_iommu_adjust_locked_vm(current-&gt;mm, entries, true);</span>
<span class="p_add">+	ret = mm_iommu_adjust_locked_vm(mm, entries, true);</span>
 	if (ret)
 		goto unlock_exit;
 
<span class="p_chunk">@@ -190,7 +184,7 @@</span> <span class="p_context"> long mm_iommu_get(unsigned long ua, unsigned long entries,</span>
 		 * of the CMA zone if possible. NOTE: faulting in + migration
 		 * can be expensive. Batching can be considered later
 		 */
<span class="p_del">-		if (get_pageblock_migratetype(page) == MIGRATE_CMA) {</span>
<span class="p_add">+		if (is_migrate_cma_page(page)) {</span>
 			if (mm_iommu_move_page_from_cma(page))
 				goto populate;
 			if (1 != get_user_pages_fast(ua + (i &lt;&lt; PAGE_SHIFT),
<span class="p_chunk">@@ -215,11 +209,11 @@</span> <span class="p_context"> long mm_iommu_get(unsigned long ua, unsigned long entries,</span>
 	mem-&gt;entries = entries;
 	*pmem = mem;
 
<span class="p_del">-	list_add_rcu(&amp;mem-&gt;next, &amp;current-&gt;mm-&gt;context.iommu_group_mem_list);</span>
<span class="p_add">+	list_add_rcu(&amp;mem-&gt;next, &amp;mm-&gt;context.iommu_group_mem_list);</span>
 
 unlock_exit:
 	if (locked_entries &amp;&amp; ret)
<span class="p_del">-		mm_iommu_adjust_locked_vm(current-&gt;mm, locked_entries, false);</span>
<span class="p_add">+		mm_iommu_adjust_locked_vm(mm, locked_entries, false);</span>
 
 	mutex_unlock(&amp;mem_list_mutex);
 
<span class="p_chunk">@@ -264,17 +258,13 @@</span> <span class="p_context"> static void mm_iommu_free(struct rcu_head *head)</span>
 static void mm_iommu_release(struct mm_iommu_table_group_mem_t *mem)
 {
 	list_del_rcu(&amp;mem-&gt;next);
<span class="p_del">-	mm_iommu_adjust_locked_vm(current-&gt;mm, mem-&gt;entries, false);</span>
 	call_rcu(&amp;mem-&gt;rcu, mm_iommu_free);
 }
 
<span class="p_del">-long mm_iommu_put(struct mm_iommu_table_group_mem_t *mem)</span>
<span class="p_add">+long mm_iommu_put(struct mm_struct *mm, struct mm_iommu_table_group_mem_t *mem)</span>
 {
 	long ret = 0;
 
<span class="p_del">-	if (!current || !current-&gt;mm)</span>
<span class="p_del">-		return -ESRCH; /* process exited */</span>
<span class="p_del">-</span>
 	mutex_lock(&amp;mem_list_mutex);
 
 	if (mem-&gt;used == 0) {
<span class="p_chunk">@@ -297,6 +287,8 @@</span> <span class="p_context"> long mm_iommu_put(struct mm_iommu_table_group_mem_t *mem)</span>
 	/* @mapped became 0 so now mappings are disabled, release the region */
 	mm_iommu_release(mem);
 
<span class="p_add">+	mm_iommu_adjust_locked_vm(mm, mem-&gt;entries, false);</span>
<span class="p_add">+</span>
 unlock_exit:
 	mutex_unlock(&amp;mem_list_mutex);
 
<span class="p_chunk">@@ -304,14 +296,12 @@</span> <span class="p_context"> long mm_iommu_put(struct mm_iommu_table_group_mem_t *mem)</span>
 }
 EXPORT_SYMBOL_GPL(mm_iommu_put);
 
<span class="p_del">-struct mm_iommu_table_group_mem_t *mm_iommu_lookup(unsigned long ua,</span>
<span class="p_del">-		unsigned long size)</span>
<span class="p_add">+struct mm_iommu_table_group_mem_t *mm_iommu_lookup(struct mm_struct *mm,</span>
<span class="p_add">+		unsigned long ua, unsigned long size)</span>
 {
 	struct mm_iommu_table_group_mem_t *mem, *ret = NULL;
 
<span class="p_del">-	list_for_each_entry_rcu(mem,</span>
<span class="p_del">-			&amp;current-&gt;mm-&gt;context.iommu_group_mem_list,</span>
<span class="p_del">-			next) {</span>
<span class="p_add">+	list_for_each_entry_rcu(mem, &amp;mm-&gt;context.iommu_group_mem_list, next) {</span>
 		if ((mem-&gt;ua &lt;= ua) &amp;&amp;
 				(ua + size &lt;= mem-&gt;ua +
 				 (mem-&gt;entries &lt;&lt; PAGE_SHIFT))) {
<span class="p_chunk">@@ -324,14 +314,12 @@</span> <span class="p_context"> struct mm_iommu_table_group_mem_t *mm_iommu_lookup(unsigned long ua,</span>
 }
 EXPORT_SYMBOL_GPL(mm_iommu_lookup);
 
<span class="p_del">-struct mm_iommu_table_group_mem_t *mm_iommu_find(unsigned long ua,</span>
<span class="p_del">-		unsigned long entries)</span>
<span class="p_add">+struct mm_iommu_table_group_mem_t *mm_iommu_find(struct mm_struct *mm,</span>
<span class="p_add">+		unsigned long ua, unsigned long entries)</span>
 {
 	struct mm_iommu_table_group_mem_t *mem, *ret = NULL;
 
<span class="p_del">-	list_for_each_entry_rcu(mem,</span>
<span class="p_del">-			&amp;current-&gt;mm-&gt;context.iommu_group_mem_list,</span>
<span class="p_del">-			next) {</span>
<span class="p_add">+	list_for_each_entry_rcu(mem, &amp;mm-&gt;context.iommu_group_mem_list, next) {</span>
 		if ((mem-&gt;ua == ua) &amp;&amp; (mem-&gt;entries == entries)) {
 			ret = mem;
 			break;
<span class="p_chunk">@@ -373,17 +361,7 @@</span> <span class="p_context"> void mm_iommu_mapped_dec(struct mm_iommu_table_group_mem_t *mem)</span>
 }
 EXPORT_SYMBOL_GPL(mm_iommu_mapped_dec);
 
<span class="p_del">-void mm_iommu_init(mm_context_t *ctx)</span>
<span class="p_add">+void mm_iommu_init(struct mm_struct *mm)</span>
 {
<span class="p_del">-	INIT_LIST_HEAD_RCU(&amp;ctx-&gt;iommu_group_mem_list);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void mm_iommu_cleanup(mm_context_t *ctx)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct mm_iommu_table_group_mem_t *mem, *tmp;</span>
<span class="p_del">-</span>
<span class="p_del">-	list_for_each_entry_safe(mem, tmp, &amp;ctx-&gt;iommu_group_mem_list, next) {</span>
<span class="p_del">-		list_del_rcu(&amp;mem-&gt;next);</span>
<span class="p_del">-		mm_iommu_do_free(mem);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	INIT_LIST_HEAD_RCU(&amp;mm-&gt;context.iommu_group_mem_list);</span>
 }
<span class="p_header">diff --git a/arch/x86/events/core.c b/arch/x86/events/core.c</span>
<span class="p_header">index 7fe88bb57e36..38623e219816 100644</span>
<span class="p_header">--- a/arch/x86/events/core.c</span>
<span class="p_header">+++ b/arch/x86/events/core.c</span>
<span class="p_chunk">@@ -2096,8 +2096,8 @@</span> <span class="p_context"> static int x86_pmu_event_init(struct perf_event *event)</span>
 
 static void refresh_pce(void *ignored)
 {
<span class="p_del">-	if (current-&gt;mm)</span>
<span class="p_del">-		load_mm_cr4(current-&gt;mm);</span>
<span class="p_add">+	if (current-&gt;active_mm)</span>
<span class="p_add">+		load_mm_cr4(current-&gt;active_mm);</span>
 }
 
 static void x86_pmu_event_mapped(struct perf_event *event)
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mshyperv.c b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_header">index 8f44c5a50ab8..f228f74051b6 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_chunk">@@ -31,6 +31,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/apic.h&gt;
 #include &lt;asm/timer.h&gt;
 #include &lt;asm/reboot.h&gt;
<span class="p_add">+#include &lt;asm/nmi.h&gt;</span>
 
 struct ms_hyperv_info ms_hyperv;
 EXPORT_SYMBOL_GPL(ms_hyperv);
<span class="p_chunk">@@ -158,6 +159,26 @@</span> <span class="p_context"> static unsigned char hv_get_nmi_reason(void)</span>
 	return 0;
 }
 
<span class="p_add">+#ifdef CONFIG_X86_LOCAL_APIC</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Prior to WS2016 Debug-VM sends NMIs to all CPUs which makes</span>
<span class="p_add">+ * it dificult to process CHANNELMSG_UNLOAD in case of crash. Handle</span>
<span class="p_add">+ * unknown NMI on the first CPU which gets it.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int hv_nmi_unknown(unsigned int val, struct pt_regs *regs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	static atomic_t nmi_cpu = ATOMIC_INIT(-1);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!unknown_nmi_panic)</span>
<span class="p_add">+		return NMI_DONE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (atomic_cmpxchg(&amp;nmi_cpu, -1, raw_smp_processor_id()) != -1)</span>
<span class="p_add">+		return NMI_HANDLED;</span>
<span class="p_add">+</span>
<span class="p_add">+	return NMI_DONE;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 static void __init ms_hyperv_init_platform(void)
 {
 	/*
<span class="p_chunk">@@ -183,6 +204,9 @@</span> <span class="p_context"> static void __init ms_hyperv_init_platform(void)</span>
 		pr_info(&quot;HyperV: LAPIC Timer Frequency: %#x\n&quot;,
 			lapic_timer_frequency);
 	}
<span class="p_add">+</span>
<span class="p_add">+	register_nmi_handler(NMI_UNKNOWN, hv_nmi_unknown, NMI_FLAG_FIRST,</span>
<span class="p_add">+			     &quot;hv_nmi_unknown&quot;);</span>
 #endif
 
 	if (ms_hyperv.features &amp; HV_X64_MSR_TIME_REF_COUNT_AVAILABLE)
<span class="p_header">diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c</span>
<span class="p_header">index 54a2372f5dbb..b5785c197e53 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/head64.c</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
  *  Copyright (C) 2000 Andrea Arcangeli &lt;andrea@suse.de&gt; SuSE
  */
 
<span class="p_add">+#define DISABLE_BRANCH_PROFILING</span>
 #include &lt;linux/init.h&gt;
 #include &lt;linux/linkage.h&gt;
 #include &lt;linux/types.h&gt;
<span class="p_header">diff --git a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c</span>
<span class="p_header">index 46b2f41f8b05..eea88fe5d969 100644</span>
<span class="p_header">--- a/arch/x86/kernel/tsc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/tsc.c</span>
<span class="p_chunk">@@ -1287,6 +1287,8 @@</span> <span class="p_context"> static int __init init_tsc_clocksource(void)</span>
 	 * exporting a reliable TSC.
 	 */
 	if (boot_cpu_has(X86_FEATURE_TSC_RELIABLE)) {
<span class="p_add">+		if (boot_cpu_has(X86_FEATURE_ART))</span>
<span class="p_add">+			art_related_clocksource = &amp;clocksource_tsc;</span>
 		clocksource_register_khz(&amp;clocksource_tsc, tsc_khz);
 		return 0;
 	}
<span class="p_header">diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">index 0493c17b8a51..333362f992e4 100644</span>
<span class="p_header">--- a/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_chunk">@@ -1,3 +1,4 @@</span> <span class="p_context"></span>
<span class="p_add">+#define DISABLE_BRANCH_PROFILING</span>
 #define pr_fmt(fmt) &quot;kasan: &quot; fmt
 #include &lt;linux/bootmem.h&gt;
 #include &lt;linux/kasan.h&gt;
<span class="p_header">diff --git a/arch/x86/pci/xen.c b/arch/x86/pci/xen.c</span>
<span class="p_header">index bedfab98077a..a00a6c07bb6f 100644</span>
<span class="p_header">--- a/arch/x86/pci/xen.c</span>
<span class="p_header">+++ b/arch/x86/pci/xen.c</span>
<span class="p_chunk">@@ -234,23 +234,14 @@</span> <span class="p_context"> static int xen_hvm_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)</span>
 		return 1;
 
 	for_each_pci_msi_entry(msidesc, dev) {
<span class="p_del">-		__pci_read_msi_msg(msidesc, &amp;msg);</span>
<span class="p_del">-		pirq = MSI_ADDR_EXT_DEST_ID(msg.address_hi) |</span>
<span class="p_del">-			((msg.address_lo &gt;&gt; MSI_ADDR_DEST_ID_SHIFT) &amp; 0xff);</span>
<span class="p_del">-		if (msg.data != XEN_PIRQ_MSI_DATA ||</span>
<span class="p_del">-		    xen_irq_from_pirq(pirq) &lt; 0) {</span>
<span class="p_del">-			pirq = xen_allocate_pirq_msi(dev, msidesc);</span>
<span class="p_del">-			if (pirq &lt; 0) {</span>
<span class="p_del">-				irq = -ENODEV;</span>
<span class="p_del">-				goto error;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			xen_msi_compose_msg(dev, pirq, &amp;msg);</span>
<span class="p_del">-			__pci_write_msi_msg(msidesc, &amp;msg);</span>
<span class="p_del">-			dev_dbg(&amp;dev-&gt;dev, &quot;xen: msi bound to pirq=%d\n&quot;, pirq);</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			dev_dbg(&amp;dev-&gt;dev,</span>
<span class="p_del">-				&quot;xen: msi already bound to pirq=%d\n&quot;, pirq);</span>
<span class="p_add">+		pirq = xen_allocate_pirq_msi(dev, msidesc);</span>
<span class="p_add">+		if (pirq &lt; 0) {</span>
<span class="p_add">+			irq = -ENODEV;</span>
<span class="p_add">+			goto error;</span>
 		}
<span class="p_add">+		xen_msi_compose_msg(dev, pirq, &amp;msg);</span>
<span class="p_add">+		__pci_write_msi_msg(msidesc, &amp;msg);</span>
<span class="p_add">+		dev_dbg(&amp;dev-&gt;dev, &quot;xen: msi bound to pirq=%d\n&quot;, pirq);</span>
 		irq = xen_bind_pirq_msi_to_irq(dev, msidesc, pirq,
 					       (type == PCI_CAP_ID_MSI) ? nvec : 1,
 					       (type == PCI_CAP_ID_MSIX) ?
<span class="p_header">diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c</span>
<span class="p_header">index 0774799942e0..c6fee7437be4 100644</span>
<span class="p_header">--- a/block/scsi_ioctl.c</span>
<span class="p_header">+++ b/block/scsi_ioctl.c</span>
<span class="p_chunk">@@ -182,6 +182,9 @@</span> <span class="p_context"> static void blk_set_cmd_filter_defaults(struct blk_cmd_filter *filter)</span>
 	__set_bit(WRITE_16, filter-&gt;write_ok);
 	__set_bit(WRITE_LONG, filter-&gt;write_ok);
 	__set_bit(WRITE_LONG_2, filter-&gt;write_ok);
<span class="p_add">+	__set_bit(WRITE_SAME, filter-&gt;write_ok);</span>
<span class="p_add">+	__set_bit(WRITE_SAME_16, filter-&gt;write_ok);</span>
<span class="p_add">+	__set_bit(WRITE_SAME_32, filter-&gt;write_ok);</span>
 	__set_bit(ERASE, filter-&gt;write_ok);
 	__set_bit(GPCMD_MODE_SELECT_10, filter-&gt;write_ok);
 	__set_bit(MODE_SELECT, filter-&gt;write_ok);
<span class="p_header">diff --git a/drivers/acpi/blacklist.c b/drivers/acpi/blacklist.c</span>
<span class="p_header">index bdc67bad61a7..4421f7c9981c 100644</span>
<span class="p_header">--- a/drivers/acpi/blacklist.c</span>
<span class="p_header">+++ b/drivers/acpi/blacklist.c</span>
<span class="p_chunk">@@ -160,6 +160,34 @@</span> <span class="p_context"> static struct dmi_system_id acpi_rev_dmi_table[] __initdata = {</span>
 		      DMI_MATCH(DMI_PRODUCT_NAME, &quot;XPS 13 9343&quot;),
 		},
 	},
<span class="p_add">+	{</span>
<span class="p_add">+	 .callback = dmi_enable_rev_override,</span>
<span class="p_add">+	 .ident = &quot;DELL Precision 5520&quot;,</span>
<span class="p_add">+	 .matches = {</span>
<span class="p_add">+		      DMI_MATCH(DMI_SYS_VENDOR, &quot;Dell Inc.&quot;),</span>
<span class="p_add">+		      DMI_MATCH(DMI_PRODUCT_NAME, &quot;Precision 5520&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+	 .callback = dmi_enable_rev_override,</span>
<span class="p_add">+	 .ident = &quot;DELL Precision 3520&quot;,</span>
<span class="p_add">+	 .matches = {</span>
<span class="p_add">+		      DMI_MATCH(DMI_SYS_VENDOR, &quot;Dell Inc.&quot;),</span>
<span class="p_add">+		      DMI_MATCH(DMI_PRODUCT_NAME, &quot;Precision 3520&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Resolves a quirk with the Dell Latitude 3350 that</span>
<span class="p_add">+	 * causes the ethernet adapter to not function.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	{</span>
<span class="p_add">+	 .callback = dmi_enable_rev_override,</span>
<span class="p_add">+	 .ident = &quot;DELL Latitude 3350&quot;,</span>
<span class="p_add">+	 .matches = {</span>
<span class="p_add">+		      DMI_MATCH(DMI_SYS_VENDOR, &quot;Dell Inc.&quot;),</span>
<span class="p_add">+		      DMI_MATCH(DMI_PRODUCT_NAME, &quot;Latitude 3350&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
 #endif
 	{}
 };
<span class="p_header">diff --git a/drivers/clk/bcm/clk-bcm2835.c b/drivers/clk/bcm/clk-bcm2835.c</span>
<span class="p_header">index 3bbd2a58db47..2acaa77ad482 100644</span>
<span class="p_header">--- a/drivers/clk/bcm/clk-bcm2835.c</span>
<span class="p_header">+++ b/drivers/clk/bcm/clk-bcm2835.c</span>
<span class="p_chunk">@@ -1598,7 +1598,7 @@</span> <span class="p_context"> static const struct bcm2835_clk_desc clk_desc_array[] = {</span>
 		.a2w_reg = A2W_PLLH_AUX,
 		.load_mask = CM_PLLH_LOADAUX,
 		.hold_mask = 0,
<span class="p_del">-		.fixed_divider = 10),</span>
<span class="p_add">+		.fixed_divider = 1),</span>
 	[BCM2835_PLLH_PIX]	= REGISTER_PLL_DIV(
 		.name = &quot;pllh_pix&quot;,
 		.source_pll = &quot;pllh&quot;,
<span class="p_header">diff --git a/drivers/dma/ioat/init.c b/drivers/dma/ioat/init.c</span>
<span class="p_header">index 015f7110b96d..d235fbe2564f 100644</span>
<span class="p_header">--- a/drivers/dma/ioat/init.c</span>
<span class="p_header">+++ b/drivers/dma/ioat/init.c</span>
<span class="p_chunk">@@ -691,7 +691,7 @@</span> <span class="p_context"> static int ioat_alloc_chan_resources(struct dma_chan *c)</span>
 	/* doing 2 32bit writes to mmio since 1 64b write doesn&#39;t work */
 	ioat_chan-&gt;completion =
 		dma_pool_zalloc(ioat_chan-&gt;ioat_dma-&gt;completion_pool,
<span class="p_del">-				GFP_KERNEL, &amp;ioat_chan-&gt;completion_dma);</span>
<span class="p_add">+				GFP_NOWAIT, &amp;ioat_chan-&gt;completion_dma);</span>
 	if (!ioat_chan-&gt;completion)
 		return -ENOMEM;
 
<span class="p_chunk">@@ -701,7 +701,7 @@</span> <span class="p_context"> static int ioat_alloc_chan_resources(struct dma_chan *c)</span>
 	       ioat_chan-&gt;reg_base + IOAT_CHANCMP_OFFSET_HIGH);
 
 	order = IOAT_MAX_ORDER;
<span class="p_del">-	ring = ioat_alloc_ring(c, order, GFP_KERNEL);</span>
<span class="p_add">+	ring = ioat_alloc_ring(c, order, GFP_NOWAIT);</span>
 	if (!ring)
 		return -ENOMEM;
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/Kbuild b/drivers/gpu/drm/nouveau/nvkm/engine/disp/Kbuild</span>
<span class="p_header">index 77a52b54a31e..70f0344c508c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/Kbuild</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/Kbuild</span>
<span class="p_chunk">@@ -95,9 +95,11 @@</span> <span class="p_context"> nvkm-y += nvkm/engine/disp/cursg84.o</span>
 nvkm-y += nvkm/engine/disp/cursgt215.o
 nvkm-y += nvkm/engine/disp/cursgf119.o
 nvkm-y += nvkm/engine/disp/cursgk104.o
<span class="p_add">+nvkm-y += nvkm/engine/disp/cursgp102.o</span>
 
 nvkm-y += nvkm/engine/disp/oimmnv50.o
 nvkm-y += nvkm/engine/disp/oimmg84.o
 nvkm-y += nvkm/engine/disp/oimmgt215.o
 nvkm-y += nvkm/engine/disp/oimmgf119.o
 nvkm-y += nvkm/engine/disp/oimmgk104.o
<span class="p_add">+nvkm-y += nvkm/engine/disp/oimmgp102.o</span>
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.c</span>
<span class="p_header">index dd2953bc9264..9d90d8b4b7e6 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.c</span>
<span class="p_chunk">@@ -82,7 +82,7 @@</span> <span class="p_context"> nv50_disp_chan_mthd(struct nv50_disp_chan *chan, int debug)</span>
 
 			if (mthd-&gt;addr) {
 				snprintf(cname_, sizeof(cname_), &quot;%s %d&quot;,
<span class="p_del">-					 mthd-&gt;name, chan-&gt;chid);</span>
<span class="p_add">+					 mthd-&gt;name, chan-&gt;chid.user);</span>
 				cname = cname_;
 			}
 
<span class="p_chunk">@@ -139,7 +139,7 @@</span> <span class="p_context"> nv50_disp_chan_uevent_ctor(struct nvkm_object *object, void *data, u32 size,</span>
 	if (!(ret = nvif_unvers(ret, &amp;data, &amp;size, args-&gt;none))) {
 		notify-&gt;size  = sizeof(struct nvif_notify_uevent_rep);
 		notify-&gt;types = 1;
<span class="p_del">-		notify-&gt;index = chan-&gt;chid;</span>
<span class="p_add">+		notify-&gt;index = chan-&gt;chid.user;</span>
 		return 0;
 	}
 
<span class="p_chunk">@@ -159,7 +159,7 @@</span> <span class="p_context"> nv50_disp_chan_rd32(struct nvkm_object *object, u64 addr, u32 *data)</span>
 	struct nv50_disp_chan *chan = nv50_disp_chan(object);
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_device *device = disp-&gt;base.engine.subdev.device;
<span class="p_del">-	*data = nvkm_rd32(device, 0x640000 + (chan-&gt;chid * 0x1000) + addr);</span>
<span class="p_add">+	*data = nvkm_rd32(device, 0x640000 + (chan-&gt;chid.user * 0x1000) + addr);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -169,7 +169,7 @@</span> <span class="p_context"> nv50_disp_chan_wr32(struct nvkm_object *object, u64 addr, u32 data)</span>
 	struct nv50_disp_chan *chan = nv50_disp_chan(object);
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_device *device = disp-&gt;base.engine.subdev.device;
<span class="p_del">-	nvkm_wr32(device, 0x640000 + (chan-&gt;chid * 0x1000) + addr, data);</span>
<span class="p_add">+	nvkm_wr32(device, 0x640000 + (chan-&gt;chid.user * 0x1000) + addr, data);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -196,7 +196,7 @@</span> <span class="p_context"> nv50_disp_chan_map(struct nvkm_object *object, u64 *addr, u32 *size)</span>
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_device *device = disp-&gt;base.engine.subdev.device;
 	*addr = device-&gt;func-&gt;resource_addr(device, 0) +
<span class="p_del">-		0x640000 + (chan-&gt;chid * 0x1000);</span>
<span class="p_add">+		0x640000 + (chan-&gt;chid.user * 0x1000);</span>
 	*size = 0x001000;
 	return 0;
 }
<span class="p_chunk">@@ -243,8 +243,8 @@</span> <span class="p_context"> nv50_disp_chan_dtor(struct nvkm_object *object)</span>
 {
 	struct nv50_disp_chan *chan = nv50_disp_chan(object);
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
<span class="p_del">-	if (chan-&gt;chid &gt;= 0)</span>
<span class="p_del">-		disp-&gt;chan[chan-&gt;chid] = NULL;</span>
<span class="p_add">+	if (chan-&gt;chid.user &gt;= 0)</span>
<span class="p_add">+		disp-&gt;chan[chan-&gt;chid.user] = NULL;</span>
 	return chan-&gt;func-&gt;dtor ? chan-&gt;func-&gt;dtor(chan) : chan;
 }
 
<span class="p_chunk">@@ -263,7 +263,7 @@</span> <span class="p_context"> nv50_disp_chan = {</span>
 int
 nv50_disp_chan_ctor(const struct nv50_disp_chan_func *func,
 		    const struct nv50_disp_chan_mthd *mthd,
<span class="p_del">-		    struct nv50_disp_root *root, int chid, int head,</span>
<span class="p_add">+		    struct nv50_disp_root *root, int ctrl, int user, int head,</span>
 		    const struct nvkm_oclass *oclass,
 		    struct nv50_disp_chan *chan)
 {
<span class="p_chunk">@@ -273,21 +273,22 @@</span> <span class="p_context"> nv50_disp_chan_ctor(const struct nv50_disp_chan_func *func,</span>
 	chan-&gt;func = func;
 	chan-&gt;mthd = mthd;
 	chan-&gt;root = root;
<span class="p_del">-	chan-&gt;chid = chid;</span>
<span class="p_add">+	chan-&gt;chid.ctrl = ctrl;</span>
<span class="p_add">+	chan-&gt;chid.user = user;</span>
 	chan-&gt;head = head;
 
<span class="p_del">-	if (disp-&gt;chan[chan-&gt;chid]) {</span>
<span class="p_del">-		chan-&gt;chid = -1;</span>
<span class="p_add">+	if (disp-&gt;chan[chan-&gt;chid.user]) {</span>
<span class="p_add">+		chan-&gt;chid.user = -1;</span>
 		return -EBUSY;
 	}
<span class="p_del">-	disp-&gt;chan[chan-&gt;chid] = chan;</span>
<span class="p_add">+	disp-&gt;chan[chan-&gt;chid.user] = chan;</span>
 	return 0;
 }
 
 int
 nv50_disp_chan_new_(const struct nv50_disp_chan_func *func,
 		    const struct nv50_disp_chan_mthd *mthd,
<span class="p_del">-		    struct nv50_disp_root *root, int chid, int head,</span>
<span class="p_add">+		    struct nv50_disp_root *root, int ctrl, int user, int head,</span>
 		    const struct nvkm_oclass *oclass,
 		    struct nvkm_object **pobject)
 {
<span class="p_chunk">@@ -297,5 +298,6 @@</span> <span class="p_context"> nv50_disp_chan_new_(const struct nv50_disp_chan_func *func,</span>
 		return -ENOMEM;
 	*pobject = &amp;chan-&gt;object;
 
<span class="p_del">-	return nv50_disp_chan_ctor(func, mthd, root, chid, head, oclass, chan);</span>
<span class="p_add">+	return nv50_disp_chan_ctor(func, mthd, root, ctrl, user,</span>
<span class="p_add">+				   head, oclass, chan);</span>
 }
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.h b/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.h</span>
<span class="p_header">index f5f683d9fd20..737b38f6fbd2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/channv50.h</span>
<span class="p_chunk">@@ -7,7 +7,11 @@</span> <span class="p_context"> struct nv50_disp_chan {</span>
 	const struct nv50_disp_chan_func *func;
 	const struct nv50_disp_chan_mthd *mthd;
 	struct nv50_disp_root *root;
<span class="p_del">-	int chid;</span>
<span class="p_add">+</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		int ctrl;</span>
<span class="p_add">+		int user;</span>
<span class="p_add">+	} chid;</span>
 	int head;
 
 	struct nvkm_object object;
<span class="p_chunk">@@ -25,11 +29,11 @@</span> <span class="p_context"> struct nv50_disp_chan_func {</span>
 
 int nv50_disp_chan_ctor(const struct nv50_disp_chan_func *,
 			const struct nv50_disp_chan_mthd *,
<span class="p_del">-			struct nv50_disp_root *, int chid, int head,</span>
<span class="p_add">+			struct nv50_disp_root *, int ctrl, int user, int head,</span>
 			const struct nvkm_oclass *, struct nv50_disp_chan *);
 int nv50_disp_chan_new_(const struct nv50_disp_chan_func *,
 			const struct nv50_disp_chan_mthd *,
<span class="p_del">-			struct nv50_disp_root *, int chid, int head,</span>
<span class="p_add">+			struct nv50_disp_root *, int ctrl, int user, int head,</span>
 			const struct nvkm_oclass *, struct nvkm_object **);
 
 extern const struct nv50_disp_chan_func nv50_disp_pioc_func;
<span class="p_chunk">@@ -90,13 +94,16 @@</span> <span class="p_context"> extern const struct nv50_disp_chan_mthd gk104_disp_ovly_chan_mthd;</span>
 struct nv50_disp_pioc_oclass {
 	int (*ctor)(const struct nv50_disp_chan_func *,
 		    const struct nv50_disp_chan_mthd *,
<span class="p_del">-		    struct nv50_disp_root *, int chid,</span>
<span class="p_add">+		    struct nv50_disp_root *, int ctrl, int user,</span>
 		    const struct nvkm_oclass *, void *data, u32 size,
 		    struct nvkm_object **);
 	struct nvkm_sclass base;
 	const struct nv50_disp_chan_func *func;
 	const struct nv50_disp_chan_mthd *mthd;
<span class="p_del">-	int chid;</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		int ctrl;</span>
<span class="p_add">+		int user;</span>
<span class="p_add">+	} chid;</span>
 };
 
 extern const struct nv50_disp_pioc_oclass nv50_disp_oimm_oclass;
<span class="p_chunk">@@ -114,15 +121,17 @@</span> <span class="p_context"> extern const struct nv50_disp_pioc_oclass gf119_disp_curs_oclass;</span>
 extern const struct nv50_disp_pioc_oclass gk104_disp_oimm_oclass;
 extern const struct nv50_disp_pioc_oclass gk104_disp_curs_oclass;
 
<span class="p_add">+extern const struct nv50_disp_pioc_oclass gp102_disp_oimm_oclass;</span>
<span class="p_add">+extern const struct nv50_disp_pioc_oclass gp102_disp_curs_oclass;</span>
 
 int nv50_disp_curs_new(const struct nv50_disp_chan_func *,
 		       const struct nv50_disp_chan_mthd *,
<span class="p_del">-		       struct nv50_disp_root *, int chid,</span>
<span class="p_add">+		       struct nv50_disp_root *, int ctrl, int user,</span>
 		       const struct nvkm_oclass *, void *data, u32 size,
 		       struct nvkm_object **);
 int nv50_disp_oimm_new(const struct nv50_disp_chan_func *,
 		       const struct nv50_disp_chan_mthd *,
<span class="p_del">-		       struct nv50_disp_root *, int chid,</span>
<span class="p_add">+		       struct nv50_disp_root *, int ctrl, int user,</span>
 		       const struct nvkm_oclass *, void *data, u32 size,
 		       struct nvkm_object **);
 #endif
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursg84.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursg84.c</span>
<span class="p_header">index dd99fc7060b1..fa781b5a7e07 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursg84.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursg84.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> g84_disp_curs_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_curs_new,
 	.func = &amp;nv50_disp_pioc_func,
<span class="p_del">-	.chid = 7,</span>
<span class="p_add">+	.chid = { 7, 7 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgf119.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgf119.c</span>
<span class="p_header">index 2a1574e06ad6..2be6fb052c65 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgf119.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgf119.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> gf119_disp_curs_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_curs_new,
 	.func = &amp;gf119_disp_pioc_func,
<span class="p_del">-	.chid = 13,</span>
<span class="p_add">+	.chid = { 13, 13 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgk104.c</span>
<span class="p_header">index 28e8f06c9472..2a99db4bf8f8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgk104.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgk104.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> gk104_disp_curs_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_curs_new,
 	.func = &amp;gf119_disp_pioc_func,
<span class="p_del">-	.chid = 13,</span>
<span class="p_add">+	.chid = { 13, 13 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgp102.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgp102.c</span>
new file mode 100644
<span class="p_header">index 000000000000..e958210d8105</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgp102.c</span>
<span class="p_chunk">@@ -0,0 +1,37 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright 2016 Red Hat Inc.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="p_add">+ * copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="p_add">+ * to deal in the Software without restriction, including without limitation</span>
<span class="p_add">+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="p_add">+ * and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="p_add">+ * Software is furnished to do so, subject to the following conditions:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The above copyright notice and this permission notice shall be included in</span>
<span class="p_add">+ * all copies or substantial portions of the Software.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="p_add">+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="p_add">+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL</span>
<span class="p_add">+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR</span>
<span class="p_add">+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,</span>
<span class="p_add">+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR</span>
<span class="p_add">+ * OTHER DEALINGS IN THE SOFTWARE.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors: Ben Skeggs &lt;bskeggs@redhat.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &quot;channv50.h&quot;</span>
<span class="p_add">+#include &quot;rootnv50.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;nvif/class.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+const struct nv50_disp_pioc_oclass</span>
<span class="p_add">+gp102_disp_curs_oclass = {</span>
<span class="p_add">+	.base.oclass = GK104_DISP_CURSOR,</span>
<span class="p_add">+	.base.minver = 0,</span>
<span class="p_add">+	.base.maxver = 0,</span>
<span class="p_add">+	.ctor = nv50_disp_curs_new,</span>
<span class="p_add">+	.func = &amp;gf119_disp_pioc_func,</span>
<span class="p_add">+	.chid = { 13, 17 },</span>
<span class="p_add">+};</span>
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgt215.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgt215.c</span>
<span class="p_header">index d8a4b9ca139c..00a7f3564450 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgt215.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursgt215.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> gt215_disp_curs_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_curs_new,
 	.func = &amp;nv50_disp_pioc_func,
<span class="p_del">-	.chid = 7,</span>
<span class="p_add">+	.chid = { 7, 7 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursnv50.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursnv50.c</span>
<span class="p_header">index 8b1320499a0f..82ff82d8c1ab 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursnv50.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/cursnv50.c</span>
<span class="p_chunk">@@ -33,7 +33,7 @@</span> <span class="p_context"></span>
 int
 nv50_disp_curs_new(const struct nv50_disp_chan_func *func,
 		   const struct nv50_disp_chan_mthd *mthd,
<span class="p_del">-		   struct nv50_disp_root *root, int chid,</span>
<span class="p_add">+		   struct nv50_disp_root *root, int ctrl, int user,</span>
 		   const struct nvkm_oclass *oclass, void *data, u32 size,
 		   struct nvkm_object **pobject)
 {
<span class="p_chunk">@@ -54,7 +54,7 @@</span> <span class="p_context"> nv50_disp_curs_new(const struct nv50_disp_chan_func *func,</span>
 	} else
 		return ret;
 
<span class="p_del">-	return nv50_disp_chan_new_(func, mthd, root, chid + head,</span>
<span class="p_add">+	return nv50_disp_chan_new_(func, mthd, root, ctrl + head, user + head,</span>
 				   head, oclass, pobject);
 }
 
<span class="p_chunk">@@ -65,5 +65,5 @@</span> <span class="p_context"> nv50_disp_curs_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_curs_new,
 	.func = &amp;nv50_disp_pioc_func,
<span class="p_del">-	.chid = 7,</span>
<span class="p_add">+	.chid = { 7, 7 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgf119.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgf119.c</span>
<span class="p_header">index a57f7cef307a..ce7cd74fbd5d 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgf119.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgf119.c</span>
<span class="p_chunk">@@ -32,8 +32,8 @@</span> <span class="p_context"> gf119_disp_dmac_bind(struct nv50_disp_dmac *chan,</span>
 		     struct nvkm_object *object, u32 handle)
 {
 	return nvkm_ramht_insert(chan-&gt;base.root-&gt;ramht, object,
<span class="p_del">-				 chan-&gt;base.chid, -9, handle,</span>
<span class="p_del">-				 chan-&gt;base.chid &lt;&lt; 27 | 0x00000001);</span>
<span class="p_add">+				 chan-&gt;base.chid.user, -9, handle,</span>
<span class="p_add">+				 chan-&gt;base.chid.user &lt;&lt; 27 | 0x00000001);</span>
 }
 
 void
<span class="p_chunk">@@ -42,22 +42,23 @@</span> <span class="p_context"> gf119_disp_dmac_fini(struct nv50_disp_dmac *chan)</span>
 	struct nv50_disp *disp = chan-&gt;base.root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;base.chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;base.chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;base.chid.user;</span>
 
 	/* deactivate channel */
<span class="p_del">-	nvkm_mask(device, 0x610490 + (chid * 0x0010), 0x00001010, 0x00001000);</span>
<span class="p_del">-	nvkm_mask(device, 0x610490 + (chid * 0x0010), 0x00000003, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610490 + (ctrl * 0x0010), 0x00001010, 0x00001000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610490 + (ctrl * 0x0010), 0x00000003, 0x00000000);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610490 + (chid * 0x10)) &amp; 0x001e0000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610490 + (ctrl * 0x10)) &amp; 0x001e0000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d fini: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610490 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d fini: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610490 + (ctrl * 0x10)));</span>
 	}
 
 	/* disable error reporting and completion notification */
<span class="p_del">-	nvkm_mask(device, 0x610090, 0x00000001 &lt;&lt; chid, 0x00000000);</span>
<span class="p_del">-	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; chid, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610090, 0x00000001 &lt;&lt; user, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; user, 0x00000000);</span>
 }
 
 static int
<span class="p_chunk">@@ -66,26 +67,27 @@</span> <span class="p_context"> gf119_disp_dmac_init(struct nv50_disp_dmac *chan)</span>
 	struct nv50_disp *disp = chan-&gt;base.root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;base.chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;base.chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;base.chid.user;</span>
 
 	/* enable error reporting */
<span class="p_del">-	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; chid, 0x00000001 &lt;&lt; chid);</span>
<span class="p_add">+	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; user, 0x00000001 &lt;&lt; user);</span>
 
 	/* initialise channel for dma command submission */
<span class="p_del">-	nvkm_wr32(device, 0x610494 + (chid * 0x0010), chan-&gt;push);</span>
<span class="p_del">-	nvkm_wr32(device, 0x610498 + (chid * 0x0010), 0x00010000);</span>
<span class="p_del">-	nvkm_wr32(device, 0x61049c + (chid * 0x0010), 0x00000001);</span>
<span class="p_del">-	nvkm_mask(device, 0x610490 + (chid * 0x0010), 0x00000010, 0x00000010);</span>
<span class="p_del">-	nvkm_wr32(device, 0x640000 + (chid * 0x1000), 0x00000000);</span>
<span class="p_del">-	nvkm_wr32(device, 0x610490 + (chid * 0x0010), 0x00000013);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610494 + (ctrl * 0x0010), chan-&gt;push);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610498 + (ctrl * 0x0010), 0x00010000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x61049c + (ctrl * 0x0010), 0x00000001);</span>
<span class="p_add">+	nvkm_mask(device, 0x610490 + (ctrl * 0x0010), 0x00000010, 0x00000010);</span>
<span class="p_add">+	nvkm_wr32(device, 0x640000 + (ctrl * 0x1000), 0x00000000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610490 + (ctrl * 0x0010), 0x00000013);</span>
 
 	/* wait for it to go inactive */
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610490 + (chid * 0x10)) &amp; 0x80000000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610490 + (ctrl * 0x10)) &amp; 0x80000000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d init: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610490 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d init: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610490 + (ctrl * 0x10)));</span>
 		return -EBUSY;
 	}
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgp104.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgp104.c</span>
<span class="p_header">index ad24c2c57696..d26d3b4c41a4 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgp104.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacgp104.c</span>
<span class="p_chunk">@@ -32,26 +32,27 @@</span> <span class="p_context"> gp104_disp_dmac_init(struct nv50_disp_dmac *chan)</span>
 	struct nv50_disp *disp = chan-&gt;base.root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;base.chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;base.chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;base.chid.user;</span>
 
 	/* enable error reporting */
<span class="p_del">-	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; chid, 0x00000001 &lt;&lt; chid);</span>
<span class="p_add">+	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; user, 0x00000001 &lt;&lt; user);</span>
 
 	/* initialise channel for dma command submission */
<span class="p_del">-	nvkm_wr32(device, 0x611494 + (chid * 0x0010), chan-&gt;push);</span>
<span class="p_del">-	nvkm_wr32(device, 0x611498 + (chid * 0x0010), 0x00010000);</span>
<span class="p_del">-	nvkm_wr32(device, 0x61149c + (chid * 0x0010), 0x00000001);</span>
<span class="p_del">-	nvkm_mask(device, 0x610490 + (chid * 0x0010), 0x00000010, 0x00000010);</span>
<span class="p_del">-	nvkm_wr32(device, 0x640000 + (chid * 0x1000), 0x00000000);</span>
<span class="p_del">-	nvkm_wr32(device, 0x610490 + (chid * 0x0010), 0x00000013);</span>
<span class="p_add">+	nvkm_wr32(device, 0x611494 + (ctrl * 0x0010), chan-&gt;push);</span>
<span class="p_add">+	nvkm_wr32(device, 0x611498 + (ctrl * 0x0010), 0x00010000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x61149c + (ctrl * 0x0010), 0x00000001);</span>
<span class="p_add">+	nvkm_mask(device, 0x610490 + (ctrl * 0x0010), 0x00000010, 0x00000010);</span>
<span class="p_add">+	nvkm_wr32(device, 0x640000 + (ctrl * 0x1000), 0x00000000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610490 + (ctrl * 0x0010), 0x00000013);</span>
 
 	/* wait for it to go inactive */
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610490 + (chid * 0x10)) &amp; 0x80000000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610490 + (ctrl * 0x10)) &amp; 0x80000000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d init: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610490 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d init: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610490 + (ctrl * 0x10)));</span>
 		return -EBUSY;
 	}
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacnv50.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacnv50.c</span>
<span class="p_header">index 9c6645a357b9..0a1381a84552 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacnv50.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/dmacnv50.c</span>
<span class="p_chunk">@@ -149,7 +149,7 @@</span> <span class="p_context"> nv50_disp_dmac_new_(const struct nv50_disp_dmac_func *func,</span>
 	chan-&gt;func = func;
 
 	ret = nv50_disp_chan_ctor(&amp;nv50_disp_dmac_func_, mthd, root,
<span class="p_del">-				  chid, head, oclass, &amp;chan-&gt;base);</span>
<span class="p_add">+				  chid, chid, head, oclass, &amp;chan-&gt;base);</span>
 	if (ret)
 		return ret;
 
<span class="p_chunk">@@ -179,9 +179,9 @@</span> <span class="p_context"> nv50_disp_dmac_bind(struct nv50_disp_dmac *chan,</span>
 		    struct nvkm_object *object, u32 handle)
 {
 	return nvkm_ramht_insert(chan-&gt;base.root-&gt;ramht, object,
<span class="p_del">-				 chan-&gt;base.chid, -10, handle,</span>
<span class="p_del">-				 chan-&gt;base.chid &lt;&lt; 28 |</span>
<span class="p_del">-				 chan-&gt;base.chid);</span>
<span class="p_add">+				 chan-&gt;base.chid.user, -10, handle,</span>
<span class="p_add">+				 chan-&gt;base.chid.user &lt;&lt; 28 |</span>
<span class="p_add">+				 chan-&gt;base.chid.user);</span>
 }
 
 static void
<span class="p_chunk">@@ -190,21 +190,22 @@</span> <span class="p_context"> nv50_disp_dmac_fini(struct nv50_disp_dmac *chan)</span>
 	struct nv50_disp *disp = chan-&gt;base.root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;base.chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;base.chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;base.chid.user;</span>
 
 	/* deactivate channel */
<span class="p_del">-	nvkm_mask(device, 0x610200 + (chid * 0x0010), 0x00001010, 0x00001000);</span>
<span class="p_del">-	nvkm_mask(device, 0x610200 + (chid * 0x0010), 0x00000003, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610200 + (ctrl * 0x0010), 0x00001010, 0x00001000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610200 + (ctrl * 0x0010), 0x00000003, 0x00000000);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610200 + (chid * 0x10)) &amp; 0x001e0000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610200 + (ctrl * 0x10)) &amp; 0x001e0000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d fini timeout, %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610200 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d fini timeout, %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610200 + (ctrl * 0x10)));</span>
 	}
 
 	/* disable error reporting and completion notifications */
<span class="p_del">-	nvkm_mask(device, 0x610028, 0x00010001 &lt;&lt; chid, 0x00000000 &lt;&lt; chid);</span>
<span class="p_add">+	nvkm_mask(device, 0x610028, 0x00010001 &lt;&lt; user, 0x00000000 &lt;&lt; user);</span>
 }
 
 static int
<span class="p_chunk">@@ -213,26 +214,27 @@</span> <span class="p_context"> nv50_disp_dmac_init(struct nv50_disp_dmac *chan)</span>
 	struct nv50_disp *disp = chan-&gt;base.root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;base.chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;base.chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;base.chid.user;</span>
 
 	/* enable error reporting */
<span class="p_del">-	nvkm_mask(device, 0x610028, 0x00010000 &lt;&lt; chid, 0x00010000 &lt;&lt; chid);</span>
<span class="p_add">+	nvkm_mask(device, 0x610028, 0x00010000 &lt;&lt; user, 0x00010000 &lt;&lt; user);</span>
 
 	/* initialise channel for dma command submission */
<span class="p_del">-	nvkm_wr32(device, 0x610204 + (chid * 0x0010), chan-&gt;push);</span>
<span class="p_del">-	nvkm_wr32(device, 0x610208 + (chid * 0x0010), 0x00010000);</span>
<span class="p_del">-	nvkm_wr32(device, 0x61020c + (chid * 0x0010), chid);</span>
<span class="p_del">-	nvkm_mask(device, 0x610200 + (chid * 0x0010), 0x00000010, 0x00000010);</span>
<span class="p_del">-	nvkm_wr32(device, 0x640000 + (chid * 0x1000), 0x00000000);</span>
<span class="p_del">-	nvkm_wr32(device, 0x610200 + (chid * 0x0010), 0x00000013);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610204 + (ctrl * 0x0010), chan-&gt;push);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610208 + (ctrl * 0x0010), 0x00010000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x61020c + (ctrl * 0x0010), ctrl);</span>
<span class="p_add">+	nvkm_mask(device, 0x610200 + (ctrl * 0x0010), 0x00000010, 0x00000010);</span>
<span class="p_add">+	nvkm_wr32(device, 0x640000 + (ctrl * 0x1000), 0x00000000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610200 + (ctrl * 0x0010), 0x00000013);</span>
 
 	/* wait for it to go inactive */
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610200 + (chid * 0x10)) &amp; 0x80000000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610200 + (ctrl * 0x10)) &amp; 0x80000000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d init timeout, %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610200 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d init timeout, %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610200 + (ctrl * 0x10)));</span>
 		return -EBUSY;
 	}
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmg84.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmg84.c</span>
<span class="p_header">index 54a4ae8d66c6..5ad5d0f5db05 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmg84.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmg84.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> g84_disp_oimm_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_oimm_new,
 	.func = &amp;nv50_disp_pioc_func,
<span class="p_del">-	.chid = 5,</span>
<span class="p_add">+	.chid = { 5, 5 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgf119.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgf119.c</span>
<span class="p_header">index c658db54afc5..1f9fd3403f07 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgf119.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgf119.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> gf119_disp_oimm_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_oimm_new,
 	.func = &amp;gf119_disp_pioc_func,
<span class="p_del">-	.chid = 9,</span>
<span class="p_add">+	.chid = { 9, 9 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgk104.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgk104.c</span>
<span class="p_header">index b1fde8c125d6..0c09fe85e952 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgk104.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgk104.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> gk104_disp_oimm_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_oimm_new,
 	.func = &amp;gf119_disp_pioc_func,
<span class="p_del">-	.chid = 9,</span>
<span class="p_add">+	.chid = { 9, 9 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgp102.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgp102.c</span>
new file mode 100644
<span class="p_header">index 000000000000..abf82365c671</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgp102.c</span>
<span class="p_chunk">@@ -0,0 +1,37 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright 2016 Red Hat Inc.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="p_add">+ * copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="p_add">+ * to deal in the Software without restriction, including without limitation</span>
<span class="p_add">+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="p_add">+ * and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="p_add">+ * Software is furnished to do so, subject to the following conditions:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The above copyright notice and this permission notice shall be included in</span>
<span class="p_add">+ * all copies or substantial portions of the Software.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="p_add">+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="p_add">+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL</span>
<span class="p_add">+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR</span>
<span class="p_add">+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,</span>
<span class="p_add">+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR</span>
<span class="p_add">+ * OTHER DEALINGS IN THE SOFTWARE.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors: Ben Skeggs &lt;bskeggs@redhat.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &quot;channv50.h&quot;</span>
<span class="p_add">+#include &quot;rootnv50.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;nvif/class.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+const struct nv50_disp_pioc_oclass</span>
<span class="p_add">+gp102_disp_oimm_oclass = {</span>
<span class="p_add">+	.base.oclass = GK104_DISP_OVERLAY,</span>
<span class="p_add">+	.base.minver = 0,</span>
<span class="p_add">+	.base.maxver = 0,</span>
<span class="p_add">+	.ctor = nv50_disp_oimm_new,</span>
<span class="p_add">+	.func = &amp;gf119_disp_pioc_func,</span>
<span class="p_add">+	.chid = { 9, 13 },</span>
<span class="p_add">+};</span>
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgt215.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgt215.c</span>
<span class="p_header">index f4e7eb3d1177..1281db28aebd 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgt215.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmgt215.c</span>
<span class="p_chunk">@@ -33,5 +33,5 @@</span> <span class="p_context"> gt215_disp_oimm_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_oimm_new,
 	.func = &amp;nv50_disp_pioc_func,
<span class="p_del">-	.chid = 5,</span>
<span class="p_add">+	.chid = { 5, 5 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmnv50.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmnv50.c</span>
<span class="p_header">index 3940b9c966ec..07540f3d32dc 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmnv50.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/oimmnv50.c</span>
<span class="p_chunk">@@ -33,7 +33,7 @@</span> <span class="p_context"></span>
 int
 nv50_disp_oimm_new(const struct nv50_disp_chan_func *func,
 		   const struct nv50_disp_chan_mthd *mthd,
<span class="p_del">-		   struct nv50_disp_root *root, int chid,</span>
<span class="p_add">+		   struct nv50_disp_root *root, int ctrl, int user,</span>
 		   const struct nvkm_oclass *oclass, void *data, u32 size,
 		   struct nvkm_object **pobject)
 {
<span class="p_chunk">@@ -54,7 +54,7 @@</span> <span class="p_context"> nv50_disp_oimm_new(const struct nv50_disp_chan_func *func,</span>
 	} else
 		return ret;
 
<span class="p_del">-	return nv50_disp_chan_new_(func, mthd, root, chid + head,</span>
<span class="p_add">+	return nv50_disp_chan_new_(func, mthd, root, ctrl + head, user + head,</span>
 				   head, oclass, pobject);
 }
 
<span class="p_chunk">@@ -65,5 +65,5 @@</span> <span class="p_context"> nv50_disp_oimm_oclass = {</span>
 	.base.maxver = 0,
 	.ctor = nv50_disp_oimm_new,
 	.func = &amp;nv50_disp_pioc_func,
<span class="p_del">-	.chid = 5,</span>
<span class="p_add">+	.chid = { 5, 5 },</span>
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocgf119.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocgf119.c</span>
<span class="p_header">index a625a9876e34..0abaa6431943 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocgf119.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocgf119.c</span>
<span class="p_chunk">@@ -32,20 +32,21 @@</span> <span class="p_context"> gf119_disp_pioc_fini(struct nv50_disp_chan *chan)</span>
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;chid.user;</span>
 
<span class="p_del">-	nvkm_mask(device, 0x610490 + (chid * 0x10), 0x00000001, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610490 + (ctrl * 0x10), 0x00000001, 0x00000000);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610490 + (chid * 0x10)) &amp; 0x00030000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610490 + (ctrl * 0x10)) &amp; 0x00030000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d fini: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610490 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d fini: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610490 + (ctrl * 0x10)));</span>
 	}
 
 	/* disable error reporting and completion notification */
<span class="p_del">-	nvkm_mask(device, 0x610090, 0x00000001 &lt;&lt; chid, 0x00000000);</span>
<span class="p_del">-	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; chid, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610090, 0x00000001 &lt;&lt; user, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; user, 0x00000000);</span>
 }
 
 static int
<span class="p_chunk">@@ -54,20 +55,21 @@</span> <span class="p_context"> gf119_disp_pioc_init(struct nv50_disp_chan *chan)</span>
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;chid.user;</span>
 
 	/* enable error reporting */
<span class="p_del">-	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; chid, 0x00000001 &lt;&lt; chid);</span>
<span class="p_add">+	nvkm_mask(device, 0x6100a0, 0x00000001 &lt;&lt; user, 0x00000001 &lt;&lt; user);</span>
 
 	/* activate channel */
<span class="p_del">-	nvkm_wr32(device, 0x610490 + (chid * 0x10), 0x00000001);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610490 + (ctrl * 0x10), 0x00000001);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		u32 tmp = nvkm_rd32(device, 0x610490 + (chid * 0x10));</span>
<span class="p_add">+		u32 tmp = nvkm_rd32(device, 0x610490 + (ctrl * 0x10));</span>
 		if ((tmp &amp; 0x00030000) == 0x00010000)
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d init: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610490 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d init: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610490 + (ctrl * 0x10)));</span>
 		return -EBUSY;
 	}
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocnv50.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocnv50.c</span>
<span class="p_header">index 9d2618dacf20..0211e0e8a35f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocnv50.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/piocnv50.c</span>
<span class="p_chunk">@@ -32,15 +32,16 @@</span> <span class="p_context"> nv50_disp_pioc_fini(struct nv50_disp_chan *chan)</span>
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;chid.user;</span>
 
<span class="p_del">-	nvkm_mask(device, 0x610200 + (chid * 0x10), 0x00000001, 0x00000000);</span>
<span class="p_add">+	nvkm_mask(device, 0x610200 + (ctrl * 0x10), 0x00000001, 0x00000000);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610200 + (chid * 0x10)) &amp; 0x00030000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610200 + (ctrl * 0x10)) &amp; 0x00030000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d timeout: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610200 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d timeout: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610200 + (ctrl * 0x10)));</span>
 	}
 }
 
<span class="p_chunk">@@ -50,26 +51,27 @@</span> <span class="p_context"> nv50_disp_pioc_init(struct nv50_disp_chan *chan)</span>
 	struct nv50_disp *disp = chan-&gt;root-&gt;disp;
 	struct nvkm_subdev *subdev = &amp;disp-&gt;base.engine.subdev;
 	struct nvkm_device *device = subdev-&gt;device;
<span class="p_del">-	int chid = chan-&gt;chid;</span>
<span class="p_add">+	int ctrl = chan-&gt;chid.ctrl;</span>
<span class="p_add">+	int user = chan-&gt;chid.user;</span>
 
<span class="p_del">-	nvkm_wr32(device, 0x610200 + (chid * 0x10), 0x00002000);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610200 + (ctrl * 0x10), 0x00002000);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		if (!(nvkm_rd32(device, 0x610200 + (chid * 0x10)) &amp; 0x00030000))</span>
<span class="p_add">+		if (!(nvkm_rd32(device, 0x610200 + (ctrl * 0x10)) &amp; 0x00030000))</span>
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d timeout0: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610200 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d timeout0: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610200 + (ctrl * 0x10)));</span>
 		return -EBUSY;
 	}
 
<span class="p_del">-	nvkm_wr32(device, 0x610200 + (chid * 0x10), 0x00000001);</span>
<span class="p_add">+	nvkm_wr32(device, 0x610200 + (ctrl * 0x10), 0x00000001);</span>
 	if (nvkm_msec(device, 2000,
<span class="p_del">-		u32 tmp = nvkm_rd32(device, 0x610200 + (chid * 0x10));</span>
<span class="p_add">+		u32 tmp = nvkm_rd32(device, 0x610200 + (ctrl * 0x10));</span>
 		if ((tmp &amp; 0x00030000) == 0x00010000)
 			break;
 	) &lt; 0) {
<span class="p_del">-		nvkm_error(subdev, &quot;ch %d timeout1: %08x\n&quot;, chid,</span>
<span class="p_del">-			   nvkm_rd32(device, 0x610200 + (chid * 0x10)));</span>
<span class="p_add">+		nvkm_error(subdev, &quot;ch %d timeout1: %08x\n&quot;, user,</span>
<span class="p_add">+			   nvkm_rd32(device, 0x610200 + (ctrl * 0x10)));</span>
 		return -EBUSY;
 	}
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootgp104.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootgp104.c</span>
<span class="p_header">index 8443e04dc626..b053b291cd94 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootgp104.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootgp104.c</span>
<span class="p_chunk">@@ -36,8 +36,8 @@</span> <span class="p_context"> gp104_disp_root = {</span>
 		&amp;gp104_disp_ovly_oclass,
 	},
 	.pioc = {
<span class="p_del">-		&amp;gk104_disp_oimm_oclass,</span>
<span class="p_del">-		&amp;gk104_disp_curs_oclass,</span>
<span class="p_add">+		&amp;gp102_disp_oimm_oclass,</span>
<span class="p_add">+		&amp;gp102_disp_curs_oclass,</span>
 	},
 };
 
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootnv50.c b/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootnv50.c</span>
<span class="p_header">index 2f9cecd81d04..05c829a603d1 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootnv50.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/engine/disp/rootnv50.c</span>
<span class="p_chunk">@@ -207,8 +207,8 @@</span> <span class="p_context"> nv50_disp_root_pioc_new_(const struct nvkm_oclass *oclass,</span>
 {
 	const struct nv50_disp_pioc_oclass *sclass = oclass-&gt;priv;
 	struct nv50_disp_root *root = nv50_disp_root(oclass-&gt;parent);
<span class="p_del">-	return sclass-&gt;ctor(sclass-&gt;func, sclass-&gt;mthd, root, sclass-&gt;chid,</span>
<span class="p_del">-			    oclass, data, size, pobject);</span>
<span class="p_add">+	return sclass-&gt;ctor(sclass-&gt;func, sclass-&gt;mthd, root, sclass-&gt;chid.ctrl,</span>
<span class="p_add">+			    sclass-&gt;chid.user, oclass, data, size, pobject);</span>
 }
 
 static int
<span class="p_header">diff --git a/drivers/gpu/drm/vc4/vc4_crtc.c b/drivers/gpu/drm/vc4/vc4_crtc.c</span>
<span class="p_header">index d544ff9b0d46..7aadce1f7e7a 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vc4/vc4_crtc.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vc4/vc4_crtc.c</span>
<span class="p_chunk">@@ -83,8 +83,7 @@</span> <span class="p_context"> struct vc4_crtc_data {</span>
 	/* Which channel of the HVS this pixelvalve sources from. */
 	int hvs_channel;
 
<span class="p_del">-	enum vc4_encoder_type encoder0_type;</span>
<span class="p_del">-	enum vc4_encoder_type encoder1_type;</span>
<span class="p_add">+	enum vc4_encoder_type encoder_types[4];</span>
 };
 
 #define CRTC_WRITE(offset, val) writel(val, vc4_crtc-&gt;regs + (offset))
<span class="p_chunk">@@ -669,6 +668,14 @@</span> <span class="p_context"> void vc4_disable_vblank(struct drm_device *dev, unsigned int crtc_id)</span>
 	CRTC_WRITE(PV_INTEN, 0);
 }
 
<span class="p_add">+/* Must be called with the event lock held */</span>
<span class="p_add">+bool vc4_event_pending(struct drm_crtc *crtc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vc4_crtc *vc4_crtc = to_vc4_crtc(crtc);</span>
<span class="p_add">+</span>
<span class="p_add">+	return !!vc4_crtc-&gt;event;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void vc4_crtc_handle_page_flip(struct vc4_crtc *vc4_crtc)
 {
 	struct drm_crtc *crtc = &amp;vc4_crtc-&gt;base;
<span class="p_chunk">@@ -859,20 +866,26 @@</span> <span class="p_context"> static const struct drm_crtc_helper_funcs vc4_crtc_helper_funcs = {</span>
 
 static const struct vc4_crtc_data pv0_data = {
 	.hvs_channel = 0,
<span class="p_del">-	.encoder0_type = VC4_ENCODER_TYPE_DSI0,</span>
<span class="p_del">-	.encoder1_type = VC4_ENCODER_TYPE_DPI,</span>
<span class="p_add">+	.encoder_types = {</span>
<span class="p_add">+		[PV_CONTROL_CLK_SELECT_DSI] = VC4_ENCODER_TYPE_DSI0,</span>
<span class="p_add">+		[PV_CONTROL_CLK_SELECT_DPI_SMI_HDMI] = VC4_ENCODER_TYPE_DPI,</span>
<span class="p_add">+	},</span>
 };
 
 static const struct vc4_crtc_data pv1_data = {
 	.hvs_channel = 2,
<span class="p_del">-	.encoder0_type = VC4_ENCODER_TYPE_DSI1,</span>
<span class="p_del">-	.encoder1_type = VC4_ENCODER_TYPE_SMI,</span>
<span class="p_add">+	.encoder_types = {</span>
<span class="p_add">+		[PV_CONTROL_CLK_SELECT_DSI] = VC4_ENCODER_TYPE_DSI1,</span>
<span class="p_add">+		[PV_CONTROL_CLK_SELECT_DPI_SMI_HDMI] = VC4_ENCODER_TYPE_SMI,</span>
<span class="p_add">+	},</span>
 };
 
 static const struct vc4_crtc_data pv2_data = {
 	.hvs_channel = 1,
<span class="p_del">-	.encoder0_type = VC4_ENCODER_TYPE_VEC,</span>
<span class="p_del">-	.encoder1_type = VC4_ENCODER_TYPE_HDMI,</span>
<span class="p_add">+	.encoder_types = {</span>
<span class="p_add">+		[PV_CONTROL_CLK_SELECT_DPI_SMI_HDMI] = VC4_ENCODER_TYPE_HDMI,</span>
<span class="p_add">+		[PV_CONTROL_CLK_SELECT_VEC] = VC4_ENCODER_TYPE_VEC,</span>
<span class="p_add">+	},</span>
 };
 
 static const struct of_device_id vc4_crtc_dt_match[] = {
<span class="p_chunk">@@ -886,17 +899,20 @@</span> <span class="p_context"> static void vc4_set_crtc_possible_masks(struct drm_device *drm,</span>
 					struct drm_crtc *crtc)
 {
 	struct vc4_crtc *vc4_crtc = to_vc4_crtc(crtc);
<span class="p_add">+	const struct vc4_crtc_data *crtc_data = vc4_crtc-&gt;data;</span>
<span class="p_add">+	const enum vc4_encoder_type *encoder_types = crtc_data-&gt;encoder_types;</span>
 	struct drm_encoder *encoder;
 
 	drm_for_each_encoder(encoder, drm) {
 		struct vc4_encoder *vc4_encoder = to_vc4_encoder(encoder);
<span class="p_del">-</span>
<span class="p_del">-		if (vc4_encoder-&gt;type == vc4_crtc-&gt;data-&gt;encoder0_type) {</span>
<span class="p_del">-			vc4_encoder-&gt;clock_select = 0;</span>
<span class="p_del">-			encoder-&gt;possible_crtcs |= drm_crtc_mask(crtc);</span>
<span class="p_del">-		} else if (vc4_encoder-&gt;type == vc4_crtc-&gt;data-&gt;encoder1_type) {</span>
<span class="p_del">-			vc4_encoder-&gt;clock_select = 1;</span>
<span class="p_del">-			encoder-&gt;possible_crtcs |= drm_crtc_mask(crtc);</span>
<span class="p_add">+		int i;</span>
<span class="p_add">+</span>
<span class="p_add">+		for (i = 0; i &lt; ARRAY_SIZE(crtc_data-&gt;encoder_types); i++) {</span>
<span class="p_add">+			if (vc4_encoder-&gt;type == encoder_types[i]) {</span>
<span class="p_add">+				vc4_encoder-&gt;clock_select = i;</span>
<span class="p_add">+				encoder-&gt;possible_crtcs |= drm_crtc_mask(crtc);</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			}</span>
 		}
 	}
 }
<span class="p_header">diff --git a/drivers/gpu/drm/vc4/vc4_drv.h b/drivers/gpu/drm/vc4/vc4_drv.h</span>
<span class="p_header">index 7c1e4d97486f..50a55ef999d6 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vc4/vc4_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/vc4/vc4_drv.h</span>
<span class="p_chunk">@@ -194,6 +194,7 @@</span> <span class="p_context"> to_vc4_plane(struct drm_plane *plane)</span>
 }
 
 enum vc4_encoder_type {
<span class="p_add">+	VC4_ENCODER_TYPE_NONE,</span>
 	VC4_ENCODER_TYPE_HDMI,
 	VC4_ENCODER_TYPE_VEC,
 	VC4_ENCODER_TYPE_DSI0,
<span class="p_chunk">@@ -440,6 +441,7 @@</span> <span class="p_context"> int vc4_bo_stats_debugfs(struct seq_file *m, void *arg);</span>
 extern struct platform_driver vc4_crtc_driver;
 int vc4_enable_vblank(struct drm_device *dev, unsigned int crtc_id);
 void vc4_disable_vblank(struct drm_device *dev, unsigned int crtc_id);
<span class="p_add">+bool vc4_event_pending(struct drm_crtc *crtc);</span>
 int vc4_crtc_debugfs_regs(struct seq_file *m, void *arg);
 int vc4_crtc_get_scanoutpos(struct drm_device *dev, unsigned int crtc_id,
 			    unsigned int flags, int *vpos, int *hpos,
<span class="p_header">diff --git a/drivers/gpu/drm/vc4/vc4_kms.c b/drivers/gpu/drm/vc4/vc4_kms.c</span>
<span class="p_header">index c1f65c6c8e60..67af2af70af0 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vc4/vc4_kms.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vc4/vc4_kms.c</span>
<span class="p_chunk">@@ -119,17 +119,34 @@</span> <span class="p_context"> static int vc4_atomic_commit(struct drm_device *dev,</span>
 
 	/* Make sure that any outstanding modesets have finished. */
 	if (nonblock) {
<span class="p_del">-		ret = down_trylock(&amp;vc4-&gt;async_modeset);</span>
<span class="p_del">-		if (ret) {</span>
<span class="p_add">+		struct drm_crtc *crtc;</span>
<span class="p_add">+		struct drm_crtc_state *crtc_state;</span>
<span class="p_add">+		unsigned long flags;</span>
<span class="p_add">+		bool busy = false;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If there&#39;s an undispatched event to send then we&#39;re</span>
<span class="p_add">+		 * obviously still busy.  If there isn&#39;t, then we can</span>
<span class="p_add">+		 * unconditionally wait for the semaphore because it</span>
<span class="p_add">+		 * shouldn&#39;t be contended (for long).</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * This is to prevent a race where queuing a new flip</span>
<span class="p_add">+		 * from userspace immediately on receipt of an event</span>
<span class="p_add">+		 * beats our clean-up and returns EBUSY.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		spin_lock_irqsave(&amp;dev-&gt;event_lock, flags);</span>
<span class="p_add">+		for_each_crtc_in_state(state, crtc, crtc_state, i)</span>
<span class="p_add">+			busy |= vc4_event_pending(crtc);</span>
<span class="p_add">+		spin_unlock_irqrestore(&amp;dev-&gt;event_lock, flags);</span>
<span class="p_add">+		if (busy) {</span>
 			kfree(c);
 			return -EBUSY;
 		}
<span class="p_del">-	} else {</span>
<span class="p_del">-		ret = down_interruptible(&amp;vc4-&gt;async_modeset);</span>
<span class="p_del">-		if (ret) {</span>
<span class="p_del">-			kfree(c);</span>
<span class="p_del">-			return ret;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	ret = down_interruptible(&amp;vc4-&gt;async_modeset);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		kfree(c);</span>
<span class="p_add">+		return ret;</span>
 	}
 
 	ret = drm_atomic_helper_prepare_planes(dev, state);
<span class="p_header">diff --git a/drivers/gpu/drm/vc4/vc4_regs.h b/drivers/gpu/drm/vc4/vc4_regs.h</span>
<span class="p_header">index 1aa44c2db556..39f6886b2410 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vc4/vc4_regs.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/vc4/vc4_regs.h</span>
<span class="p_chunk">@@ -177,8 +177,9 @@</span> <span class="p_context"></span>
 # define PV_CONTROL_WAIT_HSTART			BIT(12)
 # define PV_CONTROL_PIXEL_REP_MASK		VC4_MASK(5, 4)
 # define PV_CONTROL_PIXEL_REP_SHIFT		4
<span class="p_del">-# define PV_CONTROL_CLK_SELECT_DSI_VEC		0</span>
<span class="p_add">+# define PV_CONTROL_CLK_SELECT_DSI		0</span>
 # define PV_CONTROL_CLK_SELECT_DPI_SMI_HDMI	1
<span class="p_add">+# define PV_CONTROL_CLK_SELECT_VEC		2</span>
 # define PV_CONTROL_CLK_SELECT_MASK		VC4_MASK(3, 2)
 # define PV_CONTROL_CLK_SELECT_SHIFT		2
 # define PV_CONTROL_FIFO_CLR			BIT(1)
<span class="p_header">diff --git a/drivers/irqchip/irq-gic-v3-its.c b/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_header">index c5dee300e8a3..acb9d250a905 100644</span>
<span class="p_header">--- a/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_header">+++ b/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_chunk">@@ -1598,6 +1598,14 @@</span> <span class="p_context"> static void __maybe_unused its_enable_quirk_cavium_23144(void *data)</span>
 	its-&gt;flags |= ITS_FLAGS_WORKAROUND_CAVIUM_23144;
 }
 
<span class="p_add">+static void __maybe_unused its_enable_quirk_qdf2400_e0065(void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct its_node *its = data;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* On QDF2400, the size of the ITE is 16Bytes */</span>
<span class="p_add">+	its-&gt;ite_size = 16;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static const struct gic_quirk its_quirks[] = {
 #ifdef CONFIG_CAVIUM_ERRATUM_22375
 	{
<span class="p_chunk">@@ -1615,6 +1623,14 @@</span> <span class="p_context"> static const struct gic_quirk its_quirks[] = {</span>
 		.init	= its_enable_quirk_cavium_23144,
 	},
 #endif
<span class="p_add">+#ifdef CONFIG_QCOM_QDF2400_ERRATUM_0065</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.desc	= &quot;ITS: QDF2400 erratum 0065&quot;,</span>
<span class="p_add">+		.iidr	= 0x00001070, /* QDF2400 ITS rev 1.x */</span>
<span class="p_add">+		.mask	= 0xffffffff,</span>
<span class="p_add">+		.init	= its_enable_quirk_qdf2400_e0065,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#endif</span>
 	{
 	}
 };
<span class="p_header">diff --git a/drivers/media/usb/uvc/uvc_driver.c b/drivers/media/usb/uvc/uvc_driver.c</span>
<span class="p_header">index 302e284a95eb..cde43b63c3da 100644</span>
<span class="p_header">--- a/drivers/media/usb/uvc/uvc_driver.c</span>
<span class="p_header">+++ b/drivers/media/usb/uvc/uvc_driver.c</span>
<span class="p_chunk">@@ -1595,6 +1595,114 @@</span> <span class="p_context"> static const char *uvc_print_chain(struct uvc_video_chain *chain)</span>
 	return buffer;
 }
 
<span class="p_add">+static struct uvc_video_chain *uvc_alloc_chain(struct uvc_device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct uvc_video_chain *chain;</span>
<span class="p_add">+</span>
<span class="p_add">+	chain = kzalloc(sizeof(*chain), GFP_KERNEL);</span>
<span class="p_add">+	if (chain == NULL)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	INIT_LIST_HEAD(&amp;chain-&gt;entities);</span>
<span class="p_add">+	mutex_init(&amp;chain-&gt;ctrl_mutex);</span>
<span class="p_add">+	chain-&gt;dev = dev;</span>
<span class="p_add">+	v4l2_prio_init(&amp;chain-&gt;prio);</span>
<span class="p_add">+</span>
<span class="p_add">+	return chain;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Fallback heuristic for devices that don&#39;t connect units and terminals in a</span>
<span class="p_add">+ * valid chain.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Some devices have invalid baSourceID references, causing uvc_scan_chain()</span>
<span class="p_add">+ * to fail, but if we just take the entities we can find and put them together</span>
<span class="p_add">+ * in the most sensible chain we can think of, turns out they do work anyway.</span>
<span class="p_add">+ * Note: This heuristic assumes there is a single chain.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * At the time of writing, devices known to have such a broken chain are</span>
<span class="p_add">+ *  - Acer Integrated Camera (5986:055a)</span>
<span class="p_add">+ *  - Realtek rtl157a7 (0bda:57a7)</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int uvc_scan_fallback(struct uvc_device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct uvc_video_chain *chain;</span>
<span class="p_add">+	struct uvc_entity *iterm = NULL;</span>
<span class="p_add">+	struct uvc_entity *oterm = NULL;</span>
<span class="p_add">+	struct uvc_entity *entity;</span>
<span class="p_add">+	struct uvc_entity *prev;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Start by locating the input and output terminals. We only support</span>
<span class="p_add">+	 * devices with exactly one of each for now.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	list_for_each_entry(entity, &amp;dev-&gt;entities, list) {</span>
<span class="p_add">+		if (UVC_ENTITY_IS_ITERM(entity)) {</span>
<span class="p_add">+			if (iterm)</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+			iterm = entity;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (UVC_ENTITY_IS_OTERM(entity)) {</span>
<span class="p_add">+			if (oterm)</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+			oterm = entity;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (iterm == NULL || oterm == NULL)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Allocate the chain and fill it. */</span>
<span class="p_add">+	chain = uvc_alloc_chain(dev);</span>
<span class="p_add">+	if (chain == NULL)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (uvc_scan_chain_entity(chain, oterm) &lt; 0)</span>
<span class="p_add">+		goto error;</span>
<span class="p_add">+</span>
<span class="p_add">+	prev = oterm;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Add all Processing and Extension Units with two pads. The order</span>
<span class="p_add">+	 * doesn&#39;t matter much, use reverse list traversal to connect units in</span>
<span class="p_add">+	 * UVC descriptor order as we build the chain from output to input. This</span>
<span class="p_add">+	 * leads to units appearing in the order meant by the manufacturer for</span>
<span class="p_add">+	 * the cameras known to require this heuristic.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	list_for_each_entry_reverse(entity, &amp;dev-&gt;entities, list) {</span>
<span class="p_add">+		if (entity-&gt;type != UVC_VC_PROCESSING_UNIT &amp;&amp;</span>
<span class="p_add">+		    entity-&gt;type != UVC_VC_EXTENSION_UNIT)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (entity-&gt;num_pads != 2)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (uvc_scan_chain_entity(chain, entity) &lt; 0)</span>
<span class="p_add">+			goto error;</span>
<span class="p_add">+</span>
<span class="p_add">+		prev-&gt;baSourceID[0] = entity-&gt;id;</span>
<span class="p_add">+		prev = entity;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (uvc_scan_chain_entity(chain, iterm) &lt; 0)</span>
<span class="p_add">+		goto error;</span>
<span class="p_add">+</span>
<span class="p_add">+	prev-&gt;baSourceID[0] = iterm-&gt;id;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_add_tail(&amp;chain-&gt;list, &amp;dev-&gt;chains);</span>
<span class="p_add">+</span>
<span class="p_add">+	uvc_trace(UVC_TRACE_PROBE,</span>
<span class="p_add">+		  &quot;Found a video chain by fallback heuristic (%s).\n&quot;,</span>
<span class="p_add">+		  uvc_print_chain(chain));</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+error:</span>
<span class="p_add">+	kfree(chain);</span>
<span class="p_add">+	return -EINVAL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Scan the device for video chains and register video devices.
  *
<span class="p_chunk">@@ -1617,15 +1725,10 @@</span> <span class="p_context"> static int uvc_scan_device(struct uvc_device *dev)</span>
 		if (term-&gt;chain.next || term-&gt;chain.prev)
 			continue;
 
<span class="p_del">-		chain = kzalloc(sizeof(*chain), GFP_KERNEL);</span>
<span class="p_add">+		chain = uvc_alloc_chain(dev);</span>
 		if (chain == NULL)
 			return -ENOMEM;
 
<span class="p_del">-		INIT_LIST_HEAD(&amp;chain-&gt;entities);</span>
<span class="p_del">-		mutex_init(&amp;chain-&gt;ctrl_mutex);</span>
<span class="p_del">-		chain-&gt;dev = dev;</span>
<span class="p_del">-		v4l2_prio_init(&amp;chain-&gt;prio);</span>
<span class="p_del">-</span>
 		term-&gt;flags |= UVC_ENTITY_FLAG_DEFAULT;
 
 		if (uvc_scan_chain(chain, term) &lt; 0) {
<span class="p_chunk">@@ -1639,6 +1742,9 @@</span> <span class="p_context"> static int uvc_scan_device(struct uvc_device *dev)</span>
 		list_add_tail(&amp;chain-&gt;list, &amp;dev-&gt;chains);
 	}
 
<span class="p_add">+	if (list_empty(&amp;dev-&gt;chains))</span>
<span class="p_add">+		uvc_scan_fallback(dev);</span>
<span class="p_add">+</span>
 	if (list_empty(&amp;dev-&gt;chains)) {
 		uvc_printk(KERN_INFO, &quot;No valid video chain found.\n&quot;);
 		return -1;
<span class="p_header">diff --git a/drivers/net/ethernet/ibm/ibmveth.c b/drivers/net/ethernet/ibm/ibmveth.c</span>
<span class="p_header">index a36022ba4e42..03dca732e4c6 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ibm/ibmveth.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ibm/ibmveth.c</span>
<span class="p_chunk">@@ -1181,7 +1181,9 @@</span> <span class="p_context"> static netdev_tx_t ibmveth_start_xmit(struct sk_buff *skb,</span>
 
 static void ibmveth_rx_mss_helper(struct sk_buff *skb, u16 mss, int lrg_pkt)
 {
<span class="p_add">+	struct tcphdr *tcph;</span>
 	int offset = 0;
<span class="p_add">+	int hdr_len;</span>
 
 	/* only TCP packets will be aggregated */
 	if (skb-&gt;protocol == htons(ETH_P_IP)) {
<span class="p_chunk">@@ -1208,14 +1210,20 @@</span> <span class="p_context"> static void ibmveth_rx_mss_helper(struct sk_buff *skb, u16 mss, int lrg_pkt)</span>
 	/* if mss is not set through Large Packet bit/mss in rx buffer,
 	 * expect that the mss will be written to the tcp header checksum.
 	 */
<span class="p_add">+	tcph = (struct tcphdr *)(skb-&gt;data + offset);</span>
 	if (lrg_pkt) {
 		skb_shinfo(skb)-&gt;gso_size = mss;
 	} else if (offset) {
<span class="p_del">-		struct tcphdr *tcph = (struct tcphdr *)(skb-&gt;data + offset);</span>
<span class="p_del">-</span>
 		skb_shinfo(skb)-&gt;gso_size = ntohs(tcph-&gt;check);
 		tcph-&gt;check = 0;
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (skb_shinfo(skb)-&gt;gso_size) {</span>
<span class="p_add">+		hdr_len = offset + tcph-&gt;doff * 4;</span>
<span class="p_add">+		skb_shinfo(skb)-&gt;gso_segs =</span>
<span class="p_add">+				DIV_ROUND_UP(skb-&gt;len - hdr_len,</span>
<span class="p_add">+					     skb_shinfo(skb)-&gt;gso_size);</span>
<span class="p_add">+	}</span>
 }
 
 static int ibmveth_poll(struct napi_struct *napi, int budget)
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/e1000_phy.c b/drivers/net/ethernet/intel/igb/e1000_phy.c</span>
<span class="p_header">index 5b54254aed4f..2788a5409023 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/e1000_phy.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/e1000_phy.c</span>
<span class="p_chunk">@@ -77,6 +77,10 @@</span> <span class="p_context"> s32 igb_get_phy_id(struct e1000_hw *hw)</span>
 	s32 ret_val = 0;
 	u16 phy_id;
 
<span class="p_add">+	/* ensure PHY page selection to fix misconfigured i210 */</span>
<span class="p_add">+	if ((hw-&gt;mac.type == e1000_i210) || (hw-&gt;mac.type == e1000_i211))</span>
<span class="p_add">+		phy-&gt;ops.write_reg(hw, I347AT4_PAGE_SELECT, 0);</span>
<span class="p_add">+</span>
 	ret_val = phy-&gt;ops.read_reg(hw, PHY_ID1, &amp;phy_id);
 	if (ret_val)
 		goto out;
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">index b30671376a3d..d4fa851ced2a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_chunk">@@ -81,6 +81,7 @@</span> <span class="p_context"> static bool mlx5e_check_fragmented_striding_rq_cap(struct mlx5_core_dev *mdev)</span>
 static void mlx5e_set_rq_type_params(struct mlx5e_priv *priv, u8 rq_type)
 {
 	priv-&gt;params.rq_wq_type = rq_type;
<span class="p_add">+	priv-&gt;params.lro_wqe_sz = MLX5E_PARAMS_DEFAULT_LRO_WQE_SZ;</span>
 	switch (priv-&gt;params.rq_wq_type) {
 	case MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ:
 		priv-&gt;params.log_rq_size = MLX5E_PARAMS_DEFAULT_LOG_RQ_SIZE_MPW;
<span class="p_chunk">@@ -92,6 +93,10 @@</span> <span class="p_context"> static void mlx5e_set_rq_type_params(struct mlx5e_priv *priv, u8 rq_type)</span>
 		break;
 	default: /* MLX5_WQ_TYPE_LINKED_LIST */
 		priv-&gt;params.log_rq_size = MLX5E_PARAMS_DEFAULT_LOG_RQ_SIZE;
<span class="p_add">+</span>
<span class="p_add">+		/* Extra room needed for build_skb */</span>
<span class="p_add">+		priv-&gt;params.lro_wqe_sz -= MLX5_RX_HEADROOM +</span>
<span class="p_add">+			SKB_DATA_ALIGN(sizeof(struct skb_shared_info));</span>
 	}
 	priv-&gt;params.min_rx_wqes = mlx5_min_rx_wqes(priv-&gt;params.rq_wq_type,
 					       BIT(priv-&gt;params.log_rq_size));
<span class="p_chunk">@@ -3473,12 +3478,6 @@</span> <span class="p_context"> static void mlx5e_build_nic_netdev_priv(struct mlx5_core_dev *mdev,</span>
 	mlx5e_build_default_indir_rqt(mdev, priv-&gt;params.indirection_rqt,
 				      MLX5E_INDIR_RQT_SIZE, profile-&gt;max_nch(mdev));
 
<span class="p_del">-	priv-&gt;params.lro_wqe_sz =</span>
<span class="p_del">-		MLX5E_PARAMS_DEFAULT_LRO_WQE_SZ -</span>
<span class="p_del">-		/* Extra room needed for build_skb */</span>
<span class="p_del">-		MLX5_RX_HEADROOM -</span>
<span class="p_del">-		SKB_DATA_ALIGN(sizeof(struct skb_shared_info));</span>
<span class="p_del">-</span>
 	/* Initialize pflags */
 	MLX5E_SET_PRIV_FLAG(priv, MLX5E_PFLAG_RX_CQE_BASED_MODER,
 			    priv-&gt;params.rx_cq_period_mode == MLX5_CQ_PERIOD_MODE_START_FROM_CQE);
<span class="p_chunk">@@ -3936,6 +3935,19 @@</span> <span class="p_context"> static void mlx5e_register_vport_rep(struct mlx5_core_dev *mdev)</span>
 	}
 }
 
<span class="p_add">+static void mlx5e_unregister_vport_rep(struct mlx5_core_dev *mdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mlx5_eswitch *esw = mdev-&gt;priv.eswitch;</span>
<span class="p_add">+	int total_vfs = MLX5_TOTAL_VPORTS(mdev);</span>
<span class="p_add">+	int vport;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!MLX5_CAP_GEN(mdev, vport_group_manager))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (vport = 1; vport &lt; total_vfs; vport++)</span>
<span class="p_add">+		mlx5_eswitch_unregister_vport_rep(esw, vport);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void mlx5e_detach_netdev(struct mlx5_core_dev *mdev, struct net_device *netdev)
 {
 	struct mlx5e_priv *priv = netdev_priv(netdev);
<span class="p_chunk">@@ -3983,6 +3995,7 @@</span> <span class="p_context"> static int mlx5e_attach(struct mlx5_core_dev *mdev, void *vpriv)</span>
 		return err;
 	}
 
<span class="p_add">+	mlx5e_register_vport_rep(mdev);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -3994,6 +4007,7 @@</span> <span class="p_context"> static void mlx5e_detach(struct mlx5_core_dev *mdev, void *vpriv)</span>
 	if (!netif_device_present(netdev))
 		return;
 
<span class="p_add">+	mlx5e_unregister_vport_rep(mdev);</span>
 	mlx5e_detach_netdev(mdev, netdev);
 	mlx5e_destroy_mdev_resources(mdev);
 }
<span class="p_chunk">@@ -4012,8 +4026,6 @@</span> <span class="p_context"> static void *mlx5e_add(struct mlx5_core_dev *mdev)</span>
 	if (err)
 		return NULL;
 
<span class="p_del">-	mlx5e_register_vport_rep(mdev);</span>
<span class="p_del">-</span>
 	if (MLX5_CAP_GEN(mdev, vport_group_manager))
 		ppriv = &amp;esw-&gt;offloads.vport_reps[0];
 
<span class="p_chunk">@@ -4065,13 +4077,7 @@</span> <span class="p_context"> void mlx5e_destroy_netdev(struct mlx5_core_dev *mdev, struct mlx5e_priv *priv)</span>
 
 static void mlx5e_remove(struct mlx5_core_dev *mdev, void *vpriv)
 {
<span class="p_del">-	struct mlx5_eswitch *esw = mdev-&gt;priv.eswitch;</span>
<span class="p_del">-	int total_vfs = MLX5_TOTAL_VPORTS(mdev);</span>
 	struct mlx5e_priv *priv = vpriv;
<span class="p_del">-	int vport;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (vport = 1; vport &lt; total_vfs; vport++)</span>
<span class="p_del">-		mlx5_eswitch_unregister_vport_rep(esw, vport);</span>
 
 	unregister_netdev(priv-&gt;netdev);
 	mlx5e_detach(mdev, vpriv);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_header">index e7b2158bb48a..796bdf06122c 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_chunk">@@ -92,19 +92,18 @@</span> <span class="p_context"> static inline void mlx5e_cqes_update_owner(struct mlx5e_cq *cq, u32 cqcc, int n)</span>
 static inline void mlx5e_decompress_cqe(struct mlx5e_rq *rq,
 					struct mlx5e_cq *cq, u32 cqcc)
 {
<span class="p_del">-	u16 wqe_cnt_step;</span>
<span class="p_del">-</span>
 	cq-&gt;title.byte_cnt     = cq-&gt;mini_arr[cq-&gt;mini_arr_idx].byte_cnt;
 	cq-&gt;title.check_sum    = cq-&gt;mini_arr[cq-&gt;mini_arr_idx].checksum;
 	cq-&gt;title.op_own      &amp;= 0xf0;
 	cq-&gt;title.op_own      |= 0x01 &amp; (cqcc &gt;&gt; cq-&gt;wq.log_sz);
 	cq-&gt;title.wqe_counter  = cpu_to_be16(cq-&gt;decmprs_wqe_counter);
 
<span class="p_del">-	wqe_cnt_step =</span>
<span class="p_del">-		rq-&gt;wq_type == MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ ?</span>
<span class="p_del">-		mpwrq_get_cqe_consumed_strides(&amp;cq-&gt;title) : 1;</span>
<span class="p_del">-	cq-&gt;decmprs_wqe_counter =</span>
<span class="p_del">-		(cq-&gt;decmprs_wqe_counter + wqe_cnt_step) &amp; rq-&gt;wq.sz_m1;</span>
<span class="p_add">+	if (rq-&gt;wq_type == MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ)</span>
<span class="p_add">+		cq-&gt;decmprs_wqe_counter +=</span>
<span class="p_add">+			mpwrq_get_cqe_consumed_strides(&amp;cq-&gt;title);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		cq-&gt;decmprs_wqe_counter =</span>
<span class="p_add">+			(cq-&gt;decmprs_wqe_counter + 1) &amp; rq-&gt;wq.sz_m1;</span>
 }
 
 static inline void mlx5e_decompress_cqe_no_hash(struct mlx5e_rq *rq,
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_header">index e83072da6272..690563099313 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_chunk">@@ -500,30 +500,40 @@</span> <span class="p_context"> static int</span>
 mlxsw_sp_vr_lpm_tree_check(struct mlxsw_sp *mlxsw_sp, struct mlxsw_sp_vr *vr,
 			   struct mlxsw_sp_prefix_usage *req_prefix_usage)
 {
<span class="p_del">-	struct mlxsw_sp_lpm_tree *lpm_tree;</span>
<span class="p_add">+	struct mlxsw_sp_lpm_tree *lpm_tree = vr-&gt;lpm_tree;</span>
<span class="p_add">+	struct mlxsw_sp_lpm_tree *new_tree;</span>
<span class="p_add">+	int err;</span>
 
<span class="p_del">-	if (mlxsw_sp_prefix_usage_eq(req_prefix_usage,</span>
<span class="p_del">-				     &amp;vr-&gt;lpm_tree-&gt;prefix_usage))</span>
<span class="p_add">+	if (mlxsw_sp_prefix_usage_eq(req_prefix_usage, &amp;lpm_tree-&gt;prefix_usage))</span>
 		return 0;
 
<span class="p_del">-	lpm_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, req_prefix_usage,</span>
<span class="p_add">+	new_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, req_prefix_usage,</span>
 					 vr-&gt;proto, false);
<span class="p_del">-	if (IS_ERR(lpm_tree)) {</span>
<span class="p_add">+	if (IS_ERR(new_tree)) {</span>
 		/* We failed to get a tree according to the required
 		 * prefix usage. However, the current tree might be still good
 		 * for us if our requirement is subset of the prefixes used
 		 * in the tree.
 		 */
 		if (mlxsw_sp_prefix_usage_subset(req_prefix_usage,
<span class="p_del">-						 &amp;vr-&gt;lpm_tree-&gt;prefix_usage))</span>
<span class="p_add">+						 &amp;lpm_tree-&gt;prefix_usage))</span>
 			return 0;
<span class="p_del">-		return PTR_ERR(lpm_tree);</span>
<span class="p_add">+		return PTR_ERR(new_tree);</span>
 	}
 
<span class="p_del">-	mlxsw_sp_vr_lpm_tree_unbind(mlxsw_sp, vr);</span>
<span class="p_del">-	mlxsw_sp_lpm_tree_put(mlxsw_sp, vr-&gt;lpm_tree);</span>
<span class="p_add">+	/* Prevent packet loss by overwriting existing binding */</span>
<span class="p_add">+	vr-&gt;lpm_tree = new_tree;</span>
<span class="p_add">+	err = mlxsw_sp_vr_lpm_tree_bind(mlxsw_sp, vr);</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		goto err_tree_bind;</span>
<span class="p_add">+	mlxsw_sp_lpm_tree_put(mlxsw_sp, lpm_tree);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+err_tree_bind:</span>
 	vr-&gt;lpm_tree = lpm_tree;
<span class="p_del">-	return mlxsw_sp_vr_lpm_tree_bind(mlxsw_sp, vr);</span>
<span class="p_add">+	mlxsw_sp_lpm_tree_put(mlxsw_sp, new_tree);</span>
<span class="p_add">+	return err;</span>
 }
 
 static struct mlxsw_sp_vr *mlxsw_sp_vr_get(struct mlxsw_sp *mlxsw_sp,
<span class="p_header">diff --git a/drivers/net/geneve.c b/drivers/net/geneve.c</span>
<span class="p_header">index 8b4822ad27cb..3c1f89ab0110 100644</span>
<span class="p_header">--- a/drivers/net/geneve.c</span>
<span class="p_header">+++ b/drivers/net/geneve.c</span>
<span class="p_chunk">@@ -1039,16 +1039,22 @@</span> <span class="p_context"> static netdev_tx_t geneve_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 {
 	struct geneve_dev *geneve = netdev_priv(dev);
 	struct ip_tunnel_info *info = NULL;
<span class="p_add">+	int err;</span>
 
 	if (geneve-&gt;collect_md)
 		info = skb_tunnel_info(skb);
 
<span class="p_add">+	rcu_read_lock();</span>
 #if IS_ENABLED(CONFIG_IPV6)
 	if ((info &amp;&amp; ip_tunnel_info_af(info) == AF_INET6) ||
 	    (!info &amp;&amp; geneve-&gt;remote.sa.sa_family == AF_INET6))
<span class="p_del">-		return geneve6_xmit_skb(skb, dev, info);</span>
<span class="p_add">+		err = geneve6_xmit_skb(skb, dev, info);</span>
<span class="p_add">+	else</span>
 #endif
<span class="p_del">-	return geneve_xmit_skb(skb, dev, info);</span>
<span class="p_add">+		err = geneve_xmit_skb(skb, dev, info);</span>
<span class="p_add">+	rcu_read_unlock();</span>
<span class="p_add">+</span>
<span class="p_add">+	return err;</span>
 }
 
 static int __geneve_change_mtu(struct net_device *dev, int new_mtu, bool strict)
<span class="p_header">diff --git a/drivers/net/phy/phy.c b/drivers/net/phy/phy.c</span>
<span class="p_header">index f424b867f73e..201ffa5fe4f7 100644</span>
<span class="p_header">--- a/drivers/net/phy/phy.c</span>
<span class="p_header">+++ b/drivers/net/phy/phy.c</span>
<span class="p_chunk">@@ -611,14 +611,18 @@</span> <span class="p_context"> void phy_start_machine(struct phy_device *phydev)</span>
  * phy_trigger_machine - trigger the state machine to run
  *
  * @phydev: the phy_device struct
<span class="p_add">+ * @sync: indicate whether we should wait for the workqueue cancelation</span>
  *
  * Description: There has been a change in state which requires that the
  *   state machine runs.
  */
 
<span class="p_del">-static void phy_trigger_machine(struct phy_device *phydev)</span>
<span class="p_add">+static void phy_trigger_machine(struct phy_device *phydev, bool sync)</span>
 {
<span class="p_del">-	cancel_delayed_work_sync(&amp;phydev-&gt;state_queue);</span>
<span class="p_add">+	if (sync)</span>
<span class="p_add">+		cancel_delayed_work_sync(&amp;phydev-&gt;state_queue);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		cancel_delayed_work(&amp;phydev-&gt;state_queue);</span>
 	queue_delayed_work(system_power_efficient_wq, &amp;phydev-&gt;state_queue, 0);
 }
 
<span class="p_chunk">@@ -655,7 +659,7 @@</span> <span class="p_context"> static void phy_error(struct phy_device *phydev)</span>
 	phydev-&gt;state = PHY_HALTED;
 	mutex_unlock(&amp;phydev-&gt;lock);
 
<span class="p_del">-	phy_trigger_machine(phydev);</span>
<span class="p_add">+	phy_trigger_machine(phydev, false);</span>
 }
 
 /**
<span class="p_chunk">@@ -817,7 +821,7 @@</span> <span class="p_context"> void phy_change(struct work_struct *work)</span>
 	}
 
 	/* reschedule state queue work to run as soon as possible */
<span class="p_del">-	phy_trigger_machine(phydev);</span>
<span class="p_add">+	phy_trigger_machine(phydev, true);</span>
 	return;
 
 ignore:
<span class="p_chunk">@@ -907,7 +911,7 @@</span> <span class="p_context"> void phy_start(struct phy_device *phydev)</span>
 	if (do_resume)
 		phy_resume(phydev);
 
<span class="p_del">-	phy_trigger_machine(phydev);</span>
<span class="p_add">+	phy_trigger_machine(phydev, true);</span>
 }
 EXPORT_SYMBOL(phy_start);
 
<span class="p_header">diff --git a/drivers/net/tun.c b/drivers/net/tun.c</span>
<span class="p_header">index b31aca8146bb..a931b73393c8 100644</span>
<span class="p_header">--- a/drivers/net/tun.c</span>
<span class="p_header">+++ b/drivers/net/tun.c</span>
<span class="p_chunk">@@ -819,7 +819,18 @@</span> <span class="p_context"> static void tun_net_uninit(struct net_device *dev)</span>
 /* Net device open. */
 static int tun_net_open(struct net_device *dev)
 {
<span class="p_add">+	struct tun_struct *tun = netdev_priv(dev);</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
 	netif_tx_start_all_queues(dev);
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; tun-&gt;numqueues; i++) {</span>
<span class="p_add">+		struct tun_file *tfile;</span>
<span class="p_add">+</span>
<span class="p_add">+		tfile = rtnl_dereference(tun-&gt;tfiles[i]);</span>
<span class="p_add">+		tfile-&gt;socket.sk-&gt;sk_write_space(tfile-&gt;socket.sk);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1116,9 +1127,10 @@</span> <span class="p_context"> static unsigned int tun_chr_poll(struct file *file, poll_table *wait)</span>
 	if (!skb_array_empty(&amp;tfile-&gt;tx_array))
 		mask |= POLLIN | POLLRDNORM;
 
<span class="p_del">-	if (sock_writeable(sk) ||</span>
<span class="p_del">-	    (!test_and_set_bit(SOCKWQ_ASYNC_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags) &amp;&amp;</span>
<span class="p_del">-	     sock_writeable(sk)))</span>
<span class="p_add">+	if (tun-&gt;dev-&gt;flags &amp; IFF_UP &amp;&amp;</span>
<span class="p_add">+	    (sock_writeable(sk) ||</span>
<span class="p_add">+	     (!test_and_set_bit(SOCKWQ_ASYNC_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags) &amp;&amp;</span>
<span class="p_add">+	      sock_writeable(sk))))</span>
 		mask |= POLLOUT | POLLWRNORM;
 
 	if (tun-&gt;dev-&gt;reg_state != NETREG_REGISTERED)
<span class="p_header">diff --git a/drivers/net/vrf.c b/drivers/net/vrf.c</span>
<span class="p_header">index 95cf1d844781..bc744acabf98 100644</span>
<span class="p_header">--- a/drivers/net/vrf.c</span>
<span class="p_header">+++ b/drivers/net/vrf.c</span>
<span class="p_chunk">@@ -346,6 +346,7 @@</span> <span class="p_context"> static netdev_tx_t is_ip_tx_frame(struct sk_buff *skb, struct net_device *dev)</span>
 
 static netdev_tx_t vrf_xmit(struct sk_buff *skb, struct net_device *dev)
 {
<span class="p_add">+	int len = skb-&gt;len;</span>
 	netdev_tx_t ret = is_ip_tx_frame(skb, dev);
 
 	if (likely(ret == NET_XMIT_SUCCESS || ret == NET_XMIT_CN)) {
<span class="p_chunk">@@ -353,7 +354,7 @@</span> <span class="p_context"> static netdev_tx_t vrf_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 
 		u64_stats_update_begin(&amp;dstats-&gt;syncp);
 		dstats-&gt;tx_pkts++;
<span class="p_del">-		dstats-&gt;tx_bytes += skb-&gt;len;</span>
<span class="p_add">+		dstats-&gt;tx_bytes += len;</span>
 		u64_stats_update_end(&amp;dstats-&gt;syncp);
 	} else {
 		this_cpu_inc(dev-&gt;dstats-&gt;tx_drps);
<span class="p_header">diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c</span>
<span class="p_header">index d4f495b41bd4..3c4c2cf6d444 100644</span>
<span class="p_header">--- a/drivers/net/vxlan.c</span>
<span class="p_header">+++ b/drivers/net/vxlan.c</span>
<span class="p_chunk">@@ -1942,7 +1942,6 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 	const struct iphdr *old_iph;
 	union vxlan_addr *dst;
 	union vxlan_addr remote_ip, local_ip;
<span class="p_del">-	union vxlan_addr *src;</span>
 	struct vxlan_metadata _md;
 	struct vxlan_metadata *md = &amp;_md;
 	__be16 src_port = 0, dst_port;
<span class="p_chunk">@@ -1956,11 +1955,12 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 
 	info = skb_tunnel_info(skb);
 
<span class="p_add">+	rcu_read_lock();</span>
 	if (rdst) {
 		dst_port = rdst-&gt;remote_port ? rdst-&gt;remote_port : vxlan-&gt;cfg.dst_port;
 		vni = rdst-&gt;remote_vni;
 		dst = &amp;rdst-&gt;remote_ip;
<span class="p_del">-		src = &amp;vxlan-&gt;cfg.saddr;</span>
<span class="p_add">+		local_ip = vxlan-&gt;cfg.saddr;</span>
 		dst_cache = &amp;rdst-&gt;dst_cache;
 	} else {
 		if (!info) {
<span class="p_chunk">@@ -1979,7 +1979,6 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 			local_ip.sin6.sin6_addr = info-&gt;key.u.ipv6.src;
 		}
 		dst = &amp;remote_ip;
<span class="p_del">-		src = &amp;local_ip;</span>
 		dst_cache = &amp;info-&gt;dst_cache;
 	}
 
<span class="p_chunk">@@ -1987,7 +1986,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		if (did_rsc) {
 			/* short-circuited back to local bridge */
 			vxlan_encap_bypass(skb, vxlan, vxlan);
<span class="p_del">-			return;</span>
<span class="p_add">+			goto out_unlock;</span>
 		}
 		goto drop;
 	}
<span class="p_chunk">@@ -2028,7 +2027,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		rt = vxlan_get_route(vxlan, skb,
 				     rdst ? rdst-&gt;remote_ifindex : 0, tos,
 				     dst-&gt;sin.sin_addr.s_addr,
<span class="p_del">-				     &amp;src-&gt;sin.sin_addr.s_addr,</span>
<span class="p_add">+				     &amp;local_ip.sin.sin_addr.s_addr,</span>
 				     dst_cache, info);
 		if (IS_ERR(rt)) {
 			netdev_dbg(dev, &quot;no route to %pI4\n&quot;,
<span class="p_chunk">@@ -2056,7 +2055,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 			if (!dst_vxlan)
 				goto tx_error;
 			vxlan_encap_bypass(skb, vxlan, dst_vxlan);
<span class="p_del">-			return;</span>
<span class="p_add">+			goto out_unlock;</span>
 		}
 
 		if (!info)
<span class="p_chunk">@@ -2071,7 +2070,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		if (err &lt; 0)
 			goto xmit_tx_error;
 
<span class="p_del">-		udp_tunnel_xmit_skb(rt, sk, skb, src-&gt;sin.sin_addr.s_addr,</span>
<span class="p_add">+		udp_tunnel_xmit_skb(rt, sk, skb, local_ip.sin.sin_addr.s_addr,</span>
 				    dst-&gt;sin.sin_addr.s_addr, tos, ttl, df,
 				    src_port, dst_port, xnet, !udp_sum);
 #if IS_ENABLED(CONFIG_IPV6)
<span class="p_chunk">@@ -2087,7 +2086,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		ndst = vxlan6_get_route(vxlan, skb,
 					rdst ? rdst-&gt;remote_ifindex : 0, tos,
 					label, &amp;dst-&gt;sin6.sin6_addr,
<span class="p_del">-					&amp;src-&gt;sin6.sin6_addr,</span>
<span class="p_add">+					&amp;local_ip.sin6.sin6_addr,</span>
 					dst_cache, info);
 		if (IS_ERR(ndst)) {
 			netdev_dbg(dev, &quot;no route to %pI6\n&quot;,
<span class="p_chunk">@@ -2117,7 +2116,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 			if (!dst_vxlan)
 				goto tx_error;
 			vxlan_encap_bypass(skb, vxlan, dst_vxlan);
<span class="p_del">-			return;</span>
<span class="p_add">+			goto out_unlock;</span>
 		}
 
 		if (!info)
<span class="p_chunk">@@ -2131,15 +2130,16 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		if (err &lt; 0) {
 			dst_release(ndst);
 			dev-&gt;stats.tx_errors++;
<span class="p_del">-			return;</span>
<span class="p_add">+			goto out_unlock;</span>
 		}
 		udp_tunnel6_xmit_skb(ndst, sk, skb, dev,
<span class="p_del">-				     &amp;src-&gt;sin6.sin6_addr,</span>
<span class="p_add">+				     &amp;local_ip.sin6.sin6_addr,</span>
 				     &amp;dst-&gt;sin6.sin6_addr, tos, ttl,
 				     label, src_port, dst_port, !udp_sum);
 #endif
 	}
<span class="p_del">-</span>
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	rcu_read_unlock();</span>
 	return;
 
 drop:
<span class="p_chunk">@@ -2155,6 +2155,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 	dev-&gt;stats.tx_errors++;
 tx_free:
 	dev_kfree_skb(skb);
<span class="p_add">+	rcu_read_unlock();</span>
 }
 
 /* Transmit local packets over Vxlan
<span class="p_chunk">@@ -2637,7 +2638,7 @@</span> <span class="p_context"> static int vxlan_validate(struct nlattr *tb[], struct nlattr *data[])</span>
 
 	if (data[IFLA_VXLAN_ID]) {
 		__u32 id = nla_get_u32(data[IFLA_VXLAN_ID]);
<span class="p_del">-		if (id &gt;= VXLAN_VID_MASK)</span>
<span class="p_add">+		if (id &gt;= VXLAN_N_VID)</span>
 			return -ERANGE;
 	}
 
<span class="p_header">diff --git a/drivers/pci/iov.c b/drivers/pci/iov.c</span>
<span class="p_header">index e30f05c8517f..47227820406d 100644</span>
<span class="p_header">--- a/drivers/pci/iov.c</span>
<span class="p_header">+++ b/drivers/pci/iov.c</span>
<span class="p_chunk">@@ -306,13 +306,6 @@</span> <span class="p_context"> static int sriov_enable(struct pci_dev *dev, int nr_virtfn)</span>
 			return rc;
 	}
 
<span class="p_del">-	pci_iov_set_numvfs(dev, nr_virtfn);</span>
<span class="p_del">-	iov-&gt;ctrl |= PCI_SRIOV_CTRL_VFE | PCI_SRIOV_CTRL_MSE;</span>
<span class="p_del">-	pci_cfg_access_lock(dev);</span>
<span class="p_del">-	pci_write_config_word(dev, iov-&gt;pos + PCI_SRIOV_CTRL, iov-&gt;ctrl);</span>
<span class="p_del">-	msleep(100);</span>
<span class="p_del">-	pci_cfg_access_unlock(dev);</span>
<span class="p_del">-</span>
 	iov-&gt;initial_VFs = initial;
 	if (nr_virtfn &lt; initial)
 		initial = nr_virtfn;
<span class="p_chunk">@@ -323,6 +316,13 @@</span> <span class="p_context"> static int sriov_enable(struct pci_dev *dev, int nr_virtfn)</span>
 		goto err_pcibios;
 	}
 
<span class="p_add">+	pci_iov_set_numvfs(dev, nr_virtfn);</span>
<span class="p_add">+	iov-&gt;ctrl |= PCI_SRIOV_CTRL_VFE | PCI_SRIOV_CTRL_MSE;</span>
<span class="p_add">+	pci_cfg_access_lock(dev);</span>
<span class="p_add">+	pci_write_config_word(dev, iov-&gt;pos + PCI_SRIOV_CTRL, iov-&gt;ctrl);</span>
<span class="p_add">+	msleep(100);</span>
<span class="p_add">+	pci_cfg_access_unlock(dev);</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; initial; i++) {
 		rc = pci_iov_add_virtfn(dev, i, 0);
 		if (rc)
<span class="p_chunk">@@ -554,21 +554,61 @@</span> <span class="p_context"> void pci_iov_release(struct pci_dev *dev)</span>
 }
 
 /**
<span class="p_del">- * pci_iov_resource_bar - get position of the SR-IOV BAR</span>
<span class="p_add">+ * pci_iov_update_resource - update a VF BAR</span>
  * @dev: the PCI device
  * @resno: the resource number
  *
<span class="p_del">- * Returns position of the BAR encapsulated in the SR-IOV capability.</span>
<span class="p_add">+ * Update a VF BAR in the SR-IOV capability of a PF.</span>
  */
<span class="p_del">-int pci_iov_resource_bar(struct pci_dev *dev, int resno)</span>
<span class="p_add">+void pci_iov_update_resource(struct pci_dev *dev, int resno)</span>
 {
<span class="p_del">-	if (resno &lt; PCI_IOV_RESOURCES || resno &gt; PCI_IOV_RESOURCE_END)</span>
<span class="p_del">-		return 0;</span>
<span class="p_add">+	struct pci_sriov *iov = dev-&gt;is_physfn ? dev-&gt;sriov : NULL;</span>
<span class="p_add">+	struct resource *res = dev-&gt;resource + resno;</span>
<span class="p_add">+	int vf_bar = resno - PCI_IOV_RESOURCES;</span>
<span class="p_add">+	struct pci_bus_region region;</span>
<span class="p_add">+	u16 cmd;</span>
<span class="p_add">+	u32 new;</span>
<span class="p_add">+	int reg;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The generic pci_restore_bars() path calls this for all devices,</span>
<span class="p_add">+	 * including VFs and non-SR-IOV devices.  If this is not a PF, we</span>
<span class="p_add">+	 * have nothing to do.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!iov)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pci_read_config_word(dev, iov-&gt;pos + PCI_SRIOV_CTRL, &amp;cmd);</span>
<span class="p_add">+	if ((cmd &amp; PCI_SRIOV_CTRL_VFE) &amp;&amp; (cmd &amp; PCI_SRIOV_CTRL_MSE)) {</span>
<span class="p_add">+		dev_WARN(&amp;dev-&gt;dev, &quot;can&#39;t update enabled VF BAR%d %pR\n&quot;,</span>
<span class="p_add">+			 vf_bar, res);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ignore unimplemented BARs, unused resource slots for 64-bit</span>
<span class="p_add">+	 * BARs, and non-movable resources, e.g., those described via</span>
<span class="p_add">+	 * Enhanced Allocation.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!res-&gt;flags)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (res-&gt;flags &amp; IORESOURCE_UNSET)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (res-&gt;flags &amp; IORESOURCE_PCI_FIXED)</span>
<span class="p_add">+		return;</span>
 
<span class="p_del">-	BUG_ON(!dev-&gt;is_physfn);</span>
<span class="p_add">+	pcibios_resource_to_bus(dev-&gt;bus, &amp;region, res);</span>
<span class="p_add">+	new = region.start;</span>
<span class="p_add">+	new |= res-&gt;flags &amp; ~PCI_BASE_ADDRESS_MEM_MASK;</span>
 
<span class="p_del">-	return dev-&gt;sriov-&gt;pos + PCI_SRIOV_BAR +</span>
<span class="p_del">-		4 * (resno - PCI_IOV_RESOURCES);</span>
<span class="p_add">+	reg = iov-&gt;pos + PCI_SRIOV_BAR + 4 * vf_bar;</span>
<span class="p_add">+	pci_write_config_dword(dev, reg, new);</span>
<span class="p_add">+	if (res-&gt;flags &amp; IORESOURCE_MEM_64) {</span>
<span class="p_add">+		new = region.start &gt;&gt; 16 &gt;&gt; 16;</span>
<span class="p_add">+		pci_write_config_dword(dev, reg + 4, new);</span>
<span class="p_add">+	}</span>
 }
 
 resource_size_t __weak pcibios_iov_resource_alignment(struct pci_dev *dev,
<span class="p_header">diff --git a/drivers/pci/pci.c b/drivers/pci/pci.c</span>
<span class="p_header">index eda6a7cf0e54..6922964e3dff 100644</span>
<span class="p_header">--- a/drivers/pci/pci.c</span>
<span class="p_header">+++ b/drivers/pci/pci.c</span>
<span class="p_chunk">@@ -564,10 +564,6 @@</span> <span class="p_context"> static void pci_restore_bars(struct pci_dev *dev)</span>
 {
 	int i;
 
<span class="p_del">-	/* Per SR-IOV spec 3.4.1.11, VF BARs are RO zero */</span>
<span class="p_del">-	if (dev-&gt;is_virtfn)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
 	for (i = 0; i &lt; PCI_BRIDGE_RESOURCES; i++)
 		pci_update_resource(dev, i);
 }
<span class="p_chunk">@@ -4835,36 +4831,6 @@</span> <span class="p_context"> int pci_select_bars(struct pci_dev *dev, unsigned long flags)</span>
 }
 EXPORT_SYMBOL(pci_select_bars);
 
<span class="p_del">-/**</span>
<span class="p_del">- * pci_resource_bar - get position of the BAR associated with a resource</span>
<span class="p_del">- * @dev: the PCI device</span>
<span class="p_del">- * @resno: the resource number</span>
<span class="p_del">- * @type: the BAR type to be filled in</span>
<span class="p_del">- *</span>
<span class="p_del">- * Returns BAR position in config space, or 0 if the BAR is invalid.</span>
<span class="p_del">- */</span>
<span class="p_del">-int pci_resource_bar(struct pci_dev *dev, int resno, enum pci_bar_type *type)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int reg;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (resno &lt; PCI_ROM_RESOURCE) {</span>
<span class="p_del">-		*type = pci_bar_unknown;</span>
<span class="p_del">-		return PCI_BASE_ADDRESS_0 + 4 * resno;</span>
<span class="p_del">-	} else if (resno == PCI_ROM_RESOURCE) {</span>
<span class="p_del">-		*type = pci_bar_mem32;</span>
<span class="p_del">-		return dev-&gt;rom_base_reg;</span>
<span class="p_del">-	} else if (resno &lt; PCI_BRIDGE_RESOURCES) {</span>
<span class="p_del">-		/* device specific resource */</span>
<span class="p_del">-		*type = pci_bar_unknown;</span>
<span class="p_del">-		reg = pci_iov_resource_bar(dev, resno);</span>
<span class="p_del">-		if (reg)</span>
<span class="p_del">-			return reg;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	dev_err(&amp;dev-&gt;dev, &quot;BAR %d: invalid resource\n&quot;, resno);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /* Some architectures require additional programming to enable VGA */
 static arch_set_vga_state_t arch_set_vga_state;
 
<span class="p_header">diff --git a/drivers/pci/pci.h b/drivers/pci/pci.h</span>
<span class="p_header">index 451856210e18..a5d37f6a9fb5 100644</span>
<span class="p_header">--- a/drivers/pci/pci.h</span>
<span class="p_header">+++ b/drivers/pci/pci.h</span>
<span class="p_chunk">@@ -245,7 +245,6 @@</span> <span class="p_context"> bool pci_bus_read_dev_vendor_id(struct pci_bus *bus, int devfn, u32 *pl,</span>
 int pci_setup_device(struct pci_dev *dev);
 int __pci_read_base(struct pci_dev *dev, enum pci_bar_type type,
 		    struct resource *res, unsigned int reg);
<span class="p_del">-int pci_resource_bar(struct pci_dev *dev, int resno, enum pci_bar_type *type);</span>
 void pci_configure_ari(struct pci_dev *dev);
 void __pci_bus_size_bridges(struct pci_bus *bus,
 			struct list_head *realloc_head);
<span class="p_chunk">@@ -289,7 +288,7 @@</span> <span class="p_context"> static inline void pci_restore_ats_state(struct pci_dev *dev)</span>
 #ifdef CONFIG_PCI_IOV
 int pci_iov_init(struct pci_dev *dev);
 void pci_iov_release(struct pci_dev *dev);
<span class="p_del">-int pci_iov_resource_bar(struct pci_dev *dev, int resno);</span>
<span class="p_add">+void pci_iov_update_resource(struct pci_dev *dev, int resno);</span>
 resource_size_t pci_sriov_resource_alignment(struct pci_dev *dev, int resno);
 void pci_restore_iov_state(struct pci_dev *dev);
 int pci_iov_bus_range(struct pci_bus *bus);
<span class="p_chunk">@@ -303,10 +302,6 @@</span> <span class="p_context"> static inline void pci_iov_release(struct pci_dev *dev)</span>
 
 {
 }
<span class="p_del">-static inline int pci_iov_resource_bar(struct pci_dev *dev, int resno)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
 static inline void pci_restore_iov_state(struct pci_dev *dev)
 {
 }
<span class="p_header">diff --git a/drivers/pci/probe.c b/drivers/pci/probe.c</span>
<span class="p_header">index 300770cdc084..d266d800f246 100644</span>
<span class="p_header">--- a/drivers/pci/probe.c</span>
<span class="p_header">+++ b/drivers/pci/probe.c</span>
<span class="p_chunk">@@ -227,7 +227,8 @@</span> <span class="p_context"> int __pci_read_base(struct pci_dev *dev, enum pci_bar_type type,</span>
 			mask64 = (u32)PCI_BASE_ADDRESS_MEM_MASK;
 		}
 	} else {
<span class="p_del">-		res-&gt;flags |= (l &amp; IORESOURCE_ROM_ENABLE);</span>
<span class="p_add">+		if (l &amp; PCI_ROM_ADDRESS_ENABLE)</span>
<span class="p_add">+			res-&gt;flags |= IORESOURCE_ROM_ENABLE;</span>
 		l64 = l &amp; PCI_ROM_ADDRESS_MASK;
 		sz64 = sz &amp; PCI_ROM_ADDRESS_MASK;
 		mask64 = (u32)PCI_ROM_ADDRESS_MASK;
<span class="p_header">diff --git a/drivers/pci/rom.c b/drivers/pci/rom.c</span>
<span class="p_header">index 06663d391b39..b6edb187d160 100644</span>
<span class="p_header">--- a/drivers/pci/rom.c</span>
<span class="p_header">+++ b/drivers/pci/rom.c</span>
<span class="p_chunk">@@ -35,6 +35,11 @@</span> <span class="p_context"> int pci_enable_rom(struct pci_dev *pdev)</span>
 	if (res-&gt;flags &amp; IORESOURCE_ROM_SHADOW)
 		return 0;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ideally pci_update_resource() would update the ROM BAR address,</span>
<span class="p_add">+	 * and we would only set the enable bit here.  But apparently some</span>
<span class="p_add">+	 * devices have buggy ROM BARs that read as zero when disabled.</span>
<span class="p_add">+	 */</span>
 	pcibios_resource_to_bus(pdev-&gt;bus, &amp;region, res);
 	pci_read_config_dword(pdev, pdev-&gt;rom_base_reg, &amp;rom_addr);
 	rom_addr &amp;= ~PCI_ROM_ADDRESS_MASK;
<span class="p_header">diff --git a/drivers/pci/setup-res.c b/drivers/pci/setup-res.c</span>
<span class="p_header">index 9526e341988b..4bc589ee78d0 100644</span>
<span class="p_header">--- a/drivers/pci/setup-res.c</span>
<span class="p_header">+++ b/drivers/pci/setup-res.c</span>
<span class="p_chunk">@@ -25,21 +25,18 @@</span> <span class="p_context"></span>
 #include &lt;linux/slab.h&gt;
 #include &quot;pci.h&quot;
 
<span class="p_del">-</span>
<span class="p_del">-void pci_update_resource(struct pci_dev *dev, int resno)</span>
<span class="p_add">+static void pci_std_update_resource(struct pci_dev *dev, int resno)</span>
 {
 	struct pci_bus_region region;
 	bool disable;
 	u16 cmd;
 	u32 new, check, mask;
 	int reg;
<span class="p_del">-	enum pci_bar_type type;</span>
 	struct resource *res = dev-&gt;resource + resno;
 
<span class="p_del">-	if (dev-&gt;is_virtfn) {</span>
<span class="p_del">-		dev_warn(&amp;dev-&gt;dev, &quot;can&#39;t update VF BAR%d\n&quot;, resno);</span>
<span class="p_add">+	/* Per SR-IOV spec 3.4.1.11, VF BARs are RO zero */</span>
<span class="p_add">+	if (dev-&gt;is_virtfn)</span>
 		return;
<span class="p_del">-	}</span>
 
 	/*
 	 * Ignore resources for unimplemented BARs and unused resource slots
<span class="p_chunk">@@ -60,21 +57,34 @@</span> <span class="p_context"> void pci_update_resource(struct pci_dev *dev, int resno)</span>
 		return;
 
 	pcibios_resource_to_bus(dev-&gt;bus, &amp;region, res);
<span class="p_add">+	new = region.start;</span>
 
<span class="p_del">-	new = region.start | (res-&gt;flags &amp; PCI_REGION_FLAG_MASK);</span>
<span class="p_del">-	if (res-&gt;flags &amp; IORESOURCE_IO)</span>
<span class="p_add">+	if (res-&gt;flags &amp; IORESOURCE_IO) {</span>
 		mask = (u32)PCI_BASE_ADDRESS_IO_MASK;
<span class="p_del">-	else</span>
<span class="p_add">+		new |= res-&gt;flags &amp; ~PCI_BASE_ADDRESS_IO_MASK;</span>
<span class="p_add">+	} else if (resno == PCI_ROM_RESOURCE) {</span>
<span class="p_add">+		mask = (u32)PCI_ROM_ADDRESS_MASK;</span>
<span class="p_add">+	} else {</span>
 		mask = (u32)PCI_BASE_ADDRESS_MEM_MASK;
<span class="p_add">+		new |= res-&gt;flags &amp; ~PCI_BASE_ADDRESS_MEM_MASK;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	reg = pci_resource_bar(dev, resno, &amp;type);</span>
<span class="p_del">-	if (!reg)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	if (type != pci_bar_unknown) {</span>
<span class="p_add">+	if (resno &lt; PCI_ROM_RESOURCE) {</span>
<span class="p_add">+		reg = PCI_BASE_ADDRESS_0 + 4 * resno;</span>
<span class="p_add">+	} else if (resno == PCI_ROM_RESOURCE) {</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Apparently some Matrox devices have ROM BARs that read</span>
<span class="p_add">+		 * as zero when disabled, so don&#39;t update ROM BARs unless</span>
<span class="p_add">+		 * they&#39;re enabled.  See https://lkml.org/lkml/2005/8/30/138.</span>
<span class="p_add">+		 */</span>
 		if (!(res-&gt;flags &amp; IORESOURCE_ROM_ENABLE))
 			return;
<span class="p_add">+</span>
<span class="p_add">+		reg = dev-&gt;rom_base_reg;</span>
 		new |= PCI_ROM_ADDRESS_ENABLE;
<span class="p_del">-	}</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		return;</span>
 
 	/*
 	 * We can&#39;t update a 64-bit BAR atomically, so when possible,
<span class="p_chunk">@@ -110,6 +120,16 @@</span> <span class="p_context"> void pci_update_resource(struct pci_dev *dev, int resno)</span>
 		pci_write_config_word(dev, PCI_COMMAND, cmd);
 }
 
<span class="p_add">+void pci_update_resource(struct pci_dev *dev, int resno)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (resno &lt;= PCI_ROM_RESOURCE)</span>
<span class="p_add">+		pci_std_update_resource(dev, resno);</span>
<span class="p_add">+#ifdef CONFIG_PCI_IOV</span>
<span class="p_add">+	else if (resno &gt;= PCI_IOV_RESOURCES &amp;&amp; resno &lt;= PCI_IOV_RESOURCE_END)</span>
<span class="p_add">+		pci_iov_update_resource(dev, resno);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int pci_claim_resource(struct pci_dev *dev, int resource)
 {
 	struct resource *res = &amp;dev-&gt;resource[resource];
<span class="p_header">diff --git a/drivers/s390/crypto/ap_bus.c b/drivers/s390/crypto/ap_bus.c</span>
<span class="p_header">index ed92fb09fc8e..76b802cf2f0b 100644</span>
<span class="p_header">--- a/drivers/s390/crypto/ap_bus.c</span>
<span class="p_header">+++ b/drivers/s390/crypto/ap_bus.c</span>
<span class="p_chunk">@@ -1712,6 +1712,9 @@</span> <span class="p_context"> static void ap_scan_bus(struct work_struct *unused)</span>
 		ap_dev-&gt;queue_depth = queue_depth;
 		ap_dev-&gt;raw_hwtype = device_type;
 		ap_dev-&gt;device_type = device_type;
<span class="p_add">+		/* CEX6 toleration: map to CEX5 */</span>
<span class="p_add">+		if (device_type == AP_DEVICE_TYPE_CEX6)</span>
<span class="p_add">+			ap_dev-&gt;device_type = AP_DEVICE_TYPE_CEX5;</span>
 		ap_dev-&gt;functions = device_functions;
 		spin_lock_init(&amp;ap_dev-&gt;lock);
 		INIT_LIST_HEAD(&amp;ap_dev-&gt;pendingq);
<span class="p_header">diff --git a/drivers/s390/crypto/ap_bus.h b/drivers/s390/crypto/ap_bus.h</span>
<span class="p_header">index d7fdf5c024d7..fd66d2c450d5 100644</span>
<span class="p_header">--- a/drivers/s390/crypto/ap_bus.h</span>
<span class="p_header">+++ b/drivers/s390/crypto/ap_bus.h</span>
<span class="p_chunk">@@ -105,6 +105,7 @@</span> <span class="p_context"> static inline int ap_test_bit(unsigned int *ptr, unsigned int nr)</span>
 #define AP_DEVICE_TYPE_CEX3C	9
 #define AP_DEVICE_TYPE_CEX4	10
 #define AP_DEVICE_TYPE_CEX5	11
<span class="p_add">+#define AP_DEVICE_TYPE_CEX6	12</span>
 
 /*
  * Known function facilities
<span class="p_header">diff --git a/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c b/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c</span>
<span class="p_header">index 91dfd58b175d..c4fe95a25621 100644</span>
<span class="p_header">--- a/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c</span>
<span class="p_header">+++ b/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c</span>
<span class="p_chunk">@@ -22,7 +22,7 @@</span> <span class="p_context"></span>
  *
  ****************************************************************************/
 
<span class="p_del">-#define pr_fmt(fmt)     KBUILD_MODNAME &quot;: &quot; fmt</span>
<span class="p_add">+#define pr_fmt(fmt)	KBUILD_MODNAME &quot;: &quot; fmt</span>
 
 #include &lt;linux/module.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_chunk">@@ -82,7 +82,7 @@</span> <span class="p_context"> static void ibmvscsis_determine_resid(struct se_cmd *se_cmd,</span>
 		}
 	} else if (se_cmd-&gt;se_cmd_flags &amp; SCF_OVERFLOW_BIT) {
 		if (se_cmd-&gt;data_direction == DMA_TO_DEVICE) {
<span class="p_del">-			/*  residual data from an overflow write */</span>
<span class="p_add">+			/* residual data from an overflow write */</span>
 			rsp-&gt;flags = SRP_RSP_FLAG_DOOVER;
 			rsp-&gt;data_out_res_cnt = cpu_to_be32(residual_count);
 		} else if (se_cmd-&gt;data_direction == DMA_FROM_DEVICE) {
<span class="p_chunk">@@ -102,7 +102,7 @@</span> <span class="p_context"> static void ibmvscsis_determine_resid(struct se_cmd *se_cmd,</span>
  * and the function returns TRUE.
  *
  * EXECUTION ENVIRONMENT:
<span class="p_del">- *      Interrupt or Process environment</span>
<span class="p_add">+ *	Interrupt or Process environment</span>
  */
 static bool connection_broken(struct scsi_info *vscsi)
 {
<span class="p_chunk">@@ -325,7 +325,7 @@</span> <span class="p_context"> static struct viosrp_crq *ibmvscsis_cmd_q_dequeue(uint mask,</span>
 }
 
 /**
<span class="p_del">- * ibmvscsis_send_init_message() -  send initialize message to the client</span>
<span class="p_add">+ * ibmvscsis_send_init_message() - send initialize message to the client</span>
  * @vscsi:	Pointer to our adapter structure
  * @format:	Which Init Message format to send
  *
<span class="p_chunk">@@ -383,13 +383,13 @@</span> <span class="p_context"> static long ibmvscsis_check_init_msg(struct scsi_info *vscsi, uint *format)</span>
 					      vscsi-&gt;cmd_q.base_addr);
 		if (crq) {
 			*format = (uint)(crq-&gt;format);
<span class="p_del">-			rc =  ERROR;</span>
<span class="p_add">+			rc = ERROR;</span>
 			crq-&gt;valid = INVALIDATE_CMD_RESP_EL;
 			dma_rmb();
 		}
 	} else {
 		*format = (uint)(crq-&gt;format);
<span class="p_del">-		rc =  ERROR;</span>
<span class="p_add">+		rc = ERROR;</span>
 		crq-&gt;valid = INVALIDATE_CMD_RESP_EL;
 		dma_rmb();
 	}
<span class="p_chunk">@@ -398,166 +398,6 @@</span> <span class="p_context"> static long ibmvscsis_check_init_msg(struct scsi_info *vscsi, uint *format)</span>
 }
 
 /**
<span class="p_del">- * ibmvscsis_establish_new_q() - Establish new CRQ queue</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- * @new_state:	New state being established after resetting the queue</span>
<span class="p_del">- *</span>
<span class="p_del">- * Must be called with interrupt lock held.</span>
<span class="p_del">- */</span>
<span class="p_del">-static long ibmvscsis_establish_new_q(struct scsi_info *vscsi,  uint new_state)</span>
<span class="p_del">-{</span>
<span class="p_del">-	long rc = ADAPT_SUCCESS;</span>
<span class="p_del">-	uint format;</span>
<span class="p_del">-</span>
<span class="p_del">-	vscsi-&gt;flags &amp;= PRESERVE_FLAG_FIELDS;</span>
<span class="p_del">-	vscsi-&gt;rsp_q_timer.timer_pops = 0;</span>
<span class="p_del">-	vscsi-&gt;debit = 0;</span>
<span class="p_del">-	vscsi-&gt;credit = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	rc = vio_enable_interrupts(vscsi-&gt;dma_dev);</span>
<span class="p_del">-	if (rc) {</span>
<span class="p_del">-		pr_warn(&quot;reset_queue: failed to enable interrupts, rc %ld\n&quot;,</span>
<span class="p_del">-			rc);</span>
<span class="p_del">-		return rc;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	rc = ibmvscsis_check_init_msg(vscsi, &amp;format);</span>
<span class="p_del">-	if (rc) {</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;reset_queue: check_init_msg failed, rc %ld\n&quot;,</span>
<span class="p_del">-			rc);</span>
<span class="p_del">-		return rc;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (format == UNUSED_FORMAT &amp;&amp; new_state == WAIT_CONNECTION) {</span>
<span class="p_del">-		rc = ibmvscsis_send_init_message(vscsi, INIT_MSG);</span>
<span class="p_del">-		switch (rc) {</span>
<span class="p_del">-		case H_SUCCESS:</span>
<span class="p_del">-		case H_DROPPED:</span>
<span class="p_del">-		case H_CLOSED:</span>
<span class="p_del">-			rc = ADAPT_SUCCESS;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case H_PARAMETER:</span>
<span class="p_del">-		case H_HARDWARE:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			vscsi-&gt;state = UNDEFINED;</span>
<span class="p_del">-			rc = H_HARDWARE;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return rc;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * ibmvscsis_reset_queue() - Reset CRQ Queue</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- * @new_state:	New state to establish after resetting the queue</span>
<span class="p_del">- *</span>
<span class="p_del">- * This function calls h_free_q and then calls h_reg_q and does all</span>
<span class="p_del">- * of the bookkeeping to get us back to where we can communicate.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Actually, we don&#39;t always call h_free_crq.  A problem was discovered</span>
<span class="p_del">- * where one partition would close and reopen his queue, which would</span>
<span class="p_del">- * cause his partner to get a transport event, which would cause him to</span>
<span class="p_del">- * close and reopen his queue, which would cause the original partition</span>
<span class="p_del">- * to get a transport event, etc., etc.  To prevent this, we don&#39;t</span>
<span class="p_del">- * actually close our queue if the client initiated the reset, (i.e.</span>
<span class="p_del">- * either we got a transport event or we have detected that the client&#39;s</span>
<span class="p_del">- * queue is gone)</span>
<span class="p_del">- *</span>
<span class="p_del">- * EXECUTION ENVIRONMENT:</span>
<span class="p_del">- *	Process environment, called with interrupt lock held</span>
<span class="p_del">- */</span>
<span class="p_del">-static void ibmvscsis_reset_queue(struct scsi_info *vscsi, uint new_state)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int bytes;</span>
<span class="p_del">-	long rc = ADAPT_SUCCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	pr_debug(&quot;reset_queue: flags 0x%x\n&quot;, vscsi-&gt;flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* don&#39;t reset, the client did it for us */</span>
<span class="p_del">-	if (vscsi-&gt;flags &amp; (CLIENT_FAILED | TRANS_EVENT)) {</span>
<span class="p_del">-		vscsi-&gt;flags &amp;=  PRESERVE_FLAG_FIELDS;</span>
<span class="p_del">-		vscsi-&gt;rsp_q_timer.timer_pops = 0;</span>
<span class="p_del">-		vscsi-&gt;debit = 0;</span>
<span class="p_del">-		vscsi-&gt;credit = 0;</span>
<span class="p_del">-		vscsi-&gt;state = new_state;</span>
<span class="p_del">-		vio_enable_interrupts(vscsi-&gt;dma_dev);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		rc = ibmvscsis_free_command_q(vscsi);</span>
<span class="p_del">-		if (rc == ADAPT_SUCCESS) {</span>
<span class="p_del">-			vscsi-&gt;state = new_state;</span>
<span class="p_del">-</span>
<span class="p_del">-			bytes = vscsi-&gt;cmd_q.size * PAGE_SIZE;</span>
<span class="p_del">-			rc = h_reg_crq(vscsi-&gt;dds.unit_id,</span>
<span class="p_del">-				       vscsi-&gt;cmd_q.crq_token, bytes);</span>
<span class="p_del">-			if (rc == H_CLOSED || rc == H_SUCCESS) {</span>
<span class="p_del">-				rc = ibmvscsis_establish_new_q(vscsi,</span>
<span class="p_del">-							       new_state);</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			if (rc != ADAPT_SUCCESS) {</span>
<span class="p_del">-				pr_debug(&quot;reset_queue: reg_crq rc %ld\n&quot;, rc);</span>
<span class="p_del">-</span>
<span class="p_del">-				vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_del">-				vscsi-&gt;flags |=  RESPONSE_Q_DOWN;</span>
<span class="p_del">-				ibmvscsis_free_command_q(vscsi);</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_del">-			vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * ibmvscsis_free_cmd_resources() - Free command resources</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- * @cmd:	Command which is not longer in use</span>
<span class="p_del">- *</span>
<span class="p_del">- * Must be called with interrupt lock held.</span>
<span class="p_del">- */</span>
<span class="p_del">-static void ibmvscsis_free_cmd_resources(struct scsi_info *vscsi,</span>
<span class="p_del">-					 struct ibmvscsis_cmd *cmd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct iu_entry *iue = cmd-&gt;iue;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (cmd-&gt;type) {</span>
<span class="p_del">-	case TASK_MANAGEMENT:</span>
<span class="p_del">-	case SCSI_CDB:</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * When the queue goes down this value is cleared, so it</span>
<span class="p_del">-		 * cannot be cleared in this general purpose function.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (vscsi-&gt;debit)</span>
<span class="p_del">-			vscsi-&gt;debit -= 1;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case ADAPTER_MAD:</span>
<span class="p_del">-		vscsi-&gt;flags &amp;= ~PROCESSING_MAD;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case UNSET_TYPE:</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	default:</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;free_cmd_resources unknown type %d\n&quot;,</span>
<span class="p_del">-			cmd-&gt;type);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	cmd-&gt;iue = NULL;</span>
<span class="p_del">-	list_add_tail(&amp;cmd-&gt;list, &amp;vscsi-&gt;free_cmd);</span>
<span class="p_del">-	srp_iu_put(iue);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (list_empty(&amp;vscsi-&gt;active_q) &amp;&amp; list_empty(&amp;vscsi-&gt;schedule_q) &amp;&amp;</span>
<span class="p_del">-	    list_empty(&amp;vscsi-&gt;waiting_rsp) &amp;&amp; (vscsi-&gt;flags &amp; WAIT_FOR_IDLE)) {</span>
<span class="p_del">-		vscsi-&gt;flags &amp;= ~WAIT_FOR_IDLE;</span>
<span class="p_del">-		complete(&amp;vscsi-&gt;wait_idle);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
  * ibmvscsis_disconnect() - Helper function to disconnect
  * @work:	Pointer to work_struct, gives access to our adapter structure
  *
<span class="p_chunk">@@ -576,7 +416,6 @@</span> <span class="p_context"> static void ibmvscsis_disconnect(struct work_struct *work)</span>
 					       proc_work);
 	u16 new_state;
 	bool wait_idle = false;
<span class="p_del">-	long rc = ADAPT_SUCCESS;</span>
 
 	spin_lock_bh(&amp;vscsi-&gt;intr_lock);
 	new_state = vscsi-&gt;new_state;
<span class="p_chunk">@@ -590,7 +429,7 @@</span> <span class="p_context"> static void ibmvscsis_disconnect(struct work_struct *work)</span>
 	 * should transitition to the new state
 	 */
 	switch (vscsi-&gt;state) {
<span class="p_del">-	/*  Should never be called while in this state. */</span>
<span class="p_add">+	/* Should never be called while in this state. */</span>
 	case NO_QUEUE:
 	/*
 	 * Can never transition from this state;
<span class="p_chunk">@@ -629,30 +468,24 @@</span> <span class="p_context"> static void ibmvscsis_disconnect(struct work_struct *work)</span>
 			vscsi-&gt;state = new_state;
 		break;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If this is a transition into an error state.</span>
<span class="p_del">-	 * a client is attempting to establish a connection</span>
<span class="p_del">-	 * and has violated the RPA protocol.</span>
<span class="p_del">-	 * There can be nothing pending on the adapter although</span>
<span class="p_del">-	 * there can be requests in the command queue.</span>
<span class="p_del">-	 */</span>
 	case WAIT_ENABLED:
<span class="p_del">-	case PART_UP_WAIT_ENAB:</span>
 		switch (new_state) {
<span class="p_del">-		case ERR_DISCONNECT:</span>
<span class="p_del">-			vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_add">+		case UNCONFIGURING:</span>
 			vscsi-&gt;state = new_state;
<span class="p_add">+			vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
 			vscsi-&gt;flags &amp;= ~(SCHEDULE_DISCONNECT |
 					  DISCONNECT_SCHEDULED);
<span class="p_del">-			ibmvscsis_free_command_q(vscsi);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_del">-			ibmvscsis_reset_queue(vscsi, WAIT_ENABLED);</span>
<span class="p_add">+			dma_rmb();</span>
<span class="p_add">+			if (vscsi-&gt;flags &amp; CFG_SLEEPING) {</span>
<span class="p_add">+				vscsi-&gt;flags &amp;= ~CFG_SLEEPING;</span>
<span class="p_add">+				complete(&amp;vscsi-&gt;unconfig);</span>
<span class="p_add">+			}</span>
 			break;
 
 		/* should never happen */
<span class="p_add">+		case ERR_DISCONNECT:</span>
<span class="p_add">+		case ERR_DISCONNECT_RECONNECT:</span>
 		case WAIT_IDLE:
<span class="p_del">-			rc = ERROR;</span>
 			dev_err(&amp;vscsi-&gt;dev, &quot;disconnect: invalid state %d for WAIT_IDLE\n&quot;,
 				vscsi-&gt;state);
 			break;
<span class="p_chunk">@@ -661,6 +494,13 @@</span> <span class="p_context"> static void ibmvscsis_disconnect(struct work_struct *work)</span>
 
 	case WAIT_IDLE:
 		switch (new_state) {
<span class="p_add">+		case UNCONFIGURING:</span>
<span class="p_add">+			vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_add">+			vscsi-&gt;state = new_state;</span>
<span class="p_add">+			vscsi-&gt;flags &amp;= ~(SCHEDULE_DISCONNECT |</span>
<span class="p_add">+					  DISCONNECT_SCHEDULED);</span>
<span class="p_add">+			ibmvscsis_free_command_q(vscsi);</span>
<span class="p_add">+			break;</span>
 		case ERR_DISCONNECT:
 		case ERR_DISCONNECT_RECONNECT:
 			vscsi-&gt;state = new_state;
<span class="p_chunk">@@ -765,45 +605,348 @@</span> <span class="p_context"> static void ibmvscsis_post_disconnect(struct scsi_info *vscsi, uint new_state,</span>
 		else
 			state = vscsi-&gt;state;
 
<span class="p_del">-		switch (state) {</span>
<span class="p_del">-		case NO_QUEUE:</span>
<span class="p_del">-		case UNCONFIGURING:</span>
<span class="p_del">-			break;</span>
<span class="p_add">+		switch (state) {</span>
<span class="p_add">+		case NO_QUEUE:</span>
<span class="p_add">+		case UNCONFIGURING:</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case ERR_DISCONNECTED:</span>
<span class="p_add">+		case ERR_DISCONNECT:</span>
<span class="p_add">+		case UNDEFINED:</span>
<span class="p_add">+			if (new_state == UNCONFIGURING)</span>
<span class="p_add">+				vscsi-&gt;new_state = new_state;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_add">+			switch (new_state) {</span>
<span class="p_add">+			case UNCONFIGURING:</span>
<span class="p_add">+			case ERR_DISCONNECT:</span>
<span class="p_add">+				vscsi-&gt;new_state = new_state;</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			default:</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case WAIT_ENABLED:</span>
<span class="p_add">+		case WAIT_IDLE:</span>
<span class="p_add">+		case WAIT_CONNECTION:</span>
<span class="p_add">+		case CONNECTED:</span>
<span class="p_add">+		case SRP_PROCESSING:</span>
<span class="p_add">+			vscsi-&gt;new_state = new_state;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;Leaving post_disconnect: flags 0x%x, new_state 0x%x\n&quot;,</span>
<span class="p_add">+		 vscsi-&gt;flags, vscsi-&gt;new_state);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * ibmvscsis_handle_init_compl_msg() - Respond to an Init Complete Message</span>
<span class="p_add">+ * @vscsi:	Pointer to our adapter structure</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Must be called with interrupt lock held.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static long ibmvscsis_handle_init_compl_msg(struct scsi_info *vscsi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long rc = ADAPT_SUCCESS;</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (vscsi-&gt;state) {</span>
<span class="p_add">+	case NO_QUEUE:</span>
<span class="p_add">+	case ERR_DISCONNECT:</span>
<span class="p_add">+	case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_add">+	case ERR_DISCONNECTED:</span>
<span class="p_add">+	case UNCONFIGURING:</span>
<span class="p_add">+	case UNDEFINED:</span>
<span class="p_add">+		rc = ERROR;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+</span>
<span class="p_add">+	case WAIT_CONNECTION:</span>
<span class="p_add">+		vscsi-&gt;state = CONNECTED;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+</span>
<span class="p_add">+	case WAIT_IDLE:</span>
<span class="p_add">+	case SRP_PROCESSING:</span>
<span class="p_add">+	case CONNECTED:</span>
<span class="p_add">+	case WAIT_ENABLED:</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		rc = ERROR;</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: invalid state %d to get init compl msg\n&quot;,</span>
<span class="p_add">+			vscsi-&gt;state);</span>
<span class="p_add">+		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return rc;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * ibmvscsis_handle_init_msg() - Respond to an Init Message</span>
<span class="p_add">+ * @vscsi:	Pointer to our adapter structure</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Must be called with interrupt lock held.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static long ibmvscsis_handle_init_msg(struct scsi_info *vscsi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long rc = ADAPT_SUCCESS;</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (vscsi-&gt;state) {</span>
<span class="p_add">+	case WAIT_CONNECTION:</span>
<span class="p_add">+		rc = ibmvscsis_send_init_message(vscsi, INIT_COMPLETE_MSG);</span>
<span class="p_add">+		switch (rc) {</span>
<span class="p_add">+		case H_SUCCESS:</span>
<span class="p_add">+			vscsi-&gt;state = CONNECTED;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case H_PARAMETER:</span>
<span class="p_add">+			dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: failed to send, rc %ld\n&quot;,</span>
<span class="p_add">+				rc);</span>
<span class="p_add">+			ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT, 0);</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case H_DROPPED:</span>
<span class="p_add">+			dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: failed to send, rc %ld\n&quot;,</span>
<span class="p_add">+				rc);</span>
<span class="p_add">+			rc = ERROR;</span>
<span class="p_add">+			ibmvscsis_post_disconnect(vscsi,</span>
<span class="p_add">+						  ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case H_CLOSED:</span>
<span class="p_add">+			pr_warn(&quot;init_msg: failed to send, rc %ld\n&quot;, rc);</span>
<span class="p_add">+			rc = 0;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		break;</span>
<span class="p_add">+</span>
<span class="p_add">+	case UNDEFINED:</span>
<span class="p_add">+		rc = ERROR;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+</span>
<span class="p_add">+	case UNCONFIGURING:</span>
<span class="p_add">+		break;</span>
<span class="p_add">+</span>
<span class="p_add">+	case WAIT_ENABLED:</span>
<span class="p_add">+	case CONNECTED:</span>
<span class="p_add">+	case SRP_PROCESSING:</span>
<span class="p_add">+	case WAIT_IDLE:</span>
<span class="p_add">+	case NO_QUEUE:</span>
<span class="p_add">+	case ERR_DISCONNECT:</span>
<span class="p_add">+	case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_add">+	case ERR_DISCONNECTED:</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		rc = ERROR;</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: invalid state %d to get init msg\n&quot;,</span>
<span class="p_add">+			vscsi-&gt;state);</span>
<span class="p_add">+		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return rc;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * ibmvscsis_init_msg() - Respond to an init message</span>
<span class="p_add">+ * @vscsi:	Pointer to our adapter structure</span>
<span class="p_add">+ * @crq:	Pointer to CRQ element containing the Init Message</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * EXECUTION ENVIRONMENT:</span>
<span class="p_add">+ *	Interrupt, interrupt lock held</span>
<span class="p_add">+ */</span>
<span class="p_add">+static long ibmvscsis_init_msg(struct scsi_info *vscsi, struct viosrp_crq *crq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long rc = ADAPT_SUCCESS;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;init_msg: state 0x%hx\n&quot;, vscsi-&gt;state);</span>
<span class="p_add">+</span>
<span class="p_add">+	rc = h_vioctl(vscsi-&gt;dds.unit_id, H_GET_PARTNER_INFO,</span>
<span class="p_add">+		      (u64)vscsi-&gt;map_ioba | ((u64)PAGE_SIZE &lt;&lt; 32), 0, 0, 0,</span>
<span class="p_add">+		      0);</span>
<span class="p_add">+	if (rc == H_SUCCESS) {</span>
<span class="p_add">+		vscsi-&gt;client_data.partition_number =</span>
<span class="p_add">+			be64_to_cpu(*(u64 *)vscsi-&gt;map_buf);</span>
<span class="p_add">+		pr_debug(&quot;init_msg, part num %d\n&quot;,</span>
<span class="p_add">+			 vscsi-&gt;client_data.partition_number);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pr_debug(&quot;init_msg h_vioctl rc %ld\n&quot;, rc);</span>
<span class="p_add">+		rc = ADAPT_SUCCESS;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (crq-&gt;format == INIT_MSG) {</span>
<span class="p_add">+		rc = ibmvscsis_handle_init_msg(vscsi);</span>
<span class="p_add">+	} else if (crq-&gt;format == INIT_COMPLETE_MSG) {</span>
<span class="p_add">+		rc = ibmvscsis_handle_init_compl_msg(vscsi);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		rc = ERROR;</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: invalid format %d\n&quot;,</span>
<span class="p_add">+			(uint)crq-&gt;format);</span>
<span class="p_add">+		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return rc;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * ibmvscsis_establish_new_q() - Establish new CRQ queue</span>
<span class="p_add">+ * @vscsi:	Pointer to our adapter structure</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Must be called with interrupt lock held.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static long ibmvscsis_establish_new_q(struct scsi_info *vscsi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long rc = ADAPT_SUCCESS;</span>
<span class="p_add">+	uint format;</span>
<span class="p_add">+</span>
<span class="p_add">+	vscsi-&gt;flags &amp;= PRESERVE_FLAG_FIELDS;</span>
<span class="p_add">+	vscsi-&gt;rsp_q_timer.timer_pops = 0;</span>
<span class="p_add">+	vscsi-&gt;debit = 0;</span>
<span class="p_add">+	vscsi-&gt;credit = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	rc = vio_enable_interrupts(vscsi-&gt;dma_dev);</span>
<span class="p_add">+	if (rc) {</span>
<span class="p_add">+		pr_warn(&quot;establish_new_q: failed to enable interrupts, rc %ld\n&quot;,</span>
<span class="p_add">+			rc);</span>
<span class="p_add">+		return rc;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	rc = ibmvscsis_check_init_msg(vscsi, &amp;format);</span>
<span class="p_add">+	if (rc) {</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;establish_new_q: check_init_msg failed, rc %ld\n&quot;,</span>
<span class="p_add">+			rc);</span>
<span class="p_add">+		return rc;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (format == UNUSED_FORMAT) {</span>
<span class="p_add">+		rc = ibmvscsis_send_init_message(vscsi, INIT_MSG);</span>
<span class="p_add">+		switch (rc) {</span>
<span class="p_add">+		case H_SUCCESS:</span>
<span class="p_add">+		case H_DROPPED:</span>
<span class="p_add">+		case H_CLOSED:</span>
<span class="p_add">+			rc = ADAPT_SUCCESS;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		case H_PARAMETER:</span>
<span class="p_add">+		case H_HARDWARE:</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			vscsi-&gt;state = UNDEFINED;</span>
<span class="p_add">+			rc = H_HARDWARE;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	} else if (format == INIT_MSG) {</span>
<span class="p_add">+		rc = ibmvscsis_handle_init_msg(vscsi);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return rc;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * ibmvscsis_reset_queue() - Reset CRQ Queue</span>
<span class="p_add">+ * @vscsi:	Pointer to our adapter structure</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This function calls h_free_q and then calls h_reg_q and does all</span>
<span class="p_add">+ * of the bookkeeping to get us back to where we can communicate.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Actually, we don&#39;t always call h_free_crq.  A problem was discovered</span>
<span class="p_add">+ * where one partition would close and reopen his queue, which would</span>
<span class="p_add">+ * cause his partner to get a transport event, which would cause him to</span>
<span class="p_add">+ * close and reopen his queue, which would cause the original partition</span>
<span class="p_add">+ * to get a transport event, etc., etc.  To prevent this, we don&#39;t</span>
<span class="p_add">+ * actually close our queue if the client initiated the reset, (i.e.</span>
<span class="p_add">+ * either we got a transport event or we have detected that the client&#39;s</span>
<span class="p_add">+ * queue is gone)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * EXECUTION ENVIRONMENT:</span>
<span class="p_add">+ *	Process environment, called with interrupt lock held</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void ibmvscsis_reset_queue(struct scsi_info *vscsi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int bytes;</span>
<span class="p_add">+	long rc = ADAPT_SUCCESS;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;reset_queue: flags 0x%x\n&quot;, vscsi-&gt;flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* don&#39;t reset, the client did it for us */</span>
<span class="p_add">+	if (vscsi-&gt;flags &amp; (CLIENT_FAILED | TRANS_EVENT)) {</span>
<span class="p_add">+		vscsi-&gt;flags &amp;= PRESERVE_FLAG_FIELDS;</span>
<span class="p_add">+		vscsi-&gt;rsp_q_timer.timer_pops = 0;</span>
<span class="p_add">+		vscsi-&gt;debit = 0;</span>
<span class="p_add">+		vscsi-&gt;credit = 0;</span>
<span class="p_add">+		vscsi-&gt;state = WAIT_CONNECTION;</span>
<span class="p_add">+		vio_enable_interrupts(vscsi-&gt;dma_dev);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		rc = ibmvscsis_free_command_q(vscsi);</span>
<span class="p_add">+		if (rc == ADAPT_SUCCESS) {</span>
<span class="p_add">+			vscsi-&gt;state = WAIT_CONNECTION;</span>
<span class="p_add">+</span>
<span class="p_add">+			bytes = vscsi-&gt;cmd_q.size * PAGE_SIZE;</span>
<span class="p_add">+			rc = h_reg_crq(vscsi-&gt;dds.unit_id,</span>
<span class="p_add">+				       vscsi-&gt;cmd_q.crq_token, bytes);</span>
<span class="p_add">+			if (rc == H_CLOSED || rc == H_SUCCESS) {</span>
<span class="p_add">+				rc = ibmvscsis_establish_new_q(vscsi);</span>
<span class="p_add">+			}</span>
 
<span class="p_del">-		case ERR_DISCONNECTED:</span>
<span class="p_del">-		case ERR_DISCONNECT:</span>
<span class="p_del">-		case UNDEFINED:</span>
<span class="p_del">-			if (new_state == UNCONFIGURING)</span>
<span class="p_del">-				vscsi-&gt;new_state = new_state;</span>
<span class="p_del">-			break;</span>
<span class="p_add">+			if (rc != ADAPT_SUCCESS) {</span>
<span class="p_add">+				pr_debug(&quot;reset_queue: reg_crq rc %ld\n&quot;, rc);</span>
 
<span class="p_del">-		case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_del">-			switch (new_state) {</span>
<span class="p_del">-			case UNCONFIGURING:</span>
<span class="p_del">-			case ERR_DISCONNECT:</span>
<span class="p_del">-				vscsi-&gt;new_state = new_state;</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			default:</span>
<span class="p_del">-				break;</span>
<span class="p_add">+				vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_add">+				vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_add">+				ibmvscsis_free_command_q(vscsi);</span>
 			}
<span class="p_del">-			break;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_add">+			vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
 
<span class="p_del">-		case WAIT_ENABLED:</span>
<span class="p_del">-		case PART_UP_WAIT_ENAB:</span>
<span class="p_del">-		case WAIT_IDLE:</span>
<span class="p_del">-		case WAIT_CONNECTION:</span>
<span class="p_del">-		case CONNECTED:</span>
<span class="p_del">-		case SRP_PROCESSING:</span>
<span class="p_del">-			vscsi-&gt;new_state = new_state;</span>
<span class="p_del">-			break;</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * ibmvscsis_free_cmd_resources() - Free command resources</span>
<span class="p_add">+ * @vscsi:	Pointer to our adapter structure</span>
<span class="p_add">+ * @cmd:	Command which is not longer in use</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Must be called with interrupt lock held.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void ibmvscsis_free_cmd_resources(struct scsi_info *vscsi,</span>
<span class="p_add">+					 struct ibmvscsis_cmd *cmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iu_entry *iue = cmd-&gt;iue;</span>
 
<span class="p_del">-		default:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	switch (cmd-&gt;type) {</span>
<span class="p_add">+	case TASK_MANAGEMENT:</span>
<span class="p_add">+	case SCSI_CDB:</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * When the queue goes down this value is cleared, so it</span>
<span class="p_add">+		 * cannot be cleared in this general purpose function.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (vscsi-&gt;debit)</span>
<span class="p_add">+			vscsi-&gt;debit -= 1;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case ADAPTER_MAD:</span>
<span class="p_add">+		vscsi-&gt;flags &amp;= ~PROCESSING_MAD;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case UNSET_TYPE:</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;free_cmd_resources unknown type %d\n&quot;,</span>
<span class="p_add">+			cmd-&gt;type);</span>
<span class="p_add">+		break;</span>
 	}
 
<span class="p_del">-	pr_debug(&quot;Leaving post_disconnect: flags 0x%x, new_state 0x%x\n&quot;,</span>
<span class="p_del">-		 vscsi-&gt;flags, vscsi-&gt;new_state);</span>
<span class="p_add">+	cmd-&gt;iue = NULL;</span>
<span class="p_add">+	list_add_tail(&amp;cmd-&gt;list, &amp;vscsi-&gt;free_cmd);</span>
<span class="p_add">+	srp_iu_put(iue);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (list_empty(&amp;vscsi-&gt;active_q) &amp;&amp; list_empty(&amp;vscsi-&gt;schedule_q) &amp;&amp;</span>
<span class="p_add">+	    list_empty(&amp;vscsi-&gt;waiting_rsp) &amp;&amp; (vscsi-&gt;flags &amp; WAIT_FOR_IDLE)) {</span>
<span class="p_add">+		vscsi-&gt;flags &amp;= ~WAIT_FOR_IDLE;</span>
<span class="p_add">+		complete(&amp;vscsi-&gt;wait_idle);</span>
<span class="p_add">+	}</span>
 }
 
 /**
<span class="p_chunk">@@ -864,10 +1007,6 @@</span> <span class="p_context"> static long ibmvscsis_trans_event(struct scsi_info *vscsi,</span>
 						   TRANS_EVENT));
 			break;
 
<span class="p_del">-		case PART_UP_WAIT_ENAB:</span>
<span class="p_del">-			vscsi-&gt;state = WAIT_ENABLED;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
 		case SRP_PROCESSING:
 			if ((vscsi-&gt;debit &gt; 0) ||
 			    !list_empty(&amp;vscsi-&gt;schedule_q) ||
<span class="p_chunk">@@ -896,7 +1035,7 @@</span> <span class="p_context"> static long ibmvscsis_trans_event(struct scsi_info *vscsi,</span>
 		}
 	}
 
<span class="p_del">-	rc =  vscsi-&gt;flags &amp; SCHEDULE_DISCONNECT;</span>
<span class="p_add">+	rc = vscsi-&gt;flags &amp; SCHEDULE_DISCONNECT;</span>
 
 	pr_debug(&quot;Leaving trans_event: flags 0x%x, state 0x%hx, rc %ld\n&quot;,
 		 vscsi-&gt;flags, vscsi-&gt;state, rc);
<span class="p_chunk">@@ -1067,16 +1206,28 @@</span> <span class="p_context"> static void ibmvscsis_adapter_idle(struct scsi_info *vscsi)</span>
 		free_qs = true;
 
 	switch (vscsi-&gt;state) {
<span class="p_add">+	case UNCONFIGURING:</span>
<span class="p_add">+		ibmvscsis_free_command_q(vscsi);</span>
<span class="p_add">+		dma_rmb();</span>
<span class="p_add">+		isync();</span>
<span class="p_add">+		if (vscsi-&gt;flags &amp; CFG_SLEEPING) {</span>
<span class="p_add">+			vscsi-&gt;flags &amp;= ~CFG_SLEEPING;</span>
<span class="p_add">+			complete(&amp;vscsi-&gt;unconfig);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		break;</span>
 	case ERR_DISCONNECT_RECONNECT:
<span class="p_del">-		ibmvscsis_reset_queue(vscsi, WAIT_CONNECTION);</span>
<span class="p_add">+		ibmvscsis_reset_queue(vscsi);</span>
 		pr_debug(&quot;adapter_idle, disc_rec: flags 0x%x\n&quot;, vscsi-&gt;flags);
 		break;
 
 	case ERR_DISCONNECT:
 		ibmvscsis_free_command_q(vscsi);
<span class="p_del">-		vscsi-&gt;flags &amp;= ~DISCONNECT_SCHEDULED;</span>
<span class="p_add">+		vscsi-&gt;flags &amp;= ~(SCHEDULE_DISCONNECT | DISCONNECT_SCHEDULED);</span>
 		vscsi-&gt;flags |= RESPONSE_Q_DOWN;
<span class="p_del">-		vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_add">+		if (vscsi-&gt;tport.enabled)</span>
<span class="p_add">+			vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			vscsi-&gt;state = WAIT_ENABLED;</span>
 		pr_debug(&quot;adapter_idle, disc: flags 0x%x, state 0x%hx\n&quot;,
 			 vscsi-&gt;flags, vscsi-&gt;state);
 		break;
<span class="p_chunk">@@ -1221,7 +1372,7 @@</span> <span class="p_context"> static long ibmvscsis_copy_crq_packet(struct scsi_info *vscsi,</span>
  * @iue:	Information Unit containing the Adapter Info MAD request
  *
  * EXECUTION ENVIRONMENT:
<span class="p_del">- *	Interrupt adpater lock is held</span>
<span class="p_add">+ *	Interrupt adapter lock is held</span>
  */
 static long ibmvscsis_adapter_info(struct scsi_info *vscsi,
 				   struct iu_entry *iue)
<span class="p_chunk">@@ -1621,8 +1772,8 @@</span> <span class="p_context"> static void ibmvscsis_send_messages(struct scsi_info *vscsi)</span>
 					be64_to_cpu(msg_hi),
 					be64_to_cpu(cmd-&gt;rsp.tag));
 
<span class="p_del">-			pr_debug(&quot;send_messages: tag 0x%llx, rc %ld\n&quot;,</span>
<span class="p_del">-				 be64_to_cpu(cmd-&gt;rsp.tag), rc);</span>
<span class="p_add">+			pr_debug(&quot;send_messages: cmd %p, tag 0x%llx, rc %ld\n&quot;,</span>
<span class="p_add">+				 cmd, be64_to_cpu(cmd-&gt;rsp.tag), rc);</span>
 
 			/* if all ok free up the command element resources */
 			if (rc == H_SUCCESS) {
<span class="p_chunk">@@ -1692,7 +1843,7 @@</span> <span class="p_context"> static void ibmvscsis_send_mad_resp(struct scsi_info *vscsi,</span>
  * @crq:	Pointer to the CRQ entry containing the MAD request
  *
  * EXECUTION ENVIRONMENT:
<span class="p_del">- *	Interrupt  called with adapter lock held</span>
<span class="p_add">+ *	Interrupt, called with adapter lock held</span>
  */
 static long ibmvscsis_mad(struct scsi_info *vscsi, struct viosrp_crq *crq)
 {
<span class="p_chunk">@@ -1746,14 +1897,7 @@</span> <span class="p_context"> static long ibmvscsis_mad(struct scsi_info *vscsi, struct viosrp_crq *crq)</span>
 
 		pr_debug(&quot;mad: type %d\n&quot;, be32_to_cpu(mad-&gt;type));
 
<span class="p_del">-		if (be16_to_cpu(mad-&gt;length) &lt; 0) {</span>
<span class="p_del">-			dev_err(&amp;vscsi-&gt;dev, &quot;mad: length is &lt; 0\n&quot;);</span>
<span class="p_del">-			ibmvscsis_post_disconnect(vscsi,</span>
<span class="p_del">-						  ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_del">-			rc = SRP_VIOLATION;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			rc = ibmvscsis_process_mad(vscsi, iue);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		rc = ibmvscsis_process_mad(vscsi, iue);</span>
 
 		pr_debug(&quot;mad: status %hd, rc %ld\n&quot;, be16_to_cpu(mad-&gt;status),
 			 rc);
<span class="p_chunk">@@ -1865,7 +2009,7 @@</span> <span class="p_context"> static long ibmvscsis_srp_login_rej(struct scsi_info *vscsi,</span>
 		break;
 	case H_PERMISSION:
 		if (connection_broken(vscsi))
<span class="p_del">-			flag_bits =  RESPONSE_Q_DOWN | CLIENT_FAILED;</span>
<span class="p_add">+			flag_bits = RESPONSE_Q_DOWN | CLIENT_FAILED;</span>
 		dev_err(&amp;vscsi-&gt;dev, &quot;login_rej: error copying to client, rc %ld\n&quot;,
 			rc);
 		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT,
<span class="p_chunk">@@ -2090,248 +2234,98 @@</span> <span class="p_context"> static void ibmvscsis_srp_cmd(struct scsi_info *vscsi, struct viosrp_crq *crq)</span>
 			break;
 
 		case SRP_TSK_MGMT:
<span class="p_del">-			tsk = &amp;vio_iu(iue)-&gt;srp.tsk_mgmt;</span>
<span class="p_del">-			pr_debug(&quot;tsk_mgmt tag: %llu (0x%llx)\n&quot;, tsk-&gt;tag,</span>
<span class="p_del">-				 tsk-&gt;tag);</span>
<span class="p_del">-			cmd-&gt;rsp.tag = tsk-&gt;tag;</span>
<span class="p_del">-			vscsi-&gt;debit += 1;</span>
<span class="p_del">-			cmd-&gt;type = TASK_MANAGEMENT;</span>
<span class="p_del">-			list_add_tail(&amp;cmd-&gt;list, &amp;vscsi-&gt;schedule_q);</span>
<span class="p_del">-			queue_work(vscsi-&gt;work_q, &amp;cmd-&gt;work);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case SRP_CMD:</span>
<span class="p_del">-			pr_debug(&quot;srp_cmd tag: %llu (0x%llx)\n&quot;, srp-&gt;tag,</span>
<span class="p_del">-				 srp-&gt;tag);</span>
<span class="p_del">-			cmd-&gt;rsp.tag = srp-&gt;tag;</span>
<span class="p_del">-			vscsi-&gt;debit += 1;</span>
<span class="p_del">-			cmd-&gt;type = SCSI_CDB;</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * We want to keep track of work waiting for</span>
<span class="p_del">-			 * the workqueue.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			list_add_tail(&amp;cmd-&gt;list, &amp;vscsi-&gt;schedule_q);</span>
<span class="p_del">-			queue_work(vscsi-&gt;work_q, &amp;cmd-&gt;work);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case SRP_I_LOGOUT:</span>
<span class="p_del">-			rc = ibmvscsis_srp_i_logout(vscsi, cmd, crq);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case SRP_CRED_RSP:</span>
<span class="p_del">-		case SRP_AER_RSP:</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			ibmvscsis_free_cmd_resources(vscsi, cmd);</span>
<span class="p_del">-			dev_err(&amp;vscsi-&gt;dev, &quot;invalid srp cmd, opcode %d\n&quot;,</span>
<span class="p_del">-				(uint)srp-&gt;opcode);</span>
<span class="p_del">-			ibmvscsis_post_disconnect(vscsi,</span>
<span class="p_del">-						  ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else if (srp-&gt;opcode == SRP_LOGIN_REQ &amp;&amp; vscsi-&gt;state == CONNECTED) {</span>
<span class="p_del">-		rc = ibmvscsis_srp_login(vscsi, cmd, crq);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		ibmvscsis_free_cmd_resources(vscsi, cmd);</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;Invalid state %d to handle srp cmd\n&quot;,</span>
<span class="p_del">-			vscsi-&gt;state);</span>
<span class="p_del">-		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * ibmvscsis_ping_response() - Respond to a ping request</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- *</span>
<span class="p_del">- * Let the client know that the server is alive and waiting on</span>
<span class="p_del">- * its native I/O stack.</span>
<span class="p_del">- * If any type of error occurs from the call to queue a ping</span>
<span class="p_del">- * response then the client is either not accepting or receiving</span>
<span class="p_del">- * interrupts.  Disconnect with an error.</span>
<span class="p_del">- *</span>
<span class="p_del">- * EXECUTION ENVIRONMENT:</span>
<span class="p_del">- *	Interrupt, interrupt lock held</span>
<span class="p_del">- */</span>
<span class="p_del">-static long ibmvscsis_ping_response(struct scsi_info *vscsi)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct viosrp_crq *crq;</span>
<span class="p_del">-	u64 buffer[2] = { 0, 0 };</span>
<span class="p_del">-	long rc;</span>
<span class="p_del">-</span>
<span class="p_del">-	crq = (struct viosrp_crq *)&amp;buffer;</span>
<span class="p_del">-	crq-&gt;valid = VALID_CMD_RESP_EL;</span>
<span class="p_del">-	crq-&gt;format = (u8)MESSAGE_IN_CRQ;</span>
<span class="p_del">-	crq-&gt;status = PING_RESPONSE;</span>
<span class="p_del">-</span>
<span class="p_del">-	rc = h_send_crq(vscsi-&gt;dds.unit_id, cpu_to_be64(buffer[MSG_HI]),</span>
<span class="p_del">-			cpu_to_be64(buffer[MSG_LOW]));</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (rc) {</span>
<span class="p_del">-	case H_SUCCESS:</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case H_CLOSED:</span>
<span class="p_del">-		vscsi-&gt;flags |= CLIENT_FAILED;</span>
<span class="p_del">-	case H_DROPPED:</span>
<span class="p_del">-		vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_del">-	case H_REMOTE_PARM:</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;ping_response: h_send_crq failed, rc %ld\n&quot;,</span>
<span class="p_del">-			rc);</span>
<span class="p_del">-		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	default:</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;ping_response: h_send_crq returned unknown rc %ld\n&quot;,</span>
<span class="p_del">-			rc);</span>
<span class="p_del">-		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT, 0);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return rc;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * ibmvscsis_handle_init_compl_msg() - Respond to an Init Complete Message</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- *</span>
<span class="p_del">- * Must be called with interrupt lock held.</span>
<span class="p_del">- */</span>
<span class="p_del">-static long ibmvscsis_handle_init_compl_msg(struct scsi_info *vscsi)</span>
<span class="p_del">-{</span>
<span class="p_del">-	long rc = ADAPT_SUCCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (vscsi-&gt;state) {</span>
<span class="p_del">-	case NO_QUEUE:</span>
<span class="p_del">-	case ERR_DISCONNECT:</span>
<span class="p_del">-	case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_del">-	case ERR_DISCONNECTED:</span>
<span class="p_del">-	case UNCONFIGURING:</span>
<span class="p_del">-	case UNDEFINED:</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_del">-	case WAIT_CONNECTION:</span>
<span class="p_del">-		vscsi-&gt;state = CONNECTED;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_del">-	case WAIT_IDLE:</span>
<span class="p_del">-	case SRP_PROCESSING:</span>
<span class="p_del">-	case CONNECTED:</span>
<span class="p_del">-	case WAIT_ENABLED:</span>
<span class="p_del">-	case PART_UP_WAIT_ENAB:</span>
<span class="p_del">-	default:</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: invalid state %d to get init compl msg\n&quot;,</span>
<span class="p_del">-			vscsi-&gt;state);</span>
<span class="p_del">-		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return rc;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * ibmvscsis_handle_init_msg() - Respond to an Init Message</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- *</span>
<span class="p_del">- * Must be called with interrupt lock held.</span>
<span class="p_del">- */</span>
<span class="p_del">-static long ibmvscsis_handle_init_msg(struct scsi_info *vscsi)</span>
<span class="p_del">-{</span>
<span class="p_del">-	long rc = ADAPT_SUCCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (vscsi-&gt;state) {</span>
<span class="p_del">-	case WAIT_ENABLED:</span>
<span class="p_del">-		vscsi-&gt;state = PART_UP_WAIT_ENAB;</span>
<span class="p_del">-		break;</span>
<span class="p_add">+			tsk = &amp;vio_iu(iue)-&gt;srp.tsk_mgmt;</span>
<span class="p_add">+			pr_debug(&quot;tsk_mgmt tag: %llu (0x%llx)\n&quot;, tsk-&gt;tag,</span>
<span class="p_add">+				 tsk-&gt;tag);</span>
<span class="p_add">+			cmd-&gt;rsp.tag = tsk-&gt;tag;</span>
<span class="p_add">+			vscsi-&gt;debit += 1;</span>
<span class="p_add">+			cmd-&gt;type = TASK_MANAGEMENT;</span>
<span class="p_add">+			list_add_tail(&amp;cmd-&gt;list, &amp;vscsi-&gt;schedule_q);</span>
<span class="p_add">+			queue_work(vscsi-&gt;work_q, &amp;cmd-&gt;work);</span>
<span class="p_add">+			break;</span>
 
<span class="p_del">-	case WAIT_CONNECTION:</span>
<span class="p_del">-		rc = ibmvscsis_send_init_message(vscsi, INIT_COMPLETE_MSG);</span>
<span class="p_del">-		switch (rc) {</span>
<span class="p_del">-		case H_SUCCESS:</span>
<span class="p_del">-			vscsi-&gt;state = CONNECTED;</span>
<span class="p_add">+		case SRP_CMD:</span>
<span class="p_add">+			pr_debug(&quot;srp_cmd tag: %llu (0x%llx)\n&quot;, srp-&gt;tag,</span>
<span class="p_add">+				 srp-&gt;tag);</span>
<span class="p_add">+			cmd-&gt;rsp.tag = srp-&gt;tag;</span>
<span class="p_add">+			vscsi-&gt;debit += 1;</span>
<span class="p_add">+			cmd-&gt;type = SCSI_CDB;</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * We want to keep track of work waiting for</span>
<span class="p_add">+			 * the workqueue.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			list_add_tail(&amp;cmd-&gt;list, &amp;vscsi-&gt;schedule_q);</span>
<span class="p_add">+			queue_work(vscsi-&gt;work_q, &amp;cmd-&gt;work);</span>
 			break;
 
<span class="p_del">-		case H_PARAMETER:</span>
<span class="p_del">-			dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: failed to send, rc %ld\n&quot;,</span>
<span class="p_del">-				rc);</span>
<span class="p_del">-			ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT, 0);</span>
<span class="p_add">+		case SRP_I_LOGOUT:</span>
<span class="p_add">+			rc = ibmvscsis_srp_i_logout(vscsi, cmd, crq);</span>
 			break;
 
<span class="p_del">-		case H_DROPPED:</span>
<span class="p_del">-			dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: failed to send, rc %ld\n&quot;,</span>
<span class="p_del">-				rc);</span>
<span class="p_del">-			rc = ERROR;</span>
<span class="p_add">+		case SRP_CRED_RSP:</span>
<span class="p_add">+		case SRP_AER_RSP:</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			ibmvscsis_free_cmd_resources(vscsi, cmd);</span>
<span class="p_add">+			dev_err(&amp;vscsi-&gt;dev, &quot;invalid srp cmd, opcode %d\n&quot;,</span>
<span class="p_add">+				(uint)srp-&gt;opcode);</span>
 			ibmvscsis_post_disconnect(vscsi,
 						  ERR_DISCONNECT_RECONNECT, 0);
 			break;
<span class="p_del">-</span>
<span class="p_del">-		case H_CLOSED:</span>
<span class="p_del">-			pr_warn(&quot;init_msg: failed to send, rc %ld\n&quot;, rc);</span>
<span class="p_del">-			rc = 0;</span>
<span class="p_del">-			break;</span>
 		}
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_del">-	case UNDEFINED:</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_del">-	case UNCONFIGURING:</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_del">-	case PART_UP_WAIT_ENAB:</span>
<span class="p_del">-	case CONNECTED:</span>
<span class="p_del">-	case SRP_PROCESSING:</span>
<span class="p_del">-	case WAIT_IDLE:</span>
<span class="p_del">-	case NO_QUEUE:</span>
<span class="p_del">-	case ERR_DISCONNECT:</span>
<span class="p_del">-	case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_del">-	case ERR_DISCONNECTED:</span>
<span class="p_del">-	default:</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: invalid state %d to get init msg\n&quot;,</span>
<span class="p_add">+	} else if (srp-&gt;opcode == SRP_LOGIN_REQ &amp;&amp; vscsi-&gt;state == CONNECTED) {</span>
<span class="p_add">+		rc = ibmvscsis_srp_login(vscsi, cmd, crq);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		ibmvscsis_free_cmd_resources(vscsi, cmd);</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;Invalid state %d to handle srp cmd\n&quot;,</span>
 			vscsi-&gt;state);
 		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);
<span class="p_del">-		break;</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	return rc;</span>
 }
 
 /**
<span class="p_del">- * ibmvscsis_init_msg() - Respond to an init message</span>
<span class="p_add">+ * ibmvscsis_ping_response() - Respond to a ping request</span>
  * @vscsi:	Pointer to our adapter structure
<span class="p_del">- * @crq:	Pointer to CRQ element containing the Init Message</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Let the client know that the server is alive and waiting on</span>
<span class="p_add">+ * its native I/O stack.</span>
<span class="p_add">+ * If any type of error occurs from the call to queue a ping</span>
<span class="p_add">+ * response then the client is either not accepting or receiving</span>
<span class="p_add">+ * interrupts.  Disconnect with an error.</span>
  *
  * EXECUTION ENVIRONMENT:
  *	Interrupt, interrupt lock held
  */
<span class="p_del">-static long ibmvscsis_init_msg(struct scsi_info *vscsi, struct viosrp_crq *crq)</span>
<span class="p_add">+static long ibmvscsis_ping_response(struct scsi_info *vscsi)</span>
 {
<span class="p_del">-	long rc = ADAPT_SUCCESS;</span>
<span class="p_add">+	struct viosrp_crq *crq;</span>
<span class="p_add">+	u64 buffer[2] = { 0, 0 };</span>
<span class="p_add">+	long rc;</span>
 
<span class="p_del">-	pr_debug(&quot;init_msg: state 0x%hx\n&quot;, vscsi-&gt;state);</span>
<span class="p_add">+	crq = (struct viosrp_crq *)&amp;buffer;</span>
<span class="p_add">+	crq-&gt;valid = VALID_CMD_RESP_EL;</span>
<span class="p_add">+	crq-&gt;format = (u8)MESSAGE_IN_CRQ;</span>
<span class="p_add">+	crq-&gt;status = PING_RESPONSE;</span>
 
<span class="p_del">-	rc = h_vioctl(vscsi-&gt;dds.unit_id, H_GET_PARTNER_INFO,</span>
<span class="p_del">-		      (u64)vscsi-&gt;map_ioba | ((u64)PAGE_SIZE &lt;&lt; 32), 0, 0, 0,</span>
<span class="p_del">-		      0);</span>
<span class="p_del">-	if (rc == H_SUCCESS) {</span>
<span class="p_del">-		vscsi-&gt;client_data.partition_number =</span>
<span class="p_del">-			be64_to_cpu(*(u64 *)vscsi-&gt;map_buf);</span>
<span class="p_del">-		pr_debug(&quot;init_msg, part num %d\n&quot;,</span>
<span class="p_del">-			 vscsi-&gt;client_data.partition_number);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		pr_debug(&quot;init_msg h_vioctl rc %ld\n&quot;, rc);</span>
<span class="p_del">-		rc = ADAPT_SUCCESS;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	rc = h_send_crq(vscsi-&gt;dds.unit_id, cpu_to_be64(buffer[MSG_HI]),</span>
<span class="p_add">+			cpu_to_be64(buffer[MSG_LOW]));</span>
 
<span class="p_del">-	if (crq-&gt;format == INIT_MSG) {</span>
<span class="p_del">-		rc = ibmvscsis_handle_init_msg(vscsi);</span>
<span class="p_del">-	} else if (crq-&gt;format == INIT_COMPLETE_MSG) {</span>
<span class="p_del">-		rc = ibmvscsis_handle_init_compl_msg(vscsi);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;init_msg: invalid format %d\n&quot;,</span>
<span class="p_del">-			(uint)crq-&gt;format);</span>
<span class="p_add">+	switch (rc) {</span>
<span class="p_add">+	case H_SUCCESS:</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case H_CLOSED:</span>
<span class="p_add">+		vscsi-&gt;flags |= CLIENT_FAILED;</span>
<span class="p_add">+	case H_DROPPED:</span>
<span class="p_add">+		vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
<span class="p_add">+	case H_REMOTE_PARM:</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;ping_response: h_send_crq failed, rc %ld\n&quot;,</span>
<span class="p_add">+			rc);</span>
 		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		dev_err(&amp;vscsi-&gt;dev, &quot;ping_response: h_send_crq returned unknown rc %ld\n&quot;,</span>
<span class="p_add">+			rc);</span>
<span class="p_add">+		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT, 0);</span>
<span class="p_add">+		break;</span>
 	}
 
 	return rc;
<span class="p_chunk">@@ -2392,7 +2386,7 @@</span> <span class="p_context"> static long ibmvscsis_parse_command(struct scsi_info *vscsi,</span>
 		break;
 
 	case VALID_TRANS_EVENT:
<span class="p_del">-		rc =  ibmvscsis_trans_event(vscsi, crq);</span>
<span class="p_add">+		rc = ibmvscsis_trans_event(vscsi, crq);</span>
 		break;
 
 	case VALID_INIT_MSG:
<span class="p_chunk">@@ -2523,7 +2517,6 @@</span> <span class="p_context"> static void ibmvscsis_parse_cmd(struct scsi_info *vscsi,</span>
 		dev_err(&amp;vscsi-&gt;dev, &quot;0x%llx: parsing SRP descriptor table failed.\n&quot;,
 			srp-&gt;tag);
 		goto fail;
<span class="p_del">-		return;</span>
 	}
 
 	cmd-&gt;rsp.sol_not = srp-&gt;sol_not;
<span class="p_chunk">@@ -2560,6 +2553,10 @@</span> <span class="p_context"> static void ibmvscsis_parse_cmd(struct scsi_info *vscsi,</span>
 			       data_len, attr, dir, 0);
 	if (rc) {
 		dev_err(&amp;vscsi-&gt;dev, &quot;target_submit_cmd failed, rc %d\n&quot;, rc);
<span class="p_add">+		spin_lock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_add">+		list_del(&amp;cmd-&gt;list);</span>
<span class="p_add">+		ibmvscsis_free_cmd_resources(vscsi, cmd);</span>
<span class="p_add">+		spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
 		goto fail;
 	}
 	return;
<span class="p_chunk">@@ -2639,6 +2636,9 @@</span> <span class="p_context"> static void ibmvscsis_parse_task(struct scsi_info *vscsi,</span>
 		if (rc) {
 			dev_err(&amp;vscsi-&gt;dev, &quot;target_submit_tmr failed, rc %d\n&quot;,
 				rc);
<span class="p_add">+			spin_lock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_add">+			list_del(&amp;cmd-&gt;list);</span>
<span class="p_add">+			spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
 			cmd-&gt;se_cmd.se_tmr_req-&gt;response =
 				TMR_FUNCTION_REJECTED;
 		}
<span class="p_chunk">@@ -2787,36 +2787,6 @@</span> <span class="p_context"> static irqreturn_t ibmvscsis_interrupt(int dummy, void *data)</span>
 }
 
 /**
<span class="p_del">- * ibmvscsis_check_q() - Helper function to Check Init Message Valid</span>
<span class="p_del">- * @vscsi:	Pointer to our adapter structure</span>
<span class="p_del">- *</span>
<span class="p_del">- * Checks if a initialize message was queued by the initiatior</span>
<span class="p_del">- * while the timing window was open.  This function is called from</span>
<span class="p_del">- * probe after the CRQ is created and interrupts are enabled.</span>
<span class="p_del">- * It would only be used by adapters who wait for some event before</span>
<span class="p_del">- * completing the init handshake with the client.  For ibmvscsi, this</span>
<span class="p_del">- * event is waiting for the port to be enabled.</span>
<span class="p_del">- *</span>
<span class="p_del">- * EXECUTION ENVIRONMENT:</span>
<span class="p_del">- *	Process level only, interrupt lock held</span>
<span class="p_del">- */</span>
<span class="p_del">-static long ibmvscsis_check_q(struct scsi_info *vscsi)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint format;</span>
<span class="p_del">-	long rc;</span>
<span class="p_del">-</span>
<span class="p_del">-	rc = ibmvscsis_check_init_msg(vscsi, &amp;format);</span>
<span class="p_del">-	if (rc)</span>
<span class="p_del">-		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT_RECONNECT, 0);</span>
<span class="p_del">-	else if (format == UNUSED_FORMAT)</span>
<span class="p_del">-		vscsi-&gt;state = WAIT_ENABLED;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		vscsi-&gt;state = PART_UP_WAIT_ENAB;</span>
<span class="p_del">-</span>
<span class="p_del">-	return rc;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
  * ibmvscsis_enable_change_state() - Set new state based on enabled status
  * @vscsi:	Pointer to our adapter structure
  *
<span class="p_chunk">@@ -2827,77 +2797,19 @@</span> <span class="p_context"> static long ibmvscsis_check_q(struct scsi_info *vscsi)</span>
  */
 static long ibmvscsis_enable_change_state(struct scsi_info *vscsi)
 {
<span class="p_add">+	int bytes;</span>
 	long rc = ADAPT_SUCCESS;
 
<span class="p_del">-handle_state_change:</span>
<span class="p_del">-	switch (vscsi-&gt;state) {</span>
<span class="p_del">-	case WAIT_ENABLED:</span>
<span class="p_del">-		rc = ibmvscsis_send_init_message(vscsi, INIT_MSG);</span>
<span class="p_del">-		switch (rc) {</span>
<span class="p_del">-		case H_SUCCESS:</span>
<span class="p_del">-		case H_DROPPED:</span>
<span class="p_del">-		case H_CLOSED:</span>
<span class="p_del">-			vscsi-&gt;state =  WAIT_CONNECTION;</span>
<span class="p_del">-			rc = ADAPT_SUCCESS;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case H_PARAMETER:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case H_HARDWARE:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			vscsi-&gt;state = UNDEFINED;</span>
<span class="p_del">-			rc = H_HARDWARE;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case PART_UP_WAIT_ENAB:</span>
<span class="p_del">-		rc = ibmvscsis_send_init_message(vscsi, INIT_COMPLETE_MSG);</span>
<span class="p_del">-		switch (rc) {</span>
<span class="p_del">-		case H_SUCCESS:</span>
<span class="p_del">-			vscsi-&gt;state = CONNECTED;</span>
<span class="p_del">-			rc = ADAPT_SUCCESS;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case H_DROPPED:</span>
<span class="p_del">-		case H_CLOSED:</span>
<span class="p_del">-			vscsi-&gt;state = WAIT_ENABLED;</span>
<span class="p_del">-			goto handle_state_change;</span>
<span class="p_del">-</span>
<span class="p_del">-		case H_PARAMETER:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		case H_HARDWARE:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			rc = H_HARDWARE;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_del">-	case WAIT_CONNECTION:</span>
<span class="p_del">-	case WAIT_IDLE:</span>
<span class="p_del">-	case SRP_PROCESSING:</span>
<span class="p_del">-	case CONNECTED:</span>
<span class="p_del">-		rc = ADAPT_SUCCESS;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-		/* should not be able to get here */</span>
<span class="p_del">-	case UNCONFIGURING:</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		vscsi-&gt;state = UNDEFINED;</span>
<span class="p_del">-		break;</span>
<span class="p_add">+	bytes = vscsi-&gt;cmd_q.size * PAGE_SIZE;</span>
<span class="p_add">+	rc = h_reg_crq(vscsi-&gt;dds.unit_id, vscsi-&gt;cmd_q.crq_token, bytes);</span>
<span class="p_add">+	if (rc == H_CLOSED || rc == H_SUCCESS) {</span>
<span class="p_add">+		vscsi-&gt;state = WAIT_CONNECTION;</span>
<span class="p_add">+		rc = ibmvscsis_establish_new_q(vscsi);</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-		/* driver should never allow this to happen */</span>
<span class="p_del">-	case ERR_DISCONNECT:</span>
<span class="p_del">-	case ERR_DISCONNECT_RECONNECT:</span>
<span class="p_del">-	default:</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;in invalid state %d during enable_change_state\n&quot;,</span>
<span class="p_del">-			vscsi-&gt;state);</span>
<span class="p_del">-		rc = ADAPT_SUCCESS;</span>
<span class="p_del">-		break;</span>
<span class="p_add">+	if (rc != ADAPT_SUCCESS) {</span>
<span class="p_add">+		vscsi-&gt;state = ERR_DISCONNECTED;</span>
<span class="p_add">+		vscsi-&gt;flags |= RESPONSE_Q_DOWN;</span>
 	}
 
 	return rc;
<span class="p_chunk">@@ -2917,7 +2829,6 @@</span> <span class="p_context"> static long ibmvscsis_enable_change_state(struct scsi_info *vscsi)</span>
  */
 static long ibmvscsis_create_command_q(struct scsi_info *vscsi, int num_cmds)
 {
<span class="p_del">-	long rc = 0;</span>
 	int pages;
 	struct vio_dev *vdev = vscsi-&gt;dma_dev;
 
<span class="p_chunk">@@ -2941,22 +2852,7 @@</span> <span class="p_context"> static long ibmvscsis_create_command_q(struct scsi_info *vscsi, int num_cmds)</span>
 		return -ENOMEM;
 	}
 
<span class="p_del">-	rc =  h_reg_crq(vscsi-&gt;dds.unit_id, vscsi-&gt;cmd_q.crq_token, PAGE_SIZE);</span>
<span class="p_del">-	if (rc) {</span>
<span class="p_del">-		if (rc == H_CLOSED) {</span>
<span class="p_del">-			vscsi-&gt;state = WAIT_ENABLED;</span>
<span class="p_del">-			rc = 0;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			dma_unmap_single(&amp;vdev-&gt;dev, vscsi-&gt;cmd_q.crq_token,</span>
<span class="p_del">-					 PAGE_SIZE, DMA_BIDIRECTIONAL);</span>
<span class="p_del">-			free_page((unsigned long)vscsi-&gt;cmd_q.base_addr);</span>
<span class="p_del">-			rc = -ENODEV;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		vscsi-&gt;state = WAIT_ENABLED;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return rc;</span>
<span class="p_add">+	return 0;</span>
 }
 
 /**
<span class="p_chunk">@@ -3271,7 +3167,7 @@</span> <span class="p_context"> static void ibmvscsis_handle_crq(unsigned long data)</span>
 	/*
 	 * if we are in a path where we are waiting for all pending commands
 	 * to complete because we received a transport event and anything in
<span class="p_del">-	 * the command queue is for a new connection,  do nothing</span>
<span class="p_add">+	 * the command queue is for a new connection, do nothing</span>
 	 */
 	if (TARGET_STOP(vscsi)) {
 		vio_enable_interrupts(vscsi-&gt;dma_dev);
<span class="p_chunk">@@ -3315,7 +3211,7 @@</span> <span class="p_context"> static void ibmvscsis_handle_crq(unsigned long data)</span>
 				 * everything but transport events on the queue
 				 *
 				 * need to decrement the queue index so we can
<span class="p_del">-				 * look at the elment again</span>
<span class="p_add">+				 * look at the element again</span>
 				 */
 				if (vscsi-&gt;cmd_q.index)
 					vscsi-&gt;cmd_q.index -= 1;
<span class="p_chunk">@@ -3379,7 +3275,8 @@</span> <span class="p_context"> static int ibmvscsis_probe(struct vio_dev *vdev,</span>
 	INIT_LIST_HEAD(&amp;vscsi-&gt;waiting_rsp);
 	INIT_LIST_HEAD(&amp;vscsi-&gt;active_q);
 
<span class="p_del">-	snprintf(vscsi-&gt;tport.tport_name, 256, &quot;%s&quot;, dev_name(&amp;vdev-&gt;dev));</span>
<span class="p_add">+	snprintf(vscsi-&gt;tport.tport_name, IBMVSCSIS_NAMELEN, &quot;%s&quot;,</span>
<span class="p_add">+		 dev_name(&amp;vdev-&gt;dev));</span>
 
 	pr_debug(&quot;probe tport_name: %s\n&quot;, vscsi-&gt;tport.tport_name);
 
<span class="p_chunk">@@ -3394,6 +3291,9 @@</span> <span class="p_context"> static int ibmvscsis_probe(struct vio_dev *vdev,</span>
 	strncat(vscsi-&gt;eye, vdev-&gt;name, MAX_EYE);
 
 	vscsi-&gt;dds.unit_id = vdev-&gt;unit_address;
<span class="p_add">+	strncpy(vscsi-&gt;dds.partition_name, partition_name,</span>
<span class="p_add">+		sizeof(vscsi-&gt;dds.partition_name));</span>
<span class="p_add">+	vscsi-&gt;dds.partition_num = partition_number;</span>
 
 	spin_lock_bh(&amp;ibmvscsis_dev_lock);
 	list_add_tail(&amp;vscsi-&gt;list, &amp;ibmvscsis_dev_list);
<span class="p_chunk">@@ -3470,6 +3370,7 @@</span> <span class="p_context"> static int ibmvscsis_probe(struct vio_dev *vdev,</span>
 		     (unsigned long)vscsi);
 
 	init_completion(&amp;vscsi-&gt;wait_idle);
<span class="p_add">+	init_completion(&amp;vscsi-&gt;unconfig);</span>
 
 	snprintf(wq_name, 24, &quot;ibmvscsis%s&quot;, dev_name(&amp;vdev-&gt;dev));
 	vscsi-&gt;work_q = create_workqueue(wq_name);
<span class="p_chunk">@@ -3486,31 +3387,12 @@</span> <span class="p_context"> static int ibmvscsis_probe(struct vio_dev *vdev,</span>
 		goto destroy_WQ;
 	}
 
<span class="p_del">-	spin_lock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_del">-	vio_enable_interrupts(vdev);</span>
<span class="p_del">-	if (rc) {</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;enabling interrupts failed, rc %d\n&quot;, rc);</span>
<span class="p_del">-		rc = -ENODEV;</span>
<span class="p_del">-		spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_del">-		goto free_irq;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (ibmvscsis_check_q(vscsi)) {</span>
<span class="p_del">-		rc = ERROR;</span>
<span class="p_del">-		dev_err(&amp;vscsi-&gt;dev, &quot;probe: check_q failed, rc %d\n&quot;, rc);</span>
<span class="p_del">-		spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_del">-		goto disable_interrupt;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_add">+	vscsi-&gt;state = WAIT_ENABLED;</span>
 
 	dev_set_drvdata(&amp;vdev-&gt;dev, vscsi);
 
 	return 0;
 
<span class="p_del">-disable_interrupt:</span>
<span class="p_del">-	vio_disable_interrupts(vdev);</span>
<span class="p_del">-free_irq:</span>
<span class="p_del">-	free_irq(vdev-&gt;irq, vscsi);</span>
 destroy_WQ:
 	destroy_workqueue(vscsi-&gt;work_q);
 unmap_buf:
<span class="p_chunk">@@ -3544,10 +3426,11 @@</span> <span class="p_context"> static int ibmvscsis_remove(struct vio_dev *vdev)</span>
 
 	pr_debug(&quot;remove (%s)\n&quot;, dev_name(&amp;vscsi-&gt;dma_dev-&gt;dev));
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * TBD: Need to handle if there are commands on the waiting_rsp q</span>
<span class="p_del">-	 *      Actually, can there still be cmds outstanding to tcm?</span>
<span class="p_del">-	 */</span>
<span class="p_add">+	spin_lock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_add">+	ibmvscsis_post_disconnect(vscsi, UNCONFIGURING, 0);</span>
<span class="p_add">+	vscsi-&gt;flags |= CFG_SLEEPING;</span>
<span class="p_add">+	spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
<span class="p_add">+	wait_for_completion(&amp;vscsi-&gt;unconfig);</span>
 
 	vio_disable_interrupts(vdev);
 	free_irq(vdev-&gt;irq, vscsi);
<span class="p_chunk">@@ -3556,7 +3439,6 @@</span> <span class="p_context"> static int ibmvscsis_remove(struct vio_dev *vdev)</span>
 			 DMA_BIDIRECTIONAL);
 	kfree(vscsi-&gt;map_buf);
 	tasklet_kill(&amp;vscsi-&gt;work_task);
<span class="p_del">-	ibmvscsis_unregister_command_q(vscsi);</span>
 	ibmvscsis_destroy_command_q(vscsi);
 	ibmvscsis_freetimer(vscsi);
 	ibmvscsis_free_cmds(vscsi);
<span class="p_chunk">@@ -3610,7 +3492,7 @@</span> <span class="p_context"> static int ibmvscsis_get_system_info(void)</span>
 
 	num = of_get_property(rootdn, &quot;ibm,partition-no&quot;, NULL);
 	if (num)
<span class="p_del">-		partition_number = *num;</span>
<span class="p_add">+		partition_number = of_read_number(num, 1);</span>
 
 	of_node_put(rootdn);
 
<span class="p_chunk">@@ -3904,18 +3786,22 @@</span> <span class="p_context"> static ssize_t ibmvscsis_tpg_enable_store(struct config_item *item,</span>
 	}
 
 	if (tmp) {
<span class="p_del">-		tport-&gt;enabled = true;</span>
 		spin_lock_bh(&amp;vscsi-&gt;intr_lock);
<span class="p_add">+		tport-&gt;enabled = true;</span>
 		lrc = ibmvscsis_enable_change_state(vscsi);
 		if (lrc)
 			pr_err(&quot;enable_change_state failed, rc %ld state %d\n&quot;,
 			       lrc, vscsi-&gt;state);
 		spin_unlock_bh(&amp;vscsi-&gt;intr_lock);
 	} else {
<span class="p_add">+		spin_lock_bh(&amp;vscsi-&gt;intr_lock);</span>
 		tport-&gt;enabled = false;
<span class="p_add">+		/* This simulates the server going down */</span>
<span class="p_add">+		ibmvscsis_post_disconnect(vscsi, ERR_DISCONNECT, 0);</span>
<span class="p_add">+		spin_unlock_bh(&amp;vscsi-&gt;intr_lock);</span>
 	}
 
<span class="p_del">-	pr_debug(&quot;tpg_enable_store, state %d\n&quot;, vscsi-&gt;state);</span>
<span class="p_add">+	pr_debug(&quot;tpg_enable_store, tmp %ld, state %d\n&quot;, tmp, vscsi-&gt;state);</span>
 
 	return count;
 }
<span class="p_chunk">@@ -3985,10 +3871,10 @@</span> <span class="p_context"> static struct attribute *ibmvscsis_dev_attrs[] = {</span>
 ATTRIBUTE_GROUPS(ibmvscsis_dev);
 
 static struct class ibmvscsis_class = {
<span class="p_del">-	.name           = &quot;ibmvscsis&quot;,</span>
<span class="p_del">-	.dev_release    = ibmvscsis_dev_release,</span>
<span class="p_del">-	.class_attrs    = ibmvscsis_class_attrs,</span>
<span class="p_del">-	.dev_groups     = ibmvscsis_dev_groups,</span>
<span class="p_add">+	.name		= &quot;ibmvscsis&quot;,</span>
<span class="p_add">+	.dev_release	= ibmvscsis_dev_release,</span>
<span class="p_add">+	.class_attrs	= ibmvscsis_class_attrs,</span>
<span class="p_add">+	.dev_groups	= ibmvscsis_dev_groups,</span>
 };
 
 static struct vio_device_id ibmvscsis_device_table[] = {
<span class="p_header">diff --git a/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.h b/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.h</span>
<span class="p_header">index 981a0c992b6c..98b0ca79a5c5 100644</span>
<span class="p_header">--- a/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.h</span>
<span class="p_header">+++ b/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.h</span>
<span class="p_chunk">@@ -204,8 +204,6 @@</span> <span class="p_context"> struct scsi_info {</span>
 	struct list_head waiting_rsp;
 #define NO_QUEUE                    0x00
 #define WAIT_ENABLED                0X01
<span class="p_del">-	/* driver has received an initialize command */</span>
<span class="p_del">-#define PART_UP_WAIT_ENAB           0x02</span>
 #define WAIT_CONNECTION             0x04
 	/* have established a connection */
 #define CONNECTED                   0x08
<span class="p_chunk">@@ -259,6 +257,8 @@</span> <span class="p_context"> struct scsi_info {</span>
 #define SCHEDULE_DISCONNECT           0x00400
 	/* disconnect handler is scheduled */
 #define DISCONNECT_SCHEDULED          0x00800
<span class="p_add">+	/* remove function is sleeping */</span>
<span class="p_add">+#define CFG_SLEEPING                  0x01000</span>
 	u32 flags;
 	/* adapter lock */
 	spinlock_t intr_lock;
<span class="p_chunk">@@ -287,6 +287,7 @@</span> <span class="p_context"> struct scsi_info {</span>
 
 	struct workqueue_struct *work_q;
 	struct completion wait_idle;
<span class="p_add">+	struct completion unconfig;</span>
 	struct device dev;
 	struct vio_dev *dma_dev;
 	struct srp_target target;
<span class="p_header">diff --git a/drivers/tty/serial/8250/8250_pci.c b/drivers/tty/serial/8250/8250_pci.c</span>
<span class="p_header">index 4d09bd495a88..6e3e63675e56 100644</span>
<span class="p_header">--- a/drivers/tty/serial/8250/8250_pci.c</span>
<span class="p_header">+++ b/drivers/tty/serial/8250/8250_pci.c</span>
<span class="p_chunk">@@ -52,6 +52,7 @@</span> <span class="p_context"> struct serial_private {</span>
 	struct pci_dev		*dev;
 	unsigned int		nr;
 	struct pci_serial_quirk	*quirk;
<span class="p_add">+	const struct pciserial_board *board;</span>
 	int			line[0];
 };
 
<span class="p_chunk">@@ -3871,6 +3872,7 @@</span> <span class="p_context"> pciserial_init_ports(struct pci_dev *dev, const struct pciserial_board *board)</span>
 		}
 	}
 	priv-&gt;nr = i;
<span class="p_add">+	priv-&gt;board = board;</span>
 	return priv;
 
 err_deinit:
<span class="p_chunk">@@ -3881,7 +3883,7 @@</span> <span class="p_context"> pciserial_init_ports(struct pci_dev *dev, const struct pciserial_board *board)</span>
 }
 EXPORT_SYMBOL_GPL(pciserial_init_ports);
 
<span class="p_del">-void pciserial_remove_ports(struct serial_private *priv)</span>
<span class="p_add">+void pciserial_detach_ports(struct serial_private *priv)</span>
 {
 	struct pci_serial_quirk *quirk;
 	int i;
<span class="p_chunk">@@ -3895,7 +3897,11 @@</span> <span class="p_context"> void pciserial_remove_ports(struct serial_private *priv)</span>
 	quirk = find_quirk(priv-&gt;dev);
 	if (quirk-&gt;exit)
 		quirk-&gt;exit(priv-&gt;dev);
<span class="p_add">+}</span>
 
<span class="p_add">+void pciserial_remove_ports(struct serial_private *priv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pciserial_detach_ports(priv);</span>
 	kfree(priv);
 }
 EXPORT_SYMBOL_GPL(pciserial_remove_ports);
<span class="p_chunk">@@ -5590,7 +5596,7 @@</span> <span class="p_context"> static pci_ers_result_t serial8250_io_error_detected(struct pci_dev *dev,</span>
 		return PCI_ERS_RESULT_DISCONNECT;
 
 	if (priv)
<span class="p_del">-		pciserial_suspend_ports(priv);</span>
<span class="p_add">+		pciserial_detach_ports(priv);</span>
 
 	pci_disable_device(dev);
 
<span class="p_chunk">@@ -5615,9 +5621,18 @@</span> <span class="p_context"> static pci_ers_result_t serial8250_io_slot_reset(struct pci_dev *dev)</span>
 static void serial8250_io_resume(struct pci_dev *dev)
 {
 	struct serial_private *priv = pci_get_drvdata(dev);
<span class="p_add">+	const struct pciserial_board *board;</span>
 
<span class="p_del">-	if (priv)</span>
<span class="p_del">-		pciserial_resume_ports(priv);</span>
<span class="p_add">+	if (!priv)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	board = priv-&gt;board;</span>
<span class="p_add">+	kfree(priv);</span>
<span class="p_add">+	priv = pciserial_init_ports(dev, board);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!IS_ERR(priv)) {</span>
<span class="p_add">+		pci_set_drvdata(dev, priv);</span>
<span class="p_add">+	}</span>
 }
 
 static const struct pci_error_handlers serial8250_err_handler = {
<span class="p_header">diff --git a/drivers/usb/gadget/udc/atmel_usba_udc.c b/drivers/usb/gadget/udc/atmel_usba_udc.c</span>
<span class="p_header">index 45bc997d0711..a95b3e75f750 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/udc/atmel_usba_udc.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/udc/atmel_usba_udc.c</span>
<span class="p_chunk">@@ -1978,7 +1978,8 @@</span> <span class="p_context"> static struct usba_ep * atmel_udc_of_init(struct platform_device *pdev,</span>
 			dev_err(&amp;pdev-&gt;dev, &quot;of_probe: name error(%d)\n&quot;, ret);
 			goto err;
 		}
<span class="p_del">-		ep-&gt;ep.name = kasprintf(GFP_KERNEL, &quot;ep%d&quot;, ep-&gt;index);</span>
<span class="p_add">+		sprintf(ep-&gt;name, &quot;ep%d&quot;, ep-&gt;index);</span>
<span class="p_add">+		ep-&gt;ep.name = ep-&gt;name;</span>
 
 		ep-&gt;ep_regs = udc-&gt;regs + USBA_EPT_BASE(i);
 		ep-&gt;dma_regs = udc-&gt;regs + USBA_DMA_BASE(i);
<span class="p_header">diff --git a/drivers/usb/gadget/udc/atmel_usba_udc.h b/drivers/usb/gadget/udc/atmel_usba_udc.h</span>
<span class="p_header">index 3e1c9d589dfa..b03b2ebfc53a 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/udc/atmel_usba_udc.h</span>
<span class="p_header">+++ b/drivers/usb/gadget/udc/atmel_usba_udc.h</span>
<span class="p_chunk">@@ -280,6 +280,7 @@</span> <span class="p_context"> struct usba_ep {</span>
 	void __iomem				*ep_regs;
 	void __iomem				*dma_regs;
 	void __iomem				*fifo;
<span class="p_add">+	char					name[8];</span>
 	struct usb_ep				ep;
 	struct usba_udc				*udc;
 
<span class="p_header">diff --git a/drivers/vfio/vfio_iommu_spapr_tce.c b/drivers/vfio/vfio_iommu_spapr_tce.c</span>
<span class="p_header">index 80378ddadc5c..c8823578a1b2 100644</span>
<span class="p_header">--- a/drivers/vfio/vfio_iommu_spapr_tce.c</span>
<span class="p_header">+++ b/drivers/vfio/vfio_iommu_spapr_tce.c</span>
<span class="p_chunk">@@ -31,49 +31,49 @@</span> <span class="p_context"></span>
 static void tce_iommu_detach_group(void *iommu_data,
 		struct iommu_group *iommu_group);
 
<span class="p_del">-static long try_increment_locked_vm(long npages)</span>
<span class="p_add">+static long try_increment_locked_vm(struct mm_struct *mm, long npages)</span>
 {
 	long ret = 0, locked, lock_limit;
 
<span class="p_del">-	if (!current || !current-&gt;mm)</span>
<span class="p_del">-		return -ESRCH; /* process exited */</span>
<span class="p_add">+	if (WARN_ON_ONCE(!mm))</span>
<span class="p_add">+		return -EPERM;</span>
 
 	if (!npages)
 		return 0;
 
<span class="p_del">-	down_write(&amp;current-&gt;mm-&gt;mmap_sem);</span>
<span class="p_del">-	locked = current-&gt;mm-&gt;locked_vm + npages;</span>
<span class="p_add">+	down_write(&amp;mm-&gt;mmap_sem);</span>
<span class="p_add">+	locked = mm-&gt;locked_vm + npages;</span>
 	lock_limit = rlimit(RLIMIT_MEMLOCK) &gt;&gt; PAGE_SHIFT;
 	if (locked &gt; lock_limit &amp;&amp; !capable(CAP_IPC_LOCK))
 		ret = -ENOMEM;
 	else
<span class="p_del">-		current-&gt;mm-&gt;locked_vm += npages;</span>
<span class="p_add">+		mm-&gt;locked_vm += npages;</span>
 
 	pr_debug(&quot;[%d] RLIMIT_MEMLOCK +%ld %ld/%ld%s\n&quot;, current-&gt;pid,
 			npages &lt;&lt; PAGE_SHIFT,
<span class="p_del">-			current-&gt;mm-&gt;locked_vm &lt;&lt; PAGE_SHIFT,</span>
<span class="p_add">+			mm-&gt;locked_vm &lt;&lt; PAGE_SHIFT,</span>
 			rlimit(RLIMIT_MEMLOCK),
 			ret ? &quot; - exceeded&quot; : &quot;&quot;);
 
<span class="p_del">-	up_write(&amp;current-&gt;mm-&gt;mmap_sem);</span>
<span class="p_add">+	up_write(&amp;mm-&gt;mmap_sem);</span>
 
 	return ret;
 }
 
<span class="p_del">-static void decrement_locked_vm(long npages)</span>
<span class="p_add">+static void decrement_locked_vm(struct mm_struct *mm, long npages)</span>
 {
<span class="p_del">-	if (!current || !current-&gt;mm || !npages)</span>
<span class="p_del">-		return; /* process exited */</span>
<span class="p_add">+	if (!mm || !npages)</span>
<span class="p_add">+		return;</span>
 
<span class="p_del">-	down_write(&amp;current-&gt;mm-&gt;mmap_sem);</span>
<span class="p_del">-	if (WARN_ON_ONCE(npages &gt; current-&gt;mm-&gt;locked_vm))</span>
<span class="p_del">-		npages = current-&gt;mm-&gt;locked_vm;</span>
<span class="p_del">-	current-&gt;mm-&gt;locked_vm -= npages;</span>
<span class="p_add">+	down_write(&amp;mm-&gt;mmap_sem);</span>
<span class="p_add">+	if (WARN_ON_ONCE(npages &gt; mm-&gt;locked_vm))</span>
<span class="p_add">+		npages = mm-&gt;locked_vm;</span>
<span class="p_add">+	mm-&gt;locked_vm -= npages;</span>
 	pr_debug(&quot;[%d] RLIMIT_MEMLOCK -%ld %ld/%ld\n&quot;, current-&gt;pid,
 			npages &lt;&lt; PAGE_SHIFT,
<span class="p_del">-			current-&gt;mm-&gt;locked_vm &lt;&lt; PAGE_SHIFT,</span>
<span class="p_add">+			mm-&gt;locked_vm &lt;&lt; PAGE_SHIFT,</span>
 			rlimit(RLIMIT_MEMLOCK));
<span class="p_del">-	up_write(&amp;current-&gt;mm-&gt;mmap_sem);</span>
<span class="p_add">+	up_write(&amp;mm-&gt;mmap_sem);</span>
 }
 
 /*
<span class="p_chunk">@@ -89,6 +89,15 @@</span> <span class="p_context"> struct tce_iommu_group {</span>
 };
 
 /*
<span class="p_add">+ * A container needs to remember which preregistered region  it has</span>
<span class="p_add">+ * referenced to do proper cleanup at the userspace process exit.</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct tce_iommu_prereg {</span>
<span class="p_add">+	struct list_head next;</span>
<span class="p_add">+	struct mm_iommu_table_group_mem_t *mem;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * The container descriptor supports only a single group per container.
  * Required by the API as the container is not supplied with the IOMMU group
  * at the moment of initialization.
<span class="p_chunk">@@ -97,24 +106,68 @@</span> <span class="p_context"> struct tce_container {</span>
 	struct mutex lock;
 	bool enabled;
 	bool v2;
<span class="p_add">+	bool def_window_pending;</span>
 	unsigned long locked_pages;
<span class="p_add">+	struct mm_struct *mm;</span>
 	struct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];
 	struct list_head group_list;
<span class="p_add">+	struct list_head prereg_list;</span>
 };
 
<span class="p_add">+static long tce_iommu_mm_set(struct tce_container *container)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (container-&gt;mm) {</span>
<span class="p_add">+		if (container-&gt;mm == current-&gt;mm)</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+		return -EPERM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	BUG_ON(!current-&gt;mm);</span>
<span class="p_add">+	container-&gt;mm = current-&gt;mm;</span>
<span class="p_add">+	atomic_inc(&amp;container-&gt;mm-&gt;mm_count);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static long tce_iommu_prereg_free(struct tce_container *container,</span>
<span class="p_add">+		struct tce_iommu_prereg *tcemem)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = mm_iommu_put(container-&gt;mm, tcemem-&gt;mem);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_del(&amp;tcemem-&gt;next);</span>
<span class="p_add">+	kfree(tcemem);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static long tce_iommu_unregister_pages(struct tce_container *container,
 		__u64 vaddr, __u64 size)
 {
 	struct mm_iommu_table_group_mem_t *mem;
<span class="p_add">+	struct tce_iommu_prereg *tcemem;</span>
<span class="p_add">+	bool found = false;</span>
 
 	if ((vaddr &amp; ~PAGE_MASK) || (size &amp; ~PAGE_MASK))
 		return -EINVAL;
 
<span class="p_del">-	mem = mm_iommu_find(vaddr, size &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	mem = mm_iommu_find(container-&gt;mm, vaddr, size &gt;&gt; PAGE_SHIFT);</span>
 	if (!mem)
 		return -ENOENT;
 
<span class="p_del">-	return mm_iommu_put(mem);</span>
<span class="p_add">+	list_for_each_entry(tcemem, &amp;container-&gt;prereg_list, next) {</span>
<span class="p_add">+		if (tcemem-&gt;mem == mem) {</span>
<span class="p_add">+			found = true;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!found)</span>
<span class="p_add">+		return -ENOENT;</span>
<span class="p_add">+</span>
<span class="p_add">+	return tce_iommu_prereg_free(container, tcemem);</span>
 }
 
 static long tce_iommu_register_pages(struct tce_container *container,
<span class="p_chunk">@@ -122,22 +175,36 @@</span> <span class="p_context"> static long tce_iommu_register_pages(struct tce_container *container,</span>
 {
 	long ret = 0;
 	struct mm_iommu_table_group_mem_t *mem = NULL;
<span class="p_add">+	struct tce_iommu_prereg *tcemem;</span>
 	unsigned long entries = size &gt;&gt; PAGE_SHIFT;
 
 	if ((vaddr &amp; ~PAGE_MASK) || (size &amp; ~PAGE_MASK) ||
 			((vaddr + size) &lt; vaddr))
 		return -EINVAL;
 
<span class="p_del">-	ret = mm_iommu_get(vaddr, entries, &amp;mem);</span>
<span class="p_add">+	mem = mm_iommu_find(container-&gt;mm, vaddr, entries);</span>
<span class="p_add">+	if (mem) {</span>
<span class="p_add">+		list_for_each_entry(tcemem, &amp;container-&gt;prereg_list, next) {</span>
<span class="p_add">+			if (tcemem-&gt;mem == mem)</span>
<span class="p_add">+				return -EBUSY;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = mm_iommu_get(container-&gt;mm, vaddr, entries, &amp;mem);</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	tcemem = kzalloc(sizeof(*tcemem), GFP_KERNEL);</span>
<span class="p_add">+	tcemem-&gt;mem = mem;</span>
<span class="p_add">+	list_add(&amp;tcemem-&gt;next, &amp;container-&gt;prereg_list);</span>
<span class="p_add">+</span>
 	container-&gt;enabled = true;
 
 	return 0;
 }
 
<span class="p_del">-static long tce_iommu_userspace_view_alloc(struct iommu_table *tbl)</span>
<span class="p_add">+static long tce_iommu_userspace_view_alloc(struct iommu_table *tbl,</span>
<span class="p_add">+		struct mm_struct *mm)</span>
 {
 	unsigned long cb = _ALIGN_UP(sizeof(tbl-&gt;it_userspace[0]) *
 			tbl-&gt;it_size, PAGE_SIZE);
<span class="p_chunk">@@ -146,13 +213,13 @@</span> <span class="p_context"> static long tce_iommu_userspace_view_alloc(struct iommu_table *tbl)</span>
 
 	BUG_ON(tbl-&gt;it_userspace);
 
<span class="p_del">-	ret = try_increment_locked_vm(cb &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	ret = try_increment_locked_vm(mm, cb &gt;&gt; PAGE_SHIFT);</span>
 	if (ret)
 		return ret;
 
 	uas = vzalloc(cb);
 	if (!uas) {
<span class="p_del">-		decrement_locked_vm(cb &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+		decrement_locked_vm(mm, cb &gt;&gt; PAGE_SHIFT);</span>
 		return -ENOMEM;
 	}
 	tbl-&gt;it_userspace = uas;
<span class="p_chunk">@@ -160,7 +227,8 @@</span> <span class="p_context"> static long tce_iommu_userspace_view_alloc(struct iommu_table *tbl)</span>
 	return 0;
 }
 
<span class="p_del">-static void tce_iommu_userspace_view_free(struct iommu_table *tbl)</span>
<span class="p_add">+static void tce_iommu_userspace_view_free(struct iommu_table *tbl,</span>
<span class="p_add">+		struct mm_struct *mm)</span>
 {
 	unsigned long cb = _ALIGN_UP(sizeof(tbl-&gt;it_userspace[0]) *
 			tbl-&gt;it_size, PAGE_SIZE);
<span class="p_chunk">@@ -170,7 +238,7 @@</span> <span class="p_context"> static void tce_iommu_userspace_view_free(struct iommu_table *tbl)</span>
 
 	vfree(tbl-&gt;it_userspace);
 	tbl-&gt;it_userspace = NULL;
<span class="p_del">-	decrement_locked_vm(cb &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	decrement_locked_vm(mm, cb &gt;&gt; PAGE_SHIFT);</span>
 }
 
 static bool tce_page_is_contained(struct page *page, unsigned page_shift)
<span class="p_chunk">@@ -230,9 +298,6 @@</span> <span class="p_context"> static int tce_iommu_enable(struct tce_container *container)</span>
 	struct iommu_table_group *table_group;
 	struct tce_iommu_group *tcegrp;
 
<span class="p_del">-	if (!current-&gt;mm)</span>
<span class="p_del">-		return -ESRCH; /* process exited */</span>
<span class="p_del">-</span>
 	if (container-&gt;enabled)
 		return -EBUSY;
 
<span class="p_chunk">@@ -277,8 +342,12 @@</span> <span class="p_context"> static int tce_iommu_enable(struct tce_container *container)</span>
 	if (!table_group-&gt;tce32_size)
 		return -EPERM;
 
<span class="p_add">+	ret = tce_iommu_mm_set(container);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
 	locked = table_group-&gt;tce32_size &gt;&gt; PAGE_SHIFT;
<span class="p_del">-	ret = try_increment_locked_vm(locked);</span>
<span class="p_add">+	ret = try_increment_locked_vm(container-&gt;mm, locked);</span>
 	if (ret)
 		return ret;
 
<span class="p_chunk">@@ -296,10 +365,8 @@</span> <span class="p_context"> static void tce_iommu_disable(struct tce_container *container)</span>
 
 	container-&gt;enabled = false;
 
<span class="p_del">-	if (!current-&gt;mm)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	decrement_locked_vm(container-&gt;locked_pages);</span>
<span class="p_add">+	BUG_ON(!container-&gt;mm);</span>
<span class="p_add">+	decrement_locked_vm(container-&gt;mm, container-&gt;locked_pages);</span>
 }
 
 static void *tce_iommu_open(unsigned long arg)
<span class="p_chunk">@@ -317,6 +384,7 @@</span> <span class="p_context"> static void *tce_iommu_open(unsigned long arg)</span>
 
 	mutex_init(&amp;container-&gt;lock);
 	INIT_LIST_HEAD_RCU(&amp;container-&gt;group_list);
<span class="p_add">+	INIT_LIST_HEAD_RCU(&amp;container-&gt;prereg_list);</span>
 
 	container-&gt;v2 = arg == VFIO_SPAPR_TCE_v2_IOMMU;
 
<span class="p_chunk">@@ -326,7 +394,8 @@</span> <span class="p_context"> static void *tce_iommu_open(unsigned long arg)</span>
 static int tce_iommu_clear(struct tce_container *container,
 		struct iommu_table *tbl,
 		unsigned long entry, unsigned long pages);
<span class="p_del">-static void tce_iommu_free_table(struct iommu_table *tbl);</span>
<span class="p_add">+static void tce_iommu_free_table(struct tce_container *container,</span>
<span class="p_add">+		struct iommu_table *tbl);</span>
 
 static void tce_iommu_release(void *iommu_data)
 {
<span class="p_chunk">@@ -351,10 +420,20 @@</span> <span class="p_context"> static void tce_iommu_release(void *iommu_data)</span>
 			continue;
 
 		tce_iommu_clear(container, tbl, tbl-&gt;it_offset, tbl-&gt;it_size);
<span class="p_del">-		tce_iommu_free_table(tbl);</span>
<span class="p_add">+		tce_iommu_free_table(container, tbl);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	while (!list_empty(&amp;container-&gt;prereg_list)) {</span>
<span class="p_add">+		struct tce_iommu_prereg *tcemem;</span>
<span class="p_add">+</span>
<span class="p_add">+		tcemem = list_first_entry(&amp;container-&gt;prereg_list,</span>
<span class="p_add">+				struct tce_iommu_prereg, next);</span>
<span class="p_add">+		WARN_ON_ONCE(tce_iommu_prereg_free(container, tcemem));</span>
 	}
 
 	tce_iommu_disable(container);
<span class="p_add">+	if (container-&gt;mm)</span>
<span class="p_add">+		mmdrop(container-&gt;mm);</span>
 	mutex_destroy(&amp;container-&gt;lock);
 
 	kfree(container);
<span class="p_chunk">@@ -369,13 +448,14 @@</span> <span class="p_context"> static void tce_iommu_unuse_page(struct tce_container *container,</span>
 	put_page(page);
 }
 
<span class="p_del">-static int tce_iommu_prereg_ua_to_hpa(unsigned long tce, unsigned long size,</span>
<span class="p_add">+static int tce_iommu_prereg_ua_to_hpa(struct tce_container *container,</span>
<span class="p_add">+		unsigned long tce, unsigned long size,</span>
 		unsigned long *phpa, struct mm_iommu_table_group_mem_t **pmem)
 {
 	long ret = 0;
 	struct mm_iommu_table_group_mem_t *mem;
 
<span class="p_del">-	mem = mm_iommu_lookup(tce, size);</span>
<span class="p_add">+	mem = mm_iommu_lookup(container-&gt;mm, tce, size);</span>
 	if (!mem)
 		return -EINVAL;
 
<span class="p_chunk">@@ -388,18 +468,18 @@</span> <span class="p_context"> static int tce_iommu_prereg_ua_to_hpa(unsigned long tce, unsigned long size,</span>
 	return 0;
 }
 
<span class="p_del">-static void tce_iommu_unuse_page_v2(struct iommu_table *tbl,</span>
<span class="p_del">-		unsigned long entry)</span>
<span class="p_add">+static void tce_iommu_unuse_page_v2(struct tce_container *container,</span>
<span class="p_add">+		struct iommu_table *tbl, unsigned long entry)</span>
 {
 	struct mm_iommu_table_group_mem_t *mem = NULL;
 	int ret;
 	unsigned long hpa = 0;
 	unsigned long *pua = IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry);
 
<span class="p_del">-	if (!pua || !current || !current-&gt;mm)</span>
<span class="p_add">+	if (!pua)</span>
 		return;
 
<span class="p_del">-	ret = tce_iommu_prereg_ua_to_hpa(*pua, IOMMU_PAGE_SIZE(tbl),</span>
<span class="p_add">+	ret = tce_iommu_prereg_ua_to_hpa(container, *pua, IOMMU_PAGE_SIZE(tbl),</span>
 			&amp;hpa, &amp;mem);
 	if (ret)
 		pr_debug(&quot;%s: tce %lx at #%lx was not cached, ret=%d\n&quot;,
<span class="p_chunk">@@ -429,7 +509,7 @@</span> <span class="p_context"> static int tce_iommu_clear(struct tce_container *container,</span>
 			continue;
 
 		if (container-&gt;v2) {
<span class="p_del">-			tce_iommu_unuse_page_v2(tbl, entry);</span>
<span class="p_add">+			tce_iommu_unuse_page_v2(container, tbl, entry);</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -509,13 +589,19 @@</span> <span class="p_context"> static long tce_iommu_build_v2(struct tce_container *container,</span>
 	unsigned long hpa;
 	enum dma_data_direction dirtmp;
 
<span class="p_add">+	if (!tbl-&gt;it_userspace) {</span>
<span class="p_add">+		ret = tce_iommu_userspace_view_alloc(tbl, container-&gt;mm);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; pages; ++i) {
 		struct mm_iommu_table_group_mem_t *mem = NULL;
 		unsigned long *pua = IOMMU_TABLE_USERSPACE_ENTRY(tbl,
 				entry + i);
 
<span class="p_del">-		ret = tce_iommu_prereg_ua_to_hpa(tce, IOMMU_PAGE_SIZE(tbl),</span>
<span class="p_del">-				&amp;hpa, &amp;mem);</span>
<span class="p_add">+		ret = tce_iommu_prereg_ua_to_hpa(container,</span>
<span class="p_add">+				tce, IOMMU_PAGE_SIZE(tbl), &amp;hpa, &amp;mem);</span>
 		if (ret)
 			break;
 
<span class="p_chunk">@@ -536,7 +622,7 @@</span> <span class="p_context"> static long tce_iommu_build_v2(struct tce_container *container,</span>
 		ret = iommu_tce_xchg(tbl, entry + i, &amp;hpa, &amp;dirtmp);
 		if (ret) {
 			/* dirtmp cannot be DMA_NONE here */
<span class="p_del">-			tce_iommu_unuse_page_v2(tbl, entry + i);</span>
<span class="p_add">+			tce_iommu_unuse_page_v2(container, tbl, entry + i);</span>
 			pr_err(&quot;iommu_tce: %s failed ioba=%lx, tce=%lx, ret=%ld\n&quot;,
 					__func__, entry &lt;&lt; tbl-&gt;it_page_shift,
 					tce, ret);
<span class="p_chunk">@@ -544,7 +630,7 @@</span> <span class="p_context"> static long tce_iommu_build_v2(struct tce_container *container,</span>
 		}
 
 		if (dirtmp != DMA_NONE)
<span class="p_del">-			tce_iommu_unuse_page_v2(tbl, entry + i);</span>
<span class="p_add">+			tce_iommu_unuse_page_v2(container, tbl, entry + i);</span>
 
 		*pua = tce;
 
<span class="p_chunk">@@ -572,7 +658,7 @@</span> <span class="p_context"> static long tce_iommu_create_table(struct tce_container *container,</span>
 	if (!table_size)
 		return -EINVAL;
 
<span class="p_del">-	ret = try_increment_locked_vm(table_size &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	ret = try_increment_locked_vm(container-&gt;mm, table_size &gt;&gt; PAGE_SHIFT);</span>
 	if (ret)
 		return ret;
 
<span class="p_chunk">@@ -582,25 +668,17 @@</span> <span class="p_context"> static long tce_iommu_create_table(struct tce_container *container,</span>
 	WARN_ON(!ret &amp;&amp; !(*ptbl)-&gt;it_ops-&gt;free);
 	WARN_ON(!ret &amp;&amp; ((*ptbl)-&gt;it_allocated_size != table_size));
 
<span class="p_del">-	if (!ret &amp;&amp; container-&gt;v2) {</span>
<span class="p_del">-		ret = tce_iommu_userspace_view_alloc(*ptbl);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			(*ptbl)-&gt;it_ops-&gt;free(*ptbl);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		decrement_locked_vm(table_size &gt;&gt; PAGE_SHIFT);</span>
<span class="p_del">-</span>
 	return ret;
 }
 
<span class="p_del">-static void tce_iommu_free_table(struct iommu_table *tbl)</span>
<span class="p_add">+static void tce_iommu_free_table(struct tce_container *container,</span>
<span class="p_add">+		struct iommu_table *tbl)</span>
 {
 	unsigned long pages = tbl-&gt;it_allocated_size &gt;&gt; PAGE_SHIFT;
 
<span class="p_del">-	tce_iommu_userspace_view_free(tbl);</span>
<span class="p_add">+	tce_iommu_userspace_view_free(tbl, container-&gt;mm);</span>
 	tbl-&gt;it_ops-&gt;free(tbl);
<span class="p_del">-	decrement_locked_vm(pages);</span>
<span class="p_add">+	decrement_locked_vm(container-&gt;mm, pages);</span>
 }
 
 static long tce_iommu_create_window(struct tce_container *container,
<span class="p_chunk">@@ -663,7 +741,7 @@</span> <span class="p_context"> static long tce_iommu_create_window(struct tce_container *container,</span>
 		table_group = iommu_group_get_iommudata(tcegrp-&gt;grp);
 		table_group-&gt;ops-&gt;unset_window(table_group, num);
 	}
<span class="p_del">-	tce_iommu_free_table(tbl);</span>
<span class="p_add">+	tce_iommu_free_table(container, tbl);</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -701,12 +779,41 @@</span> <span class="p_context"> static long tce_iommu_remove_window(struct tce_container *container,</span>
 
 	/* Free table */
 	tce_iommu_clear(container, tbl, tbl-&gt;it_offset, tbl-&gt;it_size);
<span class="p_del">-	tce_iommu_free_table(tbl);</span>
<span class="p_add">+	tce_iommu_free_table(container, tbl);</span>
 	container-&gt;tables[num] = NULL;
 
 	return 0;
 }
 
<span class="p_add">+static long tce_iommu_create_default_window(struct tce_container *container)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long ret;</span>
<span class="p_add">+	__u64 start_addr = 0;</span>
<span class="p_add">+	struct tce_iommu_group *tcegrp;</span>
<span class="p_add">+	struct iommu_table_group *table_group;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!container-&gt;def_window_pending)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!tce_groups_attached(container))</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	tcegrp = list_first_entry(&amp;container-&gt;group_list,</span>
<span class="p_add">+			struct tce_iommu_group, next);</span>
<span class="p_add">+	table_group = iommu_group_get_iommudata(tcegrp-&gt;grp);</span>
<span class="p_add">+	if (!table_group)</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = tce_iommu_create_window(container, IOMMU_PAGE_SHIFT_4K,</span>
<span class="p_add">+			table_group-&gt;tce32_size, 1, &amp;start_addr);</span>
<span class="p_add">+	WARN_ON_ONCE(!ret &amp;&amp; start_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!ret)</span>
<span class="p_add">+		container-&gt;def_window_pending = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static long tce_iommu_ioctl(void *iommu_data,
 				 unsigned int cmd, unsigned long arg)
 {
<span class="p_chunk">@@ -727,7 +834,17 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		}
 
 		return (ret &lt; 0) ? 0 : ret;
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Sanity check to prevent one userspace from manipulating</span>
<span class="p_add">+	 * another userspace mm.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	BUG_ON(!container);</span>
<span class="p_add">+	if (container-&gt;mm &amp;&amp; container-&gt;mm != current-&gt;mm)</span>
<span class="p_add">+		return -EPERM;</span>
 
<span class="p_add">+	switch (cmd) {</span>
 	case VFIO_IOMMU_SPAPR_TCE_GET_INFO: {
 		struct vfio_iommu_spapr_tce_info info;
 		struct tce_iommu_group *tcegrp;
<span class="p_chunk">@@ -797,6 +914,10 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 				VFIO_DMA_MAP_FLAG_WRITE))
 			return -EINVAL;
 
<span class="p_add">+		ret = tce_iommu_create_default_window(container);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
 		num = tce_iommu_find_table(container, param.iova, &amp;tbl);
 		if (num &lt; 0)
 			return -ENXIO;
<span class="p_chunk">@@ -860,6 +981,10 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		if (param.flags)
 			return -EINVAL;
 
<span class="p_add">+		ret = tce_iommu_create_default_window(container);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
 		num = tce_iommu_find_table(container, param.iova, &amp;tbl);
 		if (num &lt; 0)
 			return -ENXIO;
<span class="p_chunk">@@ -888,6 +1013,10 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		minsz = offsetofend(struct vfio_iommu_spapr_register_memory,
 				size);
 
<span class="p_add">+		ret = tce_iommu_mm_set(container);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
 		if (copy_from_user(&amp;param, (void __user *)arg, minsz))
 			return -EFAULT;
 
<span class="p_chunk">@@ -911,6 +1040,9 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		if (!container-&gt;v2)
 			break;
 
<span class="p_add">+		if (!container-&gt;mm)</span>
<span class="p_add">+			return -EPERM;</span>
<span class="p_add">+</span>
 		minsz = offsetofend(struct vfio_iommu_spapr_register_memory,
 				size);
 
<span class="p_chunk">@@ -969,6 +1101,10 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		if (!container-&gt;v2)
 			break;
 
<span class="p_add">+		ret = tce_iommu_mm_set(container);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
 		if (!tce_groups_attached(container))
 			return -ENXIO;
 
<span class="p_chunk">@@ -986,6 +1122,10 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 
 		mutex_lock(&amp;container-&gt;lock);
 
<span class="p_add">+		ret = tce_iommu_create_default_window(container);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
 		ret = tce_iommu_create_window(container, create.page_shift,
 				create.window_size, create.levels,
 				&amp;create.start_addr);
<span class="p_chunk">@@ -1003,6 +1143,10 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		if (!container-&gt;v2)
 			break;
 
<span class="p_add">+		ret = tce_iommu_mm_set(container);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
 		if (!tce_groups_attached(container))
 			return -ENXIO;
 
<span class="p_chunk">@@ -1018,6 +1162,11 @@</span> <span class="p_context"> static long tce_iommu_ioctl(void *iommu_data,</span>
 		if (remove.flags)
 			return -EINVAL;
 
<span class="p_add">+		if (container-&gt;def_window_pending &amp;&amp; !remove.start_addr) {</span>
<span class="p_add">+			container-&gt;def_window_pending = false;</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		mutex_lock(&amp;container-&gt;lock);
 
 		ret = tce_iommu_remove_window(container, remove.start_addr);
<span class="p_chunk">@@ -1043,7 +1192,7 @@</span> <span class="p_context"> static void tce_iommu_release_ownership(struct tce_container *container,</span>
 			continue;
 
 		tce_iommu_clear(container, tbl, tbl-&gt;it_offset, tbl-&gt;it_size);
<span class="p_del">-		tce_iommu_userspace_view_free(tbl);</span>
<span class="p_add">+		tce_iommu_userspace_view_free(tbl, container-&gt;mm);</span>
 		if (tbl-&gt;it_map)
 			iommu_release_ownership(tbl);
 
<span class="p_chunk">@@ -1062,10 +1211,7 @@</span> <span class="p_context"> static int tce_iommu_take_ownership(struct tce_container *container,</span>
 		if (!tbl || !tbl-&gt;it_map)
 			continue;
 
<span class="p_del">-		rc = tce_iommu_userspace_view_alloc(tbl);</span>
<span class="p_del">-		if (!rc)</span>
<span class="p_del">-			rc = iommu_take_ownership(tbl);</span>
<span class="p_del">-</span>
<span class="p_add">+		rc = iommu_take_ownership(tbl);</span>
 		if (rc) {
 			for (j = 0; j &lt; i; ++j)
 				iommu_release_ownership(
<span class="p_chunk">@@ -1100,9 +1246,6 @@</span> <span class="p_context"> static void tce_iommu_release_ownership_ddw(struct tce_container *container,</span>
 static long tce_iommu_take_ownership_ddw(struct tce_container *container,
 		struct iommu_table_group *table_group)
 {
<span class="p_del">-	long i, ret = 0;</span>
<span class="p_del">-	struct iommu_table *tbl = NULL;</span>
<span class="p_del">-</span>
 	if (!table_group-&gt;ops-&gt;create_table || !table_group-&gt;ops-&gt;set_window ||
 			!table_group-&gt;ops-&gt;release_ownership) {
 		WARN_ON_ONCE(1);
<span class="p_chunk">@@ -1111,47 +1254,7 @@</span> <span class="p_context"> static long tce_iommu_take_ownership_ddw(struct tce_container *container,</span>
 
 	table_group-&gt;ops-&gt;take_ownership(table_group);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If it the first group attached, check if there is</span>
<span class="p_del">-	 * a default DMA window and create one if none as</span>
<span class="p_del">-	 * the userspace expects it to exist.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!tce_groups_attached(container) &amp;&amp; !container-&gt;tables[0]) {</span>
<span class="p_del">-		ret = tce_iommu_create_table(container,</span>
<span class="p_del">-				table_group,</span>
<span class="p_del">-				0, /* window number */</span>
<span class="p_del">-				IOMMU_PAGE_SHIFT_4K,</span>
<span class="p_del">-				table_group-&gt;tce32_size,</span>
<span class="p_del">-				1, /* default levels */</span>
<span class="p_del">-				&amp;tbl);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto release_exit;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			container-&gt;tables[0] = tbl;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Set all windows to the new group */</span>
<span class="p_del">-	for (i = 0; i &lt; IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {</span>
<span class="p_del">-		tbl = container-&gt;tables[i];</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!tbl)</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Set the default window to a new group */</span>
<span class="p_del">-		ret = table_group-&gt;ops-&gt;set_window(table_group, i, tbl);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto release_exit;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 0;
<span class="p_del">-</span>
<span class="p_del">-release_exit:</span>
<span class="p_del">-	for (i = 0; i &lt; IOMMU_TABLE_GROUP_MAX_TABLES; ++i)</span>
<span class="p_del">-		table_group-&gt;ops-&gt;unset_window(table_group, i);</span>
<span class="p_del">-</span>
<span class="p_del">-	table_group-&gt;ops-&gt;release_ownership(table_group);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
 }
 
 static int tce_iommu_attach_group(void *iommu_data,
<span class="p_chunk">@@ -1203,10 +1306,13 @@</span> <span class="p_context"> static int tce_iommu_attach_group(void *iommu_data,</span>
 	}
 
 	if (!table_group-&gt;ops || !table_group-&gt;ops-&gt;take_ownership ||
<span class="p_del">-			!table_group-&gt;ops-&gt;release_ownership)</span>
<span class="p_add">+			!table_group-&gt;ops-&gt;release_ownership) {</span>
 		ret = tce_iommu_take_ownership(container, table_group);
<span class="p_del">-	else</span>
<span class="p_add">+	} else {</span>
 		ret = tce_iommu_take_ownership_ddw(container, table_group);
<span class="p_add">+		if (!tce_groups_attached(container) &amp;&amp; !container-&gt;tables[0])</span>
<span class="p_add">+			container-&gt;def_window_pending = true;</span>
<span class="p_add">+	}</span>
 
 	if (!ret) {
 		tcegrp-&gt;grp = iommu_group;
<span class="p_header">diff --git a/include/linux/bpf_verifier.h b/include/linux/bpf_verifier.h</span>
<span class="p_header">index 6aaf425cebc3..a13b031dc6b8 100644</span>
<span class="p_header">--- a/include/linux/bpf_verifier.h</span>
<span class="p_header">+++ b/include/linux/bpf_verifier.h</span>
<span class="p_chunk">@@ -18,19 +18,12 @@</span> <span class="p_context"></span>
 
 struct bpf_reg_state {
 	enum bpf_reg_type type;
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Used to determine if any memory access using this register will</span>
<span class="p_del">-	 * result in a bad access.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	s64 min_value;</span>
<span class="p_del">-	u64 max_value;</span>
 	union {
 		/* valid when type == CONST_IMM | PTR_TO_STACK | UNKNOWN_VALUE */
 		s64 imm;
 
 		/* valid when type == PTR_TO_PACKET* */
 		struct {
<span class="p_del">-			u32 id;</span>
 			u16 off;
 			u16 range;
 		};
<span class="p_chunk">@@ -40,6 +33,13 @@</span> <span class="p_context"> struct bpf_reg_state {</span>
 		 */
 		struct bpf_map *map_ptr;
 	};
<span class="p_add">+	u32 id;</span>
<span class="p_add">+	/* Used to determine if any memory access using this register will</span>
<span class="p_add">+	 * result in a bad access. These two fields must be last.</span>
<span class="p_add">+	 * See states_equal()</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	s64 min_value;</span>
<span class="p_add">+	u64 max_value;</span>
 };
 
 enum bpf_stack_slot_type {
<span class="p_header">diff --git a/include/linux/dccp.h b/include/linux/dccp.h</span>
<span class="p_header">index 61d042bbbf60..68449293c4b6 100644</span>
<span class="p_header">--- a/include/linux/dccp.h</span>
<span class="p_header">+++ b/include/linux/dccp.h</span>
<span class="p_chunk">@@ -163,6 +163,7 @@</span> <span class="p_context"> struct dccp_request_sock {</span>
 	__u64			 dreq_isr;
 	__u64			 dreq_gsr;
 	__be32			 dreq_service;
<span class="p_add">+	spinlock_t		 dreq_lock;</span>
 	struct list_head	 dreq_featneg;
 	__u32			 dreq_timestamp_echo;
 	__u32			 dreq_timestamp_time;
<span class="p_header">diff --git a/include/linux/hyperv.h b/include/linux/hyperv.h</span>
<span class="p_header">index 192eef2fd766..d596a076da11 100644</span>
<span class="p_header">--- a/include/linux/hyperv.h</span>
<span class="p_header">+++ b/include/linux/hyperv.h</span>
<span class="p_chunk">@@ -1548,31 +1548,23 @@</span> <span class="p_context"> static inline struct vmpacket_descriptor *</span>
 get_next_pkt_raw(struct vmbus_channel *channel)
 {
 	struct hv_ring_buffer_info *ring_info = &amp;channel-&gt;inbound;
<span class="p_del">-	u32 read_loc = ring_info-&gt;priv_read_index;</span>
<span class="p_add">+	u32 priv_read_loc = ring_info-&gt;priv_read_index;</span>
 	void *ring_buffer = hv_get_ring_buffer(ring_info);
<span class="p_del">-	struct vmpacket_descriptor *cur_desc;</span>
<span class="p_del">-	u32 packetlen;</span>
 	u32 dsize = ring_info-&gt;ring_datasize;
<span class="p_del">-	u32 delta = read_loc - ring_info-&gt;ring_buffer-&gt;read_index;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * delta is the difference between what is available to read and</span>
<span class="p_add">+	 * what was already consumed in place. We commit read index after</span>
<span class="p_add">+	 * the whole batch is processed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	u32 delta = priv_read_loc &gt;= ring_info-&gt;ring_buffer-&gt;read_index ?</span>
<span class="p_add">+		priv_read_loc - ring_info-&gt;ring_buffer-&gt;read_index :</span>
<span class="p_add">+		(dsize - ring_info-&gt;ring_buffer-&gt;read_index) + priv_read_loc;</span>
 	u32 bytes_avail_toread = (hv_get_bytes_to_read(ring_info) - delta);
 
 	if (bytes_avail_toread &lt; sizeof(struct vmpacket_descriptor))
 		return NULL;
 
<span class="p_del">-	if ((read_loc + sizeof(*cur_desc)) &gt; dsize)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	cur_desc = ring_buffer + read_loc;</span>
<span class="p_del">-	packetlen = cur_desc-&gt;len8 &lt;&lt; 3;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the packet under consideration is wrapping around,</span>
<span class="p_del">-	 * return failure.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if ((read_loc + packetlen + VMBUS_PKT_TRAILER) &gt; (dsize - 1))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	return cur_desc;</span>
<span class="p_add">+	return ring_buffer + priv_read_loc;</span>
 }
 
 /*
<span class="p_chunk">@@ -1584,16 +1576,14 @@</span> <span class="p_context"> static inline void put_pkt_raw(struct vmbus_channel *channel,</span>
 				struct vmpacket_descriptor *desc)
 {
 	struct hv_ring_buffer_info *ring_info = &amp;channel-&gt;inbound;
<span class="p_del">-	u32 read_loc = ring_info-&gt;priv_read_index;</span>
 	u32 packetlen = desc-&gt;len8 &lt;&lt; 3;
 	u32 dsize = ring_info-&gt;ring_datasize;
 
<span class="p_del">-	if ((read_loc + packetlen + VMBUS_PKT_TRAILER) &gt; dsize)</span>
<span class="p_del">-		BUG();</span>
 	/*
 	 * Include the packet trailer.
 	 */
 	ring_info-&gt;priv_read_index += packetlen + VMBUS_PKT_TRAILER;
<span class="p_add">+	ring_info-&gt;priv_read_index %= dsize;</span>
 }
 
 /*
<span class="p_header">diff --git a/include/uapi/linux/packet_diag.h b/include/uapi/linux/packet_diag.h</span>
<span class="p_header">index d08c63f3dd6f..0c5d5dd61b6a 100644</span>
<span class="p_header">--- a/include/uapi/linux/packet_diag.h</span>
<span class="p_header">+++ b/include/uapi/linux/packet_diag.h</span>
<span class="p_chunk">@@ -64,7 +64,7 @@</span> <span class="p_context"> struct packet_diag_mclist {</span>
 	__u32	pdmc_count;
 	__u16	pdmc_type;
 	__u16	pdmc_alen;
<span class="p_del">-	__u8	pdmc_addr[MAX_ADDR_LEN];</span>
<span class="p_add">+	__u8	pdmc_addr[32]; /* MAX_ADDR_LEN */</span>
 };
 
 struct packet_diag_ring {
<span class="p_header">diff --git a/kernel/bpf/verifier.c b/kernel/bpf/verifier.c</span>
<span class="p_header">index 8199821f54cf..85d1c9423ccb 100644</span>
<span class="p_header">--- a/kernel/bpf/verifier.c</span>
<span class="p_header">+++ b/kernel/bpf/verifier.c</span>
<span class="p_chunk">@@ -212,9 +212,10 @@</span> <span class="p_context"> static void print_verifier_state(struct bpf_verifier_state *state)</span>
 		else if (t == CONST_PTR_TO_MAP || t == PTR_TO_MAP_VALUE ||
 			 t == PTR_TO_MAP_VALUE_OR_NULL ||
 			 t == PTR_TO_MAP_VALUE_ADJ)
<span class="p_del">-			verbose(&quot;(ks=%d,vs=%d)&quot;,</span>
<span class="p_add">+			verbose(&quot;(ks=%d,vs=%d,id=%u)&quot;,</span>
 				reg-&gt;map_ptr-&gt;key_size,
<span class="p_del">-				reg-&gt;map_ptr-&gt;value_size);</span>
<span class="p_add">+				reg-&gt;map_ptr-&gt;value_size,</span>
<span class="p_add">+				reg-&gt;id);</span>
 		if (reg-&gt;min_value != BPF_REGISTER_MIN_RANGE)
 			verbose(&quot;,min_value=%lld&quot;,
 				(long long)reg-&gt;min_value);
<span class="p_chunk">@@ -443,13 +444,19 @@</span> <span class="p_context"> static void init_reg_state(struct bpf_reg_state *regs)</span>
 	regs[BPF_REG_1].type = PTR_TO_CTX;
 }
 
<span class="p_del">-static void mark_reg_unknown_value(struct bpf_reg_state *regs, u32 regno)</span>
<span class="p_add">+static void __mark_reg_unknown_value(struct bpf_reg_state *regs, u32 regno)</span>
 {
<span class="p_del">-	BUG_ON(regno &gt;= MAX_BPF_REG);</span>
 	regs[regno].type = UNKNOWN_VALUE;
<span class="p_add">+	regs[regno].id = 0;</span>
 	regs[regno].imm = 0;
 }
 
<span class="p_add">+static void mark_reg_unknown_value(struct bpf_reg_state *regs, u32 regno)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(regno &gt;= MAX_BPF_REG);</span>
<span class="p_add">+	__mark_reg_unknown_value(regs, regno);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void reset_reg_range_values(struct bpf_reg_state *regs, u32 regno)
 {
 	regs[regno].min_value = BPF_REGISTER_MIN_RANGE;
<span class="p_chunk">@@ -1252,6 +1259,7 @@</span> <span class="p_context"> static int check_call(struct bpf_verifier_env *env, int func_id)</span>
 			return -EINVAL;
 		}
 		regs[BPF_REG_0].map_ptr = meta.map_ptr;
<span class="p_add">+		regs[BPF_REG_0].id = ++env-&gt;id_gen;</span>
 	} else {
 		verbose(&quot;unknown return type %d of func %d\n&quot;,
 			fn-&gt;ret_type, func_id);
<span class="p_chunk">@@ -1668,8 +1676,7 @@</span> <span class="p_context"> static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)</span>
 						insn-&gt;src_reg);
 					return -EACCES;
 				}
<span class="p_del">-				regs[insn-&gt;dst_reg].type = UNKNOWN_VALUE;</span>
<span class="p_del">-				regs[insn-&gt;dst_reg].map_ptr = NULL;</span>
<span class="p_add">+				mark_reg_unknown_value(regs, insn-&gt;dst_reg);</span>
 			}
 		} else {
 			/* case: R = imm
<span class="p_chunk">@@ -1931,6 +1938,43 @@</span> <span class="p_context"> static void reg_set_min_max_inv(struct bpf_reg_state *true_reg,</span>
 	check_reg_overflow(true_reg);
 }
 
<span class="p_add">+static void mark_map_reg(struct bpf_reg_state *regs, u32 regno, u32 id,</span>
<span class="p_add">+			 enum bpf_reg_type type)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct bpf_reg_state *reg = &amp;regs[regno];</span>
<span class="p_add">+</span>
<span class="p_add">+	if (reg-&gt;type == PTR_TO_MAP_VALUE_OR_NULL &amp;&amp; reg-&gt;id == id) {</span>
<span class="p_add">+		reg-&gt;type = type;</span>
<span class="p_add">+		/* We don&#39;t need id from this point onwards anymore, thus we</span>
<span class="p_add">+		 * should better reset it, so that state pruning has chances</span>
<span class="p_add">+		 * to take effect.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		reg-&gt;id = 0;</span>
<span class="p_add">+		if (type == UNKNOWN_VALUE)</span>
<span class="p_add">+			__mark_reg_unknown_value(regs, regno);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* The logic is similar to find_good_pkt_pointers(), both could eventually</span>
<span class="p_add">+ * be folded together at some point.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void mark_map_regs(struct bpf_verifier_state *state, u32 regno,</span>
<span class="p_add">+			  enum bpf_reg_type type)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct bpf_reg_state *regs = state-&gt;regs;</span>
<span class="p_add">+	u32 id = regs[regno].id;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; MAX_BPF_REG; i++)</span>
<span class="p_add">+		mark_map_reg(regs, i, id, type);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; MAX_BPF_STACK; i += BPF_REG_SIZE) {</span>
<span class="p_add">+		if (state-&gt;stack_slot_type[i] != STACK_SPILL)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		mark_map_reg(state-&gt;spilled_regs, i / BPF_REG_SIZE, id, type);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int check_cond_jmp_op(struct bpf_verifier_env *env,
 			     struct bpf_insn *insn, int *insn_idx)
 {
<span class="p_chunk">@@ -2018,18 +2062,13 @@</span> <span class="p_context"> static int check_cond_jmp_op(struct bpf_verifier_env *env,</span>
 	if (BPF_SRC(insn-&gt;code) == BPF_K &amp;&amp;
 	    insn-&gt;imm == 0 &amp;&amp; (opcode == BPF_JEQ || opcode == BPF_JNE) &amp;&amp;
 	    dst_reg-&gt;type == PTR_TO_MAP_VALUE_OR_NULL) {
<span class="p_del">-		if (opcode == BPF_JEQ) {</span>
<span class="p_del">-			/* next fallthrough insn can access memory via</span>
<span class="p_del">-			 * this register</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			regs[insn-&gt;dst_reg].type = PTR_TO_MAP_VALUE;</span>
<span class="p_del">-			/* branch targer cannot access it, since reg == 0 */</span>
<span class="p_del">-			mark_reg_unknown_value(other_branch-&gt;regs,</span>
<span class="p_del">-					       insn-&gt;dst_reg);</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			other_branch-&gt;regs[insn-&gt;dst_reg].type = PTR_TO_MAP_VALUE;</span>
<span class="p_del">-			mark_reg_unknown_value(regs, insn-&gt;dst_reg);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		/* Mark all identical map registers in each branch as either</span>
<span class="p_add">+		 * safe or unknown depending R == 0 or R != 0 conditional.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		mark_map_regs(this_branch, insn-&gt;dst_reg,</span>
<span class="p_add">+			      opcode == BPF_JEQ ? PTR_TO_MAP_VALUE : UNKNOWN_VALUE);</span>
<span class="p_add">+		mark_map_regs(other_branch, insn-&gt;dst_reg,</span>
<span class="p_add">+			      opcode == BPF_JEQ ? UNKNOWN_VALUE : PTR_TO_MAP_VALUE);</span>
 	} else if (BPF_SRC(insn-&gt;code) == BPF_X &amp;&amp; opcode == BPF_JGT &amp;&amp;
 		   dst_reg-&gt;type == PTR_TO_PACKET &amp;&amp;
 		   regs[insn-&gt;src_reg].type == PTR_TO_PACKET_END) {
<span class="p_chunk">@@ -2469,7 +2508,7 @@</span> <span class="p_context"> static bool states_equal(struct bpf_verifier_env *env,</span>
 		 * we didn&#39;t do a variable access into a map then we are a-ok.
 		 */
 		if (!varlen_map_access &amp;&amp;
<span class="p_del">-		    rold-&gt;type == rcur-&gt;type &amp;&amp; rold-&gt;imm == rcur-&gt;imm)</span>
<span class="p_add">+		    memcmp(rold, rcur, offsetofend(struct bpf_reg_state, id)) == 0)</span>
 			continue;
 
 		/* If we didn&#39;t map access then again we don&#39;t care about the
<span class="p_header">diff --git a/kernel/futex.c b/kernel/futex.c</span>
<span class="p_header">index 38b68c2735c5..4c6b6e697b73 100644</span>
<span class="p_header">--- a/kernel/futex.c</span>
<span class="p_header">+++ b/kernel/futex.c</span>
<span class="p_chunk">@@ -2813,7 +2813,6 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 {
 	struct hrtimer_sleeper timeout, *to = NULL;
 	struct rt_mutex_waiter rt_waiter;
<span class="p_del">-	struct rt_mutex *pi_mutex = NULL;</span>
 	struct futex_hash_bucket *hb;
 	union futex_key key2 = FUTEX_KEY_INIT;
 	struct futex_q q = futex_q_init;
<span class="p_chunk">@@ -2897,6 +2896,8 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 		if (q.pi_state &amp;&amp; (q.pi_state-&gt;owner != current)) {
 			spin_lock(q.lock_ptr);
 			ret = fixup_pi_state_owner(uaddr2, &amp;q, current);
<span class="p_add">+			if (ret &amp;&amp; rt_mutex_owner(&amp;q.pi_state-&gt;pi_mutex) == current)</span>
<span class="p_add">+				rt_mutex_unlock(&amp;q.pi_state-&gt;pi_mutex);</span>
 			/*
 			 * Drop the reference to the pi state which
 			 * the requeue_pi() code acquired for us.
<span class="p_chunk">@@ -2905,6 +2906,8 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 			spin_unlock(q.lock_ptr);
 		}
 	} else {
<span class="p_add">+		struct rt_mutex *pi_mutex;</span>
<span class="p_add">+</span>
 		/*
 		 * We have been woken up by futex_unlock_pi(), a timeout, or a
 		 * signal.  futex_unlock_pi() will not destroy the lock_ptr nor
<span class="p_chunk">@@ -2928,18 +2931,19 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 		if (res)
 			ret = (res &lt; 0) ? res : 0;
 
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If fixup_pi_state_owner() faulted and was unable to handle</span>
<span class="p_add">+		 * the fault, unlock the rt_mutex and return the fault to</span>
<span class="p_add">+		 * userspace.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (ret &amp;&amp; rt_mutex_owner(pi_mutex) == current)</span>
<span class="p_add">+			rt_mutex_unlock(pi_mutex);</span>
<span class="p_add">+</span>
 		/* Unqueue and drop the lock. */
 		unqueue_me_pi(&amp;q);
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If fixup_pi_state_owner() faulted and was unable to handle the</span>
<span class="p_del">-	 * fault, unlock the rt_mutex and return the fault to userspace.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (ret == -EFAULT) {</span>
<span class="p_del">-		if (pi_mutex &amp;&amp; rt_mutex_owner(pi_mutex) == current)</span>
<span class="p_del">-			rt_mutex_unlock(pi_mutex);</span>
<span class="p_del">-	} else if (ret == -EINTR) {</span>
<span class="p_add">+	if (ret == -EINTR) {</span>
 		/*
 		 * We&#39;ve already been requeued, but cannot restart by calling
 		 * futex_lock_pi() directly. We could restart this syscall, but
<span class="p_header">diff --git a/kernel/locking/rwsem-spinlock.c b/kernel/locking/rwsem-spinlock.c</span>
<span class="p_header">index 1591f6b3539f..2bef4ab94003 100644</span>
<span class="p_header">--- a/kernel/locking/rwsem-spinlock.c</span>
<span class="p_header">+++ b/kernel/locking/rwsem-spinlock.c</span>
<span class="p_chunk">@@ -216,10 +216,8 @@</span> <span class="p_context"> int __sched __down_write_common(struct rw_semaphore *sem, int state)</span>
 		 */
 		if (sem-&gt;count == 0)
 			break;
<span class="p_del">-		if (signal_pending_state(state, current)) {</span>
<span class="p_del">-			ret = -EINTR;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (signal_pending_state(state, current))</span>
<span class="p_add">+			goto out_nolock;</span>
 		set_task_state(tsk, state);
 		raw_spin_unlock_irqrestore(&amp;sem-&gt;wait_lock, flags);
 		schedule();
<span class="p_chunk">@@ -227,12 +225,19 @@</span> <span class="p_context"> int __sched __down_write_common(struct rw_semaphore *sem, int state)</span>
 	}
 	/* got the lock */
 	sem-&gt;count = -1;
<span class="p_del">-out:</span>
 	list_del(&amp;waiter.list);
 
 	raw_spin_unlock_irqrestore(&amp;sem-&gt;wait_lock, flags);
 
 	return ret;
<span class="p_add">+</span>
<span class="p_add">+out_nolock:</span>
<span class="p_add">+	list_del(&amp;waiter.list);</span>
<span class="p_add">+	if (!list_empty(&amp;sem-&gt;wait_list))</span>
<span class="p_add">+		__rwsem_do_wake(sem, 1);</span>
<span class="p_add">+	raw_spin_unlock_irqrestore(&amp;sem-&gt;wait_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	return -EINTR;</span>
 }
 
 void __sched __down_write(struct rw_semaphore *sem)
<span class="p_header">diff --git a/mm/slab.c b/mm/slab.c</span>
<span class="p_header">index bd878f051a3b..1f82d16a0518 100644</span>
<span class="p_header">--- a/mm/slab.c</span>
<span class="p_header">+++ b/mm/slab.c</span>
<span class="p_chunk">@@ -2332,7 +2332,7 @@</span> <span class="p_context"> static int drain_freelist(struct kmem_cache *cache,</span>
 	return nr_freed;
 }
 
<span class="p_del">-int __kmem_cache_shrink(struct kmem_cache *cachep, bool deactivate)</span>
<span class="p_add">+int __kmem_cache_shrink(struct kmem_cache *cachep)</span>
 {
 	int ret = 0;
 	int node;
<span class="p_chunk">@@ -2352,7 +2352,7 @@</span> <span class="p_context"> int __kmem_cache_shrink(struct kmem_cache *cachep, bool deactivate)</span>
 
 int __kmem_cache_shutdown(struct kmem_cache *cachep)
 {
<span class="p_del">-	return __kmem_cache_shrink(cachep, false);</span>
<span class="p_add">+	return __kmem_cache_shrink(cachep);</span>
 }
 
 void __kmem_cache_release(struct kmem_cache *cachep)
<span class="p_header">diff --git a/mm/slab.h b/mm/slab.h</span>
<span class="p_header">index bc05fdc3edce..ceb7d70cdb76 100644</span>
<span class="p_header">--- a/mm/slab.h</span>
<span class="p_header">+++ b/mm/slab.h</span>
<span class="p_chunk">@@ -146,7 +146,7 @@</span> <span class="p_context"> static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
 
 int __kmem_cache_shutdown(struct kmem_cache *);
 void __kmem_cache_release(struct kmem_cache *);
<span class="p_del">-int __kmem_cache_shrink(struct kmem_cache *, bool);</span>
<span class="p_add">+int __kmem_cache_shrink(struct kmem_cache *);</span>
 void slab_kmem_cache_release(struct kmem_cache *);
 
 struct seq_file;
<span class="p_header">diff --git a/mm/slab_common.c b/mm/slab_common.c</span>
<span class="p_header">index 329b03843863..5d2f24fbafc5 100644</span>
<span class="p_header">--- a/mm/slab_common.c</span>
<span class="p_header">+++ b/mm/slab_common.c</span>
<span class="p_chunk">@@ -573,6 +573,29 @@</span> <span class="p_context"> void memcg_deactivate_kmem_caches(struct mem_cgroup *memcg)</span>
 	get_online_cpus();
 	get_online_mems();
 
<span class="p_add">+#ifdef CONFIG_SLUB</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * In case of SLUB, we need to disable empty slab caching to</span>
<span class="p_add">+	 * avoid pinning the offline memory cgroup by freeable kmem</span>
<span class="p_add">+	 * pages charged to it. SLAB doesn&#39;t need this, as it</span>
<span class="p_add">+	 * periodically purges unused slabs.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mutex_lock(&amp;slab_mutex);</span>
<span class="p_add">+	list_for_each_entry(s, &amp;slab_caches, list) {</span>
<span class="p_add">+		c = is_root_cache(s) ? cache_from_memcg_idx(s, idx) : NULL;</span>
<span class="p_add">+		if (c) {</span>
<span class="p_add">+			c-&gt;cpu_partial = 0;</span>
<span class="p_add">+			c-&gt;min_partial = 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	mutex_unlock(&amp;slab_mutex);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * kmem_cache-&gt;cpu_partial is checked locklessly (see</span>
<span class="p_add">+	 * put_cpu_partial()). Make sure the change is visible.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	synchronize_sched();</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	mutex_lock(&amp;slab_mutex);
 	list_for_each_entry(s, &amp;slab_caches, list) {
 		if (!is_root_cache(s))
<span class="p_chunk">@@ -584,7 +607,7 @@</span> <span class="p_context"> void memcg_deactivate_kmem_caches(struct mem_cgroup *memcg)</span>
 		if (!c)
 			continue;
 
<span class="p_del">-		__kmem_cache_shrink(c, true);</span>
<span class="p_add">+		__kmem_cache_shrink(c);</span>
 		arr-&gt;entries[idx] = NULL;
 	}
 	mutex_unlock(&amp;slab_mutex);
<span class="p_chunk">@@ -755,7 +778,7 @@</span> <span class="p_context"> int kmem_cache_shrink(struct kmem_cache *cachep)</span>
 	get_online_cpus();
 	get_online_mems();
 	kasan_cache_shrink(cachep);
<span class="p_del">-	ret = __kmem_cache_shrink(cachep, false);</span>
<span class="p_add">+	ret = __kmem_cache_shrink(cachep);</span>
 	put_online_mems();
 	put_online_cpus();
 	return ret;
<span class="p_header">diff --git a/mm/slob.c b/mm/slob.c</span>
<span class="p_header">index 5ec158054ffe..eac04d4357ec 100644</span>
<span class="p_header">--- a/mm/slob.c</span>
<span class="p_header">+++ b/mm/slob.c</span>
<span class="p_chunk">@@ -634,7 +634,7 @@</span> <span class="p_context"> void __kmem_cache_release(struct kmem_cache *c)</span>
 {
 }
 
<span class="p_del">-int __kmem_cache_shrink(struct kmem_cache *d, bool deactivate)</span>
<span class="p_add">+int __kmem_cache_shrink(struct kmem_cache *d)</span>
 {
 	return 0;
 }
<span class="p_header">diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="p_header">index 7aa0e97af928..58c7526f8de2 100644</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -3887,7 +3887,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(kfree);</span>
  * being allocated from last increasing the chance that the last objects
  * are freed in them.
  */
<span class="p_del">-int __kmem_cache_shrink(struct kmem_cache *s, bool deactivate)</span>
<span class="p_add">+int __kmem_cache_shrink(struct kmem_cache *s)</span>
 {
 	int node;
 	int i;
<span class="p_chunk">@@ -3899,21 +3899,6 @@</span> <span class="p_context"> int __kmem_cache_shrink(struct kmem_cache *s, bool deactivate)</span>
 	unsigned long flags;
 	int ret = 0;
 
<span class="p_del">-	if (deactivate) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Disable empty slabs caching. Used to avoid pinning offline</span>
<span class="p_del">-		 * memory cgroups by kmem pages that can be freed.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		s-&gt;cpu_partial = 0;</span>
<span class="p_del">-		s-&gt;min_partial = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * s-&gt;cpu_partial is checked locklessly (see put_cpu_partial),</span>
<span class="p_del">-		 * so we have to make sure the change is visible.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		synchronize_sched();</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	flush_all(s);
 	for_each_kmem_cache_node(s, node, n) {
 		INIT_LIST_HEAD(&amp;discard);
<span class="p_chunk">@@ -3970,7 +3955,7 @@</span> <span class="p_context"> static int slab_mem_going_offline_callback(void *arg)</span>
 
 	mutex_lock(&amp;slab_mutex);
 	list_for_each_entry(s, &amp;slab_caches, list)
<span class="p_del">-		__kmem_cache_shrink(s, false);</span>
<span class="p_add">+		__kmem_cache_shrink(s);</span>
 	mutex_unlock(&amp;slab_mutex);
 
 	return 0;
<span class="p_header">diff --git a/net/bridge/br_forward.c b/net/bridge/br_forward.c</span>
<span class="p_header">index 7cb41aee4c82..8498e3503605 100644</span>
<span class="p_header">--- a/net/bridge/br_forward.c</span>
<span class="p_header">+++ b/net/bridge/br_forward.c</span>
<span class="p_chunk">@@ -186,8 +186,9 @@</span> <span class="p_context"> void br_flood(struct net_bridge *br, struct sk_buff *skb,</span>
 		/* Do not flood unicast traffic to ports that turn it off */
 		if (pkt_type == BR_PKT_UNICAST &amp;&amp; !(p-&gt;flags &amp; BR_FLOOD))
 			continue;
<span class="p_add">+		/* Do not flood if mc off, except for traffic we originate */</span>
 		if (pkt_type == BR_PKT_MULTICAST &amp;&amp;
<span class="p_del">-		    !(p-&gt;flags &amp; BR_MCAST_FLOOD))</span>
<span class="p_add">+		    !(p-&gt;flags &amp; BR_MCAST_FLOOD) &amp;&amp; skb-&gt;dev != br-&gt;dev)</span>
 			continue;
 
 		/* Do not flood to ports that enable proxy ARP */
<span class="p_header">diff --git a/net/bridge/br_input.c b/net/bridge/br_input.c</span>
<span class="p_header">index 855b72fbe1da..267b46af407f 100644</span>
<span class="p_header">--- a/net/bridge/br_input.c</span>
<span class="p_header">+++ b/net/bridge/br_input.c</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(br_should_route_hook);</span>
 static int
 br_netif_receive_skb(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
<span class="p_add">+	br_drop_fake_rtable(skb);</span>
 	return netif_receive_skb(skb);
 }
 
<span class="p_header">diff --git a/net/bridge/br_netfilter_hooks.c b/net/bridge/br_netfilter_hooks.c</span>
<span class="p_header">index 7fbdbae58e65..aa1df1a10dd7 100644</span>
<span class="p_header">--- a/net/bridge/br_netfilter_hooks.c</span>
<span class="p_header">+++ b/net/bridge/br_netfilter_hooks.c</span>
<span class="p_chunk">@@ -521,21 +521,6 @@</span> <span class="p_context"> static unsigned int br_nf_pre_routing(void *priv,</span>
 }
 
 
<span class="p_del">-/* PF_BRIDGE/LOCAL_IN ************************************************/</span>
<span class="p_del">-/* The packet is locally destined, which requires a real</span>
<span class="p_del">- * dst_entry, so detach the fake one.  On the way up, the</span>
<span class="p_del">- * packet would pass through PRE_ROUTING again (which already</span>
<span class="p_del">- * took place when the packet entered the bridge), but we</span>
<span class="p_del">- * register an IPv4 PRE_ROUTING &#39;sabotage&#39; hook that will</span>
<span class="p_del">- * prevent this from happening. */</span>
<span class="p_del">-static unsigned int br_nf_local_in(void *priv,</span>
<span class="p_del">-				   struct sk_buff *skb,</span>
<span class="p_del">-				   const struct nf_hook_state *state)</span>
<span class="p_del">-{</span>
<span class="p_del">-	br_drop_fake_rtable(skb);</span>
<span class="p_del">-	return NF_ACCEPT;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /* PF_BRIDGE/FORWARD *************************************************/
 static int br_nf_forward_finish(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
<span class="p_chunk">@@ -906,12 +891,6 @@</span> <span class="p_context"> static struct nf_hook_ops br_nf_ops[] __read_mostly = {</span>
 		.priority = NF_BR_PRI_BRNF,
 	},
 	{
<span class="p_del">-		.hook = br_nf_local_in,</span>
<span class="p_del">-		.pf = NFPROTO_BRIDGE,</span>
<span class="p_del">-		.hooknum = NF_BR_LOCAL_IN,</span>
<span class="p_del">-		.priority = NF_BR_PRI_BRNF,</span>
<span class="p_del">-	},</span>
<span class="p_del">-	{</span>
 		.hook = br_nf_forward_ip,
 		.pf = NFPROTO_BRIDGE,
 		.hooknum = NF_BR_FORWARD,
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index 60b0a6049e72..2e04fd188081 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -1697,27 +1697,54 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(net_dec_egress_queue);</span>
 static struct static_key netstamp_needed __read_mostly;
 #ifdef HAVE_JUMP_LABEL
 static atomic_t netstamp_needed_deferred;
<span class="p_add">+static atomic_t netstamp_wanted;</span>
 static void netstamp_clear(struct work_struct *work)
 {
 	int deferred = atomic_xchg(&amp;netstamp_needed_deferred, 0);
<span class="p_add">+	int wanted;</span>
 
<span class="p_del">-	while (deferred--)</span>
<span class="p_del">-		static_key_slow_dec(&amp;netstamp_needed);</span>
<span class="p_add">+	wanted = atomic_add_return(deferred, &amp;netstamp_wanted);</span>
<span class="p_add">+	if (wanted &gt; 0)</span>
<span class="p_add">+		static_key_enable(&amp;netstamp_needed);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		static_key_disable(&amp;netstamp_needed);</span>
 }
 static DECLARE_WORK(netstamp_work, netstamp_clear);
 #endif
 
 void net_enable_timestamp(void)
 {
<span class="p_add">+#ifdef HAVE_JUMP_LABEL</span>
<span class="p_add">+	int wanted;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (1) {</span>
<span class="p_add">+		wanted = atomic_read(&amp;netstamp_wanted);</span>
<span class="p_add">+		if (wanted &lt;= 0)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		if (atomic_cmpxchg(&amp;netstamp_wanted, wanted, wanted + 1) == wanted)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	atomic_inc(&amp;netstamp_needed_deferred);</span>
<span class="p_add">+	schedule_work(&amp;netstamp_work);</span>
<span class="p_add">+#else</span>
 	static_key_slow_inc(&amp;netstamp_needed);
<span class="p_add">+#endif</span>
 }
 EXPORT_SYMBOL(net_enable_timestamp);
 
 void net_disable_timestamp(void)
 {
 #ifdef HAVE_JUMP_LABEL
<span class="p_del">-	/* net_disable_timestamp() can be called from non process context */</span>
<span class="p_del">-	atomic_inc(&amp;netstamp_needed_deferred);</span>
<span class="p_add">+	int wanted;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (1) {</span>
<span class="p_add">+		wanted = atomic_read(&amp;netstamp_wanted);</span>
<span class="p_add">+		if (wanted &lt;= 1)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		if (atomic_cmpxchg(&amp;netstamp_wanted, wanted, wanted - 1) == wanted)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	atomic_dec(&amp;netstamp_needed_deferred);</span>
 	schedule_work(&amp;netstamp_work);
 #else
 	static_key_slow_dec(&amp;netstamp_needed);
<span class="p_header">diff --git a/net/core/skbuff.c b/net/core/skbuff.c</span>
<span class="p_header">index 1e3e0087245b..f0f462c0573d 100644</span>
<span class="p_header">--- a/net/core/skbuff.c</span>
<span class="p_header">+++ b/net/core/skbuff.c</span>
<span class="p_chunk">@@ -3814,13 +3814,14 @@</span> <span class="p_context"> void skb_complete_tx_timestamp(struct sk_buff *skb,</span>
 	if (!skb_may_tx_timestamp(sk, false))
 		return;
 
<span class="p_del">-	/* take a reference to prevent skb_orphan() from freeing the socket */</span>
<span class="p_del">-	sock_hold(sk);</span>
<span class="p_del">-</span>
<span class="p_del">-	*skb_hwtstamps(skb) = *hwtstamps;</span>
<span class="p_del">-	__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);</span>
<span class="p_del">-</span>
<span class="p_del">-	sock_put(sk);</span>
<span class="p_add">+	/* Take a reference to prevent skb_orphan() from freeing the socket,</span>
<span class="p_add">+	 * but only if the socket refcount is not zero.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (likely(atomic_inc_not_zero(&amp;sk-&gt;sk_refcnt))) {</span>
<span class="p_add">+		*skb_hwtstamps(skb) = *hwtstamps;</span>
<span class="p_add">+		__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);</span>
<span class="p_add">+		sock_put(sk);</span>
<span class="p_add">+	}</span>
 }
 EXPORT_SYMBOL_GPL(skb_complete_tx_timestamp);
 
<span class="p_chunk">@@ -3871,7 +3872,7 @@</span> <span class="p_context"> void skb_complete_wifi_ack(struct sk_buff *skb, bool acked)</span>
 {
 	struct sock *sk = skb-&gt;sk;
 	struct sock_exterr_skb *serr;
<span class="p_del">-	int err;</span>
<span class="p_add">+	int err = 1;</span>
 
 	skb-&gt;wifi_acked_valid = 1;
 	skb-&gt;wifi_acked = acked;
<span class="p_chunk">@@ -3881,14 +3882,15 @@</span> <span class="p_context"> void skb_complete_wifi_ack(struct sk_buff *skb, bool acked)</span>
 	serr-&gt;ee.ee_errno = ENOMSG;
 	serr-&gt;ee.ee_origin = SO_EE_ORIGIN_TXSTATUS;
 
<span class="p_del">-	/* take a reference to prevent skb_orphan() from freeing the socket */</span>
<span class="p_del">-	sock_hold(sk);</span>
<span class="p_del">-</span>
<span class="p_del">-	err = sock_queue_err_skb(sk, skb);</span>
<span class="p_add">+	/* Take a reference to prevent skb_orphan() from freeing the socket,</span>
<span class="p_add">+	 * but only if the socket refcount is not zero.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (likely(atomic_inc_not_zero(&amp;sk-&gt;sk_refcnt))) {</span>
<span class="p_add">+		err = sock_queue_err_skb(sk, skb);</span>
<span class="p_add">+		sock_put(sk);</span>
<span class="p_add">+	}</span>
 	if (err)
 		kfree_skb(skb);
<span class="p_del">-</span>
<span class="p_del">-	sock_put(sk);</span>
 }
 EXPORT_SYMBOL_GPL(skb_complete_wifi_ack);
 
<span class="p_header">diff --git a/net/dccp/ccids/ccid2.c b/net/dccp/ccids/ccid2.c</span>
<span class="p_header">index f053198e730c..5e3a7302f774 100644</span>
<span class="p_header">--- a/net/dccp/ccids/ccid2.c</span>
<span class="p_header">+++ b/net/dccp/ccids/ccid2.c</span>
<span class="p_chunk">@@ -749,6 +749,7 @@</span> <span class="p_context"> static void ccid2_hc_tx_exit(struct sock *sk)</span>
 	for (i = 0; i &lt; hc-&gt;tx_seqbufc; i++)
 		kfree(hc-&gt;tx_seqbuf[i]);
 	hc-&gt;tx_seqbufc = 0;
<span class="p_add">+	dccp_ackvec_parsed_cleanup(&amp;hc-&gt;tx_av_chunks);</span>
 }
 
 static void ccid2_hc_rx_packet_recv(struct sock *sk, struct sk_buff *skb)
<span class="p_header">diff --git a/net/dccp/input.c b/net/dccp/input.c</span>
<span class="p_header">index 8fedc2d49770..4a05d7876850 100644</span>
<span class="p_header">--- a/net/dccp/input.c</span>
<span class="p_header">+++ b/net/dccp/input.c</span>
<span class="p_chunk">@@ -577,6 +577,7 @@</span> <span class="p_context"> int dccp_rcv_state_process(struct sock *sk, struct sk_buff *skb,</span>
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
 	const int old_state = sk-&gt;sk_state;
<span class="p_add">+	bool acceptable;</span>
 	int queued = 0;
 
 	/*
<span class="p_chunk">@@ -603,8 +604,13 @@</span> <span class="p_context"> int dccp_rcv_state_process(struct sock *sk, struct sk_buff *skb,</span>
 	 */
 	if (sk-&gt;sk_state == DCCP_LISTEN) {
 		if (dh-&gt;dccph_type == DCCP_PKT_REQUEST) {
<span class="p_del">-			if (inet_csk(sk)-&gt;icsk_af_ops-&gt;conn_request(sk,</span>
<span class="p_del">-								    skb) &lt; 0)</span>
<span class="p_add">+			/* It is possible that we process SYN packets from backlog,</span>
<span class="p_add">+			 * so we need to make sure to disable BH right there.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			local_bh_disable();</span>
<span class="p_add">+			acceptable = inet_csk(sk)-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;</span>
<span class="p_add">+			local_bh_enable();</span>
<span class="p_add">+			if (!acceptable)</span>
 				return 1;
 			consume_skb(skb);
 			return 0;
<span class="p_header">diff --git a/net/dccp/ipv4.c b/net/dccp/ipv4.c</span>
<span class="p_header">index edbe59d203ef..86b0933ecd45 100644</span>
<span class="p_header">--- a/net/dccp/ipv4.c</span>
<span class="p_header">+++ b/net/dccp/ipv4.c</span>
<span class="p_chunk">@@ -289,7 +289,8 @@</span> <span class="p_context"> static void dccp_v4_err(struct sk_buff *skb, u32 info)</span>
 
 	switch (type) {
 	case ICMP_REDIRECT:
<span class="p_del">-		dccp_do_redirect(skb, sk);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk))</span>
<span class="p_add">+			dccp_do_redirect(skb, sk);</span>
 		goto out;
 	case ICMP_SOURCE_QUENCH:
 		/* Just silently ignore these. */
<span class="p_header">diff --git a/net/dccp/ipv6.c b/net/dccp/ipv6.c</span>
<span class="p_header">index 7506c03a7db9..237d62c493e3 100644</span>
<span class="p_header">--- a/net/dccp/ipv6.c</span>
<span class="p_header">+++ b/net/dccp/ipv6.c</span>
<span class="p_chunk">@@ -122,10 +122,12 @@</span> <span class="p_context"> static void dccp_v6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,</span>
 	np = inet6_sk(sk);
 
 	if (type == NDISC_REDIRECT) {
<span class="p_del">-		struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk)) {</span>
<span class="p_add">+			struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
 
<span class="p_del">-		if (dst)</span>
<span class="p_del">-			dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+			if (dst)</span>
<span class="p_add">+				dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+		}</span>
 		goto out;
 	}
 
<span class="p_header">diff --git a/net/dccp/minisocks.c b/net/dccp/minisocks.c</span>
<span class="p_header">index 53eddf99e4f6..39e7e2bca8db 100644</span>
<span class="p_header">--- a/net/dccp/minisocks.c</span>
<span class="p_header">+++ b/net/dccp/minisocks.c</span>
<span class="p_chunk">@@ -122,6 +122,7 @@</span> <span class="p_context"> struct sock *dccp_create_openreq_child(const struct sock *sk,</span>
 			/* It is still raw copy of parent, so invalidate
 			 * destructor and make plain sk_free() */
 			newsk-&gt;sk_destruct = NULL;
<span class="p_add">+			bh_unlock_sock(newsk);</span>
 			sk_free(newsk);
 			return NULL;
 		}
<span class="p_chunk">@@ -145,6 +146,13 @@</span> <span class="p_context"> struct sock *dccp_check_req(struct sock *sk, struct sk_buff *skb,</span>
 	struct dccp_request_sock *dreq = dccp_rsk(req);
 	bool own_req;
 
<span class="p_add">+	/* TCP/DCCP listeners became lockless.</span>
<span class="p_add">+	 * DCCP stores complex state in its request_sock, so we need</span>
<span class="p_add">+	 * a protection for them, now this code runs without being protected</span>
<span class="p_add">+	 * by the parent (listener) lock.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	spin_lock_bh(&amp;dreq-&gt;dreq_lock);</span>
<span class="p_add">+</span>
 	/* Check for retransmitted REQUEST */
 	if (dccp_hdr(skb)-&gt;dccph_type == DCCP_PKT_REQUEST) {
 
<span class="p_chunk">@@ -159,7 +167,7 @@</span> <span class="p_context"> struct sock *dccp_check_req(struct sock *sk, struct sk_buff *skb,</span>
 			inet_rtx_syn_ack(sk, req);
 		}
 		/* Network Duplicate, discard packet */
<span class="p_del">-		return NULL;</span>
<span class="p_add">+		goto out;</span>
 	}
 
 	DCCP_SKB_CB(skb)-&gt;dccpd_reset_code = DCCP_RESET_CODE_PACKET_ERROR;
<span class="p_chunk">@@ -185,20 +193,20 @@</span> <span class="p_context"> struct sock *dccp_check_req(struct sock *sk, struct sk_buff *skb,</span>
 
 	child = inet_csk(sk)-&gt;icsk_af_ops-&gt;syn_recv_sock(sk, skb, req, NULL,
 							 req, &amp;own_req);
<span class="p_del">-	if (!child)</span>
<span class="p_del">-		goto listen_overflow;</span>
<span class="p_del">-</span>
<span class="p_del">-	return inet_csk_complete_hashdance(sk, child, req, own_req);</span>
<span class="p_add">+	if (child) {</span>
<span class="p_add">+		child = inet_csk_complete_hashdance(sk, child, req, own_req);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-listen_overflow:</span>
<span class="p_del">-	dccp_pr_debug(&quot;listen_overflow!\n&quot;);</span>
 	DCCP_SKB_CB(skb)-&gt;dccpd_reset_code = DCCP_RESET_CODE_TOO_BUSY;
 drop:
 	if (dccp_hdr(skb)-&gt;dccph_type != DCCP_PKT_RESET)
 		req-&gt;rsk_ops-&gt;send_reset(sk, skb);
 
 	inet_csk_reqsk_queue_drop(sk, req);
<span class="p_del">-	return NULL;</span>
<span class="p_add">+out:</span>
<span class="p_add">+	spin_unlock_bh(&amp;dreq-&gt;dreq_lock);</span>
<span class="p_add">+	return child;</span>
 }
 
 EXPORT_SYMBOL_GPL(dccp_check_req);
<span class="p_chunk">@@ -249,6 +257,7 @@</span> <span class="p_context"> int dccp_reqsk_init(struct request_sock *req,</span>
 {
 	struct dccp_request_sock *dreq = dccp_rsk(req);
 
<span class="p_add">+	spin_lock_init(&amp;dreq-&gt;dreq_lock);</span>
 	inet_rsk(req)-&gt;ir_rmt_port = dccp_hdr(skb)-&gt;dccph_sport;
 	inet_rsk(req)-&gt;ir_num	   = ntohs(dccp_hdr(skb)-&gt;dccph_dport);
 	inet_rsk(req)-&gt;acked	   = 0;
<span class="p_header">diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c</span>
<span class="p_header">index 215143246e4b..971b9471d427 100644</span>
<span class="p_header">--- a/net/ipv4/af_inet.c</span>
<span class="p_header">+++ b/net/ipv4/af_inet.c</span>
<span class="p_chunk">@@ -1460,8 +1460,10 @@</span> <span class="p_context"> int inet_gro_complete(struct sk_buff *skb, int nhoff)</span>
 	int proto = iph-&gt;protocol;
 	int err = -ENOSYS;
 
<span class="p_del">-	if (skb-&gt;encapsulation)</span>
<span class="p_add">+	if (skb-&gt;encapsulation) {</span>
<span class="p_add">+		skb_set_inner_protocol(skb, cpu_to_be16(ETH_P_IP));</span>
 		skb_set_inner_network_header(skb, nhoff);
<span class="p_add">+	}</span>
 
 	csum_replace2(&amp;iph-&gt;check, iph-&gt;tot_len, newlen);
 	iph-&gt;tot_len = newlen;
<span class="p_header">diff --git a/net/ipv4/route.c b/net/ipv4/route.c</span>
<span class="p_header">index d851cae27dac..17e6fbf30448 100644</span>
<span class="p_header">--- a/net/ipv4/route.c</span>
<span class="p_header">+++ b/net/ipv4/route.c</span>
<span class="p_chunk">@@ -1968,6 +1968,7 @@</span> <span class="p_context"> int ip_route_input_noref(struct sk_buff *skb, __be32 daddr, __be32 saddr,</span>
 {
 	int res;
 
<span class="p_add">+	tos &amp;= IPTOS_RT_MASK;</span>
 	rcu_read_lock();
 
 	/* Multicast recognition logic is moved from route cache to here.
<span class="p_header">diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="p_header">index c71d49ce0c93..ce42ded59958 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_input.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_input.c</span>
<span class="p_chunk">@@ -5916,9 +5916,15 @@</span> <span class="p_context"> int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)</span>
 		if (th-&gt;syn) {
 			if (th-&gt;fin)
 				goto discard;
<span class="p_del">-			if (icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &lt; 0)</span>
<span class="p_del">-				return 1;</span>
<span class="p_add">+			/* It is possible that we process SYN packets from backlog,</span>
<span class="p_add">+			 * so we need to make sure to disable BH right there.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			local_bh_disable();</span>
<span class="p_add">+			acceptable = icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;</span>
<span class="p_add">+			local_bh_enable();</span>
 
<span class="p_add">+			if (!acceptable)</span>
<span class="p_add">+				return 1;</span>
 			consume_skb(skb);
 			return 0;
 		}
<span class="p_header">diff --git a/net/ipv4/tcp_ipv4.c b/net/ipv4/tcp_ipv4.c</span>
<span class="p_header">index 2259114c7242..6988566dc72f 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_ipv4.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_ipv4.c</span>
<span class="p_chunk">@@ -269,10 +269,13 @@</span> <span class="p_context"> EXPORT_SYMBOL(tcp_v4_connect);</span>
  */
 void tcp_v4_mtu_reduced(struct sock *sk)
 {
<span class="p_del">-	struct dst_entry *dst;</span>
 	struct inet_sock *inet = inet_sk(sk);
<span class="p_del">-	u32 mtu = tcp_sk(sk)-&gt;mtu_info;</span>
<span class="p_add">+	struct dst_entry *dst;</span>
<span class="p_add">+	u32 mtu;</span>
 
<span class="p_add">+	if ((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_LISTEN | TCPF_CLOSE))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	mtu = tcp_sk(sk)-&gt;mtu_info;</span>
 	dst = inet_csk_update_pmtu(sk, mtu);
 	if (!dst)
 		return;
<span class="p_chunk">@@ -418,7 +421,8 @@</span> <span class="p_context"> void tcp_v4_err(struct sk_buff *icmp_skb, u32 info)</span>
 
 	switch (type) {
 	case ICMP_REDIRECT:
<span class="p_del">-		do_redirect(icmp_skb, sk);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk))</span>
<span class="p_add">+			do_redirect(icmp_skb, sk);</span>
 		goto out;
 	case ICMP_SOURCE_QUENCH:
 		/* Just silently ignore these. */
<span class="p_header">diff --git a/net/ipv4/tcp_timer.c b/net/ipv4/tcp_timer.c</span>
<span class="p_header">index 3ea1cf804748..b1e65b3b4361 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_timer.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_timer.c</span>
<span class="p_chunk">@@ -249,7 +249,8 @@</span> <span class="p_context"> void tcp_delack_timer_handler(struct sock *sk)</span>
 
 	sk_mem_reclaim_partial(sk);
 
<span class="p_del">-	if (sk-&gt;sk_state == TCP_CLOSE || !(icsk-&gt;icsk_ack.pending &amp; ICSK_ACK_TIMER))</span>
<span class="p_add">+	if (((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_CLOSE | TCPF_LISTEN)) ||</span>
<span class="p_add">+	    !(icsk-&gt;icsk_ack.pending &amp; ICSK_ACK_TIMER))</span>
 		goto out;
 
 	if (time_after(icsk-&gt;icsk_ack.timeout, jiffies)) {
<span class="p_chunk">@@ -552,7 +553,8 @@</span> <span class="p_context"> void tcp_write_timer_handler(struct sock *sk)</span>
 	struct inet_connection_sock *icsk = inet_csk(sk);
 	int event;
 
<span class="p_del">-	if (sk-&gt;sk_state == TCP_CLOSE || !icsk-&gt;icsk_pending)</span>
<span class="p_add">+	if (((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_CLOSE | TCPF_LISTEN)) ||</span>
<span class="p_add">+	    !icsk-&gt;icsk_pending)</span>
 		goto out;
 
 	if (time_after(icsk-&gt;icsk_timeout, jiffies)) {
<span class="p_header">diff --git a/net/ipv6/ip6_fib.c b/net/ipv6/ip6_fib.c</span>
<span class="p_header">index ef5485204522..8c88a37392d0 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_fib.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_fib.c</span>
<span class="p_chunk">@@ -908,6 +908,8 @@</span> <span class="p_context"> static int fib6_add_rt2node(struct fib6_node *fn, struct rt6_info *rt,</span>
 			ins = &amp;rt-&gt;dst.rt6_next;
 			iter = *ins;
 			while (iter) {
<span class="p_add">+				if (iter-&gt;rt6i_metric &gt; rt-&gt;rt6i_metric)</span>
<span class="p_add">+					break;</span>
 				if (rt6_qualify_for_ecmp(iter)) {
 					*ins = iter-&gt;dst.rt6_next;
 					fib6_purge_rt(iter, fn, info-&gt;nl_net);
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index fc7b4017ba24..33b04ec2744a 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -294,8 +294,10 @@</span> <span class="p_context"> static int ipv6_gro_complete(struct sk_buff *skb, int nhoff)</span>
 	struct ipv6hdr *iph = (struct ipv6hdr *)(skb-&gt;data + nhoff);
 	int err = -ENOSYS;
 
<span class="p_del">-	if (skb-&gt;encapsulation)</span>
<span class="p_add">+	if (skb-&gt;encapsulation) {</span>
<span class="p_add">+		skb_set_inner_protocol(skb, cpu_to_be16(ETH_P_IPV6));</span>
 		skb_set_inner_network_header(skb, nhoff);
<span class="p_add">+	}</span>
 
 	iph-&gt;payload_len = htons(skb-&gt;len - nhoff - sizeof(*iph));
 
<span class="p_header">diff --git a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c</span>
<span class="p_header">index 9a87bfb2ec16..e27b8fdba5d2 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_output.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_output.c</span>
<span class="p_chunk">@@ -757,13 +757,14 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 	 *	Fragment the datagram.
 	 */
 
<span class="p_del">-	*prevhdr = NEXTHDR_FRAGMENT;</span>
 	troom = rt-&gt;dst.dev-&gt;needed_tailroom;
 
 	/*
 	 *	Keep copying data until we run out.
 	 */
 	while (left &gt; 0)	{
<span class="p_add">+		u8 *fragnexthdr_offset;</span>
<span class="p_add">+</span>
 		len = left;
 		/* IF: it doesn&#39;t fit, use &#39;mtu&#39; - the data space left */
 		if (len &gt; mtu)
<span class="p_chunk">@@ -808,6 +809,10 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 		 */
 		skb_copy_from_linear_data(skb, skb_network_header(frag), hlen);
 
<span class="p_add">+		fragnexthdr_offset = skb_network_header(frag);</span>
<span class="p_add">+		fragnexthdr_offset += prevhdr - skb_network_header(skb);</span>
<span class="p_add">+		*fragnexthdr_offset = NEXTHDR_FRAGMENT;</span>
<span class="p_add">+</span>
 		/*
 		 *	Build fragment header.
 		 */
<span class="p_header">diff --git a/net/ipv6/ip6_vti.c b/net/ipv6/ip6_vti.c</span>
<span class="p_header">index c299c1e2bbf0..66c2b4b41793 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_vti.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_vti.c</span>
<span class="p_chunk">@@ -691,6 +691,10 @@</span> <span class="p_context"> vti6_parm_to_user(struct ip6_tnl_parm2 *u, const struct __ip6_tnl_parm *p)</span>
 	u-&gt;link = p-&gt;link;
 	u-&gt;i_key = p-&gt;i_key;
 	u-&gt;o_key = p-&gt;o_key;
<span class="p_add">+	if (u-&gt;i_key)</span>
<span class="p_add">+		u-&gt;i_flags |= GRE_KEY;</span>
<span class="p_add">+	if (u-&gt;o_key)</span>
<span class="p_add">+		u-&gt;o_flags |= GRE_KEY;</span>
 	u-&gt;proto = p-&gt;proto;
 
 	memcpy(u-&gt;name, p-&gt;name, sizeof(u-&gt;name));
<span class="p_header">diff --git a/net/ipv6/netfilter/nf_conntrack_reasm.c b/net/ipv6/netfilter/nf_conntrack_reasm.c</span>
<span class="p_header">index 9948b5ce52da..986d4ca38832 100644</span>
<span class="p_header">--- a/net/ipv6/netfilter/nf_conntrack_reasm.c</span>
<span class="p_header">+++ b/net/ipv6/netfilter/nf_conntrack_reasm.c</span>
<span class="p_chunk">@@ -589,6 +589,7 @@</span> <span class="p_context"> int nf_ct_frag6_gather(struct net *net, struct sk_buff *skb, u32 user)</span>
 	hdr = ipv6_hdr(skb);
 	fhdr = (struct frag_hdr *)skb_transport_header(skb);
 
<span class="p_add">+	skb_orphan(skb);</span>
 	fq = fq_find(net, fhdr-&gt;identification, user, &amp;hdr-&gt;saddr, &amp;hdr-&gt;daddr,
 		     skb-&gt;dev ? skb-&gt;dev-&gt;ifindex : 0, ip6_frag_ecn(hdr));
 	if (fq == NULL) {
<span class="p_header">diff --git a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c</span>
<span class="p_header">index 667396536feb..b2e61a0e8d0a 100644</span>
<span class="p_header">--- a/net/ipv6/tcp_ipv6.c</span>
<span class="p_header">+++ b/net/ipv6/tcp_ipv6.c</span>
<span class="p_chunk">@@ -375,10 +375,12 @@</span> <span class="p_context"> static void tcp_v6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,</span>
 	np = inet6_sk(sk);
 
 	if (type == NDISC_REDIRECT) {
<span class="p_del">-		struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk)) {</span>
<span class="p_add">+			struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
 
<span class="p_del">-		if (dst)</span>
<span class="p_del">-			dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+			if (dst)</span>
<span class="p_add">+				dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+		}</span>
 		goto out;
 	}
 
<span class="p_header">diff --git a/net/l2tp/l2tp_ip.c b/net/l2tp/l2tp_ip.c</span>
<span class="p_header">index c0f0750639bd..ff750bb334fa 100644</span>
<span class="p_header">--- a/net/l2tp/l2tp_ip.c</span>
<span class="p_header">+++ b/net/l2tp/l2tp_ip.c</span>
<span class="p_chunk">@@ -388,7 +388,7 @@</span> <span class="p_context"> static int l2tp_ip_backlog_recv(struct sock *sk, struct sk_buff *skb)</span>
 drop:
 	IP_INC_STATS(sock_net(sk), IPSTATS_MIB_INDISCARDS);
 	kfree_skb(skb);
<span class="p_del">-	return -1;</span>
<span class="p_add">+	return 0;</span>
 }
 
 /* Userspace will call sendmsg() on the tunnel socket to send L2TP
<span class="p_header">diff --git a/net/mpls/af_mpls.c b/net/mpls/af_mpls.c</span>
<span class="p_header">index 5b77377e5a15..1309e2c34764 100644</span>
<span class="p_header">--- a/net/mpls/af_mpls.c</span>
<span class="p_header">+++ b/net/mpls/af_mpls.c</span>
<span class="p_chunk">@@ -956,7 +956,8 @@</span> <span class="p_context"> static void mpls_ifdown(struct net_device *dev, int event)</span>
 				/* fall through */
 			case NETDEV_CHANGE:
 				nh-&gt;nh_flags |= RTNH_F_LINKDOWN;
<span class="p_del">-				ACCESS_ONCE(rt-&gt;rt_nhn_alive) = rt-&gt;rt_nhn_alive - 1;</span>
<span class="p_add">+				if (event != NETDEV_UNREGISTER)</span>
<span class="p_add">+					ACCESS_ONCE(rt-&gt;rt_nhn_alive) = rt-&gt;rt_nhn_alive - 1;</span>
 				break;
 			}
 			if (event == NETDEV_UNREGISTER)
<span class="p_chunk">@@ -1696,6 +1697,7 @@</span> <span class="p_context"> static void mpls_net_exit(struct net *net)</span>
 	for (index = 0; index &lt; platform_labels; index++) {
 		struct mpls_route *rt = rtnl_dereference(platform_label[index]);
 		RCU_INIT_POINTER(platform_label[index], NULL);
<span class="p_add">+		mpls_notify_route(net, index, rt, NULL, NULL);</span>
 		mpls_rt_free(rt);
 	}
 	rtnl_unlock();
<span class="p_header">diff --git a/net/openvswitch/conntrack.c b/net/openvswitch/conntrack.c</span>
<span class="p_header">index eab210bb1ef0..48386bff8b4e 100644</span>
<span class="p_header">--- a/net/openvswitch/conntrack.c</span>
<span class="p_header">+++ b/net/openvswitch/conntrack.c</span>
<span class="p_chunk">@@ -367,7 +367,6 @@</span> <span class="p_context"> static int handle_fragments(struct net *net, struct sw_flow_key *key,</span>
 	} else if (key-&gt;eth.type == htons(ETH_P_IPV6)) {
 		enum ip6_defrag_users user = IP6_DEFRAG_CONNTRACK_IN + zone;
 
<span class="p_del">-		skb_orphan(skb);</span>
 		memset(IP6CB(skb), 0, sizeof(struct inet6_skb_parm));
 		err = nf_ct_frag6_gather(net, skb, user);
 		if (err) {
<span class="p_header">diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c</span>
<span class="p_header">index 34de326b4f09..f2b04a77258d 100644</span>
<span class="p_header">--- a/net/packet/af_packet.c</span>
<span class="p_header">+++ b/net/packet/af_packet.c</span>
<span class="p_chunk">@@ -3140,7 +3140,7 @@</span> <span class="p_context"> static int packet_bind_spkt(struct socket *sock, struct sockaddr *uaddr,</span>
 			    int addr_len)
 {
 	struct sock *sk = sock-&gt;sk;
<span class="p_del">-	char name[15];</span>
<span class="p_add">+	char name[sizeof(uaddr-&gt;sa_data) + 1];</span>
 
 	/*
 	 *	Check legality
<span class="p_chunk">@@ -3148,7 +3148,11 @@</span> <span class="p_context"> static int packet_bind_spkt(struct socket *sock, struct sockaddr *uaddr,</span>
 
 	if (addr_len != sizeof(struct sockaddr))
 		return -EINVAL;
<span class="p_del">-	strlcpy(name, uaddr-&gt;sa_data, sizeof(name));</span>
<span class="p_add">+	/* uaddr-&gt;sa_data comes from the userspace, it&#39;s not guaranteed to be</span>
<span class="p_add">+	 * zero-terminated.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memcpy(name, uaddr-&gt;sa_data, sizeof(uaddr-&gt;sa_data));</span>
<span class="p_add">+	name[sizeof(uaddr-&gt;sa_data)] = 0;</span>
 
 	return packet_do_bind(sk, name, 0, pkt_sk(sk)-&gt;num);
 }
<span class="p_header">diff --git a/net/sched/act_api.c b/net/sched/act_api.c</span>
<span class="p_header">index c6c2a93cc2a2..c651cfce9be6 100644</span>
<span class="p_header">--- a/net/sched/act_api.c</span>
<span class="p_header">+++ b/net/sched/act_api.c</span>
<span class="p_chunk">@@ -820,10 +820,8 @@</span> <span class="p_context"> static int tca_action_flush(struct net *net, struct nlattr *nla,</span>
 		goto out_module_put;
 
 	err = ops-&gt;walk(net, skb, &amp;dcb, RTM_DELACTION, ops);
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_add">+	if (err &lt;= 0)</span>
 		goto out_module_put;
<span class="p_del">-	if (err == 0)</span>
<span class="p_del">-		goto noflush_out;</span>
 
 	nla_nest_end(skb, nest);
 
<span class="p_chunk">@@ -840,7 +838,6 @@</span> <span class="p_context"> static int tca_action_flush(struct net *net, struct nlattr *nla,</span>
 out_module_put:
 	module_put(ops-&gt;owner);
 err_out:
<span class="p_del">-noflush_out:</span>
 	kfree_skb(skb);
 	return err;
 }
<span class="p_header">diff --git a/net/sched/act_connmark.c b/net/sched/act_connmark.c</span>
<span class="p_header">index eae07a2e774d..1191179c0341 100644</span>
<span class="p_header">--- a/net/sched/act_connmark.c</span>
<span class="p_header">+++ b/net/sched/act_connmark.c</span>
<span class="p_chunk">@@ -113,6 +113,9 @@</span> <span class="p_context"> static int tcf_connmark_init(struct net *net, struct nlattr *nla,</span>
 	if (ret &lt; 0)
 		return ret;
 
<span class="p_add">+	if (!tb[TCA_CONNMARK_PARMS])</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	parm = nla_data(tb[TCA_CONNMARK_PARMS]);
 
 	if (!tcf_hash_check(tn, parm-&gt;index, a, bind)) {
<span class="p_header">diff --git a/net/sched/act_skbmod.c b/net/sched/act_skbmod.c</span>
<span class="p_header">index e7d96381c908..f85313d60a4d 100644</span>
<span class="p_header">--- a/net/sched/act_skbmod.c</span>
<span class="p_header">+++ b/net/sched/act_skbmod.c</span>
<span class="p_chunk">@@ -228,7 +228,6 @@</span> <span class="p_context"> static int tcf_skbmod_dump(struct sk_buff *skb, struct tc_action *a,</span>
 
 	return skb-&gt;len;
 nla_put_failure:
<span class="p_del">-	rcu_read_unlock();</span>
 	nlmsg_trim(skb, b);
 	return -1;
 }
<span class="p_header">diff --git a/net/strparser/strparser.c b/net/strparser/strparser.c</span>
<span class="p_header">index 41adf362936d..b5c279b22680 100644</span>
<span class="p_header">--- a/net/strparser/strparser.c</span>
<span class="p_header">+++ b/net/strparser/strparser.c</span>
<span class="p_chunk">@@ -504,6 +504,7 @@</span> <span class="p_context"> static int __init strp_mod_init(void)</span>
 
 static void __exit strp_mod_exit(void)
 {
<span class="p_add">+	destroy_workqueue(strp_wq);</span>
 }
 module_init(strp_mod_init);
 module_exit(strp_mod_exit);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



