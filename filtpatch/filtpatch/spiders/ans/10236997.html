
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.14.21 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.14.21</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 23, 2018, 7:34 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180223073406.GB12876@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10236997/mbox/"
   >mbox</a>
|
   <a href="/patch/10236997/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10236997/">/patch/10236997/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	6C58460390 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 23 Feb 2018 07:34:47 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E52BE29443
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 23 Feb 2018 07:34:46 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id D250629446; Fri, 23 Feb 2018 07:34:46 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9B14629444
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 23 Feb 2018 07:34:29 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751895AbeBWHeV (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 23 Feb 2018 02:34:21 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:49240 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751580AbeBWHeH (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 23 Feb 2018 02:34:07 -0500
Received: from localhost (LFbn-1-12258-90.w90-92.abo.wanadoo.fr
	[90.92.71.90])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id B8ED911B7;
	Fri, 23 Feb 2018 07:34:04 +0000 (UTC)
Date: Fri, 23 Feb 2018 08:34:06 +0100
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.14.21
Message-ID: &lt;20180223073406.GB12876@kroah.com&gt;
References: &lt;20180223073351.GA12876@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20180223073351.GA12876@kroah.com&gt;
User-Agent: Mutt/1.9.3 (2018-01-21)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Feb. 23, 2018, 7:34 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">index c76afdcafbef..fb385af482ff 100644</span>
<span class="p_header">--- a/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">+++ b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_chunk">@@ -1841,13 +1841,6 @@</span> <span class="p_context"></span>
 			Built with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,
 			the default is off.
 
<span class="p_del">-	kmemcheck=	[X86] Boot-time kmemcheck enable/disable/one-shot mode</span>
<span class="p_del">-			Valid arguments: 0, 1, 2</span>
<span class="p_del">-			kmemcheck=0 (disabled)</span>
<span class="p_del">-			kmemcheck=1 (enabled)</span>
<span class="p_del">-			kmemcheck=2 (one-shot mode)</span>
<span class="p_del">-			Default: 2 (one-shot mode)</span>
<span class="p_del">-</span>
 	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.
 			Default is 0 (don&#39;t ignore, but inject #GP)
 
<span class="p_header">diff --git a/Documentation/dev-tools/index.rst b/Documentation/dev-tools/index.rst</span>
<span class="p_header">index a81787cd47d7..e313925fb0fa 100644</span>
<span class="p_header">--- a/Documentation/dev-tools/index.rst</span>
<span class="p_header">+++ b/Documentation/dev-tools/index.rst</span>
<span class="p_chunk">@@ -21,7 +21,6 @@</span> <span class="p_context"> whole; patches welcome!</span>
    kasan
    ubsan
    kmemleak
<span class="p_del">-   kmemcheck</span>
    gdb-kernel-debugging
    kgdb
    kselftest
<span class="p_header">diff --git a/Documentation/dev-tools/kmemcheck.rst b/Documentation/dev-tools/kmemcheck.rst</span>
deleted file mode 100644
<span class="p_header">index 7f3d1985de74..000000000000</span>
<span class="p_header">--- a/Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,733 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-Getting started with kmemcheck</span>
<span class="p_del">-==============================</span>
<span class="p_del">-</span>
<span class="p_del">-Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Introduction</span>
<span class="p_del">-------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck is a debugging feature for the Linux Kernel. More specifically, it</span>
<span class="p_del">-is a dynamic checker that detects and warns about some uses of uninitialized</span>
<span class="p_del">-memory.</span>
<span class="p_del">-</span>
<span class="p_del">-Userspace programmers might be familiar with Valgrind&#39;s memcheck. The main</span>
<span class="p_del">-difference between memcheck and kmemcheck is that memcheck works for userspace</span>
<span class="p_del">-programs only, and kmemcheck works for the kernel only. The implementations</span>
<span class="p_del">-are of course vastly different. Because of this, kmemcheck is not as accurate</span>
<span class="p_del">-as memcheck, but it turns out to be good enough in practice to discover real</span>
<span class="p_del">-programmer errors that the compiler is not able to find through static</span>
<span class="p_del">-analysis.</span>
<span class="p_del">-</span>
<span class="p_del">-Enabling kmemcheck on a kernel will probably slow it down to the extent that</span>
<span class="p_del">-the machine will not be usable for normal workloads such as e.g. an</span>
<span class="p_del">-interactive desktop. kmemcheck will also cause the kernel to use about twice</span>
<span class="p_del">-as much memory as normal. For this reason, kmemcheck is strictly a debugging</span>
<span class="p_del">-feature.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Downloading</span>
<span class="p_del">------------</span>
<span class="p_del">-</span>
<span class="p_del">-As of version 2.6.31-rc1, kmemcheck is included in the mainline kernel.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Configuring and compiling</span>
<span class="p_del">--------------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck only works for the x86 (both 32- and 64-bit) platform. A number of</span>
<span class="p_del">-configuration variables must have specific settings in order for the kmemcheck</span>
<span class="p_del">-menu to even appear in &quot;menuconfig&quot;. These are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_CC_OPTIMIZE_FOR_SIZE=n``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Optimize for size&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-	Without this, gcc will use certain optimizations that usually lead to</span>
<span class="p_del">-	false positive warnings from kmemcheck. An example of this is a 16-bit</span>
<span class="p_del">-	field in a struct, where gcc may load 32 bits, then discard the upper</span>
<span class="p_del">-	16 bits. kmemcheck sees only the 32-bit load, and may trigger a</span>
<span class="p_del">-	warning for the upper 16 bits (if they&#39;re uninitialized).</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_SLAB=y`` or ``CONFIG_SLUB=y``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Choose SLAB</span>
<span class="p_del">-	allocator&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_FUNCTION_TRACER=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Tracers&quot; / &quot;Kernel</span>
<span class="p_del">-	Function Tracer&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-	When function tracing is compiled in, gcc emits a call to another</span>
<span class="p_del">-	function at the beginning of every function. This means that when the</span>
<span class="p_del">-	page fault handler is called, the ftrace framework will be called</span>
<span class="p_del">-	before kmemcheck has had a chance to handle the fault. If ftrace then</span>
<span class="p_del">-	modifies memory that was tracked by kmemcheck, the result is an</span>
<span class="p_del">-	endless recursive page fault.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_DEBUG_PAGEALLOC=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Memory Debugging&quot;</span>
<span class="p_del">-	/ &quot;Debug page memory allocations&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-In addition, I highly recommend turning on ``CONFIG_DEBUG_INFO=y``. This is also</span>
<span class="p_del">-located under &quot;Kernel hacking&quot;. With this, you will be able to get line number</span>
<span class="p_del">-information from the kmemcheck warnings, which is extremely valuable in</span>
<span class="p_del">-debugging a problem. This option is not mandatory, however, because it slows</span>
<span class="p_del">-down the compilation process and produces a much bigger kernel image.</span>
<span class="p_del">-</span>
<span class="p_del">-Now the kmemcheck menu should be visible (under &quot;Kernel hacking&quot; / &quot;Memory</span>
<span class="p_del">-Debugging&quot; / &quot;kmemcheck: trap use of uninitialized memory&quot;). Here follows</span>
<span class="p_del">-a description of the kmemcheck configuration variables:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK``</span>
<span class="p_del">-	This must be enabled in order to use kmemcheck at all...</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_``[``DISABLED`` | ``ENABLED`` | ``ONESHOT``]``_BY_DEFAULT``</span>
<span class="p_del">-	This option controls the status of kmemcheck at boot-time. &quot;Enabled&quot;</span>
<span class="p_del">-	will enable kmemcheck right from the start, &quot;disabled&quot; will boot the</span>
<span class="p_del">-	kernel as normal (but with the kmemcheck code compiled in, so it can</span>
<span class="p_del">-	be enabled at run-time after the kernel has booted), and &quot;one-shot&quot; is</span>
<span class="p_del">-	a special mode which will turn kmemcheck off automatically after</span>
<span class="p_del">-	detecting the first use of uninitialized memory.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you are using kmemcheck to actively debug a problem, then you</span>
<span class="p_del">-	probably want to choose &quot;enabled&quot; here.</span>
<span class="p_del">-</span>
<span class="p_del">-	The one-shot mode is mostly useful in automated test setups because it</span>
<span class="p_del">-	can prevent floods of warnings and increase the chances of the machine</span>
<span class="p_del">-	surviving in case something is really wrong. In other cases, the one-</span>
<span class="p_del">-	shot mode could actually be counter-productive because it would turn</span>
<span class="p_del">-	itself off at the very first error -- in the case of a false positive</span>
<span class="p_del">-	too -- and this would come in the way of debugging the specific</span>
<span class="p_del">-	problem you were interested in.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you would like to use your kernel as normal, but with a chance to</span>
<span class="p_del">-	enable kmemcheck in case of some problem, it might be a good idea to</span>
<span class="p_del">-	choose &quot;disabled&quot; here. When kmemcheck is disabled, most of the run-</span>
<span class="p_del">-	time overhead is not incurred, and the kernel will be almost as fast</span>
<span class="p_del">-	as normal.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_QUEUE_SIZE``</span>
<span class="p_del">-	Select the maximum number of error reports to store in an internal</span>
<span class="p_del">-	(fixed-size) buffer. Since errors can occur virtually anywhere and in</span>
<span class="p_del">-	any context, we need a temporary storage area which is guaranteed not</span>
<span class="p_del">-	to generate any other page faults when accessed. The queue will be</span>
<span class="p_del">-	emptied as soon as a tasklet may be scheduled. If the queue is full,</span>
<span class="p_del">-	new error reports will be lost.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value of 64 is probably fine. If some code produces more</span>
<span class="p_del">-	than 64 errors within an irqs-off section, then the code is likely to</span>
<span class="p_del">-	produce many, many more, too, and these additional reports seldom give</span>
<span class="p_del">-	any more information (the first report is usually the most valuable</span>
<span class="p_del">-	anyway).</span>
<span class="p_del">-</span>
<span class="p_del">-	This number might have to be adjusted if you are not using serial</span>
<span class="p_del">-	console or similar to capture the kernel log. If you are using the</span>
<span class="p_del">-	&quot;dmesg&quot; command to save the log, then getting a lot of kmemcheck</span>
<span class="p_del">-	warnings might overflow the kernel log itself, and the earlier reports</span>
<span class="p_del">-	will get lost in that way instead. Try setting this to 10 or so on</span>
<span class="p_del">-	such a setup.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT``</span>
<span class="p_del">-	Select the number of shadow bytes to save along with each entry of the</span>
<span class="p_del">-	error-report queue. These bytes indicate what parts of an allocation</span>
<span class="p_del">-	are initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-	The number entered here is actually the logarithm of the number of</span>
<span class="p_del">-	bytes that will be saved. So if you pick for example 5 here, kmemcheck</span>
<span class="p_del">-	will save 2^5 = 32 bytes.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value should be fine for debugging most problems. It also</span>
<span class="p_del">-	fits nicely within 80 columns.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_PARTIAL_OK``</span>
<span class="p_del">-	This option (when enabled) works around certain GCC optimizations that</span>
<span class="p_del">-	produce 32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	thrown away afterwards.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value (enabled) is recommended. This may of course hide</span>
<span class="p_del">-	some real errors, but disabling it would probably produce a lot of</span>
<span class="p_del">-	false positives.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_BITOPS_OK``</span>
<span class="p_del">-	This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	accesses where not all the bits are initialized at the same time. This</span>
<span class="p_del">-	may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-	This option is probably obsolete, or it should be replaced with</span>
<span class="p_del">-	the kmemcheck-/bitfield-annotations for the code in question. The</span>
<span class="p_del">-	default value is therefore fine.</span>
<span class="p_del">-</span>
<span class="p_del">-Now compile the kernel as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-How to use</span>
<span class="p_del">-----------</span>
<span class="p_del">-</span>
<span class="p_del">-Booting</span>
<span class="p_del">-~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-First some information about the command-line options. There is only one</span>
<span class="p_del">-option specific to kmemcheck, and this is called &quot;kmemcheck&quot;. It can be used</span>
<span class="p_del">-to override the default mode as chosen by the ``CONFIG_KMEMCHECK_*_BY_DEFAULT``</span>
<span class="p_del">-option. Its possible settings are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck=0`` (disabled)</span>
<span class="p_del">-- ``kmemcheck=1`` (enabled)</span>
<span class="p_del">-- ``kmemcheck=2`` (one-shot mode)</span>
<span class="p_del">-</span>
<span class="p_del">-If SLUB debugging has been enabled in the kernel, it may take precedence over</span>
<span class="p_del">-kmemcheck in such a way that the slab caches which are under SLUB debugging</span>
<span class="p_del">-will not be tracked by kmemcheck. In order to ensure that this doesn&#39;t happen</span>
<span class="p_del">-(even though it shouldn&#39;t by default), use SLUB&#39;s boot option ``slub_debug``,</span>
<span class="p_del">-like this: ``slub_debug=-``</span>
<span class="p_del">-</span>
<span class="p_del">-In fact, this option may also be used for fine-grained control over SLUB vs.</span>
<span class="p_del">-kmemcheck. For example, if the command line includes</span>
<span class="p_del">-``kmemcheck=1 slub_debug=,dentry``, then SLUB debugging will be used only</span>
<span class="p_del">-for the &quot;dentry&quot; slab cache, and with kmemcheck tracking all the other</span>
<span class="p_del">-caches. This is advanced usage, however, and is not generally recommended.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Run-time enable/disable</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-When the kernel has booted, it is possible to enable or disable kmemcheck at</span>
<span class="p_del">-run-time. WARNING: This feature is still experimental and may cause false</span>
<span class="p_del">-positive warnings to appear. Therefore, try not to use this. If you find that</span>
<span class="p_del">-it doesn&#39;t work properly (e.g. you see an unreasonable amount of warnings), I</span>
<span class="p_del">-will be happy to take bug reports.</span>
<span class="p_del">-</span>
<span class="p_del">-Use the file ``/proc/sys/kernel/kmemcheck`` for this purpose, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ echo 0 &gt; /proc/sys/kernel/kmemcheck # disables kmemcheck</span>
<span class="p_del">-</span>
<span class="p_del">-The numbers are the same as for the ``kmemcheck=`` command-line option.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Debugging</span>
<span class="p_del">-~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-A typical report will look something like this::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-             ^</span>
<span class="p_del">-</span>
<span class="p_del">-    Pid: 1856, comm: ntpdate Not tainted 2.6.29-rc5 #264 945P-A</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-    RSP: 0018:ffff88003cdf7d98  EFLAGS: 00210002</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-    RDX: ffff88003e5d6018 RSI: ffff88003e5d6024 RDI: ffff88003cdf7e84</span>
<span class="p_del">-    RBP: ffff88003cdf7db8 R08: ffff88003e5d6000 R09: 0000000000000000</span>
<span class="p_del">-    R10: 0000000000000080 R11: 0000000000000000 R12: 000000000000000e</span>
<span class="p_del">-    R13: ffff88003cdf7e78 R14: ffff88003d530710 R15: ffff88003d5a98c8</span>
<span class="p_del">-    FS:  0000000000000000(0000) GS:ffff880001982000(0063) knlGS:00000</span>
<span class="p_del">-    CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033</span>
<span class="p_del">-    CR2: ffff88003f806ea0 CR3: 000000003c036000 CR4: 00000000000006a0</span>
<span class="p_del">-    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000</span>
<span class="p_del">-    DR3: 0000000000000000 DR6: 00000000ffff4ff0 DR7: 0000000000000400</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-     [&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span>
<span class="p_del">-</span>
<span class="p_del">-The single most valuable information in this report is the RIP (or EIP on 32-</span>
<span class="p_del">-bit) value. This will help us pinpoint exactly which instruction that caused</span>
<span class="p_del">-the warning.</span>
<span class="p_del">-</span>
<span class="p_del">-If your kernel was compiled with ``CONFIG_DEBUG_INFO=y``, then all we have to do</span>
<span class="p_del">-is give this address to the addr2line program, like this::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104ede8</span>
<span class="p_del">-	arch/x86/include/asm/string_64.h:12</span>
<span class="p_del">-	include/asm-generic/siginfo.h:287</span>
<span class="p_del">-	kernel/signal.c:380</span>
<span class="p_del">-	kernel/signal.c:410</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-e vmlinux``&quot; tells addr2line which file to look in. **IMPORTANT:**</span>
<span class="p_del">-This must be the vmlinux of the kernel that produced the warning in the</span>
<span class="p_del">-first place! If not, the line number information will almost certainly be</span>
<span class="p_del">-wrong.</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-i``&quot; tells addr2line to also print the line numbers of inlined</span>
<span class="p_del">-functions.  In this case, the flag was very important, because otherwise,</span>
<span class="p_del">-it would only have printed the first line, which is just a call to</span>
<span class="p_del">-``memcpy()``, which could be called from a thousand places in the kernel, and</span>
<span class="p_del">-is therefore not very useful.  These inlined functions would not show up in</span>
<span class="p_del">-the stack trace above, simply because the kernel doesn&#39;t load the extra</span>
<span class="p_del">-debugging information. This technique can of course be used with ordinary</span>
<span class="p_del">-kernel oopses as well.</span>
<span class="p_del">-</span>
<span class="p_del">-In this case, it&#39;s the caller of ``memcpy()`` that is interesting, and it can be</span>
<span class="p_del">-found in ``include/asm-generic/siginfo.h``, line 287::</span>
<span class="p_del">-</span>
<span class="p_del">-    281 static inline void copy_siginfo(struct siginfo *to, struct siginfo *from)</span>
<span class="p_del">-    282 {</span>
<span class="p_del">-    283         if (from-&gt;si_code &lt; 0)</span>
<span class="p_del">-    284                 memcpy(to, from, sizeof(*to));</span>
<span class="p_del">-    285         else</span>
<span class="p_del">-    286                 /* _sigchld is currently the largest know union member */</span>
<span class="p_del">-    287                 memcpy(to, from, __ARCH_SI_PREAMBLE_SIZE + sizeof(from-&gt;_sifields._sigchld));</span>
<span class="p_del">-    288 }</span>
<span class="p_del">-</span>
<span class="p_del">-Since this was a read (kmemcheck usually warns about reads only, though it can</span>
<span class="p_del">-warn about writes to unallocated or freed memory as well), it was probably the</span>
<span class="p_del">-&quot;from&quot; argument which contained some uninitialized bytes. Following the chain</span>
<span class="p_del">-of calls, we move upwards to see where &quot;from&quot; was allocated or initialized,</span>
<span class="p_del">-``kernel/signal.c``, line 380::</span>
<span class="p_del">-</span>
<span class="p_del">-    359 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)</span>
<span class="p_del">-    360 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    367         list_for_each_entry(q, &amp;list-&gt;list, list) {</span>
<span class="p_del">-    368                 if (q-&gt;info.si_signo == sig) {</span>
<span class="p_del">-    369                         if (first)</span>
<span class="p_del">-    370                                 goto still_pending;</span>
<span class="p_del">-    371                         first = q;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    377         if (first) {</span>
<span class="p_del">-    378 still_pending:</span>
<span class="p_del">-    379                 list_del_init(&amp;first-&gt;list);</span>
<span class="p_del">-    380                 copy_siginfo(info, &amp;first-&gt;info);</span>
<span class="p_del">-    381                 __sigqueue_free(first);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    392         }</span>
<span class="p_del">-    393 }</span>
<span class="p_del">-</span>
<span class="p_del">-Here, it is ``&amp;first-&gt;info`` that is being passed on to ``copy_siginfo()``. The</span>
<span class="p_del">-variable ``first`` was found on a list -- passed in as the second argument to</span>
<span class="p_del">-``collect_signal()``. We  continue our journey through the stack, to figure out</span>
<span class="p_del">-where the item on &quot;list&quot; was allocated or initialized. We move to line 410::</span>
<span class="p_del">-</span>
<span class="p_del">-    395 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,</span>
<span class="p_del">-    396                         siginfo_t *info)</span>
<span class="p_del">-    397 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    410                 collect_signal(sig, pending, info);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    414 }</span>
<span class="p_del">-</span>
<span class="p_del">-Now we need to follow the ``pending`` pointer, since that is being passed on to</span>
<span class="p_del">-``collect_signal()`` as ``list``. At this point, we&#39;ve run out of lines from the</span>
<span class="p_del">-&quot;addr2line&quot; output. Not to worry, we just paste the next addresses from the</span>
<span class="p_del">-kmemcheck stack dump, i.e.::</span>
<span class="p_del">-</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104f04e ffffffff81050bd8 \</span>
<span class="p_del">-		ffffffff8100b87d ffffffff8100c7b5</span>
<span class="p_del">-	kernel/signal.c:446</span>
<span class="p_del">-	kernel/signal.c:1806</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-Remember that since these addresses were found on the stack and not as the</span>
<span class="p_del">-RIP value, they actually point to the _next_ instruction (they are return</span>
<span class="p_del">-addresses). This becomes obvious when we look at the code for line 446::</span>
<span class="p_del">-</span>
<span class="p_del">-    422 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)</span>
<span class="p_del">-    423 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    431                 signr = __dequeue_signal(&amp;tsk-&gt;signal-&gt;shared_pending,</span>
<span class="p_del">-    432						 mask, info);</span>
<span class="p_del">-    433			/*</span>
<span class="p_del">-    434			 * itimer signal ?</span>
<span class="p_del">-    435			 *</span>
<span class="p_del">-    436			 * itimers are process shared and we restart periodic</span>
<span class="p_del">-    437			 * itimers in the signal delivery path to prevent DoS</span>
<span class="p_del">-    438			 * attacks in the high resolution timer case. This is</span>
<span class="p_del">-    439			 * compliant with the old way of self restarting</span>
<span class="p_del">-    440			 * itimers, as the SIGALRM is a legacy signal and only</span>
<span class="p_del">-    441			 * queued once. Changing the restart behaviour to</span>
<span class="p_del">-    442			 * restart the timer in the signal dequeue path is</span>
<span class="p_del">-    443			 * reducing the timer noise on heavy loaded !highres</span>
<span class="p_del">-    444			 * systems too.</span>
<span class="p_del">-    445			 */</span>
<span class="p_del">-    446			if (unlikely(signr == SIGALRM)) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    489 }</span>
<span class="p_del">-</span>
<span class="p_del">-So instead of looking at 446, we should be looking at 431, which is the line</span>
<span class="p_del">-that executes just before 446. Here we see that what we are looking for is</span>
<span class="p_del">-``&amp;tsk-&gt;signal-&gt;shared_pending``.</span>
<span class="p_del">-</span>
<span class="p_del">-Our next task is now to figure out which function that puts items on this</span>
<span class="p_del">-``shared_pending`` list. A crude, but efficient tool, is ``git grep``::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ git grep -n &#39;shared_pending&#39; kernel/</span>
<span class="p_del">-	...</span>
<span class="p_del">-	kernel/signal.c:828:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	kernel/signal.c:1339:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	...</span>
<span class="p_del">-</span>
<span class="p_del">-There were more results, but none of them were related to list operations,</span>
<span class="p_del">-and these were the only assignments. We inspect the line numbers more closely</span>
<span class="p_del">-and find that this is indeed where items are being added to the list::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-and::</span>
<span class="p_del">-</span>
<span class="p_del">-    1309 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)</span>
<span class="p_del">-    1310 {</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1339	 pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    1340	 list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1347 }</span>
<span class="p_del">-</span>
<span class="p_del">-In the first case, the list element we are looking for, ``q``, is being</span>
<span class="p_del">-returned from the function ``__sigqueue_alloc()``, which looks like an</span>
<span class="p_del">-allocation function.  Let&#39;s take a look at it::</span>
<span class="p_del">-</span>
<span class="p_del">-    187 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,</span>
<span class="p_del">-    188						 int override_rlimit)</span>
<span class="p_del">-    189 {</span>
<span class="p_del">-    190		struct sigqueue *q = NULL;</span>
<span class="p_del">-    191		struct user_struct *user;</span>
<span class="p_del">-    192</span>
<span class="p_del">-    193		/*</span>
<span class="p_del">-    194		 * We won&#39;t get problems with the target&#39;s UID changing under us</span>
<span class="p_del">-    195		 * because changing it requires RCU be used, and if t != current, the</span>
<span class="p_del">-    196		 * caller must be holding the RCU readlock (by way of a spinlock) and</span>
<span class="p_del">-    197		 * we use RCU protection here</span>
<span class="p_del">-    198		 */</span>
<span class="p_del">-    199		user = get_uid(__task_cred(t)-&gt;user);</span>
<span class="p_del">-    200		atomic_inc(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    201		if (override_rlimit ||</span>
<span class="p_del">-    202		    atomic_read(&amp;user-&gt;sigpending) &lt;=</span>
<span class="p_del">-    203				t-&gt;signal-&gt;rlim[RLIMIT_SIGPENDING].rlim_cur)</span>
<span class="p_del">-    204			q = kmem_cache_alloc(sigqueue_cachep, flags);</span>
<span class="p_del">-    205		if (unlikely(q == NULL)) {</span>
<span class="p_del">-    206			atomic_dec(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    207			free_uid(user);</span>
<span class="p_del">-    208		} else {</span>
<span class="p_del">-    209			INIT_LIST_HEAD(&amp;q-&gt;list);</span>
<span class="p_del">-    210			q-&gt;flags = 0;</span>
<span class="p_del">-    211			q-&gt;user = user;</span>
<span class="p_del">-    212		}</span>
<span class="p_del">-    213</span>
<span class="p_del">-    214		return q;</span>
<span class="p_del">-    215 }</span>
<span class="p_del">-</span>
<span class="p_del">-We see that this function initializes ``q-&gt;list``, ``q-&gt;flags``, and</span>
<span class="p_del">-``q-&gt;user``. It seems that now is the time to look at the definition of</span>
<span class="p_del">-``struct sigqueue``, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-    14 struct sigqueue {</span>
<span class="p_del">-    15	       struct list_head list;</span>
<span class="p_del">-    16	       int flags;</span>
<span class="p_del">-    17	       siginfo_t info;</span>
<span class="p_del">-    18	       struct user_struct *user;</span>
<span class="p_del">-    19 };</span>
<span class="p_del">-</span>
<span class="p_del">-And, you might remember, it was a ``memcpy()`` on ``&amp;first-&gt;info`` that</span>
<span class="p_del">-caused the warning, so this makes perfect sense. It also seems reasonable</span>
<span class="p_del">-to assume that it is the caller of ``__sigqueue_alloc()`` that has the</span>
<span class="p_del">-responsibility of filling out (initializing) this member.</span>
<span class="p_del">-</span>
<span class="p_del">-But just which fields of the struct were uninitialized? Let&#39;s look at</span>
<span class="p_del">-kmemcheck&#39;s report again::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-	     ^</span>
<span class="p_del">-</span>
<span class="p_del">-These first two lines are the memory dump of the memory object itself, and</span>
<span class="p_del">-the shadow bytemap, respectively. The memory object itself is in this case</span>
<span class="p_del">-``&amp;first-&gt;info``. Just beware that the start of this dump is NOT the start</span>
<span class="p_del">-of the object itself! The position of the caret (^) corresponds with the</span>
<span class="p_del">-address of the read (ffff88003e4a2024).</span>
<span class="p_del">-</span>
<span class="p_del">-The shadow bytemap dump legend is as follows:</span>
<span class="p_del">-</span>
<span class="p_del">-- i: initialized</span>
<span class="p_del">-- u: uninitialized</span>
<span class="p_del">-- a: unallocated (memory has been allocated by the slab layer, but has not</span>
<span class="p_del">-  yet been handed off to anybody)</span>
<span class="p_del">-- f: freed (memory has been allocated by the slab layer, but has been freed</span>
<span class="p_del">-  by the previous owner)</span>
<span class="p_del">-</span>
<span class="p_del">-In order to figure out where (relative to the start of the object) the</span>
<span class="p_del">-uninitialized memory was located, we have to look at the disassembly. For</span>
<span class="p_del">-that, we&#39;ll need the RIP address again::</span>
<span class="p_del">-</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-</span>
<span class="p_del">-	$ objdump -d --no-show-raw-insn vmlinux | grep -C 8 ffffffff8104ede8:</span>
<span class="p_del">-	ffffffff8104edc8:	mov    %r8,0x8(%r8)</span>
<span class="p_del">-	ffffffff8104edcc:	test   %r10d,%r10d</span>
<span class="p_del">-	ffffffff8104edcf:	js     ffffffff8104ee88 &lt;__dequeue_signal+0x168&gt;</span>
<span class="p_del">-	ffffffff8104edd5:	mov    %rax,%rdx</span>
<span class="p_del">-	ffffffff8104edd8:	mov    $0xc,%ecx</span>
<span class="p_del">-	ffffffff8104eddd:	mov    %r13,%rdi</span>
<span class="p_del">-	ffffffff8104ede0:	mov    $0x30,%eax</span>
<span class="p_del">-	ffffffff8104ede5:	mov    %rdx,%rsi</span>
<span class="p_del">-	ffffffff8104ede8:	rep movsl %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edea:	test   $0x2,%al</span>
<span class="p_del">-	ffffffff8104edec:	je     ffffffff8104edf0 &lt;__dequeue_signal+0xd0&gt;</span>
<span class="p_del">-	ffffffff8104edee:	movsw  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf0:	test   $0x1,%al</span>
<span class="p_del">-	ffffffff8104edf2:	je     ffffffff8104edf5 &lt;__dequeue_signal+0xd5&gt;</span>
<span class="p_del">-	ffffffff8104edf4:	movsb  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf5:	mov    %r8,%rdi</span>
<span class="p_del">-	ffffffff8104edf8:	callq  ffffffff8104de60 &lt;__sigqueue_free&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-As expected, it&#39;s the &quot;``rep movsl``&quot; instruction from the ``memcpy()``</span>
<span class="p_del">-that causes the warning. We know about ``REP MOVSL`` that it uses the register</span>
<span class="p_del">-``RCX`` to count the number of remaining iterations. By taking a look at the</span>
<span class="p_del">-register dump again (from the kmemcheck report), we can figure out how many</span>
<span class="p_del">-bytes were left to copy::</span>
<span class="p_del">-</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-</span>
<span class="p_del">-By looking at the disassembly, we also see that ``%ecx`` is being loaded</span>
<span class="p_del">-with the value ``$0xc`` just before (ffffffff8104edd8), so we are very</span>
<span class="p_del">-lucky. Keep in mind that this is the number of iterations, not bytes. And</span>
<span class="p_del">-since this is a &quot;long&quot; operation, we need to multiply by 4 to get the</span>
<span class="p_del">-number of bytes. So this means that the uninitialized value was encountered</span>
<span class="p_del">-at 4 * (0xc - 0x9) = 12 bytes from the start of the object.</span>
<span class="p_del">-</span>
<span class="p_del">-We can now try to figure out which field of the &quot;``struct siginfo``&quot; that</span>
<span class="p_del">-was not initialized. This is the beginning of the struct::</span>
<span class="p_del">-</span>
<span class="p_del">-    40 typedef struct siginfo {</span>
<span class="p_del">-    41	       int si_signo;</span>
<span class="p_del">-    42	       int si_errno;</span>
<span class="p_del">-    43	       int si_code;</span>
<span class="p_del">-    44</span>
<span class="p_del">-    45	       union {</span>
<span class="p_del">-    ..</span>
<span class="p_del">-    92	       } _sifields;</span>
<span class="p_del">-    93 } siginfo_t;</span>
<span class="p_del">-</span>
<span class="p_del">-On 64-bit, the int is 4 bytes long, so it must the union member that has</span>
<span class="p_del">-not been initialized. We can verify this using gdb::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ gdb vmlinux</span>
<span class="p_del">-	...</span>
<span class="p_del">-	(gdb) p &amp;((struct siginfo *) 0)-&gt;_sifields</span>
<span class="p_del">-	$1 = (union {...} *) 0x10</span>
<span class="p_del">-</span>
<span class="p_del">-Actually, it seems that the union member is located at offset 0x10 -- which</span>
<span class="p_del">-means that gcc has inserted 4 bytes of padding between the members ``si_code``</span>
<span class="p_del">-and ``_sifields``. We can now get a fuller picture of the memory dump::</span>
<span class="p_del">-</span>
<span class="p_del">-		 _----------------------------=&gt; si_code</span>
<span class="p_del">-		/	 _--------------------=&gt; (padding)</span>
<span class="p_del">-	       |	/	 _------------=&gt; _sifields(._kill._pid)</span>
<span class="p_del">-	       |       |	/	 _----=&gt; _sifields(._kill._uid)</span>
<span class="p_del">-	       |       |       |	/</span>
<span class="p_del">-	-------|-------|-------|-------|</span>
<span class="p_del">-	80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-	 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-</span>
<span class="p_del">-This allows us to realize another important fact: ``si_code`` contains the</span>
<span class="p_del">-value 0x80. Remember that x86 is little endian, so the first 4 bytes</span>
<span class="p_del">-&quot;80000000&quot; are really the number 0x00000080. With a bit of research, we</span>
<span class="p_del">-find that this is actually the constant ``SI_KERNEL`` defined in</span>
<span class="p_del">-``include/asm-generic/siginfo.h``::</span>
<span class="p_del">-</span>
<span class="p_del">-    144 #define SI_KERNEL	0x80		/* sent by the kernel from somewhere	 */</span>
<span class="p_del">-</span>
<span class="p_del">-This macro is used in exactly one place in the x86 kernel: In ``send_signal()``</span>
<span class="p_del">-in ``kernel/signal.c``::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    856			switch ((unsigned long) info) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    865			case (unsigned long) SEND_SIG_PRIV:</span>
<span class="p_del">-    866				q-&gt;info.si_signo = sig;</span>
<span class="p_del">-    867				q-&gt;info.si_errno = 0;</span>
<span class="p_del">-    868				q-&gt;info.si_code = SI_KERNEL;</span>
<span class="p_del">-    869				q-&gt;info.si_pid = 0;</span>
<span class="p_del">-    870				q-&gt;info.si_uid = 0;</span>
<span class="p_del">-    871				break;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-Not only does this match with the ``.si_code`` member, it also matches the place</span>
<span class="p_del">-we found earlier when looking for where siginfo_t objects are enqueued on the</span>
<span class="p_del">-``shared_pending`` list.</span>
<span class="p_del">-</span>
<span class="p_del">-So to sum up: It seems that it is the padding introduced by the compiler</span>
<span class="p_del">-between two struct fields that is uninitialized, and this gets reported when</span>
<span class="p_del">-we do a ``memcpy()`` on the struct. This means that we have identified a false</span>
<span class="p_del">-positive warning.</span>
<span class="p_del">-</span>
<span class="p_del">-Normally, kmemcheck will not report uninitialized accesses in ``memcpy()`` calls</span>
<span class="p_del">-when both the source and destination addresses are tracked. (Instead, we copy</span>
<span class="p_del">-the shadow bytemap as well). In this case, the destination address clearly</span>
<span class="p_del">-was not tracked. We can dig a little deeper into the stack trace from above::</span>
<span class="p_del">-</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-And we clearly see that the destination siginfo object is located on the</span>
<span class="p_del">-stack::</span>
<span class="p_del">-</span>
<span class="p_del">-    782 static void do_signal(struct pt_regs *regs)</span>
<span class="p_del">-    783 {</span>
<span class="p_del">-    784		struct k_sigaction ka;</span>
<span class="p_del">-    785		siginfo_t info;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    804		signr = get_signal_to_deliver(&amp;info, &amp;ka, regs, NULL);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    854 }</span>
<span class="p_del">-</span>
<span class="p_del">-And this ``&amp;info`` is what eventually gets passed to ``copy_siginfo()`` as the</span>
<span class="p_del">-destination argument.</span>
<span class="p_del">-</span>
<span class="p_del">-Now, even though we didn&#39;t find an actual error here, the example is still a</span>
<span class="p_del">-good one, because it shows how one would go about to find out what the report</span>
<span class="p_del">-was all about.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Annotating false positives</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-There are a few different ways to make annotations in the source code that</span>
<span class="p_del">-will keep kmemcheck from checking and reporting certain allocations. Here</span>
<span class="p_del">-they are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``__GFP_NOTRACK_FALSE_POSITIVE``</span>
<span class="p_del">-	This flag can be passed to ``kmalloc()`` or ``kmem_cache_alloc()``</span>
<span class="p_del">-	(therefore also to other functions that end up calling one of</span>
<span class="p_del">-	these) to indicate that the allocation should not be tracked</span>
<span class="p_del">-	because it would lead to a false positive report. This is a &quot;big</span>
<span class="p_del">-	hammer&quot; way of silencing kmemcheck; after all, even if the false</span>
<span class="p_del">-	positive pertains to particular field in a struct, for example, we</span>
<span class="p_del">-	will now lose the ability to find (real) errors in other parts of</span>
<span class="p_del">-	the same struct.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will ever trigger on accessing any part of x */</span>
<span class="p_del">-	    x = kmalloc(sizeof *x, GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck_bitfield_begin(name)``/``kmemcheck_bitfield_end(name)`` and</span>
<span class="p_del">-	``kmemcheck_annotate_bitfield(ptr, name)``</span>
<span class="p_del">-	The first two of these three macros can be used inside struct</span>
<span class="p_del">-	definitions to signal, respectively, the beginning and end of a</span>
<span class="p_del">-	bitfield. Additionally, this will assign the bitfield a name, which</span>
<span class="p_del">-	is given as an argument to the macros.</span>
<span class="p_del">-</span>
<span class="p_del">-	Having used these markers, one can later use</span>
<span class="p_del">-	kmemcheck_annotate_bitfield() at the point of allocation, to indicate</span>
<span class="p_del">-	which parts of the allocation is part of a bitfield.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo {</span>
<span class="p_del">-		int x;</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">-		int flag_a:1;</span>
<span class="p_del">-		int flag_b:1;</span>
<span class="p_del">-		kmemcheck_bitfield_end(flags);</span>
<span class="p_del">-</span>
<span class="p_del">-		int y;</span>
<span class="p_del">-	    };</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo *x = kmalloc(sizeof *x);</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will trigger on accessing the bitfield of x */</span>
<span class="p_del">-	    kmemcheck_annotate_bitfield(x, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	Note that ``kmemcheck_annotate_bitfield()`` can be used even before the</span>
<span class="p_del">-	return value of ``kmalloc()`` is checked -- in other words, passing NULL</span>
<span class="p_del">-	as the first argument is legal (and will do nothing).</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Reporting errors</span>
<span class="p_del">-----------------</span>
<span class="p_del">-</span>
<span class="p_del">-As we have seen, kmemcheck will produce false positive reports. Therefore, it</span>
<span class="p_del">-is not very wise to blindly post kmemcheck warnings to mailing lists and</span>
<span class="p_del">-maintainers. Instead, I encourage maintainers and developers to find errors</span>
<span class="p_del">-in their own code. If you get a warning, you can try to work around it, try</span>
<span class="p_del">-to figure out if it&#39;s a real error or not, or simply ignore it. Most</span>
<span class="p_del">-developers know their own code and will quickly and efficiently determine the</span>
<span class="p_del">-root cause of a kmemcheck report. This is therefore also the most efficient</span>
<span class="p_del">-way to work with kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-That said, we (the kmemcheck maintainers) will always be on the lookout for</span>
<span class="p_del">-false positives that we can annotate and silence. So whatever you find,</span>
<span class="p_del">-please drop us a note privately! Kernel configs and steps to reproduce (if</span>
<span class="p_del">-available) are of course a great help too.</span>
<span class="p_del">-</span>
<span class="p_del">-Happy hacking!</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Technical description</span>
<span class="p_del">----------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck works by marking memory pages non-present. This means that whenever</span>
<span class="p_del">-somebody attempts to access the page, a page fault is generated. The page</span>
<span class="p_del">-fault handler notices that the page was in fact only hidden, and so it calls</span>
<span class="p_del">-on the kmemcheck code to make further investigations.</span>
<span class="p_del">-</span>
<span class="p_del">-When the investigations are completed, kmemcheck &quot;shows&quot; the page by marking</span>
<span class="p_del">-it present (as it would be under normal circumstances). This way, the</span>
<span class="p_del">-interrupted code can continue as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-But after the instruction has been executed, we should hide the page again, so</span>
<span class="p_del">-that we can catch the next access too! Now kmemcheck makes use of a debugging</span>
<span class="p_del">-feature of the processor, namely single-stepping. When the processor has</span>
<span class="p_del">-finished the one instruction that generated the memory access, a debug</span>
<span class="p_del">-exception is raised. From here, we simply hide the page again and continue</span>
<span class="p_del">-execution, this time with the single-stepping feature turned off.</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck requires some assistance from the memory allocator in order to work.</span>
<span class="p_del">-The memory allocator needs to</span>
<span class="p_del">-</span>
<span class="p_del">-  1. Tell kmemcheck about newly allocated pages and pages that are about to</span>
<span class="p_del">-     be freed. This allows kmemcheck to set up and tear down the shadow memory</span>
<span class="p_del">-     for the pages in question. The shadow memory stores the status of each</span>
<span class="p_del">-     byte in the allocation proper, e.g. whether it is initialized or</span>
<span class="p_del">-     uninitialized.</span>
<span class="p_del">-</span>
<span class="p_del">-  2. Tell kmemcheck which parts of memory should be marked uninitialized.</span>
<span class="p_del">-     There are actually a few more states, such as &quot;not yet allocated&quot; and</span>
<span class="p_del">-     &quot;recently freed&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is set up using the SLAB_NOTRACK flag, it will never return</span>
<span class="p_del">-memory that can take page faults because of kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is NOT set up using the SLAB_NOTRACK flag, callers can still</span>
<span class="p_del">-request memory with the __GFP_NOTRACK or __GFP_NOTRACK_FALSE_POSITIVE flags.</span>
<span class="p_del">-This does not prevent the page faults from occurring, however, but marks the</span>
<span class="p_del">-object in question as being initialized so that no warnings will ever be</span>
<span class="p_del">-produced for this object.</span>
<span class="p_del">-</span>
<span class="p_del">-Currently, the SLAB and SLUB allocators are supported by kmemcheck.</span>
<span class="p_header">diff --git a/Documentation/devicetree/bindings/dma/snps-dma.txt b/Documentation/devicetree/bindings/dma/snps-dma.txt</span>
<span class="p_header">index a122723907ac..99acc712f83a 100644</span>
<span class="p_header">--- a/Documentation/devicetree/bindings/dma/snps-dma.txt</span>
<span class="p_header">+++ b/Documentation/devicetree/bindings/dma/snps-dma.txt</span>
<span class="p_chunk">@@ -64,6 +64,6 @@</span> <span class="p_context"> Example:</span>
 		reg = &lt;0xe0000000 0x1000&gt;;
 		interrupts = &lt;0 35 0x4&gt;;
 		dmas = &lt;&amp;dmahost 12 0 1&gt;,
<span class="p_del">-			&lt;&amp;dmahost 13 0 1 0&gt;;</span>
<span class="p_add">+			&lt;&amp;dmahost 13 1 0&gt;;</span>
 		dma-names = &quot;rx&quot;, &quot;rx&quot;;
 	};
<span class="p_header">diff --git a/Documentation/filesystems/ext4.txt b/Documentation/filesystems/ext4.txt</span>
<span class="p_header">index 5a8f7f4d2bca..7449893dc039 100644</span>
<span class="p_header">--- a/Documentation/filesystems/ext4.txt</span>
<span class="p_header">+++ b/Documentation/filesystems/ext4.txt</span>
<span class="p_chunk">@@ -233,7 +233,7 @@</span> <span class="p_context"> data_err=ignore(*)	Just print an error message if an error occurs</span>
 data_err=abort		Abort the journal if an error occurs in a file
 			data buffer in ordered mode.
 
<span class="p_del">-grpid			Give objects the same group ID as their creator.</span>
<span class="p_add">+grpid			New objects have the group ID of their parent.</span>
 bsdgroups
 
 nogrpid		(*)	New objects have the group ID of their creator.
<span class="p_header">diff --git a/MAINTAINERS b/MAINTAINERS</span>
<span class="p_header">index 2811a211632c..76ea063d8083 100644</span>
<span class="p_header">--- a/MAINTAINERS</span>
<span class="p_header">+++ b/MAINTAINERS</span>
<span class="p_chunk">@@ -7670,16 +7670,6 @@</span> <span class="p_context"> F:	include/linux/kdb.h</span>
 F:	include/linux/kgdb.h
 F:	kernel/debug/
 
<span class="p_del">-KMEMCHECK</span>
<span class="p_del">-M:	Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-M:	Pekka Enberg &lt;penberg@kernel.org&gt;</span>
<span class="p_del">-S:	Maintained</span>
<span class="p_del">-F:	Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_del">-F:	arch/x86/include/asm/kmemcheck.h</span>
<span class="p_del">-F:	arch/x86/mm/kmemcheck/</span>
<span class="p_del">-F:	include/linux/kmemcheck.h</span>
<span class="p_del">-F:	mm/kmemcheck.c</span>
<span class="p_del">-</span>
 KMEMLEAK
 M:	Catalin Marinas &lt;catalin.marinas@arm.com&gt;
 S:	Maintained
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 33176140f133..68d70485b088 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,7 +1,7 @@</span> <span class="p_context"></span>
 # SPDX-License-Identifier: GPL-2.0
 VERSION = 4
 PATCHLEVEL = 14
<span class="p_del">-SUBLEVEL = 20</span>
<span class="p_add">+SUBLEVEL = 21</span>
 EXTRAVERSION =
 NAME = Petit Gorille
 
<span class="p_header">diff --git a/arch/arm/boot/dts/arm-realview-eb-mp.dtsi b/arch/arm/boot/dts/arm-realview-eb-mp.dtsi</span>
<span class="p_header">index 7b8d90b7aeea..29b636fce23f 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/arm-realview-eb-mp.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/arm-realview-eb-mp.dtsi</span>
<span class="p_chunk">@@ -150,11 +150,6 @@</span> <span class="p_context"></span>
 	interrupts = &lt;0 8 IRQ_TYPE_LEVEL_HIGH&gt;;
 };
 
<span class="p_del">-&amp;charlcd {</span>
<span class="p_del">-	interrupt-parent = &lt;&amp;intc&gt;;</span>
<span class="p_del">-	interrupts = &lt;0  IRQ_TYPE_LEVEL_HIGH&gt;;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 &amp;serial0 {
 	interrupt-parent = &lt;&amp;intc&gt;;
 	interrupts = &lt;0 4 IRQ_TYPE_LEVEL_HIGH&gt;;
<span class="p_header">diff --git a/arch/arm/boot/dts/exynos5410.dtsi b/arch/arm/boot/dts/exynos5410.dtsi</span>
<span class="p_header">index 7eab4bc07cec..7628bbb02324 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/exynos5410.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/exynos5410.dtsi</span>
<span class="p_chunk">@@ -333,7 +333,6 @@</span> <span class="p_context"></span>
 &amp;rtc {
 	clocks = &lt;&amp;clock CLK_RTC&gt;;
 	clock-names = &quot;rtc&quot;;
<span class="p_del">-	interrupt-parent = &lt;&amp;pmu_system_controller&gt;;</span>
 	status = &quot;disabled&quot;;
 };
 
<span class="p_header">diff --git a/arch/arm/boot/dts/lpc3250-ea3250.dts b/arch/arm/boot/dts/lpc3250-ea3250.dts</span>
<span class="p_header">index 52b3ed10283a..e2bc731079be 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/lpc3250-ea3250.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/lpc3250-ea3250.dts</span>
<span class="p_chunk">@@ -156,8 +156,8 @@</span> <span class="p_context"></span>
 	uda1380: uda1380@18 {
 		compatible = &quot;nxp,uda1380&quot;;
 		reg = &lt;0x18&gt;;
<span class="p_del">-		power-gpio = &lt;&amp;gpio 0x59 0&gt;;</span>
<span class="p_del">-		reset-gpio = &lt;&amp;gpio 0x51 0&gt;;</span>
<span class="p_add">+		power-gpio = &lt;&amp;gpio 3 10 0&gt;;</span>
<span class="p_add">+		reset-gpio = &lt;&amp;gpio 3 2 0&gt;;</span>
 		dac-clk = &quot;wspll&quot;;
 	};
 
<span class="p_header">diff --git a/arch/arm/boot/dts/lpc3250-phy3250.dts b/arch/arm/boot/dts/lpc3250-phy3250.dts</span>
<span class="p_header">index fd95e2b10357..b7bd3a110a8d 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/lpc3250-phy3250.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/lpc3250-phy3250.dts</span>
<span class="p_chunk">@@ -81,8 +81,8 @@</span> <span class="p_context"></span>
 	uda1380: uda1380@18 {
 		compatible = &quot;nxp,uda1380&quot;;
 		reg = &lt;0x18&gt;;
<span class="p_del">-		power-gpio = &lt;&amp;gpio 0x59 0&gt;;</span>
<span class="p_del">-		reset-gpio = &lt;&amp;gpio 0x51 0&gt;;</span>
<span class="p_add">+		power-gpio = &lt;&amp;gpio 3 10 0&gt;;</span>
<span class="p_add">+		reset-gpio = &lt;&amp;gpio 3 2 0&gt;;</span>
 		dac-clk = &quot;wspll&quot;;
 	};
 
<span class="p_header">diff --git a/arch/arm/boot/dts/mt2701.dtsi b/arch/arm/boot/dts/mt2701.dtsi</span>
<span class="p_header">index afe12e5b51f9..f936000f0699 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/mt2701.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/mt2701.dtsi</span>
<span class="p_chunk">@@ -593,6 +593,7 @@</span> <span class="p_context"></span>
 		compatible = &quot;mediatek,mt2701-hifsys&quot;, &quot;syscon&quot;;
 		reg = &lt;0 0x1a000000 0 0x1000&gt;;
 		#clock-cells = &lt;1&gt;;
<span class="p_add">+		#reset-cells = &lt;1&gt;;</span>
 	};
 
 	usb0: usb@1a1c0000 {
<span class="p_chunk">@@ -677,6 +678,7 @@</span> <span class="p_context"></span>
 		compatible = &quot;mediatek,mt2701-ethsys&quot;, &quot;syscon&quot;;
 		reg = &lt;0 0x1b000000 0 0x1000&gt;;
 		#clock-cells = &lt;1&gt;;
<span class="p_add">+		#reset-cells = &lt;1&gt;;</span>
 	};
 
 	eth: ethernet@1b100000 {
<span class="p_header">diff --git a/arch/arm/boot/dts/mt7623.dtsi b/arch/arm/boot/dts/mt7623.dtsi</span>
<span class="p_header">index ec8a07415cb3..36983a7d7cfd 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/mt7623.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/mt7623.dtsi</span>
<span class="p_chunk">@@ -753,6 +753,7 @@</span> <span class="p_context"></span>
 			     &quot;syscon&quot;;
 		reg = &lt;0 0x1b000000 0 0x1000&gt;;
 		#clock-cells = &lt;1&gt;;
<span class="p_add">+		#reset-cells = &lt;1&gt;;</span>
 	};
 
 	eth: ethernet@1b100000 {
<span class="p_header">diff --git a/arch/arm/boot/dts/mt7623n-bananapi-bpi-r2.dts b/arch/arm/boot/dts/mt7623n-bananapi-bpi-r2.dts</span>
<span class="p_header">index 688a86378cee..7bf5aa2237c9 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/mt7623n-bananapi-bpi-r2.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/mt7623n-bananapi-bpi-r2.dts</span>
<span class="p_chunk">@@ -204,7 +204,7 @@</span> <span class="p_context"></span>
 	bus-width = &lt;4&gt;;
 	max-frequency = &lt;50000000&gt;;
 	cap-sd-highspeed;
<span class="p_del">-	cd-gpios = &lt;&amp;pio 261 0&gt;;</span>
<span class="p_add">+	cd-gpios = &lt;&amp;pio 261 GPIO_ACTIVE_LOW&gt;;</span>
 	vmmc-supply = &lt;&amp;mt6323_vmch_reg&gt;;
 	vqmmc-supply = &lt;&amp;mt6323_vio18_reg&gt;;
 };
<span class="p_header">diff --git a/arch/arm/boot/dts/s5pv210.dtsi b/arch/arm/boot/dts/s5pv210.dtsi</span>
<span class="p_header">index 726c5d0dbd5b..b290a5abb901 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/s5pv210.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/s5pv210.dtsi</span>
<span class="p_chunk">@@ -463,6 +463,7 @@</span> <span class="p_context"></span>
 			compatible = &quot;samsung,exynos4210-ohci&quot;;
 			reg = &lt;0xec300000 0x100&gt;;
 			interrupts = &lt;23&gt;;
<span class="p_add">+			interrupt-parent = &lt;&amp;vic1&gt;;</span>
 			clocks = &lt;&amp;clocks CLK_USB_HOST&gt;;
 			clock-names = &quot;usbhost&quot;;
 			#address-cells = &lt;1&gt;;
<span class="p_header">diff --git a/arch/arm/boot/dts/spear1310-evb.dts b/arch/arm/boot/dts/spear1310-evb.dts</span>
<span class="p_header">index 84101e4eebbf..0f5f379323a8 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/spear1310-evb.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/spear1310-evb.dts</span>
<span class="p_chunk">@@ -349,7 +349,7 @@</span> <span class="p_context"></span>
 			spi0: spi@e0100000 {
 				status = &quot;okay&quot;;
 				num-cs = &lt;3&gt;;
<span class="p_del">-				cs-gpios = &lt;&amp;gpio1 7 0&gt;, &lt;&amp;spics 0&gt;, &lt;&amp;spics 1&gt;;</span>
<span class="p_add">+				cs-gpios = &lt;&amp;gpio1 7 0&gt;, &lt;&amp;spics 0 0&gt;, &lt;&amp;spics 1 0&gt;;</span>
 
 				stmpe610@0 {
 					compatible = &quot;st,stmpe610&quot;;
<span class="p_header">diff --git a/arch/arm/boot/dts/spear1340.dtsi b/arch/arm/boot/dts/spear1340.dtsi</span>
<span class="p_header">index 5f347054527d..d4dbc4098653 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/spear1340.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/spear1340.dtsi</span>
<span class="p_chunk">@@ -142,8 +142,8 @@</span> <span class="p_context"></span>
 				reg = &lt;0xb4100000 0x1000&gt;;
 				interrupts = &lt;0 105 0x4&gt;;
 				status = &quot;disabled&quot;;
<span class="p_del">-				dmas = &lt;&amp;dwdma0 0x600 0 0 1&gt;, /* 0xC &lt;&lt; 11 */</span>
<span class="p_del">-					&lt;&amp;dwdma0 0x680 0 1 0&gt;; /* 0xD &lt;&lt; 7 */</span>
<span class="p_add">+				dmas = &lt;&amp;dwdma0 12 0 1&gt;,</span>
<span class="p_add">+					&lt;&amp;dwdma0 13 1 0&gt;;</span>
 				dma-names = &quot;tx&quot;, &quot;rx&quot;;
 			};
 
<span class="p_header">diff --git a/arch/arm/boot/dts/spear13xx.dtsi b/arch/arm/boot/dts/spear13xx.dtsi</span>
<span class="p_header">index 17ea0abcdbd7..086b4b333249 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/spear13xx.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/spear13xx.dtsi</span>
<span class="p_chunk">@@ -100,7 +100,7 @@</span> <span class="p_context"></span>
 			reg = &lt;0xb2800000 0x1000&gt;;
 			interrupts = &lt;0 29 0x4&gt;;
 			status = &quot;disabled&quot;;
<span class="p_del">-			dmas = &lt;&amp;dwdma0 0 0 0 0&gt;;</span>
<span class="p_add">+			dmas = &lt;&amp;dwdma0 0 0 0&gt;;</span>
 			dma-names = &quot;data&quot;;
 		};
 
<span class="p_chunk">@@ -290,8 +290,8 @@</span> <span class="p_context"></span>
 				#size-cells = &lt;0&gt;;
 				interrupts = &lt;0 31 0x4&gt;;
 				status = &quot;disabled&quot;;
<span class="p_del">-				dmas = &lt;&amp;dwdma0 0x2000 0 0 0&gt;, /* 0x4 &lt;&lt; 11 */</span>
<span class="p_del">-					&lt;&amp;dwdma0 0x0280 0 0 0&gt;;  /* 0x5 &lt;&lt; 7 */</span>
<span class="p_add">+				dmas = &lt;&amp;dwdma0 4 0 0&gt;,</span>
<span class="p_add">+					&lt;&amp;dwdma0 5 0 0&gt;;</span>
 				dma-names = &quot;tx&quot;, &quot;rx&quot;;
 			};
 
<span class="p_header">diff --git a/arch/arm/boot/dts/spear600.dtsi b/arch/arm/boot/dts/spear600.dtsi</span>
<span class="p_header">index 6b32d20acc9f..00166eb9be86 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/spear600.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/spear600.dtsi</span>
<span class="p_chunk">@@ -194,6 +194,7 @@</span> <span class="p_context"></span>
 			rtc: rtc@fc900000 {
 				compatible = &quot;st,spear600-rtc&quot;;
 				reg = &lt;0xfc900000 0x1000&gt;;
<span class="p_add">+				interrupt-parent = &lt;&amp;vic0&gt;;</span>
 				interrupts = &lt;10&gt;;
 				status = &quot;disabled&quot;;
 			};
<span class="p_header">diff --git a/arch/arm/boot/dts/ste-nomadik-stn8815.dtsi b/arch/arm/boot/dts/ste-nomadik-stn8815.dtsi</span>
<span class="p_header">index 68aab50a73ab..733678b75b88 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/ste-nomadik-stn8815.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/ste-nomadik-stn8815.dtsi</span>
<span class="p_chunk">@@ -750,6 +750,7 @@</span> <span class="p_context"></span>
 			reg = &lt;0x10120000 0x1000&gt;;
 			interrupt-names = &quot;combined&quot;;
 			interrupts = &lt;14&gt;;
<span class="p_add">+			interrupt-parent = &lt;&amp;vica&gt;;</span>
 			clocks = &lt;&amp;clcdclk&gt;, &lt;&amp;hclkclcd&gt;;
 			clock-names = &quot;clcdclk&quot;, &quot;apb_pclk&quot;;
 			status = &quot;disabled&quot;;
<span class="p_header">diff --git a/arch/arm/boot/dts/stih407.dtsi b/arch/arm/boot/dts/stih407.dtsi</span>
<span class="p_header">index fa149837df14..11fdecd9312e 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/stih407.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/stih407.dtsi</span>
<span class="p_chunk">@@ -8,6 +8,7 @@</span> <span class="p_context"></span>
  */
 #include &quot;stih407-clock.dtsi&quot;
 #include &quot;stih407-family.dtsi&quot;
<span class="p_add">+#include &lt;dt-bindings/gpio/gpio.h&gt;</span>
 / {
 	soc {
 		sti-display-subsystem {
<span class="p_chunk">@@ -122,7 +123,7 @@</span> <span class="p_context"></span>
 					 &lt;&amp;clk_s_d2_quadfs 0&gt;,
 					 &lt;&amp;clk_s_d2_quadfs 1&gt;;
 
<span class="p_del">-				hdmi,hpd-gpio = &lt;&amp;pio5 3&gt;;</span>
<span class="p_add">+				hdmi,hpd-gpio = &lt;&amp;pio5 3 GPIO_ACTIVE_LOW&gt;;</span>
 				reset-names = &quot;hdmi&quot;;
 				resets = &lt;&amp;softreset STIH407_HDMI_TX_PHY_SOFTRESET&gt;;
 				ddc = &lt;&amp;hdmiddc&gt;;
<span class="p_header">diff --git a/arch/arm/boot/dts/stih410.dtsi b/arch/arm/boot/dts/stih410.dtsi</span>
<span class="p_header">index 21fe72b183d8..96eed0dc08b8 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/stih410.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/stih410.dtsi</span>
<span class="p_chunk">@@ -9,6 +9,7 @@</span> <span class="p_context"></span>
 #include &quot;stih410-clock.dtsi&quot;
 #include &quot;stih407-family.dtsi&quot;
 #include &quot;stih410-pinctrl.dtsi&quot;
<span class="p_add">+#include &lt;dt-bindings/gpio/gpio.h&gt;</span>
 / {
 	aliases {
 		bdisp0 = &amp;bdisp0;
<span class="p_chunk">@@ -213,7 +214,7 @@</span> <span class="p_context"></span>
 					 &lt;&amp;clk_s_d2_quadfs 0&gt;,
 					 &lt;&amp;clk_s_d2_quadfs 1&gt;;
 
<span class="p_del">-				hdmi,hpd-gpio = &lt;&amp;pio5 3&gt;;</span>
<span class="p_add">+				hdmi,hpd-gpio = &lt;&amp;pio5 3 GPIO_ACTIVE_LOW&gt;;</span>
 				reset-names = &quot;hdmi&quot;;
 				resets = &lt;&amp;softreset STIH407_HDMI_TX_PHY_SOFTRESET&gt;;
 				ddc = &lt;&amp;hdmiddc&gt;;
<span class="p_header">diff --git a/arch/arm/include/asm/dma-iommu.h b/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_header">index 0722ec6be692..6821f1249300 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_chunk">@@ -7,7 +7,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm_types.h&gt;
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/dma-debug.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kref.h&gt;
 
 #define ARM_MAPPING_ERROR		(~(dma_addr_t)0x0)
<span class="p_header">diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="p_header">index b2902a5cd780..2d7344f0e208 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -57,7 +57,7 @@</span> <span class="p_context"> static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
 extern pgd_t *pgd_alloc(struct mm_struct *mm);
 extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 
<span class="p_del">-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
 
 static inline void clean_pte_table(pte_t *pte)
 {
<span class="p_header">diff --git a/arch/arm/mach-pxa/tosa-bt.c b/arch/arm/mach-pxa/tosa-bt.c</span>
<span class="p_header">index 107f37210fb9..83606087edc7 100644</span>
<span class="p_header">--- a/arch/arm/mach-pxa/tosa-bt.c</span>
<span class="p_header">+++ b/arch/arm/mach-pxa/tosa-bt.c</span>
<span class="p_chunk">@@ -132,3 +132,7 @@</span> <span class="p_context"> static struct platform_driver tosa_bt_driver = {</span>
 	},
 };
 module_platform_driver(tosa_bt_driver);
<span class="p_add">+</span>
<span class="p_add">+MODULE_LICENSE(&quot;GPL&quot;);</span>
<span class="p_add">+MODULE_AUTHOR(&quot;Dmitry Baryshkov&quot;);</span>
<span class="p_add">+MODULE_DESCRIPTION(&quot;Bluetooth built-in chip control&quot;);</span>
<span class="p_header">diff --git a/arch/arm64/boot/dts/qcom/msm8916.dtsi b/arch/arm64/boot/dts/qcom/msm8916.dtsi</span>
<span class="p_header">index dc3817593e14..61da6e65900b 100644</span>
<span class="p_header">--- a/arch/arm64/boot/dts/qcom/msm8916.dtsi</span>
<span class="p_header">+++ b/arch/arm64/boot/dts/qcom/msm8916.dtsi</span>
<span class="p_chunk">@@ -901,6 +901,7 @@</span> <span class="p_context"></span>
 					    &quot;dsi_phy_regulator&quot;;
 
 				#clock-cells = &lt;1&gt;;
<span class="p_add">+				#phy-cells = &lt;0&gt;;</span>
 
 				clocks = &lt;&amp;gcc GCC_MDSS_AHB_CLK&gt;;
 				clock-names = &quot;iface_clk&quot;;
<span class="p_chunk">@@ -1430,8 +1431,8 @@</span> <span class="p_context"></span>
 		#address-cells = &lt;1&gt;;
 		#size-cells = &lt;0&gt;;
 
<span class="p_del">-		qcom,ipc-1 = &lt;&amp;apcs 0 13&gt;;</span>
<span class="p_del">-		qcom,ipc-6 = &lt;&amp;apcs 0 19&gt;;</span>
<span class="p_add">+		qcom,ipc-1 = &lt;&amp;apcs 8 13&gt;;</span>
<span class="p_add">+		qcom,ipc-3 = &lt;&amp;apcs 8 19&gt;;</span>
 
 		apps_smsm: apps@0 {
 			reg = &lt;0&gt;;
<span class="p_header">diff --git a/arch/arm64/include/asm/pgalloc.h b/arch/arm64/include/asm/pgalloc.h</span>
<span class="p_header">index d25f4f137c2a..5ca6a573a701 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -26,7 +26,7 @@</span> <span class="p_context"></span>
 
 #define check_pgt_cache()		do { } while (0)
 
<span class="p_del">-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
 #define PGD_SIZE	(PTRS_PER_PGD * sizeof(pgd_t))
 
 #if CONFIG_PGTABLE_LEVELS &gt; 2
<span class="p_header">diff --git a/arch/arm64/kernel/cpu_errata.c b/arch/arm64/kernel/cpu_errata.c</span>
<span class="p_header">index 07823595b7f0..52f15cd896e1 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/cpu_errata.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/cpu_errata.c</span>
<span class="p_chunk">@@ -406,6 +406,15 @@</span> <span class="p_context"> const struct arm64_cpu_capabilities arm64_errata[] = {</span>
 		.capability = ARM64_HARDEN_BP_POST_GUEST_EXIT,
 		MIDR_ALL_VERSIONS(MIDR_QCOM_FALKOR_V1),
 	},
<span class="p_add">+	{</span>
<span class="p_add">+		.capability = ARM64_HARDEN_BRANCH_PREDICTOR,</span>
<span class="p_add">+		MIDR_ALL_VERSIONS(MIDR_QCOM_FALKOR),</span>
<span class="p_add">+		.enable = qcom_enable_link_stack_sanitization,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.capability = ARM64_HARDEN_BP_POST_GUEST_EXIT,</span>
<span class="p_add">+		MIDR_ALL_VERSIONS(MIDR_QCOM_FALKOR),</span>
<span class="p_add">+	},</span>
 	{
 		.capability = ARM64_HARDEN_BRANCH_PREDICTOR,
 		MIDR_ALL_VERSIONS(MIDR_BRCM_VULCAN),
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/switch.c b/arch/arm64/kvm/hyp/switch.c</span>
<span class="p_header">index 79364d3455c0..e08ae6b6b63e 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/switch.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/switch.c</span>
<span class="p_chunk">@@ -371,8 +371,10 @@</span> <span class="p_context"> int __hyp_text __kvm_vcpu_run(struct kvm_vcpu *vcpu)</span>
 		u32 midr = read_cpuid_id();
 
 		/* Apply BTAC predictors mitigation to all Falkor chips */
<span class="p_del">-		if ((midr &amp; MIDR_CPU_MODEL_MASK) == MIDR_QCOM_FALKOR_V1)</span>
<span class="p_add">+		if (((midr &amp; MIDR_CPU_MODEL_MASK) == MIDR_QCOM_FALKOR) ||</span>
<span class="p_add">+		    ((midr &amp; MIDR_CPU_MODEL_MASK) == MIDR_QCOM_FALKOR_V1)) {</span>
 			__qcom_hyp_sanitize_btac_predictors();
<span class="p_add">+		}</span>
 	}
 
 	fp_enabled = __fpsimd_enabled();
<span class="p_header">diff --git a/arch/arm64/mm/proc.S b/arch/arm64/mm/proc.S</span>
<span class="p_header">index 27058f3fd132..329a1c43365e 100644</span>
<span class="p_header">--- a/arch/arm64/mm/proc.S</span>
<span class="p_header">+++ b/arch/arm64/mm/proc.S</span>
<span class="p_chunk">@@ -190,7 +190,8 @@</span> <span class="p_context"> ENDPROC(idmap_cpu_replace_ttbr1)</span>
 	dc	cvac, cur_\()\type\()p		// Ensure any existing dirty
 	dmb	sy				// lines are written back before
 	ldr	\type, [cur_\()\type\()p]	// loading the entry
<span class="p_del">-	tbz	\type, #0, next_\()\type	// Skip invalid entries</span>
<span class="p_add">+	tbz	\type, #0, skip_\()\type	// Skip invalid and</span>
<span class="p_add">+	tbnz	\type, #11, skip_\()\type	// non-global entries</span>
 	.endm
 
 	.macro __idmap_kpti_put_pgtable_ent_ng, type
<span class="p_chunk">@@ -249,8 +250,9 @@</span> <span class="p_context"> ENTRY(idmap_kpti_install_ng_mappings)</span>
 	add	end_pgdp, cur_pgdp, #(PTRS_PER_PGD * 8)
 do_pgd:	__idmap_kpti_get_pgtable_ent	pgd
 	tbnz	pgd, #1, walk_puds
<span class="p_del">-	__idmap_kpti_put_pgtable_ent_ng	pgd</span>
 next_pgd:
<span class="p_add">+	__idmap_kpti_put_pgtable_ent_ng	pgd</span>
<span class="p_add">+skip_pgd:</span>
 	add	cur_pgdp, cur_pgdp, #8
 	cmp	cur_pgdp, end_pgdp
 	b.ne	do_pgd
<span class="p_chunk">@@ -278,8 +280,9 @@</span> <span class="p_context"> walk_puds:</span>
 	add	end_pudp, cur_pudp, #(PTRS_PER_PUD * 8)
 do_pud:	__idmap_kpti_get_pgtable_ent	pud
 	tbnz	pud, #1, walk_pmds
<span class="p_del">-	__idmap_kpti_put_pgtable_ent_ng	pud</span>
 next_pud:
<span class="p_add">+	__idmap_kpti_put_pgtable_ent_ng	pud</span>
<span class="p_add">+skip_pud:</span>
 	add	cur_pudp, cur_pudp, 8
 	cmp	cur_pudp, end_pudp
 	b.ne	do_pud
<span class="p_chunk">@@ -298,8 +301,9 @@</span> <span class="p_context"> walk_pmds:</span>
 	add	end_pmdp, cur_pmdp, #(PTRS_PER_PMD * 8)
 do_pmd:	__idmap_kpti_get_pgtable_ent	pmd
 	tbnz	pmd, #1, walk_ptes
<span class="p_del">-	__idmap_kpti_put_pgtable_ent_ng	pmd</span>
 next_pmd:
<span class="p_add">+	__idmap_kpti_put_pgtable_ent_ng	pmd</span>
<span class="p_add">+skip_pmd:</span>
 	add	cur_pmdp, cur_pmdp, #8
 	cmp	cur_pmdp, end_pmdp
 	b.ne	do_pmd
<span class="p_chunk">@@ -317,7 +321,7 @@</span> <span class="p_context"> walk_ptes:</span>
 	add	end_ptep, cur_ptep, #(PTRS_PER_PTE * 8)
 do_pte:	__idmap_kpti_get_pgtable_ent	pte
 	__idmap_kpti_put_pgtable_ent_ng	pte
<span class="p_del">-next_pte:</span>
<span class="p_add">+skip_pte:</span>
 	add	cur_ptep, cur_ptep, #8
 	cmp	cur_ptep, end_ptep
 	b.ne	do_pte
<span class="p_header">diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig</span>
<span class="p_header">index c3d798b44030..c82457b0e733 100644</span>
<span class="p_header">--- a/arch/mips/Kconfig</span>
<span class="p_header">+++ b/arch/mips/Kconfig</span>
<span class="p_chunk">@@ -119,12 +119,12 @@</span> <span class="p_context"> config MIPS_GENERIC</span>
 	select SYS_SUPPORTS_MULTITHREADING
 	select SYS_SUPPORTS_RELOCATABLE
 	select SYS_SUPPORTS_SMARTMIPS
<span class="p_del">-	select USB_EHCI_BIG_ENDIAN_DESC if BIG_ENDIAN</span>
<span class="p_del">-	select USB_EHCI_BIG_ENDIAN_MMIO if BIG_ENDIAN</span>
<span class="p_del">-	select USB_OHCI_BIG_ENDIAN_DESC if BIG_ENDIAN</span>
<span class="p_del">-	select USB_OHCI_BIG_ENDIAN_MMIO if BIG_ENDIAN</span>
<span class="p_del">-	select USB_UHCI_BIG_ENDIAN_DESC if BIG_ENDIAN</span>
<span class="p_del">-	select USB_UHCI_BIG_ENDIAN_MMIO if BIG_ENDIAN</span>
<span class="p_add">+	select USB_EHCI_BIG_ENDIAN_DESC if CPU_BIG_ENDIAN</span>
<span class="p_add">+	select USB_EHCI_BIG_ENDIAN_MMIO if CPU_BIG_ENDIAN</span>
<span class="p_add">+	select USB_OHCI_BIG_ENDIAN_DESC if CPU_BIG_ENDIAN</span>
<span class="p_add">+	select USB_OHCI_BIG_ENDIAN_MMIO if CPU_BIG_ENDIAN</span>
<span class="p_add">+	select USB_UHCI_BIG_ENDIAN_DESC if CPU_BIG_ENDIAN</span>
<span class="p_add">+	select USB_UHCI_BIG_ENDIAN_MMIO if CPU_BIG_ENDIAN</span>
 	select USE_OF
 	help
 	  Select this to build a kernel which aims to support multiple boards,
<span class="p_header">diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c</span>
<span class="p_header">index fe3939726765..795caa763da3 100644</span>
<span class="p_header">--- a/arch/mips/kernel/setup.c</span>
<span class="p_header">+++ b/arch/mips/kernel/setup.c</span>
<span class="p_chunk">@@ -374,6 +374,7 @@</span> <span class="p_context"> static void __init bootmem_init(void)</span>
 	unsigned long reserved_end;
 	unsigned long mapstart = ~0UL;
 	unsigned long bootmap_size;
<span class="p_add">+	phys_addr_t ramstart = (phys_addr_t)ULLONG_MAX;</span>
 	bool bootmap_valid = false;
 	int i;
 
<span class="p_chunk">@@ -394,7 +395,8 @@</span> <span class="p_context"> static void __init bootmem_init(void)</span>
 	max_low_pfn = 0;
 
 	/*
<span class="p_del">-	 * Find the highest page frame number we have available.</span>
<span class="p_add">+	 * Find the highest page frame number we have available</span>
<span class="p_add">+	 * and the lowest used RAM address</span>
 	 */
 	for (i = 0; i &lt; boot_mem_map.nr_map; i++) {
 		unsigned long start, end;
<span class="p_chunk">@@ -406,6 +408,8 @@</span> <span class="p_context"> static void __init bootmem_init(void)</span>
 		end = PFN_DOWN(boot_mem_map.map[i].addr
 				+ boot_mem_map.map[i].size);
 
<span class="p_add">+		ramstart = min(ramstart, boot_mem_map.map[i].addr);</span>
<span class="p_add">+</span>
 #ifndef CONFIG_HIGHMEM
 		/*
 		 * Skip highmem here so we get an accurate max_low_pfn if low
<span class="p_chunk">@@ -435,6 +439,13 @@</span> <span class="p_context"> static void __init bootmem_init(void)</span>
 		mapstart = max(reserved_end, start);
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Reserve any memory between the start of RAM and PHYS_OFFSET</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (ramstart &gt; PHYS_OFFSET)</span>
<span class="p_add">+		add_memory_region(PHYS_OFFSET, ramstart - PHYS_OFFSET,</span>
<span class="p_add">+				  BOOT_MEM_RESERVED);</span>
<span class="p_add">+</span>
 	if (min_low_pfn &gt;= max_low_pfn)
 		panic(&quot;Incorrect memory mapping !!!&quot;);
 	if (min_low_pfn &gt; ARCH_PFN_OFFSET) {
<span class="p_chunk">@@ -663,9 +674,6 @@</span> <span class="p_context"> static int __init early_parse_mem(char *p)</span>
 
 	add_memory_region(start, size, BOOT_MEM_RAM);
 
<span class="p_del">-	if (start &amp;&amp; start &gt; PHYS_OFFSET)</span>
<span class="p_del">-		add_memory_region(PHYS_OFFSET, start - PHYS_OFFSET,</span>
<span class="p_del">-				BOOT_MEM_RESERVED);</span>
 	return 0;
 }
 early_param(&quot;mem&quot;, early_parse_mem);
<span class="p_header">diff --git a/arch/openrisc/include/asm/dma-mapping.h b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_header">index f41bd3cb76d9..e212a1f0b6d2 100644</span>
<span class="p_header">--- a/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -23,7 +23,6 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;linux/dma-debug.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/dma-mapping.h&gt;
 
 extern const struct dma_map_ops or1k_dma_map_ops;
<span class="p_header">diff --git a/arch/powerpc/include/asm/pgalloc.h b/arch/powerpc/include/asm/pgalloc.h</span>
<span class="p_header">index a14203c005f1..e11f03007b57 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -18,7 +18,7 @@</span> <span class="p_context"> static inline gfp_t pgtable_gfp_flags(struct mm_struct *mm, gfp_t gfp)</span>
 }
 #endif /* MODULE */
 
<span class="p_del">-#define PGALLOC_GFP (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP (GFP_KERNEL | __GFP_ZERO)</span>
 
 #ifdef CONFIG_PPC_BOOK3S
 #include &lt;asm/book3s/pgalloc.h&gt;
<span class="p_header">diff --git a/arch/powerpc/include/asm/topology.h b/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">index 023ff9f17501..d5f2ee882f74 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/topology.h</span>
<span class="p_chunk">@@ -44,6 +44,11 @@</span> <span class="p_context"> extern int sysfs_add_device_to_node(struct device *dev, int nid);</span>
 extern void sysfs_remove_device_from_node(struct device *dev, int nid);
 extern int numa_update_cpu_topology(bool cpus_locked);
 
<span class="p_add">+static inline void update_numa_cpu_lookup_table(unsigned int cpu, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	numa_cpu_lookup_table[cpu] = node;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int early_cpu_to_node(int cpu)
 {
 	int nid;
<span class="p_header">diff --git a/arch/powerpc/kernel/exceptions-64s.S b/arch/powerpc/kernel/exceptions-64s.S</span>
<span class="p_header">index e9f72abc52b7..e91b40aa5417 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/exceptions-64s.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/exceptions-64s.S</span>
<span class="p_chunk">@@ -1617,7 +1617,7 @@</span> <span class="p_context"> USE_TEXT_SECTION()</span>
 	.balign	IFETCH_ALIGN_BYTES
 do_hash_page:
 	#ifdef CONFIG_PPC_STD_MMU_64
<span class="p_del">-	lis	r0,DSISR_BAD_FAULT_64S@h</span>
<span class="p_add">+	lis	r0,(DSISR_BAD_FAULT_64S|DSISR_DABRMATCH)@h</span>
 	ori	r0,r0,DSISR_BAD_FAULT_64S@l
 	and.	r0,r4,r0		/* weird error? */
 	bne-	handle_page_fault	/* if not, try to insert a HPTE */
<span class="p_header">diff --git a/arch/powerpc/kernel/head_32.S b/arch/powerpc/kernel/head_32.S</span>
<span class="p_header">index 8c54166491e7..29b2fed93289 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/head_32.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/head_32.S</span>
<span class="p_chunk">@@ -388,7 +388,7 @@</span> <span class="p_context"> DataAccess:</span>
 	EXCEPTION_PROLOG
 	mfspr	r10,SPRN_DSISR
 	stw	r10,_DSISR(r11)
<span class="p_del">-	andis.	r0,r10,DSISR_BAD_FAULT_32S@h</span>
<span class="p_add">+	andis.	r0,r10,(DSISR_BAD_FAULT_32S|DSISR_DABRMATCH)@h</span>
 	bne	1f			/* if not, try to put a PTE */
 	mfspr	r4,SPRN_DAR		/* into the hash table */
 	rlwinm	r3,r10,32-15,21,21	/* DSISR_STORE -&gt; _PAGE_RW */
<span class="p_header">diff --git a/arch/powerpc/mm/numa.c b/arch/powerpc/mm/numa.c</span>
<span class="p_header">index a51df9ef529d..a81279249bfb 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/numa.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/numa.c</span>
<span class="p_chunk">@@ -142,11 +142,6 @@</span> <span class="p_context"> static void reset_numa_cpu_lookup_table(void)</span>
 		numa_cpu_lookup_table[cpu] = -1;
 }
 
<span class="p_del">-static void update_numa_cpu_lookup_table(unsigned int cpu, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-	numa_cpu_lookup_table[cpu] = node;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void map_cpu_to_node(int cpu, int node)
 {
 	update_numa_cpu_lookup_table(cpu, node);
<span class="p_header">diff --git a/arch/powerpc/mm/pgtable-radix.c b/arch/powerpc/mm/pgtable-radix.c</span>
<span class="p_header">index cfbbee941a76..17ae5c15a9e0 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/pgtable-radix.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/pgtable-radix.c</span>
<span class="p_chunk">@@ -17,6 +17,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/of_fdt.h&gt;
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/string_helpers.h&gt;
<span class="p_add">+#include &lt;linux/stop_machine.h&gt;</span>
 
 #include &lt;asm/pgtable.h&gt;
 #include &lt;asm/pgalloc.h&gt;
<span class="p_chunk">@@ -671,6 +672,30 @@</span> <span class="p_context"> static void free_pmd_table(pmd_t *pmd_start, pud_t *pud)</span>
 	pud_clear(pud);
 }
 
<span class="p_add">+struct change_mapping_params {</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	unsigned long start;</span>
<span class="p_add">+	unsigned long end;</span>
<span class="p_add">+	unsigned long aligned_start;</span>
<span class="p_add">+	unsigned long aligned_end;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int stop_machine_change_mapping(void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct change_mapping_params *params =</span>
<span class="p_add">+			(struct change_mapping_params *)data;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!data)</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock(&amp;init_mm.page_table_lock);</span>
<span class="p_add">+	pte_clear(&amp;init_mm, params-&gt;aligned_start, params-&gt;pte);</span>
<span class="p_add">+	create_physical_mapping(params-&gt;aligned_start, params-&gt;start);</span>
<span class="p_add">+	create_physical_mapping(params-&gt;end, params-&gt;aligned_end);</span>
<span class="p_add">+	spin_lock(&amp;init_mm.page_table_lock);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void remove_pte_table(pte_t *pte_start, unsigned long addr,
 			     unsigned long end)
 {
<span class="p_chunk">@@ -699,6 +724,52 @@</span> <span class="p_context"> static void remove_pte_table(pte_t *pte_start, unsigned long addr,</span>
 	}
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * clear the pte and potentially split the mapping helper</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void split_kernel_mapping(unsigned long addr, unsigned long end,</span>
<span class="p_add">+				unsigned long size, pte_t *pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long mask = ~(size - 1);</span>
<span class="p_add">+	unsigned long aligned_start = addr &amp; mask;</span>
<span class="p_add">+	unsigned long aligned_end = addr + size;</span>
<span class="p_add">+	struct change_mapping_params params;</span>
<span class="p_add">+	bool split_region = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - addr) &lt; size) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We&#39;re going to clear the PTE, but not flushed</span>
<span class="p_add">+		 * the mapping, time to remap and flush. The</span>
<span class="p_add">+		 * effects if visible outside the processor or</span>
<span class="p_add">+		 * if we are running in code close to the</span>
<span class="p_add">+		 * mapping we cleared, we are in trouble.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (overlaps_kernel_text(aligned_start, addr) ||</span>
<span class="p_add">+			overlaps_kernel_text(end, aligned_end)) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Hack, just return, don&#39;t pte_clear</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			WARN_ONCE(1, &quot;Linear mapping %lx-&gt;%lx overlaps kernel &quot;</span>
<span class="p_add">+				  &quot;text, not splitting\n&quot;, addr, end);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		split_region = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (split_region) {</span>
<span class="p_add">+		params.pte = pte;</span>
<span class="p_add">+		params.start = addr;</span>
<span class="p_add">+		params.end = end;</span>
<span class="p_add">+		params.aligned_start = addr &amp; ~(size - 1);</span>
<span class="p_add">+		params.aligned_end = min_t(unsigned long, aligned_end,</span>
<span class="p_add">+				(unsigned long)__va(memblock_end_of_DRAM()));</span>
<span class="p_add">+		stop_machine(stop_machine_change_mapping, &amp;params, NULL);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pte_clear(&amp;init_mm, addr, pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void remove_pmd_table(pmd_t *pmd_start, unsigned long addr,
 			     unsigned long end)
 {
<span class="p_chunk">@@ -714,13 +785,7 @@</span> <span class="p_context"> static void remove_pmd_table(pmd_t *pmd_start, unsigned long addr,</span>
 			continue;
 
 		if (pmd_huge(*pmd)) {
<span class="p_del">-			if (!IS_ALIGNED(addr, PMD_SIZE) ||</span>
<span class="p_del">-			    !IS_ALIGNED(next, PMD_SIZE)) {</span>
<span class="p_del">-				WARN_ONCE(1, &quot;%s: unaligned range\n&quot;, __func__);</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			pte_clear(&amp;init_mm, addr, (pte_t *)pmd);</span>
<span class="p_add">+			split_kernel_mapping(addr, end, PMD_SIZE, (pte_t *)pmd);</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -745,13 +810,7 @@</span> <span class="p_context"> static void remove_pud_table(pud_t *pud_start, unsigned long addr,</span>
 			continue;
 
 		if (pud_huge(*pud)) {
<span class="p_del">-			if (!IS_ALIGNED(addr, PUD_SIZE) ||</span>
<span class="p_del">-			    !IS_ALIGNED(next, PUD_SIZE)) {</span>
<span class="p_del">-				WARN_ONCE(1, &quot;%s: unaligned range\n&quot;, __func__);</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			pte_clear(&amp;init_mm, addr, (pte_t *)pud);</span>
<span class="p_add">+			split_kernel_mapping(addr, end, PUD_SIZE, (pte_t *)pud);</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -777,13 +836,7 @@</span> <span class="p_context"> static void remove_pagetable(unsigned long start, unsigned long end)</span>
 			continue;
 
 		if (pgd_huge(*pgd)) {
<span class="p_del">-			if (!IS_ALIGNED(addr, PGDIR_SIZE) ||</span>
<span class="p_del">-			    !IS_ALIGNED(next, PGDIR_SIZE)) {</span>
<span class="p_del">-				WARN_ONCE(1, &quot;%s: unaligned range\n&quot;, __func__);</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			pte_clear(&amp;init_mm, addr, (pte_t *)pgd);</span>
<span class="p_add">+			split_kernel_mapping(addr, end, PGDIR_SIZE, (pte_t *)pgd);</span>
 			continue;
 		}
 
<span class="p_header">diff --git a/arch/powerpc/mm/pgtable_64.c b/arch/powerpc/mm/pgtable_64.c</span>
<span class="p_header">index ac0717a90ca6..12f95b1f7d07 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/pgtable_64.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/pgtable_64.c</span>
<span class="p_chunk">@@ -483,6 +483,8 @@</span> <span class="p_context"> void mmu_partition_table_set_entry(unsigned int lpid, unsigned long dw0,</span>
 	if (old &amp; PATB_HR) {
 		asm volatile(PPC_TLBIE_5(%0,%1,2,0,1) : :
 			     &quot;r&quot; (TLBIEL_INVAL_SET_LPID), &quot;r&quot; (lpid));
<span class="p_add">+		asm volatile(PPC_TLBIE_5(%0,%1,2,1,1) : :</span>
<span class="p_add">+			     &quot;r&quot; (TLBIEL_INVAL_SET_LPID), &quot;r&quot; (lpid));</span>
 		trace_tlbie(lpid, 0, TLBIEL_INVAL_SET_LPID, lpid, 2, 0, 1);
 	} else {
 		asm volatile(PPC_TLBIE_5(%0,%1,2,0,0) : :
<span class="p_header">diff --git a/arch/powerpc/mm/tlb-radix.c b/arch/powerpc/mm/tlb-radix.c</span>
<span class="p_header">index d304028641a2..4b295cfd5f7e 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/tlb-radix.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/tlb-radix.c</span>
<span class="p_chunk">@@ -453,14 +453,12 @@</span> <span class="p_context"> void radix__flush_tlb_all(void)</span>
 	 */
 	asm volatile(PPC_TLBIE_5(%0, %4, %3, %2, %1)
 		     : : &quot;r&quot;(rb), &quot;i&quot;(r), &quot;i&quot;(1), &quot;i&quot;(ric), &quot;r&quot;(rs) : &quot;memory&quot;);
<span class="p_del">-	trace_tlbie(0, 0, rb, rs, ric, prs, r);</span>
 	/*
 	 * now flush host entires by passing PRS = 0 and LPID == 0
 	 */
 	asm volatile(PPC_TLBIE_5(%0, %4, %3, %2, %1)
 		     : : &quot;r&quot;(rb), &quot;i&quot;(r), &quot;i&quot;(prs), &quot;i&quot;(ric), &quot;r&quot;(0) : &quot;memory&quot;);
 	asm volatile(&quot;eieio; tlbsync; ptesync&quot;: : :&quot;memory&quot;);
<span class="p_del">-	trace_tlbie(0, 0, rb, 0, ric, prs, r);</span>
 }
 
 void radix__flush_tlb_pte_p9_dd1(unsigned long old_pte, struct mm_struct *mm,
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/hotplug-cpu.c b/arch/powerpc/platforms/pseries/hotplug-cpu.c</span>
<span class="p_header">index fadb95efbb9e..b1ac8ac38434 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/hotplug-cpu.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/hotplug-cpu.c</span>
<span class="p_chunk">@@ -36,6 +36,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/xics.h&gt;
 #include &lt;asm/xive.h&gt;
 #include &lt;asm/plpar_wrappers.h&gt;
<span class="p_add">+#include &lt;asm/topology.h&gt;</span>
 
 #include &quot;pseries.h&quot;
 #include &quot;offline_states.h&quot;
<span class="p_chunk">@@ -331,6 +332,7 @@</span> <span class="p_context"> static void pseries_remove_processor(struct device_node *np)</span>
 			BUG_ON(cpu_online(cpu));
 			set_cpu_present(cpu, false);
 			set_hard_smp_processor_id(cpu, -1);
<span class="p_add">+			update_numa_cpu_lookup_table(cpu, -1);</span>
 			break;
 		}
 		if (cpu &gt;= nr_cpu_ids)
<span class="p_header">diff --git a/arch/powerpc/sysdev/xive/spapr.c b/arch/powerpc/sysdev/xive/spapr.c</span>
<span class="p_header">index d9c4c9366049..091f1d0d0af1 100644</span>
<span class="p_header">--- a/arch/powerpc/sysdev/xive/spapr.c</span>
<span class="p_header">+++ b/arch/powerpc/sysdev/xive/spapr.c</span>
<span class="p_chunk">@@ -356,7 +356,8 @@</span> <span class="p_context"> static int xive_spapr_configure_queue(u32 target, struct xive_q *q, u8 prio,</span>
 
 	rc = plpar_int_get_queue_info(0, target, prio, &amp;esn_page, &amp;esn_size);
 	if (rc) {
<span class="p_del">-		pr_err(&quot;Error %lld getting queue info prio %d\n&quot;, rc, prio);</span>
<span class="p_add">+		pr_err(&quot;Error %lld getting queue info CPU %d prio %d\n&quot;, rc,</span>
<span class="p_add">+		       target, prio);</span>
 		rc = -EIO;
 		goto fail;
 	}
<span class="p_chunk">@@ -370,7 +371,8 @@</span> <span class="p_context"> static int xive_spapr_configure_queue(u32 target, struct xive_q *q, u8 prio,</span>
 	/* Configure and enable the queue in HW */
 	rc = plpar_int_set_queue_config(flags, target, prio, qpage_phys, order);
 	if (rc) {
<span class="p_del">-		pr_err(&quot;Error %lld setting queue for prio %d\n&quot;, rc, prio);</span>
<span class="p_add">+		pr_err(&quot;Error %lld setting queue for CPU %d prio %d\n&quot;, rc,</span>
<span class="p_add">+		       target, prio);</span>
 		rc = -EIO;
 	} else {
 		q-&gt;qpage = qpage;
<span class="p_chunk">@@ -389,8 +391,8 @@</span> <span class="p_context"> static int xive_spapr_setup_queue(unsigned int cpu, struct xive_cpu *xc,</span>
 	if (IS_ERR(qpage))
 		return PTR_ERR(qpage);
 
<span class="p_del">-	return xive_spapr_configure_queue(cpu, q, prio, qpage,</span>
<span class="p_del">-					  xive_queue_shift);</span>
<span class="p_add">+	return xive_spapr_configure_queue(get_hard_smp_processor_id(cpu),</span>
<span class="p_add">+					  q, prio, qpage, xive_queue_shift);</span>
 }
 
 static void xive_spapr_cleanup_queue(unsigned int cpu, struct xive_cpu *xc,
<span class="p_chunk">@@ -399,10 +401,12 @@</span> <span class="p_context"> static void xive_spapr_cleanup_queue(unsigned int cpu, struct xive_cpu *xc,</span>
 	struct xive_q *q = &amp;xc-&gt;queue[prio];
 	unsigned int alloc_order;
 	long rc;
<span class="p_add">+	int hw_cpu = get_hard_smp_processor_id(cpu);</span>
 
<span class="p_del">-	rc = plpar_int_set_queue_config(0, cpu, prio, 0, 0);</span>
<span class="p_add">+	rc = plpar_int_set_queue_config(0, hw_cpu, prio, 0, 0);</span>
 	if (rc)
<span class="p_del">-		pr_err(&quot;Error %ld setting queue for prio %d\n&quot;, rc, prio);</span>
<span class="p_add">+		pr_err(&quot;Error %ld setting queue for CPU %d prio %d\n&quot;, rc,</span>
<span class="p_add">+		       hw_cpu, prio);</span>
 
 	alloc_order = xive_alloc_order(xive_queue_shift);
 	free_pages((unsigned long)q-&gt;qpage, alloc_order);
<span class="p_header">diff --git a/arch/s390/kernel/compat_linux.c b/arch/s390/kernel/compat_linux.c</span>
<span class="p_header">index 59eea9c65d3e..79b7a3438d54 100644</span>
<span class="p_header">--- a/arch/s390/kernel/compat_linux.c</span>
<span class="p_header">+++ b/arch/s390/kernel/compat_linux.c</span>
<span class="p_chunk">@@ -110,7 +110,7 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE2(s390_setregid16, u16, rgid, u16, egid)</span>
 
 COMPAT_SYSCALL_DEFINE1(s390_setgid16, u16, gid)
 {
<span class="p_del">-	return sys_setgid((gid_t)gid);</span>
<span class="p_add">+	return sys_setgid(low2highgid(gid));</span>
 }
 
 COMPAT_SYSCALL_DEFINE2(s390_setreuid16, u16, ruid, u16, euid)
<span class="p_chunk">@@ -120,7 +120,7 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE2(s390_setreuid16, u16, ruid, u16, euid)</span>
 
 COMPAT_SYSCALL_DEFINE1(s390_setuid16, u16, uid)
 {
<span class="p_del">-	return sys_setuid((uid_t)uid);</span>
<span class="p_add">+	return sys_setuid(low2highuid(uid));</span>
 }
 
 COMPAT_SYSCALL_DEFINE3(s390_setresuid16, u16, ruid, u16, euid, u16, suid)
<span class="p_chunk">@@ -173,12 +173,12 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE3(s390_getresgid16, u16 __user *, rgidp,</span>
 
 COMPAT_SYSCALL_DEFINE1(s390_setfsuid16, u16, uid)
 {
<span class="p_del">-	return sys_setfsuid((uid_t)uid);</span>
<span class="p_add">+	return sys_setfsuid(low2highuid(uid));</span>
 }
 
 COMPAT_SYSCALL_DEFINE1(s390_setfsgid16, u16, gid)
 {
<span class="p_del">-	return sys_setfsgid((gid_t)gid);</span>
<span class="p_add">+	return sys_setfsgid(low2highgid(gid));</span>
 }
 
 static int groups16_to_user(u16 __user *grouplist, struct group_info *group_info)
<span class="p_header">diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c</span>
<span class="p_header">index e1d751ae2498..1a2526676a87 100644</span>
<span class="p_header">--- a/arch/sh/kernel/dwarf.c</span>
<span class="p_header">+++ b/arch/sh/kernel/dwarf.c</span>
<span class="p_chunk">@@ -1172,11 +1172,11 @@</span> <span class="p_context"> static int __init dwarf_unwinder_init(void)</span>
 
 	dwarf_frame_cachep = kmem_cache_create(&quot;dwarf_frames&quot;,
 			sizeof(struct dwarf_frame), 0,
<span class="p_del">-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);</span>
<span class="p_add">+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);</span>
 
 	dwarf_reg_cachep = kmem_cache_create(&quot;dwarf_regs&quot;,
 			sizeof(struct dwarf_reg), 0,
<span class="p_del">-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);</span>
<span class="p_add">+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);</span>
 
 	dwarf_frame_pool = mempool_create_slab_pool(DWARF_FRAME_MIN_REQ,
 						    dwarf_frame_cachep);
<span class="p_header">diff --git a/arch/sh/kernel/process.c b/arch/sh/kernel/process.c</span>
<span class="p_header">index b2d9963d5978..68b1a67533ce 100644</span>
<span class="p_header">--- a/arch/sh/kernel/process.c</span>
<span class="p_header">+++ b/arch/sh/kernel/process.c</span>
<span class="p_chunk">@@ -59,7 +59,7 @@</span> <span class="p_context"> void arch_task_cache_init(void)</span>
 
 	task_xstate_cachep = kmem_cache_create(&quot;task_xstate&quot;, xstate_size,
 					       __alignof__(union thread_xstate),
<span class="p_del">-					       SLAB_PANIC | SLAB_NOTRACK, NULL);</span>
<span class="p_add">+					       SLAB_PANIC, NULL);</span>
 }
 
 #ifdef CONFIG_SH_FPU_EMU
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index a0cc1be767c8..984e9d65ea0d 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -2934,7 +2934,7 @@</span> <span class="p_context"> void __flush_tlb_all(void)</span>
 pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
 			    unsigned long address)
 {
<span class="p_del">-	struct page *page = alloc_page(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);</span>
<span class="p_add">+	struct page *page = alloc_page(GFP_KERNEL | __GFP_ZERO);</span>
 	pte_t *pte = NULL;
 
 	if (page)
<span class="p_chunk">@@ -2946,7 +2946,7 @@</span> <span class="p_context"> pte_t *pte_alloc_one_kernel(struct mm_struct *mm,</span>
 pgtable_t pte_alloc_one(struct mm_struct *mm,
 			unsigned long address)
 {
<span class="p_del">-	struct page *page = alloc_page(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);</span>
<span class="p_add">+	struct page *page = alloc_page(GFP_KERNEL | __GFP_ZERO);</span>
 	if (!page)
 		return NULL;
 	if (!pgtable_page_ctor(page)) {
<span class="p_header">diff --git a/arch/unicore32/include/asm/pgalloc.h b/arch/unicore32/include/asm/pgalloc.h</span>
<span class="p_header">index 26775793c204..f0fdb268f8f2 100644</span>
<span class="p_header">--- a/arch/unicore32/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/unicore32/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -28,7 +28,7 @@</span> <span class="p_context"> extern void free_pgd_slow(struct mm_struct *mm, pgd_t *pgd);</span>
 #define pgd_alloc(mm)			get_pgd_slow(mm)
 #define pgd_free(mm, pgd)		free_pgd_slow(mm, pgd)
 
<span class="p_del">-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
 
 /*
  * Allocate one PTE table.
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 17de6acc0eab..559b37bf5a2e 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -111,7 +111,6 @@</span> <span class="p_context"> config X86</span>
 	select HAVE_ARCH_JUMP_LABEL
 	select HAVE_ARCH_KASAN			if X86_64
 	select HAVE_ARCH_KGDB
<span class="p_del">-	select HAVE_ARCH_KMEMCHECK</span>
 	select HAVE_ARCH_MMAP_RND_BITS		if MMU
 	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if MMU &amp;&amp; COMPAT
 	select HAVE_ARCH_COMPAT_MMAP_BASES	if MMU &amp;&amp; COMPAT
<span class="p_chunk">@@ -1443,7 +1442,7 @@</span> <span class="p_context"> config ARCH_DMA_ADDR_T_64BIT</span>
 
 config X86_DIRECT_GBPAGES
 	def_bool y
<span class="p_del">-	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC</span>
 	---help---
 	  Certain kernel features effectively disable kernel
 	  linear 1 GB mappings (even if the CPU otherwise
<span class="p_header">diff --git a/arch/x86/Makefile b/arch/x86/Makefile</span>
<span class="p_header">index 504b1a4535ac..fad55160dcb9 100644</span>
<span class="p_header">--- a/arch/x86/Makefile</span>
<span class="p_header">+++ b/arch/x86/Makefile</span>
<span class="p_chunk">@@ -158,11 +158,6 @@</span> <span class="p_context"> ifdef CONFIG_X86_X32</span>
 endif
 export CONFIG_X86_X32_ABI
 
<span class="p_del">-# Don&#39;t unroll struct assignments with kmemcheck enabled</span>
<span class="p_del">-ifeq ($(CONFIG_KMEMCHECK),y)</span>
<span class="p_del">-	KBUILD_CFLAGS += $(call cc-option,-fno-builtin-memcpy)</span>
<span class="p_del">-endif</span>
<span class="p_del">-</span>
 #
 # If the function graph tracer is used with mcount instead of fentry,
 # &#39;-maccumulate-outgoing-args&#39; is needed to prevent a GCC bug
<span class="p_header">diff --git a/arch/x86/entry/calling.h b/arch/x86/entry/calling.h</span>
<span class="p_header">index 3f48f695d5e6..dce7092ab24a 100644</span>
<span class="p_header">--- a/arch/x86/entry/calling.h</span>
<span class="p_header">+++ b/arch/x86/entry/calling.h</span>
<span class="p_chunk">@@ -97,80 +97,69 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
 
 #define SIZEOF_PTREGS	21*8
 
<span class="p_del">-	.macro ALLOC_PT_GPREGS_ON_STACK</span>
<span class="p_del">-	addq	$-(15*8), %rsp</span>
<span class="p_del">-	.endm</span>
<span class="p_add">+.macro PUSH_AND_CLEAR_REGS rdx=%rdx rax=%rax</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Push registers and sanitize registers of values that a</span>
<span class="p_add">+	 * speculation attack might otherwise want to exploit. The</span>
<span class="p_add">+	 * lower registers are likely clobbered well before they</span>
<span class="p_add">+	 * could be put to use in a speculative execution gadget.</span>
<span class="p_add">+	 * Interleave XOR with PUSH for better uop scheduling:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pushq   %rdi		/* pt_regs-&gt;di */</span>
<span class="p_add">+	pushq   %rsi		/* pt_regs-&gt;si */</span>
<span class="p_add">+	pushq	\rdx		/* pt_regs-&gt;dx */</span>
<span class="p_add">+	pushq   %rcx		/* pt_regs-&gt;cx */</span>
<span class="p_add">+	pushq   \rax		/* pt_regs-&gt;ax */</span>
<span class="p_add">+	pushq   %r8		/* pt_regs-&gt;r8 */</span>
<span class="p_add">+	xorq    %r8, %r8	/* nospec   r8 */</span>
<span class="p_add">+	pushq   %r9		/* pt_regs-&gt;r9 */</span>
<span class="p_add">+	xorq    %r9, %r9	/* nospec   r9 */</span>
<span class="p_add">+	pushq   %r10		/* pt_regs-&gt;r10 */</span>
<span class="p_add">+	xorq    %r10, %r10	/* nospec   r10 */</span>
<span class="p_add">+	pushq   %r11		/* pt_regs-&gt;r11 */</span>
<span class="p_add">+	xorq    %r11, %r11	/* nospec   r11*/</span>
<span class="p_add">+	pushq	%rbx		/* pt_regs-&gt;rbx */</span>
<span class="p_add">+	xorl    %ebx, %ebx	/* nospec   rbx*/</span>
<span class="p_add">+	pushq	%rbp		/* pt_regs-&gt;rbp */</span>
<span class="p_add">+	xorl    %ebp, %ebp	/* nospec   rbp*/</span>
<span class="p_add">+	pushq	%r12		/* pt_regs-&gt;r12 */</span>
<span class="p_add">+	xorq    %r12, %r12	/* nospec   r12*/</span>
<span class="p_add">+	pushq	%r13		/* pt_regs-&gt;r13 */</span>
<span class="p_add">+	xorq    %r13, %r13	/* nospec   r13*/</span>
<span class="p_add">+	pushq	%r14		/* pt_regs-&gt;r14 */</span>
<span class="p_add">+	xorq    %r14, %r14	/* nospec   r14*/</span>
<span class="p_add">+	pushq	%r15		/* pt_regs-&gt;r15 */</span>
<span class="p_add">+	xorq    %r15, %r15	/* nospec   r15*/</span>
<span class="p_add">+	UNWIND_HINT_REGS</span>
<span class="p_add">+.endm</span>
 
<span class="p_del">-	.macro SAVE_C_REGS_HELPER offset=0 rax=1 rcx=1 r8910=1 r11=1</span>
<span class="p_del">-	.if \r11</span>
<span class="p_del">-	movq %r11, 6*8+\offset(%rsp)</span>
<span class="p_del">-	.endif</span>
<span class="p_del">-	.if \r8910</span>
<span class="p_del">-	movq %r10, 7*8+\offset(%rsp)</span>
<span class="p_del">-	movq %r9,  8*8+\offset(%rsp)</span>
<span class="p_del">-	movq %r8,  9*8+\offset(%rsp)</span>
<span class="p_del">-	.endif</span>
<span class="p_del">-	.if \rax</span>
<span class="p_del">-	movq %rax, 10*8+\offset(%rsp)</span>
<span class="p_del">-	.endif</span>
<span class="p_del">-	.if \rcx</span>
<span class="p_del">-	movq %rcx, 11*8+\offset(%rsp)</span>
<span class="p_del">-	.endif</span>
<span class="p_del">-	movq %rdx, 12*8+\offset(%rsp)</span>
<span class="p_del">-	movq %rsi, 13*8+\offset(%rsp)</span>
<span class="p_del">-	movq %rdi, 14*8+\offset(%rsp)</span>
<span class="p_del">-	UNWIND_HINT_REGS offset=\offset extra=0</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-	.macro SAVE_C_REGS offset=0</span>
<span class="p_del">-	SAVE_C_REGS_HELPER \offset, 1, 1, 1, 1</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-	.macro SAVE_C_REGS_EXCEPT_RAX_RCX offset=0</span>
<span class="p_del">-	SAVE_C_REGS_HELPER \offset, 0, 0, 1, 1</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-	.macro SAVE_C_REGS_EXCEPT_R891011</span>
<span class="p_del">-	SAVE_C_REGS_HELPER 0, 1, 1, 0, 0</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-	.macro SAVE_C_REGS_EXCEPT_RCX_R891011</span>
<span class="p_del">-	SAVE_C_REGS_HELPER 0, 1, 0, 0, 0</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-	.macro SAVE_C_REGS_EXCEPT_RAX_RCX_R11</span>
<span class="p_del">-	SAVE_C_REGS_HELPER 0, 0, 0, 1, 0</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-</span>
<span class="p_del">-	.macro SAVE_EXTRA_REGS offset=0</span>
<span class="p_del">-	movq %r15, 0*8+\offset(%rsp)</span>
<span class="p_del">-	movq %r14, 1*8+\offset(%rsp)</span>
<span class="p_del">-	movq %r13, 2*8+\offset(%rsp)</span>
<span class="p_del">-	movq %r12, 3*8+\offset(%rsp)</span>
<span class="p_del">-	movq %rbp, 4*8+\offset(%rsp)</span>
<span class="p_del">-	movq %rbx, 5*8+\offset(%rsp)</span>
<span class="p_del">-	UNWIND_HINT_REGS offset=\offset</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-</span>
<span class="p_del">-	.macro POP_EXTRA_REGS</span>
<span class="p_add">+.macro POP_REGS pop_rdi=1 skip_r11rcx=0</span>
 	popq %r15
 	popq %r14
 	popq %r13
 	popq %r12
 	popq %rbp
 	popq %rbx
<span class="p_del">-	.endm</span>
<span class="p_del">-</span>
<span class="p_del">-	.macro POP_C_REGS</span>
<span class="p_add">+	.if \skip_r11rcx</span>
<span class="p_add">+	popq %rsi</span>
<span class="p_add">+	.else</span>
 	popq %r11
<span class="p_add">+	.endif</span>
 	popq %r10
 	popq %r9
 	popq %r8
 	popq %rax
<span class="p_add">+	.if \skip_r11rcx</span>
<span class="p_add">+	popq %rsi</span>
<span class="p_add">+	.else</span>
 	popq %rcx
<span class="p_add">+	.endif</span>
 	popq %rdx
 	popq %rsi
<span class="p_add">+	.if \pop_rdi</span>
 	popq %rdi
<span class="p_del">-	.endm</span>
<span class="p_del">-</span>
<span class="p_del">-	.macro icebp</span>
<span class="p_del">-	.byte 0xf1</span>
<span class="p_del">-	.endm</span>
<span class="p_add">+	.endif</span>
<span class="p_add">+.endm</span>
 
 /*
  * This is a sneaky trick to help the unwinder find pt_regs on the stack.  The
<span class="p_chunk">@@ -178,7 +167,7 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
  * is just setting the LSB, which makes it an invalid stack address and is also
  * a signal to the unwinder that it&#39;s a pt_regs pointer in disguise.
  *
<span class="p_del">- * NOTE: This macro must be used *after* SAVE_EXTRA_REGS because it corrupts</span>
<span class="p_add">+ * NOTE: This macro must be used *after* PUSH_AND_CLEAR_REGS because it corrupts</span>
  * the original rbp.
  */
 .macro ENCODE_FRAME_POINTER ptregs_offset=0
<span class="p_header">diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S</span>
<span class="p_header">index 16e2d72e79a0..68a2d76e4f8f 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_64.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_64.S</span>
<span class="p_chunk">@@ -209,7 +209,7 @@</span> <span class="p_context"> ENTRY(entry_SYSCALL_64)</span>
 
 	swapgs
 	/*
<span class="p_del">-	 * This path is not taken when PAGE_TABLE_ISOLATION is disabled so it</span>
<span class="p_add">+	 * This path is only taken when PAGE_TABLE_ISOLATION is disabled so it</span>
 	 * is not required to switch CR3.
 	 */
 	movq	%rsp, PER_CPU_VAR(rsp_scratch)
<span class="p_chunk">@@ -223,22 +223,8 @@</span> <span class="p_context"> ENTRY(entry_SYSCALL_64)</span>
 	pushq	%rcx				/* pt_regs-&gt;ip */
 GLOBAL(entry_SYSCALL_64_after_hwframe)
 	pushq	%rax				/* pt_regs-&gt;orig_ax */
<span class="p_del">-	pushq	%rdi				/* pt_regs-&gt;di */</span>
<span class="p_del">-	pushq	%rsi				/* pt_regs-&gt;si */</span>
<span class="p_del">-	pushq	%rdx				/* pt_regs-&gt;dx */</span>
<span class="p_del">-	pushq	%rcx				/* pt_regs-&gt;cx */</span>
<span class="p_del">-	pushq	$-ENOSYS			/* pt_regs-&gt;ax */</span>
<span class="p_del">-	pushq	%r8				/* pt_regs-&gt;r8 */</span>
<span class="p_del">-	pushq	%r9				/* pt_regs-&gt;r9 */</span>
<span class="p_del">-	pushq	%r10				/* pt_regs-&gt;r10 */</span>
<span class="p_del">-	pushq	%r11				/* pt_regs-&gt;r11 */</span>
<span class="p_del">-	pushq	%rbx				/* pt_regs-&gt;rbx */</span>
<span class="p_del">-	pushq	%rbp				/* pt_regs-&gt;rbp */</span>
<span class="p_del">-	pushq	%r12				/* pt_regs-&gt;r12 */</span>
<span class="p_del">-	pushq	%r13				/* pt_regs-&gt;r13 */</span>
<span class="p_del">-	pushq	%r14				/* pt_regs-&gt;r14 */</span>
<span class="p_del">-	pushq	%r15				/* pt_regs-&gt;r15 */</span>
<span class="p_del">-	UNWIND_HINT_REGS</span>
<span class="p_add">+</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS rax=$-ENOSYS</span>
 
 	TRACE_IRQS_OFF
 
<span class="p_chunk">@@ -317,15 +303,7 @@</span> <span class="p_context"> GLOBAL(entry_SYSCALL_64_after_hwframe)</span>
 syscall_return_via_sysret:
 	/* rcx and r11 are already restored (see code above) */
 	UNWIND_HINT_EMPTY
<span class="p_del">-	POP_EXTRA_REGS</span>
<span class="p_del">-	popq	%rsi	/* skip r11 */</span>
<span class="p_del">-	popq	%r10</span>
<span class="p_del">-	popq	%r9</span>
<span class="p_del">-	popq	%r8</span>
<span class="p_del">-	popq	%rax</span>
<span class="p_del">-	popq	%rsi	/* skip rcx */</span>
<span class="p_del">-	popq	%rdx</span>
<span class="p_del">-	popq	%rsi</span>
<span class="p_add">+	POP_REGS pop_rdi=0 skip_r11rcx=1</span>
 
 	/*
 	 * Now all regs are restored except RSP and RDI.
<span class="p_chunk">@@ -555,9 +533,7 @@</span> <span class="p_context"> END(irq_entries_start)</span>
 	call	switch_to_thread_stack
 1:
 
<span class="p_del">-	ALLOC_PT_GPREGS_ON_STACK</span>
<span class="p_del">-	SAVE_C_REGS</span>
<span class="p_del">-	SAVE_EXTRA_REGS</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS</span>
 	ENCODE_FRAME_POINTER
 
 	testb	$3, CS(%rsp)
<span class="p_chunk">@@ -618,15 +594,7 @@</span> <span class="p_context"> GLOBAL(swapgs_restore_regs_and_return_to_usermode)</span>
 	ud2
 1:
 #endif
<span class="p_del">-	POP_EXTRA_REGS</span>
<span class="p_del">-	popq	%r11</span>
<span class="p_del">-	popq	%r10</span>
<span class="p_del">-	popq	%r9</span>
<span class="p_del">-	popq	%r8</span>
<span class="p_del">-	popq	%rax</span>
<span class="p_del">-	popq	%rcx</span>
<span class="p_del">-	popq	%rdx</span>
<span class="p_del">-	popq	%rsi</span>
<span class="p_add">+	POP_REGS pop_rdi=0</span>
 
 	/*
 	 * The stack is now user RDI, orig_ax, RIP, CS, EFLAGS, RSP, SS.
<span class="p_chunk">@@ -684,8 +652,7 @@</span> <span class="p_context"> GLOBAL(restore_regs_and_return_to_kernel)</span>
 	ud2
 1:
 #endif
<span class="p_del">-	POP_EXTRA_REGS</span>
<span class="p_del">-	POP_C_REGS</span>
<span class="p_add">+	POP_REGS</span>
 	addq	$8, %rsp	/* skip regs-&gt;orig_ax */
 	INTERRUPT_RETURN
 
<span class="p_chunk">@@ -900,7 +867,9 @@</span> <span class="p_context"> ENTRY(\sym)</span>
 	pushq	$-1				/* ORIG_RAX: no syscall to restart */
 	.endif
 
<span class="p_del">-	ALLOC_PT_GPREGS_ON_STACK</span>
<span class="p_add">+	/* Save all registers in pt_regs */</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS</span>
<span class="p_add">+	ENCODE_FRAME_POINTER</span>
 
 	.if \paranoid &lt; 2
 	testb	$3, CS(%rsp)			/* If coming from userspace, switch stacks */
<span class="p_chunk">@@ -1111,9 +1080,7 @@</span> <span class="p_context"> ENTRY(xen_failsafe_callback)</span>
 	addq	$0x30, %rsp
 	UNWIND_HINT_IRET_REGS
 	pushq	$-1 /* orig_ax = -1 =&gt; not a system call */
<span class="p_del">-	ALLOC_PT_GPREGS_ON_STACK</span>
<span class="p_del">-	SAVE_C_REGS</span>
<span class="p_del">-	SAVE_EXTRA_REGS</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS</span>
 	ENCODE_FRAME_POINTER
 	jmp	error_exit
 END(xen_failsafe_callback)
<span class="p_chunk">@@ -1150,16 +1117,13 @@</span> <span class="p_context"> idtentry machine_check		do_mce			has_error_code=0	paranoid=1</span>
 #endif
 
 /*
<span class="p_del">- * Save all registers in pt_regs, and switch gs if needed.</span>
<span class="p_add">+ * Switch gs if needed.</span>
  * Use slow, but surefire &quot;are we in kernel?&quot; check.
  * Return: ebx=0: need swapgs on exit, ebx=1: otherwise
  */
 ENTRY(paranoid_entry)
 	UNWIND_HINT_FUNC
 	cld
<span class="p_del">-	SAVE_C_REGS 8</span>
<span class="p_del">-	SAVE_EXTRA_REGS 8</span>
<span class="p_del">-	ENCODE_FRAME_POINTER 8</span>
 	movl	$1, %ebx
 	movl	$MSR_GS_BASE, %ecx
 	rdmsr
<span class="p_chunk">@@ -1198,21 +1162,18 @@</span> <span class="p_context"> ENTRY(paranoid_exit)</span>
 	jmp	.Lparanoid_exit_restore
 .Lparanoid_exit_no_swapgs:
 	TRACE_IRQS_IRETQ_DEBUG
<span class="p_add">+	RESTORE_CR3	scratch_reg=%rbx save_reg=%r14</span>
 .Lparanoid_exit_restore:
 	jmp restore_regs_and_return_to_kernel
 END(paranoid_exit)
 
 /*
<span class="p_del">- * Save all registers in pt_regs, and switch gs if needed.</span>
<span class="p_add">+ * Switch gs if needed.</span>
  * Return: EBX=0: came from user mode; EBX=1: otherwise
  */
 ENTRY(error_entry)
<span class="p_del">-	UNWIND_HINT_FUNC</span>
<span class="p_add">+	UNWIND_HINT_REGS offset=8</span>
 	cld
<span class="p_del">-	SAVE_C_REGS 8</span>
<span class="p_del">-	SAVE_EXTRA_REGS 8</span>
<span class="p_del">-	ENCODE_FRAME_POINTER 8</span>
<span class="p_del">-	xorl	%ebx, %ebx</span>
 	testb	$3, CS+8(%rsp)
 	jz	.Lerror_kernelspace
 
<span class="p_chunk">@@ -1393,22 +1354,7 @@</span> <span class="p_context"> ENTRY(nmi)</span>
 	pushq	1*8(%rdx)	/* pt_regs-&gt;rip */
 	UNWIND_HINT_IRET_REGS
 	pushq   $-1		/* pt_regs-&gt;orig_ax */
<span class="p_del">-	pushq   %rdi		/* pt_regs-&gt;di */</span>
<span class="p_del">-	pushq   %rsi		/* pt_regs-&gt;si */</span>
<span class="p_del">-	pushq   (%rdx)		/* pt_regs-&gt;dx */</span>
<span class="p_del">-	pushq   %rcx		/* pt_regs-&gt;cx */</span>
<span class="p_del">-	pushq   %rax		/* pt_regs-&gt;ax */</span>
<span class="p_del">-	pushq   %r8		/* pt_regs-&gt;r8 */</span>
<span class="p_del">-	pushq   %r9		/* pt_regs-&gt;r9 */</span>
<span class="p_del">-	pushq   %r10		/* pt_regs-&gt;r10 */</span>
<span class="p_del">-	pushq   %r11		/* pt_regs-&gt;r11 */</span>
<span class="p_del">-	pushq	%rbx		/* pt_regs-&gt;rbx */</span>
<span class="p_del">-	pushq	%rbp		/* pt_regs-&gt;rbp */</span>
<span class="p_del">-	pushq	%r12		/* pt_regs-&gt;r12 */</span>
<span class="p_del">-	pushq	%r13		/* pt_regs-&gt;r13 */</span>
<span class="p_del">-	pushq	%r14		/* pt_regs-&gt;r14 */</span>
<span class="p_del">-	pushq	%r15		/* pt_regs-&gt;r15 */</span>
<span class="p_del">-	UNWIND_HINT_REGS</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS rdx=(%rdx)</span>
 	ENCODE_FRAME_POINTER
 
 	/*
<span class="p_chunk">@@ -1618,7 +1564,8 @@</span> <span class="p_context"> end_repeat_nmi:</span>
 	 * frame to point back to repeat_nmi.
 	 */
 	pushq	$-1				/* ORIG_RAX: no syscall to restart */
<span class="p_del">-	ALLOC_PT_GPREGS_ON_STACK</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS</span>
<span class="p_add">+	ENCODE_FRAME_POINTER</span>
 
 	/*
 	 * Use paranoid_entry to handle SWAPGS, but no need to use paranoid_exit
<span class="p_chunk">@@ -1642,8 +1589,7 @@</span> <span class="p_context"> end_repeat_nmi:</span>
 nmi_swapgs:
 	SWAPGS_UNSAFE_STACK
 nmi_restore:
<span class="p_del">-	POP_EXTRA_REGS</span>
<span class="p_del">-	POP_C_REGS</span>
<span class="p_add">+	POP_REGS</span>
 
 	/*
 	 * Skip orig_ax and the &quot;outermost&quot; frame to point RSP at the &quot;iret&quot;
<span class="p_header">diff --git a/arch/x86/entry/entry_64_compat.S b/arch/x86/entry/entry_64_compat.S</span>
<span class="p_header">index 98d5358e4041..fd65e016e413 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_64_compat.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_64_compat.S</span>
<span class="p_chunk">@@ -85,15 +85,25 @@</span> <span class="p_context"> ENTRY(entry_SYSENTER_compat)</span>
 	pushq	%rcx			/* pt_regs-&gt;cx */
 	pushq	$-ENOSYS		/* pt_regs-&gt;ax */
 	pushq   $0			/* pt_regs-&gt;r8  = 0 */
<span class="p_add">+	xorq	%r8, %r8		/* nospec   r8 */</span>
 	pushq   $0			/* pt_regs-&gt;r9  = 0 */
<span class="p_add">+	xorq	%r9, %r9		/* nospec   r9 */</span>
 	pushq   $0			/* pt_regs-&gt;r10 = 0 */
<span class="p_add">+	xorq	%r10, %r10		/* nospec   r10 */</span>
 	pushq   $0			/* pt_regs-&gt;r11 = 0 */
<span class="p_add">+	xorq	%r11, %r11		/* nospec   r11 */</span>
 	pushq   %rbx                    /* pt_regs-&gt;rbx */
<span class="p_add">+	xorl	%ebx, %ebx		/* nospec   rbx */</span>
 	pushq   %rbp                    /* pt_regs-&gt;rbp (will be overwritten) */
<span class="p_add">+	xorl	%ebp, %ebp		/* nospec   rbp */</span>
 	pushq   $0			/* pt_regs-&gt;r12 = 0 */
<span class="p_add">+	xorq	%r12, %r12		/* nospec   r12 */</span>
 	pushq   $0			/* pt_regs-&gt;r13 = 0 */
<span class="p_add">+	xorq	%r13, %r13		/* nospec   r13 */</span>
 	pushq   $0			/* pt_regs-&gt;r14 = 0 */
<span class="p_add">+	xorq	%r14, %r14		/* nospec   r14 */</span>
 	pushq   $0			/* pt_regs-&gt;r15 = 0 */
<span class="p_add">+	xorq	%r15, %r15		/* nospec   r15 */</span>
 	cld
 
 	/*
<span class="p_chunk">@@ -214,15 +224,25 @@</span> <span class="p_context"> GLOBAL(entry_SYSCALL_compat_after_hwframe)</span>
 	pushq	%rbp			/* pt_regs-&gt;cx (stashed in bp) */
 	pushq	$-ENOSYS		/* pt_regs-&gt;ax */
 	pushq   $0			/* pt_regs-&gt;r8  = 0 */
<span class="p_add">+	xorq	%r8, %r8		/* nospec   r8 */</span>
 	pushq   $0			/* pt_regs-&gt;r9  = 0 */
<span class="p_add">+	xorq	%r9, %r9		/* nospec   r9 */</span>
 	pushq   $0			/* pt_regs-&gt;r10 = 0 */
<span class="p_add">+	xorq	%r10, %r10		/* nospec   r10 */</span>
 	pushq   $0			/* pt_regs-&gt;r11 = 0 */
<span class="p_add">+	xorq	%r11, %r11		/* nospec   r11 */</span>
 	pushq   %rbx                    /* pt_regs-&gt;rbx */
<span class="p_add">+	xorl	%ebx, %ebx		/* nospec   rbx */</span>
 	pushq   %rbp                    /* pt_regs-&gt;rbp (will be overwritten) */
<span class="p_add">+	xorl	%ebp, %ebp		/* nospec   rbp */</span>
 	pushq   $0			/* pt_regs-&gt;r12 = 0 */
<span class="p_add">+	xorq	%r12, %r12		/* nospec   r12 */</span>
 	pushq   $0			/* pt_regs-&gt;r13 = 0 */
<span class="p_add">+	xorq	%r13, %r13		/* nospec   r13 */</span>
 	pushq   $0			/* pt_regs-&gt;r14 = 0 */
<span class="p_add">+	xorq	%r14, %r14		/* nospec   r14 */</span>
 	pushq   $0			/* pt_regs-&gt;r15 = 0 */
<span class="p_add">+	xorq	%r15, %r15		/* nospec   r15 */</span>
 
 	/*
 	 * User mode is traced as though IRQs are on, and SYSENTER
<span class="p_chunk">@@ -338,15 +358,25 @@</span> <span class="p_context"> ENTRY(entry_INT80_compat)</span>
 	pushq	%rcx			/* pt_regs-&gt;cx */
 	pushq	$-ENOSYS		/* pt_regs-&gt;ax */
 	pushq   $0			/* pt_regs-&gt;r8  = 0 */
<span class="p_add">+	xorq	%r8, %r8		/* nospec   r8 */</span>
 	pushq   $0			/* pt_regs-&gt;r9  = 0 */
<span class="p_add">+	xorq	%r9, %r9		/* nospec   r9 */</span>
 	pushq   $0			/* pt_regs-&gt;r10 = 0 */
<span class="p_add">+	xorq	%r10, %r10		/* nospec   r10 */</span>
 	pushq   $0			/* pt_regs-&gt;r11 = 0 */
<span class="p_add">+	xorq	%r11, %r11		/* nospec   r11 */</span>
 	pushq   %rbx                    /* pt_regs-&gt;rbx */
<span class="p_add">+	xorl	%ebx, %ebx		/* nospec   rbx */</span>
 	pushq   %rbp                    /* pt_regs-&gt;rbp */
<span class="p_add">+	xorl	%ebp, %ebp		/* nospec   rbp */</span>
 	pushq   %r12                    /* pt_regs-&gt;r12 */
<span class="p_add">+	xorq	%r12, %r12		/* nospec   r12 */</span>
 	pushq   %r13                    /* pt_regs-&gt;r13 */
<span class="p_add">+	xorq	%r13, %r13		/* nospec   r13 */</span>
 	pushq   %r14                    /* pt_regs-&gt;r14 */
<span class="p_add">+	xorq	%r14, %r14		/* nospec   r14 */</span>
 	pushq   %r15                    /* pt_regs-&gt;r15 */
<span class="p_add">+	xorq	%r15, %r15		/* nospec   r15 */</span>
 	cld
 
 	/*
<span class="p_header">diff --git a/arch/x86/events/intel/core.c b/arch/x86/events/intel/core.c</span>
<span class="p_header">index 09c26a4f139c..1c2558430cf0 100644</span>
<span class="p_header">--- a/arch/x86/events/intel/core.c</span>
<span class="p_header">+++ b/arch/x86/events/intel/core.c</span>
<span class="p_chunk">@@ -3559,7 +3559,7 @@</span> <span class="p_context"> static int intel_snb_pebs_broken(int cpu)</span>
 		break;
 
 	case INTEL_FAM6_SANDYBRIDGE_X:
<span class="p_del">-		switch (cpu_data(cpu).x86_mask) {</span>
<span class="p_add">+		switch (cpu_data(cpu).x86_stepping) {</span>
 		case 6: rev = 0x618; break;
 		case 7: rev = 0x70c; break;
 		}
<span class="p_header">diff --git a/arch/x86/events/intel/lbr.c b/arch/x86/events/intel/lbr.c</span>
<span class="p_header">index ae64d0b69729..cf372b90557e 100644</span>
<span class="p_header">--- a/arch/x86/events/intel/lbr.c</span>
<span class="p_header">+++ b/arch/x86/events/intel/lbr.c</span>
<span class="p_chunk">@@ -1186,7 +1186,7 @@</span> <span class="p_context"> void __init intel_pmu_lbr_init_atom(void)</span>
 	 * on PMU interrupt
 	 */
 	if (boot_cpu_data.x86_model == 28
<span class="p_del">-	    &amp;&amp; boot_cpu_data.x86_mask &lt; 10) {</span>
<span class="p_add">+	    &amp;&amp; boot_cpu_data.x86_stepping &lt; 10) {</span>
 		pr_cont(&quot;LBR disabled due to erratum&quot;);
 		return;
 	}
<span class="p_header">diff --git a/arch/x86/events/intel/p6.c b/arch/x86/events/intel/p6.c</span>
<span class="p_header">index a5604c352930..408879b0c0d4 100644</span>
<span class="p_header">--- a/arch/x86/events/intel/p6.c</span>
<span class="p_header">+++ b/arch/x86/events/intel/p6.c</span>
<span class="p_chunk">@@ -234,7 +234,7 @@</span> <span class="p_context"> static __initconst const struct x86_pmu p6_pmu = {</span>
 
 static __init void p6_pmu_rdpmc_quirk(void)
 {
<span class="p_del">-	if (boot_cpu_data.x86_mask &lt; 9) {</span>
<span class="p_add">+	if (boot_cpu_data.x86_stepping &lt; 9) {</span>
 		/*
 		 * PPro erratum 26; fixed in stepping 9 and above.
 		 */
<span class="p_header">diff --git a/arch/x86/include/asm/acpi.h b/arch/x86/include/asm/acpi.h</span>
<span class="p_header">index 8d0ec9df1cbe..f077401869ee 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/acpi.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/acpi.h</span>
<span class="p_chunk">@@ -94,7 +94,7 @@</span> <span class="p_context"> static inline unsigned int acpi_processor_cstate_check(unsigned int max_cstate)</span>
 	if (boot_cpu_data.x86 == 0x0F &amp;&amp;
 	    boot_cpu_data.x86_vendor == X86_VENDOR_AMD &amp;&amp;
 	    boot_cpu_data.x86_model &lt;= 0x05 &amp;&amp;
<span class="p_del">-	    boot_cpu_data.x86_mask &lt; 0x0A)</span>
<span class="p_add">+	    boot_cpu_data.x86_stepping &lt; 0x0A)</span>
 		return 1;
 	else if (boot_cpu_has(X86_BUG_AMD_APIC_C1E))
 		return 1;
<span class="p_header">diff --git a/arch/x86/include/asm/barrier.h b/arch/x86/include/asm/barrier.h</span>
<span class="p_header">index 1e7c955b6303..4db77731e130 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/barrier.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/barrier.h</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"> static inline unsigned long array_index_mask_nospec(unsigned long index,</span>
 
 	asm (&quot;cmp %1,%2; sbb %0,%0;&quot;
 			:&quot;=r&quot; (mask)
<span class="p_del">-			:&quot;r&quot;(size),&quot;r&quot; (index)</span>
<span class="p_add">+			:&quot;g&quot;(size),&quot;r&quot; (index)</span>
 			:&quot;cc&quot;);
 	return mask;
 }
<span class="p_header">diff --git a/arch/x86/include/asm/bug.h b/arch/x86/include/asm/bug.h</span>
<span class="p_header">index 34d99af43994..6804d6642767 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/bug.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/bug.h</span>
<span class="p_chunk">@@ -5,23 +5,20 @@</span> <span class="p_context"></span>
 #include &lt;linux/stringify.h&gt;
 
 /*
<span class="p_del">- * Since some emulators terminate on UD2, we cannot use it for WARN.</span>
<span class="p_del">- * Since various instruction decoders disagree on the length of UD1,</span>
<span class="p_del">- * we cannot use it either. So use UD0 for WARN.</span>
<span class="p_add">+ * Despite that some emulators terminate on UD2, we use it for WARN().</span>
  *
<span class="p_del">- * (binutils knows about &quot;ud1&quot; but {en,de}codes it as 2 bytes, whereas</span>
<span class="p_del">- *  our kernel decoder thinks it takes a ModRM byte, which seems consistent</span>
<span class="p_del">- *  with various things like the Intel SDM instruction encoding rules)</span>
<span class="p_add">+ * Since various instruction decoders/specs disagree on the encoding of</span>
<span class="p_add">+ * UD0/UD1.</span>
  */
 
<span class="p_del">-#define ASM_UD0		&quot;.byte 0x0f, 0xff&quot;</span>
<span class="p_add">+#define ASM_UD0		&quot;.byte 0x0f, 0xff&quot; /* + ModRM (for Intel) */</span>
 #define ASM_UD1		&quot;.byte 0x0f, 0xb9&quot; /* + ModRM */
 #define ASM_UD2		&quot;.byte 0x0f, 0x0b&quot;
 
 #define INSN_UD0	0xff0f
 #define INSN_UD2	0x0b0f
 
<span class="p_del">-#define LEN_UD0		2</span>
<span class="p_add">+#define LEN_UD2		2</span>
 
 #ifdef CONFIG_GENERIC_BUG
 
<span class="p_chunk">@@ -77,7 +74,11 @@</span> <span class="p_context"> do {								\</span>
 	unreachable();						\
 } while (0)
 
<span class="p_del">-#define __WARN_FLAGS(flags)	_BUG_FLAGS(ASM_UD0, BUGFLAG_WARNING|(flags))</span>
<span class="p_add">+#define __WARN_FLAGS(flags)					\</span>
<span class="p_add">+do {								\</span>
<span class="p_add">+	_BUG_FLAGS(ASM_UD2, BUGFLAG_WARNING|(flags));		\</span>
<span class="p_add">+	annotate_reachable();					\</span>
<span class="p_add">+} while (0)</span>
 
 #include &lt;asm-generic/bug.h&gt;
 
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 836ca1178a6a..69f16f0729d0 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -7,7 +7,6 @@</span> <span class="p_context"></span>
  * Documentation/DMA-API.txt for documentation.
  */
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;asm/io.h&gt;
<span class="p_header">diff --git a/arch/x86/include/asm/kmemcheck.h b/arch/x86/include/asm/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index 945a0337fbcf..000000000000</span>
<span class="p_header">--- a/arch/x86/include/asm/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,43 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-#define ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;asm/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs);</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code);</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs);</span>
<span class="p_del">-#else</span>
<span class="p_del">-static inline bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/include/asm/nospec-branch.h b/arch/x86/include/asm/nospec-branch.h</span>
<span class="p_header">index 4d57894635f2..76b058533e47 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/nospec-branch.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/nospec-branch.h</span>
<span class="p_chunk">@@ -6,6 +6,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/alternative.h&gt;
 #include &lt;asm/alternative-asm.h&gt;
 #include &lt;asm/cpufeatures.h&gt;
<span class="p_add">+#include &lt;asm/msr-index.h&gt;</span>
 
 #ifdef __ASSEMBLY__
 
<span class="p_chunk">@@ -164,10 +165,15 @@</span> <span class="p_context"> static inline void vmexit_fill_RSB(void)</span>
 
 static inline void indirect_branch_prediction_barrier(void)
 {
<span class="p_del">-	alternative_input(&quot;&quot;,</span>
<span class="p_del">-			  &quot;call __ibp_barrier&quot;,</span>
<span class="p_del">-			  X86_FEATURE_USE_IBPB,</span>
<span class="p_del">-			  ASM_NO_INPUT_CLOBBER(&quot;eax&quot;, &quot;ecx&quot;, &quot;edx&quot;, &quot;memory&quot;));</span>
<span class="p_add">+	asm volatile(ALTERNATIVE(&quot;&quot;,</span>
<span class="p_add">+				 &quot;movl %[msr], %%ecx\n\t&quot;</span>
<span class="p_add">+				 &quot;movl %[val], %%eax\n\t&quot;</span>
<span class="p_add">+				 &quot;movl $0, %%edx\n\t&quot;</span>
<span class="p_add">+				 &quot;wrmsr&quot;,</span>
<span class="p_add">+				 X86_FEATURE_USE_IBPB)</span>
<span class="p_add">+		     : : [msr] &quot;i&quot; (MSR_IA32_PRED_CMD),</span>
<span class="p_add">+			 [val] &quot;i&quot; (PRED_CMD_IBPB)</span>
<span class="p_add">+		     : &quot;eax&quot;, &quot;ecx&quot;, &quot;edx&quot;, &quot;memory&quot;);</span>
 }
 
 #endif /* __ASSEMBLY__ */
<span class="p_header">diff --git a/arch/x86/include/asm/page_64.h b/arch/x86/include/asm/page_64.h</span>
<span class="p_header">index 4baa6bceb232..d652a3808065 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/page_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/page_64.h</span>
<span class="p_chunk">@@ -52,10 +52,6 @@</span> <span class="p_context"> static inline void clear_page(void *page)</span>
 
 void copy_page(void *to, void *from);
 
<span class="p_del">-#ifdef CONFIG_X86_MCE</span>
<span class="p_del">-#define arch_unmap_kpfn arch_unmap_kpfn</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #endif	/* !__ASSEMBLY__ */
 
 #ifdef CONFIG_X86_VSYSCALL_EMULATION
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt.h b/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">index 892df375b615..554841fab717 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt.h</span>
<span class="p_chunk">@@ -297,9 +297,9 @@</span> <span class="p_context"> static inline void __flush_tlb_global(void)</span>
 {
 	PVOP_VCALL0(pv_mmu_ops.flush_tlb_kernel);
 }
<span class="p_del">-static inline void __flush_tlb_single(unsigned long addr)</span>
<span class="p_add">+static inline void __flush_tlb_one_user(unsigned long addr)</span>
 {
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.flush_tlb_single, addr);</span>
<span class="p_add">+	PVOP_VCALL1(pv_mmu_ops.flush_tlb_one_user, addr);</span>
 }
 
 static inline void flush_tlb_others(const struct cpumask *cpumask,
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_types.h b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">index 6ec54d01972d..f624f1f10316 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_chunk">@@ -217,7 +217,7 @@</span> <span class="p_context"> struct pv_mmu_ops {</span>
 	/* TLB operations */
 	void (*flush_tlb_user)(void);
 	void (*flush_tlb_kernel)(void);
<span class="p_del">-	void (*flush_tlb_single)(unsigned long addr);</span>
<span class="p_add">+	void (*flush_tlb_one_user)(unsigned long addr);</span>
 	void (*flush_tlb_others)(const struct cpumask *cpus,
 				 const struct flush_tlb_info *info);
 
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index 211368922cad..8b8f1f14a0bf 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -668,11 +668,6 @@</span> <span class="p_context"> static inline bool pte_accessible(struct mm_struct *mm, pte_t a)</span>
 	return false;
 }
 
<span class="p_del">-static inline int pte_hidden(pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return pte_flags(pte) &amp; _PAGE_HIDDEN;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline int pmd_present(pmd_t pmd)
 {
 	/*
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_32.h b/arch/x86/include/asm/pgtable_32.h</span>
<span class="p_header">index e67c0620aec2..e55466760ff8 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_32.h</span>
<span class="p_chunk">@@ -61,7 +61,7 @@</span> <span class="p_context"> void paging_init(void);</span>
 #define kpte_clear_flush(ptep, vaddr)		\
 do {						\
 	pte_clear(&amp;init_mm, (vaddr), (ptep));	\
<span class="p_del">-	__flush_tlb_one((vaddr));		\</span>
<span class="p_add">+	__flush_tlb_one_kernel((vaddr));		\</span>
 } while (0)
 
 #endif /* !__ASSEMBLY__ */
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">index 9e9b05fc4860..3696398a9475 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_chunk">@@ -32,7 +32,6 @@</span> <span class="p_context"></span>
 
 #define _PAGE_BIT_SPECIAL	_PAGE_BIT_SOFTW1
 #define _PAGE_BIT_CPA_TEST	_PAGE_BIT_SOFTW1
<span class="p_del">-#define _PAGE_BIT_HIDDEN	_PAGE_BIT_SOFTW3 /* hidden by kmemcheck */</span>
 #define _PAGE_BIT_SOFT_DIRTY	_PAGE_BIT_SOFTW3 /* software dirty tracking */
 #define _PAGE_BIT_DEVMAP	_PAGE_BIT_SOFTW4
 
<span class="p_chunk">@@ -79,18 +78,6 @@</span> <span class="p_context"></span>
 #define _PAGE_KNL_ERRATUM_MASK 0
 #endif
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-#define _PAGE_HIDDEN	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_HIDDEN)</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define _PAGE_HIDDEN	(_AT(pteval_t, 0))</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * The same hidden bit is used by kmemcheck, but since kmemcheck</span>
<span class="p_del">- * works on kernel pages while soft-dirty engine on user space,</span>
<span class="p_del">- * they do not conflict with each other.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
 #ifdef CONFIG_MEM_SOFT_DIRTY
 #define _PAGE_SOFT_DIRTY	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_SOFT_DIRTY)
 #else
<span class="p_header">diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h</span>
<span class="p_header">index c57c6e77c29f..15fc074bd628 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/processor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/processor.h</span>
<span class="p_chunk">@@ -91,7 +91,7 @@</span> <span class="p_context"> struct cpuinfo_x86 {</span>
 	__u8			x86;		/* CPU family */
 	__u8			x86_vendor;	/* CPU vendor */
 	__u8			x86_model;
<span class="p_del">-	__u8			x86_mask;</span>
<span class="p_add">+	__u8			x86_stepping;</span>
 #ifdef CONFIG_X86_64
 	/* Number of 4K pages in DTLB/ITLB combined(in pages): */
 	int			x86_tlbsize;
<span class="p_chunk">@@ -109,7 +109,7 @@</span> <span class="p_context"> struct cpuinfo_x86 {</span>
 	char			x86_vendor_id[16];
 	char			x86_model_id[64];
 	/* in KB - valid for CPUS which support this call: */
<span class="p_del">-	int			x86_cache_size;</span>
<span class="p_add">+	unsigned int		x86_cache_size;</span>
 	int			x86_cache_alignment;	/* In bytes */
 	/* Cache QoS architectural values: */
 	int			x86_cache_max_rmid;	/* max index */
<span class="p_chunk">@@ -968,7 +968,4 @@</span> <span class="p_context"> bool xen_set_default_idle(void);</span>
 
 void stop_this_cpu(void *dummy);
 void df_debug(struct pt_regs *regs, long error_code);
<span class="p_del">-</span>
<span class="p_del">-void __ibp_barrier(void);</span>
<span class="p_del">-</span>
 #endif /* _ASM_X86_PROCESSOR_H */
<span class="p_header">diff --git a/arch/x86/include/asm/string_32.h b/arch/x86/include/asm/string_32.h</span>
<span class="p_header">index 076502241eae..55d392c6bd29 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_32.h</span>
<span class="p_chunk">@@ -179,8 +179,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
  *	No 3D Now!
  */
 
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
<span class="p_del">-</span>
 #if (__GNUC__ &gt;= 4)
 #define memcpy(t, f, n) __builtin_memcpy(t, f, n)
 #else
<span class="p_chunk">@@ -189,13 +187,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
 	 ? __constant_memcpy((t), (f), (n))	\
 	 : __memcpy((t), (f), (n)))
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(t, f, n) __memcpy((t), (f), (n))</span>
<span class="p_del">-#endif</span>
 
 #endif
 #endif /* !CONFIG_FORTIFY_SOURCE */
<span class="p_header">diff --git a/arch/x86/include/asm/string_64.h b/arch/x86/include/asm/string_64.h</span>
<span class="p_header">index 0b1b4445f4c5..533f74c300c2 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_64.h</span>
<span class="p_chunk">@@ -33,7 +33,6 @@</span> <span class="p_context"> extern void *memcpy(void *to, const void *from, size_t len);</span>
 extern void *__memcpy(void *to, const void *from, size_t len);
 
 #ifndef CONFIG_FORTIFY_SOURCE
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
 #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &lt; 3) || __GNUC__ &lt; 4
 #define memcpy(dst, src, len)					\
 ({								\
<span class="p_chunk">@@ -46,13 +45,6 @@</span> <span class="p_context"> extern void *__memcpy(void *to, const void *from, size_t len);</span>
 	__ret;							\
 })
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(dst, src, len) __inline_memcpy((dst), (src), (len))</span>
<span class="p_del">-#endif</span>
 #endif /* !CONFIG_FORTIFY_SOURCE */
 
 #define __HAVE_ARCH_MEMSET
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 4405c4b308e8..704f31315dde 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -140,7 +140,7 @@</span> <span class="p_context"> static inline unsigned long build_cr3_noflush(pgd_t *pgd, u16 asid)</span>
 #else
 #define __flush_tlb() __native_flush_tlb()
 #define __flush_tlb_global() __native_flush_tlb_global()
<span class="p_del">-#define __flush_tlb_single(addr) __native_flush_tlb_single(addr)</span>
<span class="p_add">+#define __flush_tlb_one_user(addr) __native_flush_tlb_one_user(addr)</span>
 #endif
 
 static inline bool tlb_defer_switch_to_init_mm(void)
<span class="p_chunk">@@ -397,7 +397,7 @@</span> <span class="p_context"> static inline void __native_flush_tlb_global(void)</span>
 /*
  * flush one page in the user mapping
  */
<span class="p_del">-static inline void __native_flush_tlb_single(unsigned long addr)</span>
<span class="p_add">+static inline void __native_flush_tlb_one_user(unsigned long addr)</span>
 {
 	u32 loaded_mm_asid = this_cpu_read(cpu_tlbstate.loaded_mm_asid);
 
<span class="p_chunk">@@ -434,18 +434,31 @@</span> <span class="p_context"> static inline void __flush_tlb_all(void)</span>
 /*
  * flush one page in the kernel mapping
  */
<span class="p_del">-static inline void __flush_tlb_one(unsigned long addr)</span>
<span class="p_add">+static inline void __flush_tlb_one_kernel(unsigned long addr)</span>
 {
 	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);
<span class="p_del">-	__flush_tlb_single(addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If PTI is off, then __flush_tlb_one_user() is just INVLPG or its</span>
<span class="p_add">+	 * paravirt equivalent.  Even with PCID, this is sufficient: we only</span>
<span class="p_add">+	 * use PCID if we also use global PTEs for the kernel mapping, and</span>
<span class="p_add">+	 * INVLPG flushes global translations across all address spaces.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If PTI is on, then the kernel is mapped with non-global PTEs, and</span>
<span class="p_add">+	 * __flush_tlb_one_user() will flush the given address for the current</span>
<span class="p_add">+	 * kernel address space and for its usermode counterpart, but it does</span>
<span class="p_add">+	 * not flush it for other address spaces.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__flush_tlb_one_user(addr);</span>
 
 	if (!static_cpu_has(X86_FEATURE_PTI))
 		return;
 
 	/*
<span class="p_del">-	 * __flush_tlb_single() will have cleared the TLB entry for this ASID,</span>
<span class="p_del">-	 * but since kernel space is replicated across all, we must also</span>
<span class="p_del">-	 * invalidate all others.</span>
<span class="p_add">+	 * See above.  We need to propagate the flush to all other address</span>
<span class="p_add">+	 * spaces.  In principle, we only need to propagate it to kernelmode</span>
<span class="p_add">+	 * address spaces, but the extra bookkeeping we would need is not</span>
<span class="p_add">+	 * worth it.</span>
 	 */
 	invalidate_other_asid();
 }
<span class="p_header">diff --git a/arch/x86/include/asm/xor.h b/arch/x86/include/asm/xor.h</span>
<span class="p_header">index 1f5c5161ead6..45c8605467f1 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/xor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/xor.h</span>
<span class="p_chunk">@@ -1,7 +1,4 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-/* kmemcheck doesn&#39;t handle MMX/SSE/SSE2 instructions */</span>
<span class="p_del">-# include &lt;asm-generic/xor.h&gt;</span>
<span class="p_del">-#elif !defined(_ASM_X86_XOR_H)</span>
<span class="p_add">+#ifndef _ASM_X86_XOR_H</span>
 #define _ASM_X86_XOR_H
 
 /*
<span class="p_header">diff --git a/arch/x86/kernel/acpi/apei.c b/arch/x86/kernel/acpi/apei.c</span>
<span class="p_header">index ea3046e0b0cf..28d70ac93faf 100644</span>
<span class="p_header">--- a/arch/x86/kernel/acpi/apei.c</span>
<span class="p_header">+++ b/arch/x86/kernel/acpi/apei.c</span>
<span class="p_chunk">@@ -55,5 +55,5 @@</span> <span class="p_context"> void arch_apei_report_mem_error(int sev, struct cper_sec_mem_err *mem_err)</span>
 
 void arch_apei_flush_tlb_one(unsigned long addr)
 {
<span class="p_del">-	__flush_tlb_one(addr);</span>
<span class="p_add">+	__flush_tlb_one_kernel(addr);</span>
 }
<span class="p_header">diff --git a/arch/x86/kernel/amd_nb.c b/arch/x86/kernel/amd_nb.c</span>
<span class="p_header">index 6db28f17ff28..c88e0b127810 100644</span>
<span class="p_header">--- a/arch/x86/kernel/amd_nb.c</span>
<span class="p_header">+++ b/arch/x86/kernel/amd_nb.c</span>
<span class="p_chunk">@@ -235,7 +235,7 @@</span> <span class="p_context"> int amd_cache_northbridges(void)</span>
 	if (boot_cpu_data.x86 == 0x10 &amp;&amp;
 	    boot_cpu_data.x86_model &gt;= 0x8 &amp;&amp;
 	    (boot_cpu_data.x86_model &gt; 0x9 ||
<span class="p_del">-	     boot_cpu_data.x86_mask &gt;= 0x1))</span>
<span class="p_add">+	     boot_cpu_data.x86_stepping &gt;= 0x1))</span>
 		amd_northbridges.flags |= AMD_NB_L3_INDEX_DISABLE;
 
 	if (boot_cpu_data.x86 == 0x15)
<span class="p_header">diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c</span>
<span class="p_header">index 89c7c8569e5e..5942aa5f569b 100644</span>
<span class="p_header">--- a/arch/x86/kernel/apic/apic.c</span>
<span class="p_header">+++ b/arch/x86/kernel/apic/apic.c</span>
<span class="p_chunk">@@ -553,7 +553,7 @@</span> <span class="p_context"> static DEFINE_PER_CPU(struct clock_event_device, lapic_events);</span>
 
 static u32 hsx_deadline_rev(void)
 {
<span class="p_del">-	switch (boot_cpu_data.x86_mask) {</span>
<span class="p_add">+	switch (boot_cpu_data.x86_stepping) {</span>
 	case 0x02: return 0x3a; /* EP */
 	case 0x04: return 0x0f; /* EX */
 	}
<span class="p_chunk">@@ -563,7 +563,7 @@</span> <span class="p_context"> static u32 hsx_deadline_rev(void)</span>
 
 static u32 bdx_deadline_rev(void)
 {
<span class="p_del">-	switch (boot_cpu_data.x86_mask) {</span>
<span class="p_add">+	switch (boot_cpu_data.x86_stepping) {</span>
 	case 0x02: return 0x00000011;
 	case 0x03: return 0x0700000e;
 	case 0x04: return 0x0f00000c;
<span class="p_chunk">@@ -575,7 +575,7 @@</span> <span class="p_context"> static u32 bdx_deadline_rev(void)</span>
 
 static u32 skx_deadline_rev(void)
 {
<span class="p_del">-	switch (boot_cpu_data.x86_mask) {</span>
<span class="p_add">+	switch (boot_cpu_data.x86_stepping) {</span>
 	case 0x03: return 0x01000136;
 	case 0x04: return 0x02000014;
 	}
<span class="p_header">diff --git a/arch/x86/kernel/apm_32.c b/arch/x86/kernel/apm_32.c</span>
<span class="p_header">index e4b0d92b3ae0..2a7fd56e67b3 100644</span>
<span class="p_header">--- a/arch/x86/kernel/apm_32.c</span>
<span class="p_header">+++ b/arch/x86/kernel/apm_32.c</span>
<span class="p_chunk">@@ -2389,6 +2389,7 @@</span> <span class="p_context"> static int __init apm_init(void)</span>
 	if (HZ != 100)
 		idle_period = (idle_period * HZ) / 100;
 	if (idle_threshold &lt; 100) {
<span class="p_add">+		cpuidle_poll_state_init(&amp;apm_idle_driver);</span>
 		if (!cpuidle_register_driver(&amp;apm_idle_driver))
 			if (cpuidle_register_device(&amp;apm_cpuidle_device))
 				cpuidle_unregister_driver(&amp;apm_idle_driver);
<span class="p_header">diff --git a/arch/x86/kernel/asm-offsets_32.c b/arch/x86/kernel/asm-offsets_32.c</span>
<span class="p_header">index fa1261eefa16..f91ba53e06c8 100644</span>
<span class="p_header">--- a/arch/x86/kernel/asm-offsets_32.c</span>
<span class="p_header">+++ b/arch/x86/kernel/asm-offsets_32.c</span>
<span class="p_chunk">@@ -18,7 +18,7 @@</span> <span class="p_context"> void foo(void)</span>
 	OFFSET(CPUINFO_x86, cpuinfo_x86, x86);
 	OFFSET(CPUINFO_x86_vendor, cpuinfo_x86, x86_vendor);
 	OFFSET(CPUINFO_x86_model, cpuinfo_x86, x86_model);
<span class="p_del">-	OFFSET(CPUINFO_x86_mask, cpuinfo_x86, x86_mask);</span>
<span class="p_add">+	OFFSET(CPUINFO_x86_stepping, cpuinfo_x86, x86_stepping);</span>
 	OFFSET(CPUINFO_cpuid_level, cpuinfo_x86, cpuid_level);
 	OFFSET(CPUINFO_x86_capability, cpuinfo_x86, x86_capability);
 	OFFSET(CPUINFO_x86_vendor_id, cpuinfo_x86, x86_vendor_id);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/amd.c b/arch/x86/kernel/cpu/amd.c</span>
<span class="p_header">index ea831c858195..e7d5a7883632 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/amd.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/amd.c</span>
<span class="p_chunk">@@ -119,7 +119,7 @@</span> <span class="p_context"> static void init_amd_k6(struct cpuinfo_x86 *c)</span>
 		return;
 	}
 
<span class="p_del">-	if (c-&gt;x86_model == 6 &amp;&amp; c-&gt;x86_mask == 1) {</span>
<span class="p_add">+	if (c-&gt;x86_model == 6 &amp;&amp; c-&gt;x86_stepping == 1) {</span>
 		const int K6_BUG_LOOP = 1000000;
 		int n;
 		void (*f_vide)(void);
<span class="p_chunk">@@ -149,7 +149,7 @@</span> <span class="p_context"> static void init_amd_k6(struct cpuinfo_x86 *c)</span>
 
 	/* K6 with old style WHCR */
 	if (c-&gt;x86_model &lt; 8 ||
<span class="p_del">-	   (c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_mask &lt; 8)) {</span>
<span class="p_add">+	   (c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_stepping &lt; 8)) {</span>
 		/* We can only write allocate on the low 508Mb */
 		if (mbytes &gt; 508)
 			mbytes = 508;
<span class="p_chunk">@@ -168,7 +168,7 @@</span> <span class="p_context"> static void init_amd_k6(struct cpuinfo_x86 *c)</span>
 		return;
 	}
 
<span class="p_del">-	if ((c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_mask &gt; 7) ||</span>
<span class="p_add">+	if ((c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_stepping &gt; 7) ||</span>
 	     c-&gt;x86_model == 9 || c-&gt;x86_model == 13) {
 		/* The more serious chips .. */
 
<span class="p_chunk">@@ -221,7 +221,7 @@</span> <span class="p_context"> static void init_amd_k7(struct cpuinfo_x86 *c)</span>
 	 * are more robust with CLK_CTL set to 200xxxxx instead of 600xxxxx
 	 * As per AMD technical note 27212 0.2
 	 */
<span class="p_del">-	if ((c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_mask &gt;= 1) || (c-&gt;x86_model &gt; 8)) {</span>
<span class="p_add">+	if ((c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_stepping &gt;= 1) || (c-&gt;x86_model &gt; 8)) {</span>
 		rdmsr(MSR_K7_CLK_CTL, l, h);
 		if ((l &amp; 0xfff00000) != 0x20000000) {
 			pr_info(&quot;CPU: CLK_CTL MSR was %x. Reprogramming to %x\n&quot;,
<span class="p_chunk">@@ -241,12 +241,12 @@</span> <span class="p_context"> static void init_amd_k7(struct cpuinfo_x86 *c)</span>
 	 * but they are not certified as MP capable.
 	 */
 	/* Athlon 660/661 is valid. */
<span class="p_del">-	if ((c-&gt;x86_model == 6) &amp;&amp; ((c-&gt;x86_mask == 0) ||</span>
<span class="p_del">-	    (c-&gt;x86_mask == 1)))</span>
<span class="p_add">+	if ((c-&gt;x86_model == 6) &amp;&amp; ((c-&gt;x86_stepping == 0) ||</span>
<span class="p_add">+	    (c-&gt;x86_stepping == 1)))</span>
 		return;
 
 	/* Duron 670 is valid */
<span class="p_del">-	if ((c-&gt;x86_model == 7) &amp;&amp; (c-&gt;x86_mask == 0))</span>
<span class="p_add">+	if ((c-&gt;x86_model == 7) &amp;&amp; (c-&gt;x86_stepping == 0))</span>
 		return;
 
 	/*
<span class="p_chunk">@@ -256,8 +256,8 @@</span> <span class="p_context"> static void init_amd_k7(struct cpuinfo_x86 *c)</span>
 	 * See http://www.heise.de/newsticker/data/jow-18.10.01-000 for
 	 * more.
 	 */
<span class="p_del">-	if (((c-&gt;x86_model == 6) &amp;&amp; (c-&gt;x86_mask &gt;= 2)) ||</span>
<span class="p_del">-	    ((c-&gt;x86_model == 7) &amp;&amp; (c-&gt;x86_mask &gt;= 1)) ||</span>
<span class="p_add">+	if (((c-&gt;x86_model == 6) &amp;&amp; (c-&gt;x86_stepping &gt;= 2)) ||</span>
<span class="p_add">+	    ((c-&gt;x86_model == 7) &amp;&amp; (c-&gt;x86_stepping &gt;= 1)) ||</span>
 	     (c-&gt;x86_model &gt; 7))
 		if (cpu_has(c, X86_FEATURE_MP))
 			return;
<span class="p_chunk">@@ -583,7 +583,7 @@</span> <span class="p_context"> static void early_init_amd(struct cpuinfo_x86 *c)</span>
 	/*  Set MTRR capability flag if appropriate */
 	if (c-&gt;x86 == 5)
 		if (c-&gt;x86_model == 13 || c-&gt;x86_model == 9 ||
<span class="p_del">-		    (c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_mask &gt;= 8))</span>
<span class="p_add">+		    (c-&gt;x86_model == 8 &amp;&amp; c-&gt;x86_stepping &gt;= 8))</span>
 			set_cpu_cap(c, X86_FEATURE_K6_MTRR);
 #endif
 #if defined(CONFIG_X86_LOCAL_APIC) &amp;&amp; defined(CONFIG_PCI)
<span class="p_chunk">@@ -769,7 +769,7 @@</span> <span class="p_context"> static void init_amd_zn(struct cpuinfo_x86 *c)</span>
 	 * Fix erratum 1076: CPB feature bit not being set in CPUID. It affects
 	 * all up to and including B1.
 	 */
<span class="p_del">-	if (c-&gt;x86_model &lt;= 1 &amp;&amp; c-&gt;x86_mask &lt;= 1)</span>
<span class="p_add">+	if (c-&gt;x86_model &lt;= 1 &amp;&amp; c-&gt;x86_stepping &lt;= 1)</span>
 		set_cpu_cap(c, X86_FEATURE_CPB);
 }
 
<span class="p_chunk">@@ -880,11 +880,11 @@</span> <span class="p_context"> static unsigned int amd_size_cache(struct cpuinfo_x86 *c, unsigned int size)</span>
 	/* AMD errata T13 (order #21922) */
 	if ((c-&gt;x86 == 6)) {
 		/* Duron Rev A0 */
<span class="p_del">-		if (c-&gt;x86_model == 3 &amp;&amp; c-&gt;x86_mask == 0)</span>
<span class="p_add">+		if (c-&gt;x86_model == 3 &amp;&amp; c-&gt;x86_stepping == 0)</span>
 			size = 64;
 		/* Tbird rev A1/A2 */
 		if (c-&gt;x86_model == 4 &amp;&amp;
<span class="p_del">-			(c-&gt;x86_mask == 0 || c-&gt;x86_mask == 1))</span>
<span class="p_add">+			(c-&gt;x86_stepping == 0 || c-&gt;x86_stepping == 1))</span>
 			size = 256;
 	}
 	return size;
<span class="p_chunk">@@ -1021,7 +1021,7 @@</span> <span class="p_context"> static bool cpu_has_amd_erratum(struct cpuinfo_x86 *cpu, const int *erratum)</span>
 	}
 
 	/* OSVW unavailable or ID unknown, match family-model-stepping range */
<span class="p_del">-	ms = (cpu-&gt;x86_model &lt;&lt; 4) | cpu-&gt;x86_mask;</span>
<span class="p_add">+	ms = (cpu-&gt;x86_model &lt;&lt; 4) | cpu-&gt;x86_stepping;</span>
 	while ((range = *erratum++))
 		if ((cpu-&gt;x86 == AMD_MODEL_RANGE_FAMILY(range)) &amp;&amp;
 		    (ms &gt;= AMD_MODEL_RANGE_START(range)) &amp;&amp;
<span class="p_header">diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_header">index 71949bf2de5a..d71c8b54b696 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_chunk">@@ -162,8 +162,7 @@</span> <span class="p_context"> static enum spectre_v2_mitigation_cmd __init spectre_v2_parse_cmdline(void)</span>
 	if (cmdline_find_option_bool(boot_command_line, &quot;nospectre_v2&quot;))
 		return SPECTRE_V2_CMD_NONE;
 	else {
<span class="p_del">-		ret = cmdline_find_option(boot_command_line, &quot;spectre_v2&quot;, arg,</span>
<span class="p_del">-					  sizeof(arg));</span>
<span class="p_add">+		ret = cmdline_find_option(boot_command_line, &quot;spectre_v2&quot;, arg, sizeof(arg));</span>
 		if (ret &lt; 0)
 			return SPECTRE_V2_CMD_AUTO;
 
<span class="p_chunk">@@ -175,8 +174,7 @@</span> <span class="p_context"> static enum spectre_v2_mitigation_cmd __init spectre_v2_parse_cmdline(void)</span>
 		}
 
 		if (i &gt;= ARRAY_SIZE(mitigation_options)) {
<span class="p_del">-			pr_err(&quot;unknown option (%s). Switching to AUTO select\n&quot;,</span>
<span class="p_del">-			       mitigation_options[i].option);</span>
<span class="p_add">+			pr_err(&quot;unknown option (%s). Switching to AUTO select\n&quot;, arg);</span>
 			return SPECTRE_V2_CMD_AUTO;
 		}
 	}
<span class="p_chunk">@@ -185,8 +183,7 @@</span> <span class="p_context"> static enum spectre_v2_mitigation_cmd __init spectre_v2_parse_cmdline(void)</span>
 	     cmd == SPECTRE_V2_CMD_RETPOLINE_AMD ||
 	     cmd == SPECTRE_V2_CMD_RETPOLINE_GENERIC) &amp;&amp;
 	    !IS_ENABLED(CONFIG_RETPOLINE)) {
<span class="p_del">-		pr_err(&quot;%s selected but not compiled in. Switching to AUTO select\n&quot;,</span>
<span class="p_del">-		       mitigation_options[i].option);</span>
<span class="p_add">+		pr_err(&quot;%s selected but not compiled in. Switching to AUTO select\n&quot;, mitigation_options[i].option);</span>
 		return SPECTRE_V2_CMD_AUTO;
 	}
 
<span class="p_chunk">@@ -256,14 +253,14 @@</span> <span class="p_context"> static void __init spectre_v2_select_mitigation(void)</span>
 			goto retpoline_auto;
 		break;
 	}
<span class="p_del">-	pr_err(&quot;kernel not compiled with retpoline; no mitigation available!&quot;);</span>
<span class="p_add">+	pr_err(&quot;Spectre mitigation: kernel not compiled with retpoline; no mitigation available!&quot;);</span>
 	return;
 
 retpoline_auto:
 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
 	retpoline_amd:
 		if (!boot_cpu_has(X86_FEATURE_LFENCE_RDTSC)) {
<span class="p_del">-			pr_err(&quot;LFENCE not serializing. Switching to generic retpoline\n&quot;);</span>
<span class="p_add">+			pr_err(&quot;Spectre mitigation: LFENCE not serializing, switching to generic retpoline\n&quot;);</span>
 			goto retpoline_generic;
 		}
 		mode = retp_compiler() ? SPECTRE_V2_RETPOLINE_AMD :
<span class="p_chunk">@@ -281,7 +278,7 @@</span> <span class="p_context"> static void __init spectre_v2_select_mitigation(void)</span>
 	pr_info(&quot;%s\n&quot;, spectre_v2_strings[mode]);
 
 	/*
<span class="p_del">-	 * If neither SMEP or KPTI are available, there is a risk of</span>
<span class="p_add">+	 * If neither SMEP nor PTI are available, there is a risk of</span>
 	 * hitting userspace addresses in the RSB after a context switch
 	 * from a shallow call stack to a deeper one. To prevent this fill
 	 * the entire RSB, even when using IBRS.
<span class="p_chunk">@@ -295,21 +292,20 @@</span> <span class="p_context"> static void __init spectre_v2_select_mitigation(void)</span>
 	if ((!boot_cpu_has(X86_FEATURE_PTI) &amp;&amp;
 	     !boot_cpu_has(X86_FEATURE_SMEP)) || is_skylake_era()) {
 		setup_force_cpu_cap(X86_FEATURE_RSB_CTXSW);
<span class="p_del">-		pr_info(&quot;Filling RSB on context switch\n&quot;);</span>
<span class="p_add">+		pr_info(&quot;Spectre v2 mitigation: Filling RSB on context switch\n&quot;);</span>
 	}
 
 	/* Initialize Indirect Branch Prediction Barrier if supported */
 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
<span class="p_del">-		pr_info(&quot;Enabling Indirect Branch Prediction Barrier\n&quot;);</span>
<span class="p_add">+		pr_info(&quot;Spectre v2 mitigation: Enabling Indirect Branch Prediction Barrier\n&quot;);</span>
 	}
 }
 
 #undef pr_fmt
 
 #ifdef CONFIG_SYSFS
<span class="p_del">-ssize_t cpu_show_meltdown(struct device *dev,</span>
<span class="p_del">-			  struct device_attribute *attr, char *buf)</span>
<span class="p_add">+ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)</span>
 {
 	if (!boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN))
 		return sprintf(buf, &quot;Not affected\n&quot;);
<span class="p_chunk">@@ -318,16 +314,14 @@</span> <span class="p_context"> ssize_t cpu_show_meltdown(struct device *dev,</span>
 	return sprintf(buf, &quot;Vulnerable\n&quot;);
 }
 
<span class="p_del">-ssize_t cpu_show_spectre_v1(struct device *dev,</span>
<span class="p_del">-			    struct device_attribute *attr, char *buf)</span>
<span class="p_add">+ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, char *buf)</span>
 {
 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V1))
 		return sprintf(buf, &quot;Not affected\n&quot;);
 	return sprintf(buf, &quot;Mitigation: __user pointer sanitization\n&quot;);
 }
 
<span class="p_del">-ssize_t cpu_show_spectre_v2(struct device *dev,</span>
<span class="p_del">-			    struct device_attribute *attr, char *buf)</span>
<span class="p_add">+ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, char *buf)</span>
 {
 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
 		return sprintf(buf, &quot;Not affected\n&quot;);
<span class="p_chunk">@@ -337,9 +331,3 @@</span> <span class="p_context"> ssize_t cpu_show_spectre_v2(struct device *dev,</span>
 		       spectre_v2_module_string());
 }
 #endif
<span class="p_del">-</span>
<span class="p_del">-void __ibp_barrier(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	__wrmsr(MSR_IA32_PRED_CMD, PRED_CMD_IBPB, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(__ibp_barrier);</span>
<span class="p_header">diff --git a/arch/x86/kernel/cpu/centaur.c b/arch/x86/kernel/cpu/centaur.c</span>
<span class="p_header">index 68bc6d9b3132..595be776727d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/centaur.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/centaur.c</span>
<span class="p_chunk">@@ -136,7 +136,7 @@</span> <span class="p_context"> static void init_centaur(struct cpuinfo_x86 *c)</span>
 			clear_cpu_cap(c, X86_FEATURE_TSC);
 			break;
 		case 8:
<span class="p_del">-			switch (c-&gt;x86_mask) {</span>
<span class="p_add">+			switch (c-&gt;x86_stepping) {</span>
 			default:
 			name = &quot;2&quot;;
 				break;
<span class="p_chunk">@@ -211,7 +211,7 @@</span> <span class="p_context"> centaur_size_cache(struct cpuinfo_x86 *c, unsigned int size)</span>
 	 *  - Note, it seems this may only be in engineering samples.
 	 */
 	if ((c-&gt;x86 == 6) &amp;&amp; (c-&gt;x86_model == 9) &amp;&amp;
<span class="p_del">-				(c-&gt;x86_mask == 1) &amp;&amp; (size == 65))</span>
<span class="p_add">+				(c-&gt;x86_stepping == 1) &amp;&amp; (size == 65))</span>
 		size -= 1;
 	return size;
 }
<span class="p_header">diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">index 92b66e21bae5..651b7afed4da 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -707,7 +707,7 @@</span> <span class="p_context"> void cpu_detect(struct cpuinfo_x86 *c)</span>
 		cpuid(0x00000001, &amp;tfms, &amp;misc, &amp;junk, &amp;cap0);
 		c-&gt;x86		= x86_family(tfms);
 		c-&gt;x86_model	= x86_model(tfms);
<span class="p_del">-		c-&gt;x86_mask	= x86_stepping(tfms);</span>
<span class="p_add">+		c-&gt;x86_stepping	= x86_stepping(tfms);</span>
 
 		if (cap0 &amp; (1&lt;&lt;19)) {
 			c-&gt;x86_clflush_size = ((misc &gt;&gt; 8) &amp; 0xff) * 8;
<span class="p_chunk">@@ -1160,9 +1160,9 @@</span> <span class="p_context"> static void identify_cpu(struct cpuinfo_x86 *c)</span>
 	int i;
 
 	c-&gt;loops_per_jiffy = loops_per_jiffy;
<span class="p_del">-	c-&gt;x86_cache_size = -1;</span>
<span class="p_add">+	c-&gt;x86_cache_size = 0;</span>
 	c-&gt;x86_vendor = X86_VENDOR_UNKNOWN;
<span class="p_del">-	c-&gt;x86_model = c-&gt;x86_mask = 0;	/* So far unknown... */</span>
<span class="p_add">+	c-&gt;x86_model = c-&gt;x86_stepping = 0;	/* So far unknown... */</span>
 	c-&gt;x86_vendor_id[0] = &#39;\0&#39;; /* Unset */
 	c-&gt;x86_model_id[0] = &#39;\0&#39;;  /* Unset */
 	c-&gt;x86_max_cores = 1;
<span class="p_chunk">@@ -1353,8 +1353,8 @@</span> <span class="p_context"> void print_cpu_info(struct cpuinfo_x86 *c)</span>
 
 	pr_cont(&quot; (family: 0x%x, model: 0x%x&quot;, c-&gt;x86, c-&gt;x86_model);
 
<span class="p_del">-	if (c-&gt;x86_mask || c-&gt;cpuid_level &gt;= 0)</span>
<span class="p_del">-		pr_cont(&quot;, stepping: 0x%x)\n&quot;, c-&gt;x86_mask);</span>
<span class="p_add">+	if (c-&gt;x86_stepping || c-&gt;cpuid_level &gt;= 0)</span>
<span class="p_add">+		pr_cont(&quot;, stepping: 0x%x)\n&quot;, c-&gt;x86_stepping);</span>
 	else
 		pr_cont(&quot;)\n&quot;);
 }
<span class="p_header">diff --git a/arch/x86/kernel/cpu/cyrix.c b/arch/x86/kernel/cpu/cyrix.c</span>
<span class="p_header">index 6b4bb335641f..8949b7ae6d92 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/cyrix.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/cyrix.c</span>
<span class="p_chunk">@@ -215,7 +215,7 @@</span> <span class="p_context"> static void init_cyrix(struct cpuinfo_x86 *c)</span>
 
 	/* common case step number/rev -- exceptions handled below */
 	c-&gt;x86_model = (dir1 &gt;&gt; 4) + 1;
<span class="p_del">-	c-&gt;x86_mask = dir1 &amp; 0xf;</span>
<span class="p_add">+	c-&gt;x86_stepping = dir1 &amp; 0xf;</span>
 
 	/* Now cook; the original recipe is by Channing Corn, from Cyrix.
 	 * We do the same thing for each generation: we work out
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">index 4cf4f8cbc69d..d19e903214b4 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_chunk">@@ -116,14 +116,13 @@</span> <span class="p_context"> struct sku_microcode {</span>
 	u32 microcode;
 };
 static const struct sku_microcode spectre_bad_microcodes[] = {
<span class="p_del">-	{ INTEL_FAM6_KABYLAKE_DESKTOP,	0x0B,	0x84 },</span>
<span class="p_del">-	{ INTEL_FAM6_KABYLAKE_DESKTOP,	0x0A,	0x84 },</span>
<span class="p_del">-	{ INTEL_FAM6_KABYLAKE_DESKTOP,	0x09,	0x84 },</span>
<span class="p_del">-	{ INTEL_FAM6_KABYLAKE_MOBILE,	0x0A,	0x84 },</span>
<span class="p_del">-	{ INTEL_FAM6_KABYLAKE_MOBILE,	0x09,	0x84 },</span>
<span class="p_add">+	{ INTEL_FAM6_KABYLAKE_DESKTOP,	0x0B,	0x80 },</span>
<span class="p_add">+	{ INTEL_FAM6_KABYLAKE_DESKTOP,	0x0A,	0x80 },</span>
<span class="p_add">+	{ INTEL_FAM6_KABYLAKE_DESKTOP,	0x09,	0x80 },</span>
<span class="p_add">+	{ INTEL_FAM6_KABYLAKE_MOBILE,	0x0A,	0x80 },</span>
<span class="p_add">+	{ INTEL_FAM6_KABYLAKE_MOBILE,	0x09,	0x80 },</span>
 	{ INTEL_FAM6_SKYLAKE_X,		0x03,	0x0100013e },
 	{ INTEL_FAM6_SKYLAKE_X,		0x04,	0x0200003c },
<span class="p_del">-	{ INTEL_FAM6_SKYLAKE_MOBILE,	0x03,	0xc2 },</span>
 	{ INTEL_FAM6_SKYLAKE_DESKTOP,	0x03,	0xc2 },
 	{ INTEL_FAM6_BROADWELL_CORE,	0x04,	0x28 },
 	{ INTEL_FAM6_BROADWELL_GT3E,	0x01,	0x1b },
<span class="p_chunk">@@ -136,8 +135,6 @@</span> <span class="p_context"> static const struct sku_microcode spectre_bad_microcodes[] = {</span>
 	{ INTEL_FAM6_HASWELL_X,		0x02,	0x3b },
 	{ INTEL_FAM6_HASWELL_X,		0x04,	0x10 },
 	{ INTEL_FAM6_IVYBRIDGE_X,	0x04,	0x42a },
<span class="p_del">-	/* Updated in the 20180108 release; blacklist until we know otherwise */</span>
<span class="p_del">-	{ INTEL_FAM6_ATOM_GEMINI_LAKE,	0x01,	0x22 },</span>
 	/* Observed in the wild */
 	{ INTEL_FAM6_SANDYBRIDGE_X,	0x06,	0x61b },
 	{ INTEL_FAM6_SANDYBRIDGE_X,	0x07,	0x712 },
<span class="p_chunk">@@ -149,7 +146,7 @@</span> <span class="p_context"> static bool bad_spectre_microcode(struct cpuinfo_x86 *c)</span>
 
 	for (i = 0; i &lt; ARRAY_SIZE(spectre_bad_microcodes); i++) {
 		if (c-&gt;x86_model == spectre_bad_microcodes[i].model &amp;&amp;
<span class="p_del">-		    c-&gt;x86_mask == spectre_bad_microcodes[i].stepping)</span>
<span class="p_add">+		    c-&gt;x86_stepping == spectre_bad_microcodes[i].stepping)</span>
 			return (c-&gt;microcode &lt;= spectre_bad_microcodes[i].microcode);
 	}
 	return false;
<span class="p_chunk">@@ -196,7 +193,7 @@</span> <span class="p_context"> static void early_init_intel(struct cpuinfo_x86 *c)</span>
 	 * need the microcode to have already been loaded... so if it is
 	 * not, recommend a BIOS update and disable large pages.
 	 */
<span class="p_del">-	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model == 0x1c &amp;&amp; c-&gt;x86_mask &lt;= 2 &amp;&amp;</span>
<span class="p_add">+	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model == 0x1c &amp;&amp; c-&gt;x86_stepping &lt;= 2 &amp;&amp;</span>
 	    c-&gt;microcode &lt; 0x20e) {
 		pr_warn(&quot;Atom PSE erratum detected, BIOS microcode update recommended\n&quot;);
 		clear_cpu_cap(c, X86_FEATURE_PSE);
<span class="p_chunk">@@ -212,7 +209,7 @@</span> <span class="p_context"> static void early_init_intel(struct cpuinfo_x86 *c)</span>
 
 	/* CPUID workaround for 0F33/0F34 CPU */
 	if (c-&gt;x86 == 0xF &amp;&amp; c-&gt;x86_model == 0x3
<span class="p_del">-	    &amp;&amp; (c-&gt;x86_mask == 0x3 || c-&gt;x86_mask == 0x4))</span>
<span class="p_add">+	    &amp;&amp; (c-&gt;x86_stepping == 0x3 || c-&gt;x86_stepping == 0x4))</span>
 		c-&gt;x86_phys_bits = 36;
 
 	/*
<span class="p_chunk">@@ -253,21 +250,6 @@</span> <span class="p_context"> static void early_init_intel(struct cpuinfo_x86 *c)</span>
 	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model &lt; 15)
 		clear_cpu_cap(c, X86_FEATURE_PAT);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * P4s have a &quot;fast strings&quot; feature which causes single-</span>
<span class="p_del">-	 * stepping REP instructions to only generate a #DB on</span>
<span class="p_del">-	 * cache-line boundaries.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Ingo Molnar reported a Pentium D (model 6) and a Xeon</span>
<span class="p_del">-	 * (model 2) with the same problem.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (c-&gt;x86 == 15)</span>
<span class="p_del">-		if (msr_clear_bit(MSR_IA32_MISC_ENABLE,</span>
<span class="p_del">-				  MSR_IA32_MISC_ENABLE_FAST_STRING_BIT) &gt; 0)</span>
<span class="p_del">-			pr_info(&quot;kmemcheck: Disabling fast string operations\n&quot;);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	/*
 	 * If fast string is not enabled in IA32_MISC_ENABLE for any reason,
 	 * clear the fast string and enhanced fast string CPU capabilities.
<span class="p_chunk">@@ -325,7 +307,7 @@</span> <span class="p_context"> int ppro_with_ram_bug(void)</span>
 	if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &amp;&amp;
 	    boot_cpu_data.x86 == 6 &amp;&amp;
 	    boot_cpu_data.x86_model == 1 &amp;&amp;
<span class="p_del">-	    boot_cpu_data.x86_mask &lt; 8) {</span>
<span class="p_add">+	    boot_cpu_data.x86_stepping &lt; 8) {</span>
 		pr_info(&quot;Pentium Pro with Errata#50 detected. Taking evasive action.\n&quot;);
 		return 1;
 	}
<span class="p_chunk">@@ -342,7 +324,7 @@</span> <span class="p_context"> static void intel_smp_check(struct cpuinfo_x86 *c)</span>
 	 * Mask B, Pentium, but not Pentium MMX
 	 */
 	if (c-&gt;x86 == 5 &amp;&amp;
<span class="p_del">-	    c-&gt;x86_mask &gt;= 1 &amp;&amp; c-&gt;x86_mask &lt;= 4 &amp;&amp;</span>
<span class="p_add">+	    c-&gt;x86_stepping &gt;= 1 &amp;&amp; c-&gt;x86_stepping &lt;= 4 &amp;&amp;</span>
 	    c-&gt;x86_model &lt;= 3) {
 		/*
 		 * Remember we have B step Pentia with bugs
<span class="p_chunk">@@ -385,7 +367,7 @@</span> <span class="p_context"> static void intel_workarounds(struct cpuinfo_x86 *c)</span>
 	 * SEP CPUID bug: Pentium Pro reports SEP but doesn&#39;t have it until
 	 * model 3 mask 3
 	 */
<span class="p_del">-	if ((c-&gt;x86&lt;&lt;8 | c-&gt;x86_model&lt;&lt;4 | c-&gt;x86_mask) &lt; 0x633)</span>
<span class="p_add">+	if ((c-&gt;x86&lt;&lt;8 | c-&gt;x86_model&lt;&lt;4 | c-&gt;x86_stepping) &lt; 0x633)</span>
 		clear_cpu_cap(c, X86_FEATURE_SEP);
 
 	/*
<span class="p_chunk">@@ -403,7 +385,7 @@</span> <span class="p_context"> static void intel_workarounds(struct cpuinfo_x86 *c)</span>
 	 * P4 Xeon erratum 037 workaround.
 	 * Hardware prefetcher may cause stale data to be loaded into the cache.
 	 */
<span class="p_del">-	if ((c-&gt;x86 == 15) &amp;&amp; (c-&gt;x86_model == 1) &amp;&amp; (c-&gt;x86_mask == 1)) {</span>
<span class="p_add">+	if ((c-&gt;x86 == 15) &amp;&amp; (c-&gt;x86_model == 1) &amp;&amp; (c-&gt;x86_stepping == 1)) {</span>
 		if (msr_set_bit(MSR_IA32_MISC_ENABLE,
 				MSR_IA32_MISC_ENABLE_PREFETCH_DISABLE_BIT) &gt; 0) {
 			pr_info(&quot;CPU: C0 stepping P4 Xeon detected.\n&quot;);
<span class="p_chunk">@@ -418,7 +400,7 @@</span> <span class="p_context"> static void intel_workarounds(struct cpuinfo_x86 *c)</span>
 	 * Specification Update&quot;).
 	 */
 	if (boot_cpu_has(X86_FEATURE_APIC) &amp;&amp; (c-&gt;x86&lt;&lt;8 | c-&gt;x86_model&lt;&lt;4) == 0x520 &amp;&amp;
<span class="p_del">-	    (c-&gt;x86_mask &lt; 0x6 || c-&gt;x86_mask == 0xb))</span>
<span class="p_add">+	    (c-&gt;x86_stepping &lt; 0x6 || c-&gt;x86_stepping == 0xb))</span>
 		set_cpu_bug(c, X86_BUG_11AP);
 
 
<span class="p_chunk">@@ -665,7 +647,7 @@</span> <span class="p_context"> static void init_intel(struct cpuinfo_x86 *c)</span>
 		case 6:
 			if (l2 == 128)
 				p = &quot;Celeron (Mendocino)&quot;;
<span class="p_del">-			else if (c-&gt;x86_mask == 0 || c-&gt;x86_mask == 5)</span>
<span class="p_add">+			else if (c-&gt;x86_stepping == 0 || c-&gt;x86_stepping == 5)</span>
 				p = &quot;Celeron-A&quot;;
 			break;
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel_rdt.c b/arch/x86/kernel/cpu/intel_rdt.c</span>
<span class="p_header">index 99442370de40..18dd8f22e353 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel_rdt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel_rdt.c</span>
<span class="p_chunk">@@ -771,7 +771,7 @@</span> <span class="p_context"> static __init void rdt_quirks(void)</span>
 			cache_alloc_hsw_probe();
 		break;
 	case INTEL_FAM6_SKYLAKE_X:
<span class="p_del">-		if (boot_cpu_data.x86_mask &lt;= 4)</span>
<span class="p_add">+		if (boot_cpu_data.x86_stepping &lt;= 4)</span>
 			set_rdt_options(&quot;!cmt,!mbmtotal,!mbmlocal,!l3cat&quot;);
 	}
 }
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mcheck/mce-internal.h b/arch/x86/kernel/cpu/mcheck/mce-internal.h</span>
<span class="p_header">index aa0d5df9dc60..e956eb267061 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mcheck/mce-internal.h</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mcheck/mce-internal.h</span>
<span class="p_chunk">@@ -115,4 +115,19 @@</span> <span class="p_context"> static inline void mce_unregister_injector_chain(struct notifier_block *nb)	{ }</span>
 
 extern struct mca_config mca_cfg;
 
<span class="p_add">+#ifndef CONFIG_X86_64</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * On 32-bit systems it would be difficult to safely unmap a poison page</span>
<span class="p_add">+ * from the kernel 1:1 map because there are no non-canonical addresses that</span>
<span class="p_add">+ * we can use to refer to the address without risking a speculative access.</span>
<span class="p_add">+ * However, this isn&#39;t much of an issue because:</span>
<span class="p_add">+ * 1) Few unmappable pages are in the 1:1 map. Most are in HIGHMEM which</span>
<span class="p_add">+ *    are only mapped into the kernel as needed</span>
<span class="p_add">+ * 2) Few people would run a 32-bit kernel on a machine that supports</span>
<span class="p_add">+ *    recoverable errors because they have too much memory to boot 32-bit.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void mce_unmap_kpfn(unsigned long pfn) {}</span>
<span class="p_add">+#define mce_unmap_kpfn mce_unmap_kpfn</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif /* __X86_MCE_INTERNAL_H__ */
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mcheck/mce.c b/arch/x86/kernel/cpu/mcheck/mce.c</span>
<span class="p_header">index a9e898b71208..73237aa271ea 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mcheck/mce.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mcheck/mce.c</span>
<span class="p_chunk">@@ -106,6 +106,10 @@</span> <span class="p_context"> static struct irq_work mce_irq_work;</span>
 
 static void (*quirk_no_way_out)(int bank, struct mce *m, struct pt_regs *regs);
 
<span class="p_add">+#ifndef mce_unmap_kpfn</span>
<span class="p_add">+static void mce_unmap_kpfn(unsigned long pfn);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 /*
  * CPU/chipset specific EDAC code can register a notifier call here to print
  * MCE errors in a human-readable form.
<span class="p_chunk">@@ -582,7 +586,8 @@</span> <span class="p_context"> static int srao_decode_notifier(struct notifier_block *nb, unsigned long val,</span>
 
 	if (mce_usable_address(mce) &amp;&amp; (mce-&gt;severity == MCE_AO_SEVERITY)) {
 		pfn = mce-&gt;addr &gt;&gt; PAGE_SHIFT;
<span class="p_del">-		memory_failure(pfn, MCE_VECTOR, 0);</span>
<span class="p_add">+		if (memory_failure(pfn, MCE_VECTOR, 0))</span>
<span class="p_add">+			mce_unmap_kpfn(pfn);</span>
 	}
 
 	return NOTIFY_OK;
<span class="p_chunk">@@ -1049,12 +1054,13 @@</span> <span class="p_context"> static int do_memory_failure(struct mce *m)</span>
 	ret = memory_failure(m-&gt;addr &gt;&gt; PAGE_SHIFT, MCE_VECTOR, flags);
 	if (ret)
 		pr_err(&quot;Memory error not recovered&quot;);
<span class="p_add">+	else</span>
<span class="p_add">+		mce_unmap_kpfn(m-&gt;addr &gt;&gt; PAGE_SHIFT);</span>
 	return ret;
 }
 
<span class="p_del">-#if defined(arch_unmap_kpfn) &amp;&amp; defined(CONFIG_MEMORY_FAILURE)</span>
<span class="p_del">-</span>
<span class="p_del">-void arch_unmap_kpfn(unsigned long pfn)</span>
<span class="p_add">+#ifndef mce_unmap_kpfn</span>
<span class="p_add">+static void mce_unmap_kpfn(unsigned long pfn)</span>
 {
 	unsigned long decoy_addr;
 
<span class="p_chunk">@@ -1065,7 +1071,7 @@</span> <span class="p_context"> void arch_unmap_kpfn(unsigned long pfn)</span>
 	 * We would like to just call:
 	 *	set_memory_np((unsigned long)pfn_to_kaddr(pfn), 1);
 	 * but doing that would radically increase the odds of a
<span class="p_del">-	 * speculative access to the posion page because we&#39;d have</span>
<span class="p_add">+	 * speculative access to the poison page because we&#39;d have</span>
 	 * the virtual address of the kernel 1:1 mapping sitting
 	 * around in registers.
 	 * Instead we get tricky.  We create a non-canonical address
<span class="p_chunk">@@ -1090,7 +1096,6 @@</span> <span class="p_context"> void arch_unmap_kpfn(unsigned long pfn)</span>
 
 	if (set_memory_np(decoy_addr, 1))
 		pr_warn(&quot;Could not invalidate pfn=0x%lx from 1:1 map\n&quot;, pfn);
<span class="p_del">-</span>
 }
 #endif
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/microcode/intel.c b/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_header">index f7c55b0e753a..a15db2b4e0d6 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_chunk">@@ -921,7 +921,7 @@</span> <span class="p_context"> static bool is_blacklisted(unsigned int cpu)</span>
 	 */
 	if (c-&gt;x86 == 6 &amp;&amp;
 	    c-&gt;x86_model == INTEL_FAM6_BROADWELL_X &amp;&amp;
<span class="p_del">-	    c-&gt;x86_mask == 0x01 &amp;&amp;</span>
<span class="p_add">+	    c-&gt;x86_stepping == 0x01 &amp;&amp;</span>
 	    llc_size_per_core &gt; 2621440 &amp;&amp;
 	    c-&gt;microcode &lt; 0x0b000021) {
 		pr_err_once(&quot;Erratum BDF90: late loading with revision &lt; 0x0b000021 (0x%x) disabled.\n&quot;, c-&gt;microcode);
<span class="p_chunk">@@ -944,7 +944,7 @@</span> <span class="p_context"> static enum ucode_state request_microcode_fw(int cpu, struct device *device,</span>
 		return UCODE_NFOUND;
 
 	sprintf(name, &quot;intel-ucode/%02x-%02x-%02x&quot;,
<span class="p_del">-		c-&gt;x86, c-&gt;x86_model, c-&gt;x86_mask);</span>
<span class="p_add">+		c-&gt;x86, c-&gt;x86_model, c-&gt;x86_stepping);</span>
 
 	if (request_firmware_direct(&amp;firmware, name, device)) {
 		pr_debug(&quot;data file %s load failed\n&quot;, name);
<span class="p_chunk">@@ -982,7 +982,7 @@</span> <span class="p_context"> static struct microcode_ops microcode_intel_ops = {</span>
 
 static int __init calc_llc_size_per_core(struct cpuinfo_x86 *c)
 {
<span class="p_del">-	u64 llc_size = c-&gt;x86_cache_size * 1024;</span>
<span class="p_add">+	u64 llc_size = c-&gt;x86_cache_size * 1024ULL;</span>
 
 	do_div(llc_size, c-&gt;x86_max_cores);
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mtrr/generic.c b/arch/x86/kernel/cpu/mtrr/generic.c</span>
<span class="p_header">index fdc55215d44d..e12ee86906c6 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mtrr/generic.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mtrr/generic.c</span>
<span class="p_chunk">@@ -859,7 +859,7 @@</span> <span class="p_context"> int generic_validate_add_page(unsigned long base, unsigned long size,</span>
 	 */
 	if (is_cpu(INTEL) &amp;&amp; boot_cpu_data.x86 == 6 &amp;&amp;
 	    boot_cpu_data.x86_model == 1 &amp;&amp;
<span class="p_del">-	    boot_cpu_data.x86_mask &lt;= 7) {</span>
<span class="p_add">+	    boot_cpu_data.x86_stepping &lt;= 7) {</span>
 		if (base &amp; ((1 &lt;&lt; (22 - PAGE_SHIFT)) - 1)) {
 			pr_warn(&quot;mtrr: base(0x%lx000) is not 4 MiB aligned\n&quot;, base);
 			return -EINVAL;
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mtrr/main.c b/arch/x86/kernel/cpu/mtrr/main.c</span>
<span class="p_header">index 40d5a8a75212..7468de429087 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mtrr/main.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mtrr/main.c</span>
<span class="p_chunk">@@ -711,8 +711,8 @@</span> <span class="p_context"> void __init mtrr_bp_init(void)</span>
 			if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &amp;&amp;
 			    boot_cpu_data.x86 == 0xF &amp;&amp;
 			    boot_cpu_data.x86_model == 0x3 &amp;&amp;
<span class="p_del">-			    (boot_cpu_data.x86_mask == 0x3 ||</span>
<span class="p_del">-			     boot_cpu_data.x86_mask == 0x4))</span>
<span class="p_add">+			    (boot_cpu_data.x86_stepping == 0x3 ||</span>
<span class="p_add">+			     boot_cpu_data.x86_stepping == 0x4))</span>
 				phys_addr = 36;
 
 			size_or_mask = SIZE_OR_MASK_BITS(phys_addr);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/proc.c b/arch/x86/kernel/cpu/proc.c</span>
<span class="p_header">index e7ecedafa1c8..2c8522a39ed5 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/proc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/proc.c</span>
<span class="p_chunk">@@ -72,8 +72,8 @@</span> <span class="p_context"> static int show_cpuinfo(struct seq_file *m, void *v)</span>
 		   c-&gt;x86_model,
 		   c-&gt;x86_model_id[0] ? c-&gt;x86_model_id : &quot;unknown&quot;);
 
<span class="p_del">-	if (c-&gt;x86_mask || c-&gt;cpuid_level &gt;= 0)</span>
<span class="p_del">-		seq_printf(m, &quot;stepping\t: %d\n&quot;, c-&gt;x86_mask);</span>
<span class="p_add">+	if (c-&gt;x86_stepping || c-&gt;cpuid_level &gt;= 0)</span>
<span class="p_add">+		seq_printf(m, &quot;stepping\t: %d\n&quot;, c-&gt;x86_stepping);</span>
 	else
 		seq_puts(m, &quot;stepping\t: unknown\n&quot;);
 	if (c-&gt;microcode)
<span class="p_chunk">@@ -91,8 +91,8 @@</span> <span class="p_context"> static int show_cpuinfo(struct seq_file *m, void *v)</span>
 	}
 
 	/* Cache size */
<span class="p_del">-	if (c-&gt;x86_cache_size &gt;= 0)</span>
<span class="p_del">-		seq_printf(m, &quot;cache size\t: %d KB\n&quot;, c-&gt;x86_cache_size);</span>
<span class="p_add">+	if (c-&gt;x86_cache_size)</span>
<span class="p_add">+		seq_printf(m, &quot;cache size\t: %u KB\n&quot;, c-&gt;x86_cache_size);</span>
 
 	show_cpuinfo_core(m, c, cpu);
 	show_cpuinfo_misc(m, c);
<span class="p_header">diff --git a/arch/x86/kernel/early-quirks.c b/arch/x86/kernel/early-quirks.c</span>
<span class="p_header">index 1e82f787c160..c87560e1e3ef 100644</span>
<span class="p_header">--- a/arch/x86/kernel/early-quirks.c</span>
<span class="p_header">+++ b/arch/x86/kernel/early-quirks.c</span>
<span class="p_chunk">@@ -527,6 +527,7 @@</span> <span class="p_context"> static const struct pci_device_id intel_early_ids[] __initconst = {</span>
 	INTEL_SKL_IDS(&amp;gen9_early_ops),
 	INTEL_BXT_IDS(&amp;gen9_early_ops),
 	INTEL_KBL_IDS(&amp;gen9_early_ops),
<span class="p_add">+	INTEL_CFL_IDS(&amp;gen9_early_ops),</span>
 	INTEL_GLK_IDS(&amp;gen9_early_ops),
 	INTEL_CNL_IDS(&amp;gen9_early_ops),
 };
<span class="p_header">diff --git a/arch/x86/kernel/espfix_64.c b/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">index 9c4e7ba6870c..cbded50ee601 100644</span>
<span class="p_header">--- a/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/espfix_64.c</span>
<span class="p_chunk">@@ -57,7 +57,7 @@</span> <span class="p_context"></span>
 # error &quot;Need more virtual address space for the ESPFIX hack&quot;
 #endif
 
<span class="p_del">-#define PGALLOC_GFP (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP (GFP_KERNEL | __GFP_ZERO)</span>
 
 /* This contains the *bottom* address of the espfix stack */
 DEFINE_PER_CPU_READ_MOSTLY(unsigned long, espfix_stack);
<span class="p_header">diff --git a/arch/x86/kernel/head_32.S b/arch/x86/kernel/head_32.S</span>
<span class="p_header">index c29020907886..b59e4fb40fd9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head_32.S</span>
<span class="p_header">+++ b/arch/x86/kernel/head_32.S</span>
<span class="p_chunk">@@ -37,7 +37,7 @@</span> <span class="p_context"></span>
 #define X86		new_cpu_data+CPUINFO_x86
 #define X86_VENDOR	new_cpu_data+CPUINFO_x86_vendor
 #define X86_MODEL	new_cpu_data+CPUINFO_x86_model
<span class="p_del">-#define X86_MASK	new_cpu_data+CPUINFO_x86_mask</span>
<span class="p_add">+#define X86_STEPPING	new_cpu_data+CPUINFO_x86_stepping</span>
 #define X86_HARD_MATH	new_cpu_data+CPUINFO_hard_math
 #define X86_CPUID	new_cpu_data+CPUINFO_cpuid_level
 #define X86_CAPABILITY	new_cpu_data+CPUINFO_x86_capability
<span class="p_chunk">@@ -332,7 +332,7 @@</span> <span class="p_context"> ENTRY(startup_32_smp)</span>
 	shrb $4,%al
 	movb %al,X86_MODEL
 	andb $0x0f,%cl		# mask mask revision
<span class="p_del">-	movb %cl,X86_MASK</span>
<span class="p_add">+	movb %cl,X86_STEPPING</span>
 	movl %edx,X86_CAPABILITY
 
 .Lis486:
<span class="p_header">diff --git a/arch/x86/kernel/mpparse.c b/arch/x86/kernel/mpparse.c</span>
<span class="p_header">index 3a4b12809ab5..bc6bc6689e68 100644</span>
<span class="p_header">--- a/arch/x86/kernel/mpparse.c</span>
<span class="p_header">+++ b/arch/x86/kernel/mpparse.c</span>
<span class="p_chunk">@@ -407,7 +407,7 @@</span> <span class="p_context"> static inline void __init construct_default_ISA_mptable(int mpc_default_type)</span>
 	processor.apicver = mpc_default_type &gt; 4 ? 0x10 : 0x01;
 	processor.cpuflag = CPU_ENABLED;
 	processor.cpufeature = (boot_cpu_data.x86 &lt;&lt; 8) |
<span class="p_del">-	    (boot_cpu_data.x86_model &lt;&lt; 4) | boot_cpu_data.x86_mask;</span>
<span class="p_add">+	    (boot_cpu_data.x86_model &lt;&lt; 4) | boot_cpu_data.x86_stepping;</span>
 	processor.featureflag = boot_cpu_data.x86_capability[CPUID_1_EDX];
 	processor.reserved[0] = 0;
 	processor.reserved[1] = 0;
<span class="p_header">diff --git a/arch/x86/kernel/paravirt.c b/arch/x86/kernel/paravirt.c</span>
<span class="p_header">index 19a3e8f961c7..e1df9ef5d78c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/paravirt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/paravirt.c</span>
<span class="p_chunk">@@ -190,9 +190,9 @@</span> <span class="p_context"> static void native_flush_tlb_global(void)</span>
 	__native_flush_tlb_global();
 }
 
<span class="p_del">-static void native_flush_tlb_single(unsigned long addr)</span>
<span class="p_add">+static void native_flush_tlb_one_user(unsigned long addr)</span>
 {
<span class="p_del">-	__native_flush_tlb_single(addr);</span>
<span class="p_add">+	__native_flush_tlb_one_user(addr);</span>
 }
 
 struct static_key paravirt_steal_enabled;
<span class="p_chunk">@@ -391,7 +391,7 @@</span> <span class="p_context"> struct pv_mmu_ops pv_mmu_ops __ro_after_init = {</span>
 
 	.flush_tlb_user = native_flush_tlb,
 	.flush_tlb_kernel = native_flush_tlb_global,
<span class="p_del">-	.flush_tlb_single = native_flush_tlb_single,</span>
<span class="p_add">+	.flush_tlb_one_user = native_flush_tlb_one_user,</span>
 	.flush_tlb_others = native_flush_tlb_others,
 
 	.pgd_alloc = __paravirt_pgd_alloc,
<span class="p_header">diff --git a/arch/x86/kernel/relocate_kernel_64.S b/arch/x86/kernel/relocate_kernel_64.S</span>
<span class="p_header">index 307d3bac5f04..11eda21eb697 100644</span>
<span class="p_header">--- a/arch/x86/kernel/relocate_kernel_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/relocate_kernel_64.S</span>
<span class="p_chunk">@@ -68,6 +68,9 @@</span> <span class="p_context"> relocate_kernel:</span>
 	movq	%cr4, %rax
 	movq	%rax, CR4(%r11)
 
<span class="p_add">+	/* Save CR4. Required to enable the right paging mode later. */</span>
<span class="p_add">+	movq	%rax, %r13</span>
<span class="p_add">+</span>
 	/* zero out flags, and disable interrupts */
 	pushq $0
 	popfq
<span class="p_chunk">@@ -126,8 +129,13 @@</span> <span class="p_context"> identity_mapped:</span>
 	/*
 	 * Set cr4 to a known state:
 	 *  - physical address extension enabled
<span class="p_add">+	 *  - 5-level paging, if it was enabled before</span>
 	 */
 	movl	$X86_CR4_PAE, %eax
<span class="p_add">+	testq	$X86_CR4_LA57, %r13</span>
<span class="p_add">+	jz	1f</span>
<span class="p_add">+	orl	$X86_CR4_LA57, %eax</span>
<span class="p_add">+1:</span>
 	movq	%rax, %cr4
 
 	jmp 1f
<span class="p_header">diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c</span>
<span class="p_header">index b33e860d32fe..a66428dc92ae 100644</span>
<span class="p_header">--- a/arch/x86/kernel/traps.c</span>
<span class="p_header">+++ b/arch/x86/kernel/traps.c</span>
<span class="p_chunk">@@ -42,7 +42,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/edac.h&gt;
 #endif
 
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
 #include &lt;asm/stacktrace.h&gt;
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/debugreg.h&gt;
<span class="p_chunk">@@ -181,7 +180,7 @@</span> <span class="p_context"> int fixup_bug(struct pt_regs *regs, int trapnr)</span>
 		break;
 
 	case BUG_TRAP_TYPE_WARN:
<span class="p_del">-		regs-&gt;ip += LEN_UD0;</span>
<span class="p_add">+		regs-&gt;ip += LEN_UD2;</span>
 		return 1;
 	}
 
<span class="p_chunk">@@ -764,10 +763,6 @@</span> <span class="p_context"> dotraplinkage void do_debug(struct pt_regs *regs, long error_code)</span>
 	if (!dr6 &amp;&amp; user_mode(regs))
 		user_icebp = 1;
 
<span class="p_del">-	/* Catch kmemcheck conditions! */</span>
<span class="p_del">-	if ((dr6 &amp; DR_STEP) &amp;&amp; kmemcheck_trap(regs))</span>
<span class="p_del">-		goto exit;</span>
<span class="p_del">-</span>
 	/* Store the virtualized DR6 value */
 	tsk-&gt;thread.debugreg6 = dr6;
 
<span class="p_header">diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c</span>
<span class="p_header">index beb7f8795bc1..ca000fc644bc 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.c</span>
<span class="p_chunk">@@ -5063,7 +5063,7 @@</span> <span class="p_context"> void kvm_mmu_uninit_vm(struct kvm *kvm)</span>
 typedef bool (*slot_level_handler) (struct kvm *kvm, struct kvm_rmap_head *rmap_head);
 
 /* The caller should hold mmu-lock before calling this function. */
<span class="p_del">-static bool</span>
<span class="p_add">+static __always_inline bool</span>
 slot_handle_level_range(struct kvm *kvm, struct kvm_memory_slot *memslot,
 			slot_level_handler fn, int start_level, int end_level,
 			gfn_t start_gfn, gfn_t end_gfn, bool lock_flush_tlb)
<span class="p_chunk">@@ -5093,7 +5093,7 @@</span> <span class="p_context"> slot_handle_level_range(struct kvm *kvm, struct kvm_memory_slot *memslot,</span>
 	return flush;
 }
 
<span class="p_del">-static bool</span>
<span class="p_add">+static __always_inline bool</span>
 slot_handle_level(struct kvm *kvm, struct kvm_memory_slot *memslot,
 		  slot_level_handler fn, int start_level, int end_level,
 		  bool lock_flush_tlb)
<span class="p_chunk">@@ -5104,7 +5104,7 @@</span> <span class="p_context"> slot_handle_level(struct kvm *kvm, struct kvm_memory_slot *memslot,</span>
 			lock_flush_tlb);
 }
 
<span class="p_del">-static bool</span>
<span class="p_add">+static __always_inline bool</span>
 slot_handle_all_level(struct kvm *kvm, struct kvm_memory_slot *memslot,
 		      slot_level_handler fn, bool lock_flush_tlb)
 {
<span class="p_chunk">@@ -5112,7 +5112,7 @@</span> <span class="p_context"> slot_handle_all_level(struct kvm *kvm, struct kvm_memory_slot *memslot,</span>
 				 PT_MAX_HUGEPAGE_LEVEL, lock_flush_tlb);
 }
 
<span class="p_del">-static bool</span>
<span class="p_add">+static __always_inline bool</span>
 slot_handle_large_level(struct kvm *kvm, struct kvm_memory_slot *memslot,
 			slot_level_handler fn, bool lock_flush_tlb)
 {
<span class="p_chunk">@@ -5120,7 +5120,7 @@</span> <span class="p_context"> slot_handle_large_level(struct kvm *kvm, struct kvm_memory_slot *memslot,</span>
 				 PT_MAX_HUGEPAGE_LEVEL, lock_flush_tlb);
 }
 
<span class="p_del">-static bool</span>
<span class="p_add">+static __always_inline bool</span>
 slot_handle_leaf(struct kvm *kvm, struct kvm_memory_slot *memslot,
 		 slot_level_handler fn, bool lock_flush_tlb)
 {
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index 0ea909ca45c2..dd35c6c50516 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -10127,7 +10127,8 @@</span> <span class="p_context"> static void nested_get_vmcs12_pages(struct kvm_vcpu *vcpu,</span>
 	if (cpu_has_vmx_msr_bitmap() &amp;&amp;
 	    nested_cpu_has(vmcs12, CPU_BASED_USE_MSR_BITMAPS) &amp;&amp;
 	    nested_vmx_merge_msr_bitmap(vcpu, vmcs12))
<span class="p_del">-		;</span>
<span class="p_add">+		vmcs_set_bits(CPU_BASED_VM_EXEC_CONTROL,</span>
<span class="p_add">+			      CPU_BASED_USE_MSR_BITMAPS);</span>
 	else
 		vmcs_clear_bits(CPU_BASED_VM_EXEC_CONTROL,
 				CPU_BASED_USE_MSR_BITMAPS);
<span class="p_chunk">@@ -10216,8 +10217,8 @@</span> <span class="p_context"> static inline bool nested_vmx_merge_msr_bitmap(struct kvm_vcpu *vcpu,</span>
 	 *    updated to reflect this when L1 (or its L2s) actually write to
 	 *    the MSR.
 	 */
<span class="p_del">-	bool pred_cmd = msr_write_intercepted_l01(vcpu, MSR_IA32_PRED_CMD);</span>
<span class="p_del">-	bool spec_ctrl = msr_write_intercepted_l01(vcpu, MSR_IA32_SPEC_CTRL);</span>
<span class="p_add">+	bool pred_cmd = !msr_write_intercepted_l01(vcpu, MSR_IA32_PRED_CMD);</span>
<span class="p_add">+	bool spec_ctrl = !msr_write_intercepted_l01(vcpu, MSR_IA32_SPEC_CTRL);</span>
 
 	if (!nested_cpu_has_virt_x2apic_mode(vmcs12) &amp;&amp;
 	    !pred_cmd &amp;&amp; !spec_ctrl)
<span class="p_header">diff --git a/arch/x86/lib/cpu.c b/arch/x86/lib/cpu.c</span>
<span class="p_header">index d6f848d1211d..2dd1fe13a37b 100644</span>
<span class="p_header">--- a/arch/x86/lib/cpu.c</span>
<span class="p_header">+++ b/arch/x86/lib/cpu.c</span>
<span class="p_chunk">@@ -18,7 +18,7 @@</span> <span class="p_context"> unsigned int x86_model(unsigned int sig)</span>
 {
 	unsigned int fam, model;
 
<span class="p_del">-	 fam = x86_family(sig);</span>
<span class="p_add">+	fam = x86_family(sig);</span>
 
 	model = (sig &gt;&gt; 4) &amp; 0xf;
 
<span class="p_header">diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="p_header">index 52906808e277..27e9e90a8d35 100644</span>
<span class="p_header">--- a/arch/x86/mm/Makefile</span>
<span class="p_header">+++ b/arch/x86/mm/Makefile</span>
<span class="p_chunk">@@ -29,8 +29,6 @@</span> <span class="p_context"> obj-$(CONFIG_X86_PTDUMP)	+= debug_pagetables.o</span>
 
 obj-$(CONFIG_HIGHMEM)		+= highmem_32.o
 
<span class="p_del">-obj-$(CONFIG_KMEMCHECK)		+= kmemcheck/</span>
<span class="p_del">-</span>
 KASAN_SANITIZE_kasan_init_$(BITS).o := n
 obj-$(CONFIG_KASAN)		+= kasan_init_$(BITS).o
 
<span class="p_header">diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="p_header">index b264b590eeec..9150fe2c9b26 100644</span>
<span class="p_header">--- a/arch/x86/mm/fault.c</span>
<span class="p_header">+++ b/arch/x86/mm/fault.c</span>
<span class="p_chunk">@@ -20,7 +20,6 @@</span> <span class="p_context"></span>
 #include &lt;asm/cpufeature.h&gt;		/* boot_cpu_has, ...		*/
 #include &lt;asm/traps.h&gt;			/* dotraplinkage, ...		*/
 #include &lt;asm/pgalloc.h&gt;		/* pgd_*(), ...			*/
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;		/* kmemcheck_*(), ...		*/</span>
 #include &lt;asm/fixmap.h&gt;			/* VSYSCALL_ADDR		*/
 #include &lt;asm/vsyscall.h&gt;		/* emulate_vsyscall		*/
 #include &lt;asm/vm86.h&gt;			/* struct vm86			*/
<span class="p_chunk">@@ -1257,8 +1256,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 	 * Detect and handle instructions that would cause a page fault for
 	 * both a tracked kernel page and a userspace page.
 	 */
<span class="p_del">-	if (kmemcheck_active(regs))</span>
<span class="p_del">-		kmemcheck_hide(regs);</span>
 	prefetchw(&amp;mm-&gt;mmap_sem);
 
 	if (unlikely(kmmio_fault(regs, address)))
<span class="p_chunk">@@ -1281,9 +1278,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 		if (!(error_code &amp; (X86_PF_RSVD | X86_PF_USER | X86_PF_PROT))) {
 			if (vmalloc_fault(address) &gt;= 0)
 				return;
<span class="p_del">-</span>
<span class="p_del">-			if (kmemcheck_fault(regs, address, error_code))</span>
<span class="p_del">-				return;</span>
 		}
 
 		/* Can handle a stale RO-&gt;RW TLB: */
<span class="p_header">diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c</span>
<span class="p_header">index 6b462a472a7b..82f5252c723a 100644</span>
<span class="p_header">--- a/arch/x86/mm/init.c</span>
<span class="p_header">+++ b/arch/x86/mm/init.c</span>
<span class="p_chunk">@@ -93,8 +93,7 @@</span> <span class="p_context"> __ref void *alloc_low_pages(unsigned int num)</span>
 		unsigned int order;
 
 		order = get_order((unsigned long)num &lt;&lt; PAGE_SHIFT);
<span class="p_del">-		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_NOTRACK |</span>
<span class="p_del">-						__GFP_ZERO, order);</span>
<span class="p_add">+		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_ZERO, order);</span>
 	}
 
 	if ((pgt_buf_end + num) &gt; pgt_buf_top || !can_use_brk_pgt) {
<span class="p_chunk">@@ -171,12 +170,11 @@</span> <span class="p_context"> static void enable_global_pages(void)</span>
 static void __init probe_page_size_mask(void)
 {
 	/*
<span class="p_del">-	 * For CONFIG_KMEMCHECK or pagealloc debugging, identity mapping will</span>
<span class="p_del">-	 * use small pages.</span>
<span class="p_add">+	 * For pagealloc debugging, identity mapping will use small pages.</span>
 	 * This will simplify cpa(), which otherwise needs to support splitting
 	 * large pages into small in interrupt context, etc.
 	 */
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled() &amp;&amp; !IS_ENABLED(CONFIG_KMEMCHECK))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled())</span>
 		page_size_mask |= 1 &lt;&lt; PG_LEVEL_2M;
 	else
 		direct_gbpages = 0;
<span class="p_header">diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c</span>
<span class="p_header">index adcea90a2046..fe85d1204db8 100644</span>
<span class="p_header">--- a/arch/x86/mm/init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/init_64.c</span>
<span class="p_chunk">@@ -184,7 +184,7 @@</span> <span class="p_context"> static __ref void *spp_getpage(void)</span>
 	void *ptr;
 
 	if (after_bootmem)
<span class="p_del">-		ptr = (void *) get_zeroed_page(GFP_ATOMIC | __GFP_NOTRACK);</span>
<span class="p_add">+		ptr = (void *) get_zeroed_page(GFP_ATOMIC);</span>
 	else
 		ptr = alloc_bootmem_pages(PAGE_SIZE);
 
<span class="p_chunk">@@ -256,7 +256,7 @@</span> <span class="p_context"> static void __set_pte_vaddr(pud_t *pud, unsigned long vaddr, pte_t new_pte)</span>
 	 * It&#39;s enough to flush this one mapping.
 	 * (PGE mappings get flushed as well)
 	 */
<span class="p_del">-	__flush_tlb_one(vaddr);</span>
<span class="p_add">+	__flush_tlb_one_kernel(vaddr);</span>
 }
 
 void set_pte_vaddr_p4d(p4d_t *p4d_page, unsigned long vaddr, pte_t new_pte)
<span class="p_header">diff --git a/arch/x86/mm/ioremap.c b/arch/x86/mm/ioremap.c</span>
<span class="p_header">index 34f0e1847dd6..bb120e59c597 100644</span>
<span class="p_header">--- a/arch/x86/mm/ioremap.c</span>
<span class="p_header">+++ b/arch/x86/mm/ioremap.c</span>
<span class="p_chunk">@@ -749,5 +749,5 @@</span> <span class="p_context"> void __init __early_set_fixmap(enum fixed_addresses idx,</span>
 		set_pte(pte, pfn_pte(phys &gt;&gt; PAGE_SHIFT, flags));
 	else
 		pte_clear(&amp;init_mm, addr, pte);
<span class="p_del">-	__flush_tlb_one(addr);</span>
<span class="p_add">+	__flush_tlb_one_kernel(addr);</span>
 }
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/Makefile b/arch/x86/mm/kmemcheck/Makefile</span>
deleted file mode 100644
<span class="p_header">index 520b3bce4095..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/Makefile</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-obj-y := error.o kmemcheck.o opcode.o pte.o selftest.o shadow.o</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/error.c b/arch/x86/mm/kmemcheck/error.c</span>
deleted file mode 100644
<span class="p_header">index 872ec4159a68..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,228 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kdebug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/stacktrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_error_type {</span>
<span class="p_del">-	KMEMCHECK_ERROR_INVALID_ACCESS,</span>
<span class="p_del">-	KMEMCHECK_ERROR_BUG,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-#define SHADOW_COPY_SIZE (1 &lt;&lt; CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT)</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_error {</span>
<span class="p_del">-	enum kmemcheck_error_type type;</span>
<span class="p_del">-</span>
<span class="p_del">-	union {</span>
<span class="p_del">-		/* KMEMCHECK_ERROR_INVALID_ACCESS */</span>
<span class="p_del">-		struct {</span>
<span class="p_del">-			/* Kind of access that caused the error */</span>
<span class="p_del">-			enum kmemcheck_shadow state;</span>
<span class="p_del">-			/* Address and size of the erroneous read */</span>
<span class="p_del">-			unsigned long	address;</span>
<span class="p_del">-			unsigned int	size;</span>
<span class="p_del">-		};</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct pt_regs		regs;</span>
<span class="p_del">-	struct stack_trace	trace;</span>
<span class="p_del">-	unsigned long		trace_entries[32];</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We compress it to a char. */</span>
<span class="p_del">-	unsigned char		shadow_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-	unsigned char		memory_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Create a ring queue of errors to output. We can&#39;t call printk() directly</span>
<span class="p_del">- * from the kmemcheck traps, since this may call the console drivers and</span>
<span class="p_del">- * result in a recursive fault.</span>
<span class="p_del">- */</span>
<span class="p_del">-static struct kmemcheck_error error_fifo[CONFIG_KMEMCHECK_QUEUE_SIZE];</span>
<span class="p_del">-static unsigned int error_count;</span>
<span class="p_del">-static unsigned int error_rd;</span>
<span class="p_del">-static unsigned int error_wr;</span>
<span class="p_del">-static unsigned int error_missed_count;</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_wr(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == ARRAY_SIZE(error_fifo)) {</span>
<span class="p_del">-		++error_missed_count;</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_wr];</span>
<span class="p_del">-	if (++error_wr == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_wr = 0;</span>
<span class="p_del">-	++error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_rd(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == 0)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_rd];</span>
<span class="p_del">-	if (++error_rd == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_rd = 0;</span>
<span class="p_del">-	--error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static const char *desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &quot;unallocated&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &quot;uninitialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &quot;initialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &quot;freed&quot;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	static const char short_desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &#39;a&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &#39;u&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &#39;i&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &#39;f&#39;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_rd();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (e-&gt;type) {</span>
<span class="p_del">-	case KMEMCHECK_ERROR_INVALID_ACCESS:</span>
<span class="p_del">-		printk(KERN_WARNING &quot;WARNING: kmemcheck: Caught %d-bit read from %s memory (%p)\n&quot;,</span>
<span class="p_del">-			8 * e-&gt;size, e-&gt;state &lt; ARRAY_SIZE(desc) ?</span>
<span class="p_del">-				desc[e-&gt;state] : &quot;(invalid shadow state)&quot;,</span>
<span class="p_del">-			(void *) e-&gt;address);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i)</span>
<span class="p_del">-			printk(KERN_CONT &quot;%02x&quot;, e-&gt;memory_copy[i]);</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i) {</span>
<span class="p_del">-			if (e-&gt;shadow_copy[i] &lt; ARRAY_SIZE(short_desc))</span>
<span class="p_del">-				printk(KERN_CONT &quot; %c&quot;, short_desc[e-&gt;shadow_copy[i]]);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				printk(KERN_CONT &quot; ?&quot;);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-		printk(KERN_WARNING &quot;%*c\n&quot;, 2 + 2</span>
<span class="p_del">-			* (int) (e-&gt;address &amp; (SHADOW_COPY_SIZE - 1)), &#39;^&#39;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case KMEMCHECK_ERROR_BUG:</span>
<span class="p_del">-		printk(KERN_EMERG &quot;ERROR: kmemcheck: Fatal error\n&quot;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	__show_regs(&amp;e-&gt;regs, 1);</span>
<span class="p_del">-	print_stack_trace(&amp;e-&gt;trace, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void do_wakeup(unsigned long data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	while (error_count &gt; 0)</span>
<span class="p_del">-		kmemcheck_error_recall();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_missed_count &gt; 0) {</span>
<span class="p_del">-		printk(KERN_WARNING &quot;kmemcheck: Lost %d error reports because &quot;</span>
<span class="p_del">-			&quot;the queue was too small\n&quot;, error_missed_count);</span>
<span class="p_del">-		error_missed_count = 0;</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static DECLARE_TASKLET(kmemcheck_tasklet, &amp;do_wakeup, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of an error report.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static unsigned long prev_ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	void *shadow_copy;</span>
<span class="p_del">-	void *memory_copy;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t report several adjacent errors from the same EIP. */</span>
<span class="p_del">-	if (regs-&gt;ip == prev_ip)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	prev_ip = regs-&gt;ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_INVALID_ACCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;state = state;</span>
<span class="p_del">-	e-&gt;address = address;</span>
<span class="p_del">-	e-&gt;size = size;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save regs */</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save stack trace */</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 0;</span>
<span class="p_del">-	save_stack_trace_regs(regs, &amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Round address down to nearest 16 bytes */</span>
<span class="p_del">-	shadow_copy = kmemcheck_shadow_lookup(address</span>
<span class="p_del">-		&amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	BUG_ON(!shadow_copy);</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(e-&gt;shadow_copy, shadow_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_addr(address);</span>
<span class="p_del">-	memory_copy = (void *) (address &amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	memcpy(e-&gt;memory_copy, memory_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-	kmemcheck_hide_addr(address);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of a kmemcheck bug.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_BUG;</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 1;</span>
<span class="p_del">-	save_stack_trace(&amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/error.h b/arch/x86/mm/kmemcheck/error.h</span>
deleted file mode 100644
<span class="p_header">index 39f80d7a874d..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,16 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/kmemcheck.c b/arch/x86/mm/kmemcheck/kmemcheck.c</span>
deleted file mode 100644
<span class="p_header">index 4515bae36bbe..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,658 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/**</span>
<span class="p_del">- * kmemcheck - a heavyweight memory checker for the linux kernel</span>
<span class="p_del">- * Copyright (C) 2007, 2008  Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">- * (With a lot of help from Ingo Molnar and Pekka Enberg.)</span>
<span class="p_del">- *</span>
<span class="p_del">- * This program is free software; you can redistribute it and/or modify</span>
<span class="p_del">- * it under the terms of the GNU General Public License (version 2) as</span>
<span class="p_del">- * published by the Free Software Foundation.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/init.h&gt;</span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kallsyms.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/page-flags.h&gt;</span>
<span class="p_del">-#include &lt;linux/percpu.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 0</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 1</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 2</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_enabled = KMEMCHECK_ENABLED;</span>
<span class="p_del">-</span>
<span class="p_del">-int __init kmemcheck_init(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Limit SMP to use a single CPU. We rely on the fact that this code</span>
<span class="p_del">-	 * runs before SMP is set up.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (setup_max_cpus &gt; 1) {</span>
<span class="p_del">-		printk(KERN_INFO</span>
<span class="p_del">-			&quot;kmemcheck: Limiting number of CPUs to 1.\n&quot;);</span>
<span class="p_del">-		setup_max_cpus = 1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_selftest()) {</span>
<span class="p_del">-		printk(KERN_INFO &quot;kmemcheck: self-tests failed; disabling\n&quot;);</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_INFO &quot;kmemcheck: Initialized\n&quot;);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_initcall(kmemcheck_init);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * We need to parse the kmemcheck= option before any memory is allocated.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int __init param_kmemcheck(char *str)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int val;</span>
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!str)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = kstrtoint(str, 0, &amp;val);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	kmemcheck_enabled = val;</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_param(&quot;kmemcheck&quot;, param_kmemcheck);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_context {</span>
<span class="p_del">-	bool busy;</span>
<span class="p_del">-	int balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * There can be at most two memory operands to an instruction, but</span>
<span class="p_del">-	 * each address can cross a page boundary -- so we may need up to</span>
<span class="p_del">-	 * four addresses that must be hidden/revealed for each fault.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	unsigned long addr[4];</span>
<span class="p_del">-	unsigned long n_addrs;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Data size of the instruction that caused a fault. */</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static DEFINE_PER_CPU(struct kmemcheck_context, kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	return data-&gt;balance &gt; 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Save an address that needs to be shown/hidden */</span>
<span class="p_del">-static void kmemcheck_save_addr(unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(data-&gt;n_addrs &gt;= ARRAY_SIZE(data-&gt;addr));</span>
<span class="p_del">-	data-&gt;addr[data-&gt;n_addrs++] = addr;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_show_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_show_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_hide_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_hide_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #PF handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 0)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * None of the addresses actually belonged to kmemcheck. Note that</span>
<span class="p_del">-	 * this is not an error.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_show_all() == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	++data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The IF needs to be cleared as well, so that the faulting</span>
<span class="p_del">-	 * instruction can run &quot;uninterrupted&quot;. Otherwise, we might take</span>
<span class="p_del">-	 * an interrupt and start executing that before we&#39;ve had a chance</span>
<span class="p_del">-	 * to hide the page again.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * NOTE: In the rare case of multiple faults, we must not override</span>
<span class="p_del">-	 * the original flags:</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!(regs-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		data-&gt;flags = regs-&gt;flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	regs-&gt;flags |= X86_EFLAGS_TF;</span>
<span class="p_del">-	regs-&gt;flags &amp;= ~X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #DB handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 1)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;n_addrs = 0;</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-			regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-		if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-			regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		n = kmemcheck_hide_all();</span>
<span class="p_del">-	else</span>
<span class="p_del">-		n = kmemcheck_show_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (n == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	--data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;n_addrs = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-	if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-		regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* This will also check the &quot;hidden&quot; flag of the PTE. */</span>
<span class="p_del">-	return kmemcheck_pte_lookup((unsigned long) page_address(p));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may NOT cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t warn about it again. */</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-</span>
<span class="p_del">-	return status == KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_read_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * What we do is basically to split the access across the</span>
<span class="p_del">-	 * two pages and handle each part separately. Yes, this means</span>
<span class="p_del">-	 * that we may now see reads that are 3 + 5 bytes, for</span>
<span class="p_del">-	 * example (and if both are uninitialized, there will be two</span>
<span class="p_del">-	 * reports), but it makes the code a lot simpler.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_read_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_read_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_write_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See comment in kmemcheck_read(). */</span>
<span class="p_del">-	kmemcheck_write_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_write_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Copying is hard. We have two addresses, each of which may be split across</span>
<span class="p_del">- * a page (and each page will have different shadow addresses).</span>
<span class="p_del">- */</span>
<span class="p_del">-static void kmemcheck_copy(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long src_addr, unsigned long dst_addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t shadow[8];</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	unsigned long page;</span>
<span class="p_del">-	unsigned long next_addr;</span>
<span class="p_del">-	unsigned long next_page;</span>
<span class="p_del">-</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(size &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-	page = src_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = src_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - src_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i - n];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	page = dst_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = dst_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - dst_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i - n] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, src_addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_method {</span>
<span class="p_del">-	KMEMCHECK_READ,</span>
<span class="p_del">-	KMEMCHECK_WRITE,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_access(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long fallback_address, enum kmemcheck_method fallback_method)</span>
<span class="p_del">-{</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const uint8_t *insn_primary;</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Recursive fault -- ouch. */</span>
<span class="p_del">-	if (data-&gt;busy) {</span>
<span class="p_del">-		kmemcheck_show_addr(fallback_address);</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;busy = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	insn = (const uint8_t *) regs-&gt;ip;</span>
<span class="p_del">-	insn_primary = kmemcheck_opcode_get_primary(insn);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (insn_primary[0]) {</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-		/* AND, OR, XOR */</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Unfortunately, these instructions have to be excluded from</span>
<span class="p_del">-		 * our regular checking since they access only some (and not</span>
<span class="p_del">-		 * all) bits. This clears out &quot;bogus&quot; bitfield-access warnings.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-	case 0x80:</span>
<span class="p_del">-	case 0x81:</span>
<span class="p_del">-	case 0x82:</span>
<span class="p_del">-	case 0x83:</span>
<span class="p_del">-		switch ((insn_primary[1] &gt;&gt; 3) &amp; 7) {</span>
<span class="p_del">-			/* OR */</span>
<span class="p_del">-		case 1:</span>
<span class="p_del">-			/* AND */</span>
<span class="p_del">-		case 4:</span>
<span class="p_del">-			/* XOR */</span>
<span class="p_del">-		case 6:</span>
<span class="p_del">-			kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* ADD */</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			/* ADC */</span>
<span class="p_del">-		case 2:</span>
<span class="p_del">-			/* SBB */</span>
<span class="p_del">-		case 3:</span>
<span class="p_del">-			/* SUB */</span>
<span class="p_del">-		case 5:</span>
<span class="p_del">-			/* CMP */</span>
<span class="p_del">-		case 7:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		break;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-		/* MOVS, MOVSB, MOVSW, MOVSD */</span>
<span class="p_del">-	case 0xa4:</span>
<span class="p_del">-	case 0xa5:</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * These instructions are special because they take two</span>
<span class="p_del">-		 * addresses, but we only get one page fault.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_copy(regs, regs-&gt;si, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* CMPS, CMPSB, CMPSW, CMPSD */</span>
<span class="p_del">-	case 0xa6:</span>
<span class="p_del">-	case 0xa7:</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;si, size);</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the opcode isn&#39;t special in any way, we use the data from the</span>
<span class="p_del">-	 * page fault handler to determine the address and type of memory</span>
<span class="p_del">-	 * access.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	switch (fallback_method) {</span>
<span class="p_del">-	case KMEMCHECK_READ:</span>
<span class="p_del">-		kmemcheck_read(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	case KMEMCHECK_WRITE:</span>
<span class="p_del">-		kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-out:</span>
<span class="p_del">-	data-&gt;busy = false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs, unsigned long address,</span>
<span class="p_del">-	unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * XXX: Is it safe to assume that memory accesses from virtual 86</span>
<span class="p_del">-	 * mode or non-kernel code segments will _never_ access kernel</span>
<span class="p_del">-	 * memory (e.g. tracked pages)? For now, we need this to avoid</span>
<span class="p_del">-	 * invoking kmemcheck for PnP BIOS calls.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (regs-&gt;flags &amp; X86_VM_MASK)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-	if (regs-&gt;cs != __KERNEL_CS)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	WARN_ON_ONCE(in_nmi());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_code &amp; 2)</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_WRITE);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_READ);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!kmemcheck_active(regs))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We&#39;re done. */</span>
<span class="p_del">-	kmemcheck_hide(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/opcode.c b/arch/x86/mm/kmemcheck/opcode.c</span>
deleted file mode 100644
<span class="p_header">index df8109ddf7fe..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,107 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-static bool opcode_is_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return</span>
<span class="p_del">-		/* Group 1 */</span>
<span class="p_del">-		b == 0xf0 || b == 0xf2 || b == 0xf3</span>
<span class="p_del">-		/* Group 2 */</span>
<span class="p_del">-		|| b == 0x2e || b == 0x36 || b == 0x3e || b == 0x26</span>
<span class="p_del">-		|| b == 0x64 || b == 0x65</span>
<span class="p_del">-		/* Group 3 */</span>
<span class="p_del">-		|| b == 0x66</span>
<span class="p_del">-		/* Group 4 */</span>
<span class="p_del">-		|| b == 0x67;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (b &amp; 0xf0) == 0x40;</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#define REX_W (1 &lt;&lt; 3)</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This is a VERY crude opcode decoder. We only need to find the size of the</span>
<span class="p_del">- * load/store that caused our #PF and this should work for all the opcodes</span>
<span class="p_del">- * that we care about. Moreover, the ones who invented this instruction set</span>
<span class="p_del">- * should be shot.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* Default operand size */</span>
<span class="p_del">-	int operand_size_override = 4;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* prefixes */</span>
<span class="p_del">-	for (; opcode_is_prefix(*op); ++op) {</span>
<span class="p_del">-		if (*op == 0x66)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* REX prefix */</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op)) {</span>
<span class="p_del">-		uint8_t rex = *op;</span>
<span class="p_del">-</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-		if (rex &amp; REX_W) {</span>
<span class="p_del">-			switch (*op) {</span>
<span class="p_del">-			case 0x63:</span>
<span class="p_del">-				*size = 4;</span>
<span class="p_del">-				return;</span>
<span class="p_del">-			case 0x0f:</span>
<span class="p_del">-				++op;</span>
<span class="p_del">-</span>
<span class="p_del">-				switch (*op) {</span>
<span class="p_del">-				case 0xb6:</span>
<span class="p_del">-				case 0xbe:</span>
<span class="p_del">-					*size = 1;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				case 0xb7:</span>
<span class="p_del">-				case 0xbf:</span>
<span class="p_del">-					*size = 2;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				}</span>
<span class="p_del">-</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			*size = 8;</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* escape opcode */</span>
<span class="p_del">-	if (*op == 0x0f) {</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * This is move with zero-extend and sign-extend, respectively;</span>
<span class="p_del">-		 * we don&#39;t have to think about 0xb6/0xbe, because this is</span>
<span class="p_del">-		 * already handled in the conditional below.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (*op == 0xb7 || *op == 0xbf)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	*size = (*op &amp; 1) ? operand_size_override : 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* skip prefixes */</span>
<span class="p_del">-	while (opcode_is_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	return op;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/opcode.h b/arch/x86/mm/kmemcheck/opcode.h</span>
deleted file mode 100644
<span class="p_header">index 51a1ce94c24a..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,10 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size);</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/pte.c b/arch/x86/mm/kmemcheck/pte.c</span>
deleted file mode 100644
<span class="p_header">index 8a03be90272a..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,23 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (level != PG_LEVEL_4K)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (!pte_hidden(*pte))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	return pte;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/pte.h b/arch/x86/mm/kmemcheck/pte.h</span>
deleted file mode 100644
<span class="p_header">index b595612382c2..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,11 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/selftest.c b/arch/x86/mm/kmemcheck/selftest.c</span>
deleted file mode 100644
<span class="p_header">index 7ce0be1f99eb..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,71 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_del">-#include &lt;linux/bug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-struct selftest_opcode {</span>
<span class="p_del">-	unsigned int expected_size;</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const char *desc;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static const struct selftest_opcode selftest_opcodes[] = {</span>
<span class="p_del">-	/* REP MOVS */</span>
<span class="p_del">-	{1, &quot;\xf3\xa4&quot;, 		&quot;rep movsb &lt;mem8&gt;, &lt;mem8&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\xf3\xa5&quot;,			&quot;rep movsl &lt;mem32&gt;, &lt;mem32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xb6\x51\xf8&quot;,	&quot;movzwq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xb6\x51\xf8&quot;,		&quot;movzwq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xbe\x51\xf8&quot;,	&quot;movswq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xbe\x51\xf8&quot;,		&quot;movswq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xb6\x51\xf8&quot;,	&quot;movzbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xb7\x51\xf8&quot;,	&quot;movzbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xbe\x51\xf8&quot;,	&quot;movsbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xbf\x51\xf8&quot;,	&quot;movsbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\x49\x63\x51\xf8&quot;,		&quot;movslq &lt;mem32&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcode_one(const struct selftest_opcode *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned size;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(op-&gt;insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (size == op-&gt;expected_size)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_WARNING &quot;kmemcheck: opcode %s: expected size %d, got %d\n&quot;,</span>
<span class="p_del">-		op-&gt;desc, op-&gt;expected_size, size);</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcodes_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; ARRAY_SIZE(selftest_opcodes); ++i)</span>
<span class="p_del">-		pass = pass &amp;&amp; selftest_opcode_one(&amp;selftest_opcodes[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	pass = pass &amp;&amp; selftest_opcodes_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/selftest.h b/arch/x86/mm/kmemcheck/selftest.h</span>
deleted file mode 100644
<span class="p_header">index 8d759aae453d..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,7 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-#define ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/shadow.c b/arch/x86/mm/kmemcheck/shadow.c</span>
deleted file mode 100644
<span class="p_header">index c2638a7d2c10..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,173 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/export.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/page.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Return the shadow address for the given address. Returns NULL if the</span>
<span class="p_del">- * address is not tracked.</span>
<span class="p_del">- *</span>
<span class="p_del">- * We need to be extremely careful not to follow any invalid pointers,</span>
<span class="p_del">- * because this function can be called for *any* possible address.</span>
<span class="p_del">- */</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	struct page *page;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!virt_addr_valid(address))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	page = virt_to_page(address);</span>
<span class="p_del">-	if (!page-&gt;shadow)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	return page-&gt;shadow + (address &amp; (PAGE_SIZE - 1));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void mark_shadow(void *address, unsigned int n,</span>
<span class="p_del">-	enum kmemcheck_shadow status)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long addr = (unsigned long) address;</span>
<span class="p_del">-	unsigned long last_addr = addr + n - 1;</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long last_page = last_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned int first_n;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* If the memory range crosses a page boundary, stop there. */</span>
<span class="p_del">-	if (page == last_page)</span>
<span class="p_del">-		first_n = n;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		first_n = page + PAGE_SIZE - addr;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (shadow)</span>
<span class="p_del">-		memset(shadow, status, first_n);</span>
<span class="p_del">-</span>
<span class="p_del">-	addr += first_n;</span>
<span class="p_del">-	n -= first_n;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do full-page memset()s. */</span>
<span class="p_del">-	while (n &gt;= PAGE_SIZE) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, PAGE_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-		addr += PAGE_SIZE;</span>
<span class="p_del">-		n -= PAGE_SIZE;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do the remaining page, if any. */</span>
<span class="p_del">-	if (n &gt; 0) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, n);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNALLOCATED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNINITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Fill the shadow memory of the given address such that the memory at that</span>
<span class="p_del">- * address is marked as being initialized.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_INITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(kmemcheck_mark_initialized);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_FREED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_unallocated(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Make sure _some_ bytes are initialized. Gcc frequently generates</span>
<span class="p_del">-	 * code to access neighboring bytes.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-#else</span>
<span class="p_del">-	return kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* All bytes must be initialized. */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] != KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-		x[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/shadow.h b/arch/x86/mm/kmemcheck/shadow.h</span>
deleted file mode 100644
<span class="p_header">index 49768dc18664..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,19 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow {</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNALLOCATED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNINITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_INITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_FREED,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size);</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow,</span>
<span class="p_del">-						unsigned int size);</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmmio.c b/arch/x86/mm/kmmio.c</span>
<span class="p_header">index c21c2ed04612..aa44c3aa4cd5 100644</span>
<span class="p_header">--- a/arch/x86/mm/kmmio.c</span>
<span class="p_header">+++ b/arch/x86/mm/kmmio.c</span>
<span class="p_chunk">@@ -168,7 +168,7 @@</span> <span class="p_context"> static int clear_page_presence(struct kmmio_fault_page *f, bool clear)</span>
 		return -1;
 	}
 
<span class="p_del">-	__flush_tlb_one(f-&gt;addr);</span>
<span class="p_add">+	__flush_tlb_one_kernel(f-&gt;addr);</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/x86/mm/pageattr.c b/arch/x86/mm/pageattr.c</span>
<span class="p_header">index dfb7d657cf43..3ed9a08885c5 100644</span>
<span class="p_header">--- a/arch/x86/mm/pageattr.c</span>
<span class="p_header">+++ b/arch/x86/mm/pageattr.c</span>
<span class="p_chunk">@@ -753,7 +753,7 @@</span> <span class="p_context"> static int split_large_page(struct cpa_data *cpa, pte_t *kpte,</span>
 
 	if (!debug_pagealloc_enabled())
 		spin_unlock(&amp;cpa_lock);
<span class="p_del">-	base = alloc_pages(GFP_KERNEL | __GFP_NOTRACK, 0);</span>
<span class="p_add">+	base = alloc_pages(GFP_KERNEL, 0);</span>
 	if (!debug_pagealloc_enabled())
 		spin_lock(&amp;cpa_lock);
 	if (!base)
<span class="p_chunk">@@ -904,7 +904,7 @@</span> <span class="p_context"> static void unmap_pud_range(p4d_t *p4d, unsigned long start, unsigned long end)</span>
 
 static int alloc_pte_page(pmd_t *pmd)
 {
<span class="p_del">-	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL);</span>
 	if (!pte)
 		return -1;
 
<span class="p_chunk">@@ -914,7 +914,7 @@</span> <span class="p_context"> static int alloc_pte_page(pmd_t *pmd)</span>
 
 static int alloc_pmd_page(pud_t *pud)
 {
<span class="p_del">-	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL);</span>
 	if (!pmd)
 		return -1;
 
<span class="p_chunk">@@ -1120,7 +1120,7 @@</span> <span class="p_context"> static int populate_pgd(struct cpa_data *cpa, unsigned long addr)</span>
 	pgd_entry = cpa-&gt;pgd + pgd_index(addr);
 
 	if (pgd_none(*pgd_entry)) {
<span class="p_del">-		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL);</span>
 		if (!p4d)
 			return -1;
 
<span class="p_chunk">@@ -1132,7 +1132,7 @@</span> <span class="p_context"> static int populate_pgd(struct cpa_data *cpa, unsigned long addr)</span>
 	 */
 	p4d = p4d_offset(pgd_entry, addr);
 	if (p4d_none(*p4d)) {
<span class="p_del">-		pud = (pud_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+		pud = (pud_t *)get_zeroed_page(GFP_KERNEL);</span>
 		if (!pud)
 			return -1;
 
<span class="p_header">diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c</span>
<span class="p_header">index 9b7bcbd33cc2..004abf9ebf12 100644</span>
<span class="p_header">--- a/arch/x86/mm/pgtable.c</span>
<span class="p_header">+++ b/arch/x86/mm/pgtable.c</span>
<span class="p_chunk">@@ -7,7 +7,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/fixmap.h&gt;
 #include &lt;asm/mtrr.h&gt;
 
<span class="p_del">-#define PGALLOC_GFP (GFP_KERNEL_ACCOUNT | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP (GFP_KERNEL_ACCOUNT | __GFP_ZERO)</span>
 
 #ifdef CONFIG_HIGHPTE
 #define PGALLOC_USER_GFP __GFP_HIGHMEM
<span class="p_header">diff --git a/arch/x86/mm/pgtable_32.c b/arch/x86/mm/pgtable_32.c</span>
<span class="p_header">index c3c5274410a9..9bb7f0ab9fe6 100644</span>
<span class="p_header">--- a/arch/x86/mm/pgtable_32.c</span>
<span class="p_header">+++ b/arch/x86/mm/pgtable_32.c</span>
<span class="p_chunk">@@ -63,7 +63,7 @@</span> <span class="p_context"> void set_pte_vaddr(unsigned long vaddr, pte_t pteval)</span>
 	 * It&#39;s enough to flush this one mapping.
 	 * (PGE mappings get flushed as well)
 	 */
<span class="p_del">-	__flush_tlb_one(vaddr);</span>
<span class="p_add">+	__flush_tlb_one_kernel(vaddr);</span>
 }
 
 unsigned long __FIXADDR_TOP = 0xfffff000;
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 012d02624848..0c936435ea93 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -492,7 +492,7 @@</span> <span class="p_context"> static void flush_tlb_func_common(const struct flush_tlb_info *f,</span>
 	 *    flush that changes context.tlb_gen from 2 to 3.  If they get
 	 *    processed on this CPU in reverse order, we&#39;ll see
 	 *     local_tlb_gen == 1, mm_tlb_gen == 3, and end != TLB_FLUSH_ALL.
<span class="p_del">-	 *    If we were to use __flush_tlb_single() and set local_tlb_gen to</span>
<span class="p_add">+	 *    If we were to use __flush_tlb_one_user() and set local_tlb_gen to</span>
 	 *    3, we&#39;d be break the invariant: we&#39;d update local_tlb_gen above
 	 *    1 without the full flush that&#39;s needed for tlb_gen 2.
 	 *
<span class="p_chunk">@@ -513,7 +513,7 @@</span> <span class="p_context"> static void flush_tlb_func_common(const struct flush_tlb_info *f,</span>
 
 		addr = f-&gt;start;
 		while (addr &lt; f-&gt;end) {
<span class="p_del">-			__flush_tlb_single(addr);</span>
<span class="p_add">+			__flush_tlb_one_user(addr);</span>
 			addr += PAGE_SIZE;
 		}
 		if (local)
<span class="p_chunk">@@ -660,7 +660,7 @@</span> <span class="p_context"> static void do_kernel_range_flush(void *info)</span>
 
 	/* flush range by one by one &#39;invlpg&#39; */
 	for (addr = f-&gt;start; addr &lt; f-&gt;end; addr += PAGE_SIZE)
<span class="p_del">-		__flush_tlb_one(addr);</span>
<span class="p_add">+		__flush_tlb_one_kernel(addr);</span>
 }
 
 void flush_tlb_kernel_range(unsigned long start, unsigned long end)
<span class="p_header">diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c</span>
<span class="p_header">index 61975b6bcb1a..ad5d9538f0f9 100644</span>
<span class="p_header">--- a/arch/x86/platform/efi/efi_64.c</span>
<span class="p_header">+++ b/arch/x86/platform/efi/efi_64.c</span>
<span class="p_chunk">@@ -211,7 +211,7 @@</span> <span class="p_context"> int __init efi_alloc_page_tables(void)</span>
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
<span class="p_del">-	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO;</span>
<span class="p_add">+	gfp_mask = GFP_KERNEL | __GFP_ZERO;</span>
 	efi_pgd = (pgd_t *)__get_free_pages(gfp_mask, PGD_ALLOCATION_ORDER);
 	if (!efi_pgd)
 		return -ENOMEM;
<span class="p_header">diff --git a/arch/x86/platform/uv/tlb_uv.c b/arch/x86/platform/uv/tlb_uv.c</span>
<span class="p_header">index 8538a6723171..7d5d53f36a7a 100644</span>
<span class="p_header">--- a/arch/x86/platform/uv/tlb_uv.c</span>
<span class="p_header">+++ b/arch/x86/platform/uv/tlb_uv.c</span>
<span class="p_chunk">@@ -299,7 +299,7 @@</span> <span class="p_context"> static void bau_process_message(struct msg_desc *mdp, struct bau_control *bcp,</span>
 		local_flush_tlb();
 		stat-&gt;d_alltlb++;
 	} else {
<span class="p_del">-		__flush_tlb_single(msg-&gt;address);</span>
<span class="p_add">+		__flush_tlb_one_user(msg-&gt;address);</span>
 		stat-&gt;d_onetlb++;
 	}
 	stat-&gt;d_requestee++;
<span class="p_header">diff --git a/arch/x86/xen/mmu_pv.c b/arch/x86/xen/mmu_pv.c</span>
<span class="p_header">index a0e2b8c6e5c7..d0b943a6b117 100644</span>
<span class="p_header">--- a/arch/x86/xen/mmu_pv.c</span>
<span class="p_header">+++ b/arch/x86/xen/mmu_pv.c</span>
<span class="p_chunk">@@ -1300,12 +1300,12 @@</span> <span class="p_context"> static void xen_flush_tlb(void)</span>
 	preempt_enable();
 }
 
<span class="p_del">-static void xen_flush_tlb_single(unsigned long addr)</span>
<span class="p_add">+static void xen_flush_tlb_one_user(unsigned long addr)</span>
 {
 	struct mmuext_op *op;
 	struct multicall_space mcs;
 
<span class="p_del">-	trace_xen_mmu_flush_tlb_single(addr);</span>
<span class="p_add">+	trace_xen_mmu_flush_tlb_one_user(addr);</span>
 
 	preempt_disable();
 
<span class="p_chunk">@@ -2360,7 +2360,7 @@</span> <span class="p_context"> static const struct pv_mmu_ops xen_mmu_ops __initconst = {</span>
 
 	.flush_tlb_user = xen_flush_tlb,
 	.flush_tlb_kernel = xen_flush_tlb,
<span class="p_del">-	.flush_tlb_single = xen_flush_tlb_single,</span>
<span class="p_add">+	.flush_tlb_one_user = xen_flush_tlb_one_user,</span>
 	.flush_tlb_others = xen_flush_tlb_others,
 
 	.pgd_alloc = xen_pgd_alloc,
<span class="p_header">diff --git a/arch/x86/xen/p2m.c b/arch/x86/xen/p2m.c</span>
<span class="p_header">index 6083ba462f35..15812e553b95 100644</span>
<span class="p_header">--- a/arch/x86/xen/p2m.c</span>
<span class="p_header">+++ b/arch/x86/xen/p2m.c</span>
<span class="p_chunk">@@ -694,6 +694,9 @@</span> <span class="p_context"> int set_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,</span>
 	int i, ret = 0;
 	pte_t *pte;
 
<span class="p_add">+	if (xen_feature(XENFEAT_auto_translated_physmap))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	if (kmap_ops) {
 		ret = HYPERVISOR_grant_table_op(GNTTABOP_map_grant_ref,
 						kmap_ops, count);
<span class="p_chunk">@@ -736,6 +739,9 @@</span> <span class="p_context"> int clear_foreign_p2m_mapping(struct gnttab_unmap_grant_ref *unmap_ops,</span>
 {
 	int i, ret = 0;
 
<span class="p_add">+	if (xen_feature(XENFEAT_auto_translated_physmap))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; count; i++) {
 		unsigned long mfn = __pfn_to_mfn(page_to_pfn(pages[i]));
 		unsigned long pfn = page_to_pfn(pages[i]);
<span class="p_header">diff --git a/arch/x86/xen/xen-head.S b/arch/x86/xen/xen-head.S</span>
<span class="p_header">index 497cc55a0c16..96f26e026783 100644</span>
<span class="p_header">--- a/arch/x86/xen/xen-head.S</span>
<span class="p_header">+++ b/arch/x86/xen/xen-head.S</span>
<span class="p_chunk">@@ -9,7 +9,9 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/boot.h&gt;
 #include &lt;asm/asm.h&gt;
<span class="p_add">+#include &lt;asm/msr.h&gt;</span>
 #include &lt;asm/page_types.h&gt;
<span class="p_add">+#include &lt;asm/percpu.h&gt;</span>
 #include &lt;asm/unwind_hints.h&gt;
 
 #include &lt;xen/interface/elfnote.h&gt;
<span class="p_chunk">@@ -35,6 +37,20 @@</span> <span class="p_context"> ENTRY(startup_xen)</span>
 	mov %_ASM_SI, xen_start_info
 	mov $init_thread_union+THREAD_SIZE, %_ASM_SP
 
<span class="p_add">+#ifdef CONFIG_X86_64</span>
<span class="p_add">+	/* Set up %gs.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The base of %gs always points to the bottom of the irqstack</span>
<span class="p_add">+	 * union.  If the stack protector canary is enabled, it is</span>
<span class="p_add">+	 * located at %gs:40.  Note that, on SMP, the boot cpu uses</span>
<span class="p_add">+	 * init data section till per cpu areas are set up.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	movl	$MSR_GS_BASE,%ecx</span>
<span class="p_add">+	movq	$INIT_PER_CPU_VAR(irq_stack_union),%rax</span>
<span class="p_add">+	cdq</span>
<span class="p_add">+	wrmsr</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	jmp xen_start_kernel
 END(startup_xen)
 	__FINIT
<span class="p_header">diff --git a/block/blk-wbt.c b/block/blk-wbt.c</span>
<span class="p_header">index e59d59c11ebb..5c105514bca7 100644</span>
<span class="p_header">--- a/block/blk-wbt.c</span>
<span class="p_header">+++ b/block/blk-wbt.c</span>
<span class="p_chunk">@@ -698,7 +698,15 @@</span> <span class="p_context"> u64 wbt_default_latency_nsec(struct request_queue *q)</span>
 
 static int wbt_data_dir(const struct request *rq)
 {
<span class="p_del">-	return rq_data_dir(rq);</span>
<span class="p_add">+	const int op = req_op(rq);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (op == REQ_OP_READ)</span>
<span class="p_add">+		return READ;</span>
<span class="p_add">+	else if (op == REQ_OP_WRITE || op == REQ_OP_FLUSH)</span>
<span class="p_add">+		return WRITE;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* don&#39;t account */</span>
<span class="p_add">+	return -1;</span>
 }
 
 int wbt_init(struct request_queue *q)
<span class="p_header">diff --git a/crypto/xor.c b/crypto/xor.c</span>
<span class="p_header">index 263af9fb45ea..bce9fe7af40a 100644</span>
<span class="p_header">--- a/crypto/xor.c</span>
<span class="p_header">+++ b/crypto/xor.c</span>
<span class="p_chunk">@@ -122,12 +122,7 @@</span> <span class="p_context"> calibrate_xor_blocks(void)</span>
 		goto out;
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Note: Since the memory is not actually used for _anything_ but to</span>
<span class="p_del">-	 * test the XOR speed, we don&#39;t really want kmemcheck to warn about</span>
<span class="p_del">-	 * reading uninitialized bytes here.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	b1 = (void *) __get_free_pages(GFP_KERNEL | __GFP_NOTRACK, 2);</span>
<span class="p_add">+	b1 = (void *) __get_free_pages(GFP_KERNEL, 2);</span>
 	if (!b1) {
 		printk(KERN_WARNING &quot;xor: Yikes!  No memory available.\n&quot;);
 		return -ENOMEM;
<span class="p_header">diff --git a/drivers/base/core.c b/drivers/base/core.c</span>
<span class="p_header">index 12ebd055724c..c8501cdb95f4 100644</span>
<span class="p_header">--- a/drivers/base/core.c</span>
<span class="p_header">+++ b/drivers/base/core.c</span>
<span class="p_chunk">@@ -313,6 +313,9 @@</span> <span class="p_context"> static void __device_link_del(struct device_link *link)</span>
 	dev_info(link-&gt;consumer, &quot;Dropping the link to %s\n&quot;,
 		 dev_name(link-&gt;supplier));
 
<span class="p_add">+	if (link-&gt;flags &amp; DL_FLAG_PM_RUNTIME)</span>
<span class="p_add">+		pm_runtime_drop_link(link-&gt;consumer);</span>
<span class="p_add">+</span>
 	list_del(&amp;link-&gt;s_node);
 	list_del(&amp;link-&gt;c_node);
 	device_link_free(link);
<span class="p_header">diff --git a/drivers/block/rbd.c b/drivers/block/rbd.c</span>
<span class="p_header">index 609227211295..fe4fd8aee19f 100644</span>
<span class="p_header">--- a/drivers/block/rbd.c</span>
<span class="p_header">+++ b/drivers/block/rbd.c</span>
<span class="p_chunk">@@ -124,11 +124,13 @@</span> <span class="p_context"> static int atomic_dec_return_safe(atomic_t *v)</span>
 #define RBD_FEATURE_STRIPINGV2		(1ULL&lt;&lt;1)
 #define RBD_FEATURE_EXCLUSIVE_LOCK	(1ULL&lt;&lt;2)
 #define RBD_FEATURE_DATA_POOL		(1ULL&lt;&lt;7)
<span class="p_add">+#define RBD_FEATURE_OPERATIONS		(1ULL&lt;&lt;8)</span>
 
 #define RBD_FEATURES_ALL	(RBD_FEATURE_LAYERING |		\
 				 RBD_FEATURE_STRIPINGV2 |	\
 				 RBD_FEATURE_EXCLUSIVE_LOCK |	\
<span class="p_del">-				 RBD_FEATURE_DATA_POOL)</span>
<span class="p_add">+				 RBD_FEATURE_DATA_POOL |	\</span>
<span class="p_add">+				 RBD_FEATURE_OPERATIONS)</span>
 
 /* Features supported by this (client software) implementation. */
 
<span class="p_header">diff --git a/drivers/bluetooth/Kconfig b/drivers/bluetooth/Kconfig</span>
<span class="p_header">index 98a60db8e5d1..b33c8d6eb8c7 100644</span>
<span class="p_header">--- a/drivers/bluetooth/Kconfig</span>
<span class="p_header">+++ b/drivers/bluetooth/Kconfig</span>
<span class="p_chunk">@@ -66,6 +66,7 @@</span> <span class="p_context"> config BT_HCIBTSDIO</span>
 
 config BT_HCIUART
 	tristate &quot;HCI UART driver&quot;
<span class="p_add">+	depends on SERIAL_DEV_BUS || !SERIAL_DEV_BUS</span>
 	depends on TTY
 	help
 	  Bluetooth HCI UART driver.
<span class="p_chunk">@@ -80,7 +81,6 @@</span> <span class="p_context"> config BT_HCIUART</span>
 config BT_HCIUART_SERDEV
 	bool
 	depends on SERIAL_DEV_BUS &amp;&amp; BT_HCIUART
<span class="p_del">-	depends on SERIAL_DEV_BUS=y || SERIAL_DEV_BUS=BT_HCIUART</span>
 	default y
 
 config BT_HCIUART_H4
<span class="p_header">diff --git a/drivers/char/hw_random/via-rng.c b/drivers/char/hw_random/via-rng.c</span>
<span class="p_header">index d1f5bb534e0e..6e9df558325b 100644</span>
<span class="p_header">--- a/drivers/char/hw_random/via-rng.c</span>
<span class="p_header">+++ b/drivers/char/hw_random/via-rng.c</span>
<span class="p_chunk">@@ -162,7 +162,7 @@</span> <span class="p_context"> static int via_rng_init(struct hwrng *rng)</span>
 	/* Enable secondary noise source on CPUs where it is present. */
 
 	/* Nehemiah stepping 8 and higher */
<span class="p_del">-	if ((c-&gt;x86_model == 9) &amp;&amp; (c-&gt;x86_mask &gt; 7))</span>
<span class="p_add">+	if ((c-&gt;x86_model == 9) &amp;&amp; (c-&gt;x86_stepping &gt; 7))</span>
 		lo |= VIA_NOISESRC2;
 
 	/* Esther */
<span class="p_header">diff --git a/drivers/char/random.c b/drivers/char/random.c</span>
<span class="p_header">index 8ad92707e45f..ea0115cf5fc0 100644</span>
<span class="p_header">--- a/drivers/char/random.c</span>
<span class="p_header">+++ b/drivers/char/random.c</span>
<span class="p_chunk">@@ -259,7 +259,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/cryptohash.h&gt;
 #include &lt;linux/fips.h&gt;
 #include &lt;linux/ptrace.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/workqueue.h&gt;
 #include &lt;linux/irq.h&gt;
 #include &lt;linux/syscalls.h&gt;
<span class="p_header">diff --git a/drivers/cpufreq/acpi-cpufreq.c b/drivers/cpufreq/acpi-cpufreq.c</span>
<span class="p_header">index 3a2ca0f79daf..d0c34df0529c 100644</span>
<span class="p_header">--- a/drivers/cpufreq/acpi-cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/acpi-cpufreq.c</span>
<span class="p_chunk">@@ -629,7 +629,7 @@</span> <span class="p_context"> static int acpi_cpufreq_blacklist(struct cpuinfo_x86 *c)</span>
 	if (c-&gt;x86_vendor == X86_VENDOR_INTEL) {
 		if ((c-&gt;x86 == 15) &amp;&amp;
 		    (c-&gt;x86_model == 6) &amp;&amp;
<span class="p_del">-		    (c-&gt;x86_mask == 8)) {</span>
<span class="p_add">+		    (c-&gt;x86_stepping == 8)) {</span>
 			pr_info(&quot;Intel(R) Xeon(R) 7100 Errata AL30, processors may lock up on frequency changes: disabling acpi-cpufreq\n&quot;);
 			return -ENODEV;
 		    }
<span class="p_header">diff --git a/drivers/cpufreq/longhaul.c b/drivers/cpufreq/longhaul.c</span>
<span class="p_header">index c46a12df40dd..d5e27bc7585a 100644</span>
<span class="p_header">--- a/drivers/cpufreq/longhaul.c</span>
<span class="p_header">+++ b/drivers/cpufreq/longhaul.c</span>
<span class="p_chunk">@@ -775,7 +775,7 @@</span> <span class="p_context"> static int longhaul_cpu_init(struct cpufreq_policy *policy)</span>
 		break;
 
 	case 7:
<span class="p_del">-		switch (c-&gt;x86_mask) {</span>
<span class="p_add">+		switch (c-&gt;x86_stepping) {</span>
 		case 0:
 			longhaul_version = TYPE_LONGHAUL_V1;
 			cpu_model = CPU_SAMUEL2;
<span class="p_chunk">@@ -787,7 +787,7 @@</span> <span class="p_context"> static int longhaul_cpu_init(struct cpufreq_policy *policy)</span>
 			break;
 		case 1 ... 15:
 			longhaul_version = TYPE_LONGHAUL_V2;
<span class="p_del">-			if (c-&gt;x86_mask &lt; 8) {</span>
<span class="p_add">+			if (c-&gt;x86_stepping &lt; 8) {</span>
 				cpu_model = CPU_SAMUEL2;
 				cpuname = &quot;C3 &#39;Samuel 2&#39; [C5B]&quot;;
 			} else {
<span class="p_chunk">@@ -814,7 +814,7 @@</span> <span class="p_context"> static int longhaul_cpu_init(struct cpufreq_policy *policy)</span>
 		numscales = 32;
 		memcpy(mults, nehemiah_mults, sizeof(nehemiah_mults));
 		memcpy(eblcr, nehemiah_eblcr, sizeof(nehemiah_eblcr));
<span class="p_del">-		switch (c-&gt;x86_mask) {</span>
<span class="p_add">+		switch (c-&gt;x86_stepping) {</span>
 		case 0 ... 1:
 			cpu_model = CPU_NEHEMIAH;
 			cpuname = &quot;C3 &#39;Nehemiah A&#39; [C5XLOE]&quot;;
<span class="p_header">diff --git a/drivers/cpufreq/p4-clockmod.c b/drivers/cpufreq/p4-clockmod.c</span>
<span class="p_header">index fd77812313f3..a25741b1281b 100644</span>
<span class="p_header">--- a/drivers/cpufreq/p4-clockmod.c</span>
<span class="p_header">+++ b/drivers/cpufreq/p4-clockmod.c</span>
<span class="p_chunk">@@ -168,7 +168,7 @@</span> <span class="p_context"> static int cpufreq_p4_cpu_init(struct cpufreq_policy *policy)</span>
 #endif
 
 	/* Errata workaround */
<span class="p_del">-	cpuid = (c-&gt;x86 &lt;&lt; 8) | (c-&gt;x86_model &lt;&lt; 4) | c-&gt;x86_mask;</span>
<span class="p_add">+	cpuid = (c-&gt;x86 &lt;&lt; 8) | (c-&gt;x86_model &lt;&lt; 4) | c-&gt;x86_stepping;</span>
 	switch (cpuid) {
 	case 0x0f07:
 	case 0x0f0a:
<span class="p_header">diff --git a/drivers/cpufreq/powernow-k7.c b/drivers/cpufreq/powernow-k7.c</span>
<span class="p_header">index 80ac313e6c59..302e9ce793a0 100644</span>
<span class="p_header">--- a/drivers/cpufreq/powernow-k7.c</span>
<span class="p_header">+++ b/drivers/cpufreq/powernow-k7.c</span>
<span class="p_chunk">@@ -131,7 +131,7 @@</span> <span class="p_context"> static int check_powernow(void)</span>
 		return 0;
 	}
 
<span class="p_del">-	if ((c-&gt;x86_model == 6) &amp;&amp; (c-&gt;x86_mask == 0)) {</span>
<span class="p_add">+	if ((c-&gt;x86_model == 6) &amp;&amp; (c-&gt;x86_stepping == 0)) {</span>
 		pr_info(&quot;K7 660[A0] core detected, enabling errata workarounds\n&quot;);
 		have_a0 = 1;
 	}
<span class="p_header">diff --git a/drivers/cpufreq/powernv-cpufreq.c b/drivers/cpufreq/powernv-cpufreq.c</span>
<span class="p_header">index 3ff5160451b4..7e1e5bbcf430 100644</span>
<span class="p_header">--- a/drivers/cpufreq/powernv-cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/powernv-cpufreq.c</span>
<span class="p_chunk">@@ -287,9 +287,9 @@</span> <span class="p_context"> static int init_powernv_pstates(void)</span>
 
 		if (id == pstate_max)
 			powernv_pstate_info.max = i;
<span class="p_del">-		else if (id == pstate_nominal)</span>
<span class="p_add">+		if (id == pstate_nominal)</span>
 			powernv_pstate_info.nominal = i;
<span class="p_del">-		else if (id == pstate_min)</span>
<span class="p_add">+		if (id == pstate_min)</span>
 			powernv_pstate_info.min = i;
 
 		if (powernv_pstate_info.wof_enabled &amp;&amp; id == pstate_turbo) {
<span class="p_header">diff --git a/drivers/cpufreq/speedstep-centrino.c b/drivers/cpufreq/speedstep-centrino.c</span>
<span class="p_header">index 41bc5397f4bb..4fa5adf16c70 100644</span>
<span class="p_header">--- a/drivers/cpufreq/speedstep-centrino.c</span>
<span class="p_header">+++ b/drivers/cpufreq/speedstep-centrino.c</span>
<span class="p_chunk">@@ -37,7 +37,7 @@</span> <span class="p_context"> struct cpu_id</span>
 {
 	__u8	x86;            /* CPU family */
 	__u8	x86_model;	/* model */
<span class="p_del">-	__u8	x86_mask;	/* stepping */</span>
<span class="p_add">+	__u8	x86_stepping;	/* stepping */</span>
 };
 
 enum {
<span class="p_chunk">@@ -277,7 +277,7 @@</span> <span class="p_context"> static int centrino_verify_cpu_id(const struct cpuinfo_x86 *c,</span>
 {
 	if ((c-&gt;x86 == x-&gt;x86) &amp;&amp;
 	    (c-&gt;x86_model == x-&gt;x86_model) &amp;&amp;
<span class="p_del">-	    (c-&gt;x86_mask == x-&gt;x86_mask))</span>
<span class="p_add">+	    (c-&gt;x86_stepping == x-&gt;x86_stepping))</span>
 		return 1;
 	return 0;
 }
<span class="p_header">diff --git a/drivers/cpufreq/speedstep-lib.c b/drivers/cpufreq/speedstep-lib.c</span>
<span class="p_header">index ccab452a4ef5..dd7bb00991f4 100644</span>
<span class="p_header">--- a/drivers/cpufreq/speedstep-lib.c</span>
<span class="p_header">+++ b/drivers/cpufreq/speedstep-lib.c</span>
<span class="p_chunk">@@ -272,9 +272,9 @@</span> <span class="p_context"> unsigned int speedstep_detect_processor(void)</span>
 		ebx = cpuid_ebx(0x00000001);
 		ebx &amp;= 0x000000FF;
 
<span class="p_del">-		pr_debug(&quot;ebx value is %x, x86_mask is %x\n&quot;, ebx, c-&gt;x86_mask);</span>
<span class="p_add">+		pr_debug(&quot;ebx value is %x, x86_stepping is %x\n&quot;, ebx, c-&gt;x86_stepping);</span>
 
<span class="p_del">-		switch (c-&gt;x86_mask) {</span>
<span class="p_add">+		switch (c-&gt;x86_stepping) {</span>
 		case 4:
 			/*
 			 * B-stepping [M-P4-M]
<span class="p_chunk">@@ -361,7 +361,7 @@</span> <span class="p_context"> unsigned int speedstep_detect_processor(void)</span>
 				msr_lo, msr_hi);
 		if ((msr_hi &amp; (1&lt;&lt;18)) &amp;&amp;
 		    (relaxed_check ? 1 : (msr_hi &amp; (3&lt;&lt;24)))) {
<span class="p_del">-			if (c-&gt;x86_mask == 0x01) {</span>
<span class="p_add">+			if (c-&gt;x86_stepping == 0x01) {</span>
 				pr_debug(&quot;early PIII version\n&quot;);
 				return SPEEDSTEP_CPU_PIII_C_EARLY;
 			} else
<span class="p_header">diff --git a/drivers/crypto/padlock-aes.c b/drivers/crypto/padlock-aes.c</span>
<span class="p_header">index b3869748cc6b..c939f18f70cc 100644</span>
<span class="p_header">--- a/drivers/crypto/padlock-aes.c</span>
<span class="p_header">+++ b/drivers/crypto/padlock-aes.c</span>
<span class="p_chunk">@@ -512,7 +512,7 @@</span> <span class="p_context"> static int __init padlock_init(void)</span>
 
 	printk(KERN_NOTICE PFX &quot;Using VIA PadLock ACE for AES algorithm.\n&quot;);
 
<span class="p_del">-	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model == 15 &amp;&amp; c-&gt;x86_mask == 2) {</span>
<span class="p_add">+	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model == 15 &amp;&amp; c-&gt;x86_stepping == 2) {</span>
 		ecb_fetch_blocks = MAX_ECB_FETCH_BLOCKS;
 		cbc_fetch_blocks = MAX_CBC_FETCH_BLOCKS;
 		printk(KERN_NOTICE PFX &quot;VIA Nano stepping 2 detected: enabling workaround.\n&quot;);
<span class="p_header">diff --git a/drivers/crypto/sunxi-ss/sun4i-ss-prng.c b/drivers/crypto/sunxi-ss/sun4i-ss-prng.c</span>
<span class="p_header">index 0d01d1624252..63d636424161 100644</span>
<span class="p_header">--- a/drivers/crypto/sunxi-ss/sun4i-ss-prng.c</span>
<span class="p_header">+++ b/drivers/crypto/sunxi-ss/sun4i-ss-prng.c</span>
<span class="p_chunk">@@ -28,7 +28,7 @@</span> <span class="p_context"> int sun4i_ss_prng_generate(struct crypto_rng *tfm, const u8 *src,</span>
 	algt = container_of(alg, struct sun4i_ss_alg_template, alg.rng);
 	ss = algt-&gt;ss;
 
<span class="p_del">-	spin_lock(&amp;ss-&gt;slock);</span>
<span class="p_add">+	spin_lock_bh(&amp;ss-&gt;slock);</span>
 
 	writel(mode, ss-&gt;base + SS_CTL);
 
<span class="p_chunk">@@ -51,6 +51,6 @@</span> <span class="p_context"> int sun4i_ss_prng_generate(struct crypto_rng *tfm, const u8 *src,</span>
 	}
 
 	writel(0, ss-&gt;base + SS_CTL);
<span class="p_del">-	spin_unlock(&amp;ss-&gt;slock);</span>
<span class="p_del">-	return dlen;</span>
<span class="p_add">+	spin_unlock_bh(&amp;ss-&gt;slock);</span>
<span class="p_add">+	return 0;</span>
 }
<span class="p_header">diff --git a/drivers/devfreq/devfreq.c b/drivers/devfreq/devfreq.c</span>
<span class="p_header">index a1c4ee818614..202476fbbc4c 100644</span>
<span class="p_header">--- a/drivers/devfreq/devfreq.c</span>
<span class="p_header">+++ b/drivers/devfreq/devfreq.c</span>
<span class="p_chunk">@@ -676,7 +676,7 @@</span> <span class="p_context"> struct devfreq *devm_devfreq_add_device(struct device *dev,</span>
 	devfreq = devfreq_add_device(dev, profile, governor_name, data);
 	if (IS_ERR(devfreq)) {
 		devres_free(ptr);
<span class="p_del">-		return ERR_PTR(-ENOMEM);</span>
<span class="p_add">+		return devfreq;</span>
 	}
 
 	*ptr = devfreq;
<span class="p_header">diff --git a/drivers/dma-buf/reservation.c b/drivers/dma-buf/reservation.c</span>
<span class="p_header">index b44d9d7db347..012fa3d1f407 100644</span>
<span class="p_header">--- a/drivers/dma-buf/reservation.c</span>
<span class="p_header">+++ b/drivers/dma-buf/reservation.c</span>
<span class="p_chunk">@@ -455,13 +455,15 @@</span> <span class="p_context"> long reservation_object_wait_timeout_rcu(struct reservation_object *obj,</span>
 					 unsigned long timeout)
 {
 	struct dma_fence *fence;
<span class="p_del">-	unsigned seq, shared_count, i = 0;</span>
<span class="p_add">+	unsigned seq, shared_count;</span>
 	long ret = timeout ? timeout : 1;
<span class="p_add">+	int i;</span>
 
 retry:
 	shared_count = 0;
 	seq = read_seqcount_begin(&amp;obj-&gt;seq);
 	rcu_read_lock();
<span class="p_add">+	i = -1;</span>
 
 	fence = rcu_dereference(obj-&gt;fence_excl);
 	if (fence &amp;&amp; !test_bit(DMA_FENCE_FLAG_SIGNALED_BIT, &amp;fence-&gt;flags)) {
<span class="p_chunk">@@ -477,14 +479,14 @@</span> <span class="p_context"> long reservation_object_wait_timeout_rcu(struct reservation_object *obj,</span>
 		fence = NULL;
 	}
 
<span class="p_del">-	if (!fence &amp;&amp; wait_all) {</span>
<span class="p_add">+	if (wait_all) {</span>
 		struct reservation_object_list *fobj =
 						rcu_dereference(obj-&gt;fence);
 
 		if (fobj)
 			shared_count = fobj-&gt;shared_count;
 
<span class="p_del">-		for (i = 0; i &lt; shared_count; ++i) {</span>
<span class="p_add">+		for (i = 0; !fence &amp;&amp; i &lt; shared_count; ++i) {</span>
 			struct dma_fence *lfence = rcu_dereference(fobj-&gt;shared[i]);
 
 			if (test_bit(DMA_FENCE_FLAG_SIGNALED_BIT,
<span class="p_header">diff --git a/drivers/edac/amd64_edac.c b/drivers/edac/amd64_edac.c</span>
<span class="p_header">index ac2f30295efe..59ce32e405ac 100644</span>
<span class="p_header">--- a/drivers/edac/amd64_edac.c</span>
<span class="p_header">+++ b/drivers/edac/amd64_edac.c</span>
<span class="p_chunk">@@ -3147,7 +3147,7 @@</span> <span class="p_context"> static struct amd64_family_type *per_family_init(struct amd64_pvt *pvt)</span>
 	struct amd64_family_type *fam_type = NULL;
 
 	pvt-&gt;ext_model  = boot_cpu_data.x86_model &gt;&gt; 4;
<span class="p_del">-	pvt-&gt;stepping	= boot_cpu_data.x86_mask;</span>
<span class="p_add">+	pvt-&gt;stepping	= boot_cpu_data.x86_stepping;</span>
 	pvt-&gt;model	= boot_cpu_data.x86_model;
 	pvt-&gt;fam	= boot_cpu_data.x86;
 
<span class="p_header">diff --git a/drivers/gpu/drm/amd/powerplay/smumgr/rv_smumgr.h b/drivers/gpu/drm/amd/powerplay/smumgr/rv_smumgr.h</span>
<span class="p_header">index 262c8ded87c0..dafc9c4b1e6f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/powerplay/smumgr/rv_smumgr.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/powerplay/smumgr/rv_smumgr.h</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"> struct smu_table_entry {</span>
 	uint32_t table_addr_high;
 	uint32_t table_addr_low;
 	uint8_t *table;
<span class="p_del">-	uint32_t handle;</span>
<span class="p_add">+	unsigned long handle;</span>
 };
 
 struct smu_table_array {
<span class="p_header">diff --git a/drivers/gpu/drm/ast/ast_mode.c b/drivers/gpu/drm/ast/ast_mode.c</span>
<span class="p_header">index 6f3849ec0c1d..e9f1e6fe7b94 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/ast/ast_mode.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/ast/ast_mode.c</span>
<span class="p_chunk">@@ -644,6 +644,7 @@</span> <span class="p_context"> static void ast_crtc_commit(struct drm_crtc *crtc)</span>
 {
 	struct ast_private *ast = crtc-&gt;dev-&gt;dev_private;
 	ast_set_index_reg_mask(ast, AST_IO_SEQ_PORT, 0x1, 0xdf, 0);
<span class="p_add">+	ast_crtc_load_lut(crtc);</span>
 }
 
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.h b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">index 18d9da53282b..3f818412765c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_chunk">@@ -842,6 +842,7 @@</span> <span class="p_context"> struct intel_device_info {</span>
 	u8 gen;
 	u16 gen_mask;
 	enum intel_platform platform;
<span class="p_add">+	u8 gt; /* GT number, 0 if undefined */</span>
 	u8 ring_mask; /* Rings supported by the HW */
 	u8 num_rings;
 #define DEFINE_FLAG(name) u8 name:1
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_pci.c b/drivers/gpu/drm/i915/i915_pci.c</span>
<span class="p_header">index 09d97e0990b7..2985f1e418ad 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_pci.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_pci.c</span>
<span class="p_chunk">@@ -224,15 +224,34 @@</span> <span class="p_context"> static const struct intel_device_info intel_ironlake_m_info = {</span>
 	GEN_DEFAULT_PIPEOFFSETS, \
 	CURSOR_OFFSETS
 
<span class="p_del">-static const struct intel_device_info intel_sandybridge_d_info = {</span>
<span class="p_del">-	GEN6_FEATURES,</span>
<span class="p_del">-	.platform = INTEL_SANDYBRIDGE,</span>
<span class="p_add">+#define SNB_D_PLATFORM \</span>
<span class="p_add">+	GEN6_FEATURES, \</span>
<span class="p_add">+	.platform = INTEL_SANDYBRIDGE</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_sandybridge_d_gt1_info = {</span>
<span class="p_add">+	SNB_D_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
 };
 
<span class="p_del">-static const struct intel_device_info intel_sandybridge_m_info = {</span>
<span class="p_del">-	GEN6_FEATURES,</span>
<span class="p_del">-	.platform = INTEL_SANDYBRIDGE,</span>
<span class="p_del">-	.is_mobile = 1,</span>
<span class="p_add">+static const struct intel_device_info intel_sandybridge_d_gt2_info = {</span>
<span class="p_add">+	SNB_D_PLATFORM,</span>
<span class="p_add">+	.gt = 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+#define SNB_M_PLATFORM \</span>
<span class="p_add">+	GEN6_FEATURES, \</span>
<span class="p_add">+	.platform = INTEL_SANDYBRIDGE, \</span>
<span class="p_add">+	.is_mobile = 1</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_sandybridge_m_gt1_info = {</span>
<span class="p_add">+	SNB_M_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_sandybridge_m_gt2_info = {</span>
<span class="p_add">+	SNB_M_PLATFORM,</span>
<span class="p_add">+	.gt = 2,</span>
 };
 
 #define GEN7_FEATURES  \
<span class="p_chunk">@@ -249,22 +268,41 @@</span> <span class="p_context"> static const struct intel_device_info intel_sandybridge_m_info = {</span>
 	GEN_DEFAULT_PIPEOFFSETS, \
 	IVB_CURSOR_OFFSETS
 
<span class="p_del">-static const struct intel_device_info intel_ivybridge_d_info = {</span>
<span class="p_del">-	GEN7_FEATURES,</span>
<span class="p_del">-	.platform = INTEL_IVYBRIDGE,</span>
<span class="p_del">-	.has_l3_dpf = 1,</span>
<span class="p_add">+#define IVB_D_PLATFORM \</span>
<span class="p_add">+	GEN7_FEATURES, \</span>
<span class="p_add">+	.platform = INTEL_IVYBRIDGE, \</span>
<span class="p_add">+	.has_l3_dpf = 1</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_ivybridge_d_gt1_info = {</span>
<span class="p_add">+	IVB_D_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
 };
 
<span class="p_del">-static const struct intel_device_info intel_ivybridge_m_info = {</span>
<span class="p_del">-	GEN7_FEATURES,</span>
<span class="p_del">-	.platform = INTEL_IVYBRIDGE,</span>
<span class="p_del">-	.is_mobile = 1,</span>
<span class="p_del">-	.has_l3_dpf = 1,</span>
<span class="p_add">+static const struct intel_device_info intel_ivybridge_d_gt2_info = {</span>
<span class="p_add">+	IVB_D_PLATFORM,</span>
<span class="p_add">+	.gt = 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+#define IVB_M_PLATFORM \</span>
<span class="p_add">+	GEN7_FEATURES, \</span>
<span class="p_add">+	.platform = INTEL_IVYBRIDGE, \</span>
<span class="p_add">+	.is_mobile = 1, \</span>
<span class="p_add">+	.has_l3_dpf = 1</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_ivybridge_m_gt1_info = {</span>
<span class="p_add">+	IVB_M_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_ivybridge_m_gt2_info = {</span>
<span class="p_add">+	IVB_M_PLATFORM,</span>
<span class="p_add">+	.gt = 2,</span>
 };
 
 static const struct intel_device_info intel_ivybridge_q_info = {
 	GEN7_FEATURES,
 	.platform = INTEL_IVYBRIDGE,
<span class="p_add">+	.gt = 2,</span>
 	.num_pipes = 0, /* legal, last one wins */
 	.has_l3_dpf = 1,
 };
<span class="p_chunk">@@ -299,10 +337,24 @@</span> <span class="p_context"> static const struct intel_device_info intel_valleyview_info = {</span>
 	.has_rc6p = 0 /* RC6p removed-by HSW */, \
 	.has_runtime_pm = 1
 
<span class="p_del">-static const struct intel_device_info intel_haswell_info = {</span>
<span class="p_del">-	HSW_FEATURES,</span>
<span class="p_del">-	.platform = INTEL_HASWELL,</span>
<span class="p_del">-	.has_l3_dpf = 1,</span>
<span class="p_add">+#define HSW_PLATFORM \</span>
<span class="p_add">+	HSW_FEATURES, \</span>
<span class="p_add">+	.platform = INTEL_HASWELL, \</span>
<span class="p_add">+	.has_l3_dpf = 1</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_haswell_gt1_info = {</span>
<span class="p_add">+	HSW_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_haswell_gt2_info = {</span>
<span class="p_add">+	HSW_PLATFORM,</span>
<span class="p_add">+	.gt = 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_haswell_gt3_info = {</span>
<span class="p_add">+	HSW_PLATFORM,</span>
<span class="p_add">+	.gt = 3,</span>
 };
 
 #define BDW_FEATURES \
<span class="p_chunk">@@ -318,12 +370,27 @@</span> <span class="p_context"> static const struct intel_device_info intel_haswell_info = {</span>
 	.gen = 8, \
 	.platform = INTEL_BROADWELL
 
<span class="p_del">-static const struct intel_device_info intel_broadwell_info = {</span>
<span class="p_add">+static const struct intel_device_info intel_broadwell_gt1_info = {</span>
<span class="p_add">+	BDW_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_broadwell_gt2_info = {</span>
 	BDW_PLATFORM,
<span class="p_add">+	.gt = 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_broadwell_rsvd_info = {</span>
<span class="p_add">+	BDW_PLATFORM,</span>
<span class="p_add">+	.gt = 3,</span>
<span class="p_add">+	/* According to the device ID those devices are GT3, they were</span>
<span class="p_add">+	 * previously treated as not GT3, keep it like that.</span>
<span class="p_add">+	 */</span>
 };
 
 static const struct intel_device_info intel_broadwell_gt3_info = {
 	BDW_PLATFORM,
<span class="p_add">+	.gt = 3,</span>
 	.ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING | BSD2_RING,
 };
 
<span class="p_chunk">@@ -358,13 +425,29 @@</span> <span class="p_context"> static const struct intel_device_info intel_cherryview_info = {</span>
 	.has_guc = 1, \
 	.ddb_size = 896
 
<span class="p_del">-static const struct intel_device_info intel_skylake_info = {</span>
<span class="p_add">+static const struct intel_device_info intel_skylake_gt1_info = {</span>
 	SKL_PLATFORM,
<span class="p_add">+	.gt = 1,</span>
 };
 
<span class="p_del">-static const struct intel_device_info intel_skylake_gt3_info = {</span>
<span class="p_add">+static const struct intel_device_info intel_skylake_gt2_info = {</span>
 	SKL_PLATFORM,
<span class="p_del">-	.ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING | BSD2_RING,</span>
<span class="p_add">+	.gt = 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+#define SKL_GT3_PLUS_PLATFORM \</span>
<span class="p_add">+	SKL_PLATFORM, \</span>
<span class="p_add">+	.ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING | BSD2_RING</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_skylake_gt3_info = {</span>
<span class="p_add">+	SKL_GT3_PLUS_PLATFORM,</span>
<span class="p_add">+	.gt = 3,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_skylake_gt4_info = {</span>
<span class="p_add">+	SKL_GT3_PLUS_PLATFORM,</span>
<span class="p_add">+	.gt = 4,</span>
 };
 
 #define GEN9_LP_FEATURES \
<span class="p_chunk">@@ -416,12 +499,19 @@</span> <span class="p_context"> static const struct intel_device_info intel_geminilake_info = {</span>
 	.has_guc = 1, \
 	.ddb_size = 896
 
<span class="p_del">-static const struct intel_device_info intel_kabylake_info = {</span>
<span class="p_add">+static const struct intel_device_info intel_kabylake_gt1_info = {</span>
 	KBL_PLATFORM,
<span class="p_add">+	.gt = 1,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_kabylake_gt2_info = {</span>
<span class="p_add">+	KBL_PLATFORM,</span>
<span class="p_add">+	.gt = 2,</span>
 };
 
 static const struct intel_device_info intel_kabylake_gt3_info = {
 	KBL_PLATFORM,
<span class="p_add">+	.gt = 3,</span>
 	.ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING | BSD2_RING,
 };
 
<span class="p_chunk">@@ -434,20 +524,28 @@</span> <span class="p_context"> static const struct intel_device_info intel_kabylake_gt3_info = {</span>
 	.has_guc = 1, \
 	.ddb_size = 896
 
<span class="p_del">-static const struct intel_device_info intel_coffeelake_info = {</span>
<span class="p_add">+static const struct intel_device_info intel_coffeelake_gt1_info = {</span>
<span class="p_add">+	CFL_PLATFORM,</span>
<span class="p_add">+	.gt = 1,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct intel_device_info intel_coffeelake_gt2_info = {</span>
 	CFL_PLATFORM,
<span class="p_add">+	.gt = 2,</span>
 };
 
 static const struct intel_device_info intel_coffeelake_gt3_info = {
 	CFL_PLATFORM,
<span class="p_add">+	.gt = 3,</span>
 	.ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING | BSD2_RING,
 };
 
<span class="p_del">-static const struct intel_device_info intel_cannonlake_info = {</span>
<span class="p_add">+static const struct intel_device_info intel_cannonlake_gt2_info = {</span>
 	BDW_FEATURES,
 	.is_alpha_support = 1,
 	.platform = INTEL_CANNONLAKE,
 	.gen = 10,
<span class="p_add">+	.gt = 2,</span>
 	.ddb_size = 1024,
 	.has_csr = 1,
 	.color = { .degamma_lut_size = 0, .gamma_lut_size = 1024 }
<span class="p_chunk">@@ -476,31 +574,40 @@</span> <span class="p_context"> static const struct pci_device_id pciidlist[] = {</span>
 	INTEL_PINEVIEW_IDS(&amp;intel_pineview_info),
 	INTEL_IRONLAKE_D_IDS(&amp;intel_ironlake_d_info),
 	INTEL_IRONLAKE_M_IDS(&amp;intel_ironlake_m_info),
<span class="p_del">-	INTEL_SNB_D_IDS(&amp;intel_sandybridge_d_info),</span>
<span class="p_del">-	INTEL_SNB_M_IDS(&amp;intel_sandybridge_m_info),</span>
<span class="p_add">+	INTEL_SNB_D_GT1_IDS(&amp;intel_sandybridge_d_gt1_info),</span>
<span class="p_add">+	INTEL_SNB_D_GT2_IDS(&amp;intel_sandybridge_d_gt2_info),</span>
<span class="p_add">+	INTEL_SNB_M_GT1_IDS(&amp;intel_sandybridge_m_gt1_info),</span>
<span class="p_add">+	INTEL_SNB_M_GT2_IDS(&amp;intel_sandybridge_m_gt2_info),</span>
 	INTEL_IVB_Q_IDS(&amp;intel_ivybridge_q_info), /* must be first IVB */
<span class="p_del">-	INTEL_IVB_M_IDS(&amp;intel_ivybridge_m_info),</span>
<span class="p_del">-	INTEL_IVB_D_IDS(&amp;intel_ivybridge_d_info),</span>
<span class="p_del">-	INTEL_HSW_IDS(&amp;intel_haswell_info),</span>
<span class="p_add">+	INTEL_IVB_M_GT1_IDS(&amp;intel_ivybridge_m_gt1_info),</span>
<span class="p_add">+	INTEL_IVB_M_GT2_IDS(&amp;intel_ivybridge_m_gt2_info),</span>
<span class="p_add">+	INTEL_IVB_D_GT1_IDS(&amp;intel_ivybridge_d_gt1_info),</span>
<span class="p_add">+	INTEL_IVB_D_GT2_IDS(&amp;intel_ivybridge_d_gt2_info),</span>
<span class="p_add">+	INTEL_HSW_GT1_IDS(&amp;intel_haswell_gt1_info),</span>
<span class="p_add">+	INTEL_HSW_GT2_IDS(&amp;intel_haswell_gt2_info),</span>
<span class="p_add">+	INTEL_HSW_GT3_IDS(&amp;intel_haswell_gt3_info),</span>
 	INTEL_VLV_IDS(&amp;intel_valleyview_info),
<span class="p_del">-	INTEL_BDW_GT12_IDS(&amp;intel_broadwell_info),</span>
<span class="p_add">+	INTEL_BDW_GT1_IDS(&amp;intel_broadwell_gt1_info),</span>
<span class="p_add">+	INTEL_BDW_GT2_IDS(&amp;intel_broadwell_gt2_info),</span>
 	INTEL_BDW_GT3_IDS(&amp;intel_broadwell_gt3_info),
<span class="p_del">-	INTEL_BDW_RSVD_IDS(&amp;intel_broadwell_info),</span>
<span class="p_add">+	INTEL_BDW_RSVD_IDS(&amp;intel_broadwell_rsvd_info),</span>
 	INTEL_CHV_IDS(&amp;intel_cherryview_info),
<span class="p_del">-	INTEL_SKL_GT1_IDS(&amp;intel_skylake_info),</span>
<span class="p_del">-	INTEL_SKL_GT2_IDS(&amp;intel_skylake_info),</span>
<span class="p_add">+	INTEL_SKL_GT1_IDS(&amp;intel_skylake_gt1_info),</span>
<span class="p_add">+	INTEL_SKL_GT2_IDS(&amp;intel_skylake_gt2_info),</span>
 	INTEL_SKL_GT3_IDS(&amp;intel_skylake_gt3_info),
<span class="p_del">-	INTEL_SKL_GT4_IDS(&amp;intel_skylake_gt3_info),</span>
<span class="p_add">+	INTEL_SKL_GT4_IDS(&amp;intel_skylake_gt4_info),</span>
 	INTEL_BXT_IDS(&amp;intel_broxton_info),
 	INTEL_GLK_IDS(&amp;intel_geminilake_info),
<span class="p_del">-	INTEL_KBL_GT1_IDS(&amp;intel_kabylake_info),</span>
<span class="p_del">-	INTEL_KBL_GT2_IDS(&amp;intel_kabylake_info),</span>
<span class="p_add">+	INTEL_KBL_GT1_IDS(&amp;intel_kabylake_gt1_info),</span>
<span class="p_add">+	INTEL_KBL_GT2_IDS(&amp;intel_kabylake_gt2_info),</span>
 	INTEL_KBL_GT3_IDS(&amp;intel_kabylake_gt3_info),
 	INTEL_KBL_GT4_IDS(&amp;intel_kabylake_gt3_info),
<span class="p_del">-	INTEL_CFL_S_IDS(&amp;intel_coffeelake_info),</span>
<span class="p_del">-	INTEL_CFL_H_IDS(&amp;intel_coffeelake_info),</span>
<span class="p_del">-	INTEL_CFL_U_IDS(&amp;intel_coffeelake_gt3_info),</span>
<span class="p_del">-	INTEL_CNL_IDS(&amp;intel_cannonlake_info),</span>
<span class="p_add">+	INTEL_CFL_S_GT1_IDS(&amp;intel_coffeelake_gt1_info),</span>
<span class="p_add">+	INTEL_CFL_S_GT2_IDS(&amp;intel_coffeelake_gt2_info),</span>
<span class="p_add">+	INTEL_CFL_H_GT2_IDS(&amp;intel_coffeelake_gt2_info),</span>
<span class="p_add">+	INTEL_CFL_U_GT3_IDS(&amp;intel_coffeelake_gt3_info),</span>
<span class="p_add">+	INTEL_CNL_U_GT2_IDS(&amp;intel_cannonlake_gt2_info),</span>
<span class="p_add">+	INTEL_CNL_Y_GT2_IDS(&amp;intel_cannonlake_gt2_info),</span>
 	{0, 0, 0}
 };
 MODULE_DEVICE_TABLE(pci, pciidlist);
<span class="p_header">diff --git a/drivers/gpu/drm/qxl/qxl_cmd.c b/drivers/gpu/drm/qxl/qxl_cmd.c</span>
<span class="p_header">index 74fc9362ecf9..3eb920851141 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/qxl/qxl_cmd.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/qxl/qxl_cmd.c</span>
<span class="p_chunk">@@ -388,7 +388,11 @@</span> <span class="p_context"> void qxl_io_create_primary(struct qxl_device *qdev,</span>
 	create-&gt;width = bo-&gt;surf.width;
 	create-&gt;height = bo-&gt;surf.height;
 	create-&gt;stride = bo-&gt;surf.stride;
<span class="p_del">-	create-&gt;mem = qxl_bo_physical_address(qdev, bo, offset);</span>
<span class="p_add">+	if (bo-&gt;shadow) {</span>
<span class="p_add">+		create-&gt;mem = qxl_bo_physical_address(qdev, bo-&gt;shadow, offset);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		create-&gt;mem = qxl_bo_physical_address(qdev, bo, offset);</span>
<span class="p_add">+	}</span>
 
 	QXL_INFO(qdev, &quot;%s: mem = %llx, from %p\n&quot;, __func__, create-&gt;mem,
 		 bo-&gt;kptr);
<span class="p_header">diff --git a/drivers/gpu/drm/qxl/qxl_display.c b/drivers/gpu/drm/qxl/qxl_display.c</span>
<span class="p_header">index afbf50d0c08f..9a9214ae0fb5 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/qxl/qxl_display.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/qxl/qxl_display.c</span>
<span class="p_chunk">@@ -289,6 +289,7 @@</span> <span class="p_context"> static void qxl_crtc_destroy(struct drm_crtc *crtc)</span>
 {
 	struct qxl_crtc *qxl_crtc = to_qxl_crtc(crtc);
 
<span class="p_add">+	qxl_bo_unref(&amp;qxl_crtc-&gt;cursor_bo);</span>
 	drm_crtc_cleanup(crtc);
 	kfree(qxl_crtc);
 }
<span class="p_chunk">@@ -305,7 +306,9 @@</span> <span class="p_context"> static const struct drm_crtc_funcs qxl_crtc_funcs = {</span>
 void qxl_user_framebuffer_destroy(struct drm_framebuffer *fb)
 {
 	struct qxl_framebuffer *qxl_fb = to_qxl_framebuffer(fb);
<span class="p_add">+	struct qxl_bo *bo = gem_to_qxl_bo(qxl_fb-&gt;obj);</span>
 
<span class="p_add">+	WARN_ON(bo-&gt;shadow);</span>
 	drm_gem_object_unreference_unlocked(qxl_fb-&gt;obj);
 	drm_framebuffer_cleanup(fb);
 	kfree(qxl_fb);
<span class="p_chunk">@@ -493,6 +496,53 @@</span> <span class="p_context"> static int qxl_primary_atomic_check(struct drm_plane *plane,</span>
 	return 0;
 }
 
<span class="p_add">+static int qxl_primary_apply_cursor(struct drm_plane *plane)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_device *dev = plane-&gt;dev;</span>
<span class="p_add">+	struct qxl_device *qdev = dev-&gt;dev_private;</span>
<span class="p_add">+	struct drm_framebuffer *fb = plane-&gt;state-&gt;fb;</span>
<span class="p_add">+	struct qxl_crtc *qcrtc = to_qxl_crtc(plane-&gt;state-&gt;crtc);</span>
<span class="p_add">+	struct qxl_cursor_cmd *cmd;</span>
<span class="p_add">+	struct qxl_release *release;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!qcrtc-&gt;cursor_bo)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = qxl_alloc_release_reserved(qdev, sizeof(*cmd),</span>
<span class="p_add">+					 QXL_RELEASE_CURSOR_CMD,</span>
<span class="p_add">+					 &amp;release, NULL);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = qxl_release_list_add(release, qcrtc-&gt;cursor_bo);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		goto out_free_release;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = qxl_release_reserve_list(release, false);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		goto out_free_release;</span>
<span class="p_add">+</span>
<span class="p_add">+	cmd = (struct qxl_cursor_cmd *)qxl_release_map(qdev, release);</span>
<span class="p_add">+	cmd-&gt;type = QXL_CURSOR_SET;</span>
<span class="p_add">+	cmd-&gt;u.set.position.x = plane-&gt;state-&gt;crtc_x + fb-&gt;hot_x;</span>
<span class="p_add">+	cmd-&gt;u.set.position.y = plane-&gt;state-&gt;crtc_y + fb-&gt;hot_y;</span>
<span class="p_add">+</span>
<span class="p_add">+	cmd-&gt;u.set.shape = qxl_bo_physical_address(qdev, qcrtc-&gt;cursor_bo, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+	cmd-&gt;u.set.visible = 1;</span>
<span class="p_add">+	qxl_release_unmap(qdev, release, &amp;cmd-&gt;release_info);</span>
<span class="p_add">+</span>
<span class="p_add">+	qxl_push_cursor_ring_release(qdev, release, QXL_CMD_CURSOR, false);</span>
<span class="p_add">+	qxl_release_fence_buffer_objects(release);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+out_free_release:</span>
<span class="p_add">+	qxl_release_free(qdev, release);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void qxl_primary_atomic_update(struct drm_plane *plane,
 				      struct drm_plane_state *old_state)
 {
<span class="p_chunk">@@ -508,6 +558,8 @@</span> <span class="p_context"> static void qxl_primary_atomic_update(struct drm_plane *plane,</span>
 	    .x2 = qfb-&gt;base.width,
 	    .y2 = qfb-&gt;base.height
 	};
<span class="p_add">+	int ret;</span>
<span class="p_add">+	bool same_shadow = false;</span>
 
 	if (old_state-&gt;fb) {
 		qfb_old = to_qxl_framebuffer(old_state-&gt;fb);
<span class="p_chunk">@@ -519,15 +571,28 @@</span> <span class="p_context"> static void qxl_primary_atomic_update(struct drm_plane *plane,</span>
 	if (bo == bo_old)
 		return;
 
<span class="p_add">+	if (bo_old &amp;&amp; bo_old-&gt;shadow &amp;&amp; bo-&gt;shadow &amp;&amp;</span>
<span class="p_add">+	    bo_old-&gt;shadow == bo-&gt;shadow) {</span>
<span class="p_add">+		same_shadow = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (bo_old &amp;&amp; bo_old-&gt;is_primary) {
<span class="p_del">-		qxl_io_destroy_primary(qdev);</span>
<span class="p_add">+		if (!same_shadow)</span>
<span class="p_add">+			qxl_io_destroy_primary(qdev);</span>
 		bo_old-&gt;is_primary = false;
<span class="p_add">+</span>
<span class="p_add">+		ret = qxl_primary_apply_cursor(plane);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			DRM_ERROR(</span>
<span class="p_add">+			&quot;could not set cursor after creating primary&quot;);</span>
 	}
 
 	if (!bo-&gt;is_primary) {
<span class="p_del">-		qxl_io_create_primary(qdev, 0, bo);</span>
<span class="p_add">+		if (!same_shadow)</span>
<span class="p_add">+			qxl_io_create_primary(qdev, 0, bo);</span>
 		bo-&gt;is_primary = true;
 	}
<span class="p_add">+</span>
 	qxl_draw_dirty_fb(qdev, qfb, bo, 0, 0, &amp;norect, 1, 1);
 }
 
<span class="p_chunk">@@ -560,11 +625,12 @@</span> <span class="p_context"> static void qxl_cursor_atomic_update(struct drm_plane *plane,</span>
 	struct drm_device *dev = plane-&gt;dev;
 	struct qxl_device *qdev = dev-&gt;dev_private;
 	struct drm_framebuffer *fb = plane-&gt;state-&gt;fb;
<span class="p_add">+	struct qxl_crtc *qcrtc = to_qxl_crtc(plane-&gt;state-&gt;crtc);</span>
 	struct qxl_release *release;
 	struct qxl_cursor_cmd *cmd;
 	struct qxl_cursor *cursor;
 	struct drm_gem_object *obj;
<span class="p_del">-	struct qxl_bo *cursor_bo, *user_bo = NULL;</span>
<span class="p_add">+	struct qxl_bo *cursor_bo = NULL, *user_bo = NULL;</span>
 	int ret;
 	void *user_ptr;
 	int size = 64*64*4;
<span class="p_chunk">@@ -617,6 +683,10 @@</span> <span class="p_context"> static void qxl_cursor_atomic_update(struct drm_plane *plane,</span>
 		cmd-&gt;u.set.shape = qxl_bo_physical_address(qdev,
 							   cursor_bo, 0);
 		cmd-&gt;type = QXL_CURSOR_SET;
<span class="p_add">+</span>
<span class="p_add">+		qxl_bo_unref(&amp;qcrtc-&gt;cursor_bo);</span>
<span class="p_add">+		qcrtc-&gt;cursor_bo = cursor_bo;</span>
<span class="p_add">+		cursor_bo = NULL;</span>
 	} else {
 
 		ret = qxl_release_reserve_list(release, true);
<span class="p_chunk">@@ -634,6 +704,8 @@</span> <span class="p_context"> static void qxl_cursor_atomic_update(struct drm_plane *plane,</span>
 	qxl_push_cursor_ring_release(qdev, release, QXL_CMD_CURSOR, false);
 	qxl_release_fence_buffer_objects(release);
 
<span class="p_add">+	qxl_bo_unref(&amp;cursor_bo);</span>
<span class="p_add">+</span>
 	return;
 
 out_backoff:
<span class="p_chunk">@@ -679,8 +751,9 @@</span> <span class="p_context"> static void qxl_cursor_atomic_disable(struct drm_plane *plane,</span>
 static int qxl_plane_prepare_fb(struct drm_plane *plane,
 				struct drm_plane_state *new_state)
 {
<span class="p_add">+	struct qxl_device *qdev = plane-&gt;dev-&gt;dev_private;</span>
 	struct drm_gem_object *obj;
<span class="p_del">-	struct qxl_bo *user_bo;</span>
<span class="p_add">+	struct qxl_bo *user_bo, *old_bo = NULL;</span>
 	int ret;
 
 	if (!new_state-&gt;fb)
<span class="p_chunk">@@ -689,6 +762,32 @@</span> <span class="p_context"> static int qxl_plane_prepare_fb(struct drm_plane *plane,</span>
 	obj = to_qxl_framebuffer(new_state-&gt;fb)-&gt;obj;
 	user_bo = gem_to_qxl_bo(obj);
 
<span class="p_add">+	if (plane-&gt;type == DRM_PLANE_TYPE_PRIMARY &amp;&amp;</span>
<span class="p_add">+	    user_bo-&gt;is_dumb &amp;&amp; !user_bo-&gt;shadow) {</span>
<span class="p_add">+		if (plane-&gt;state-&gt;fb) {</span>
<span class="p_add">+			obj = to_qxl_framebuffer(plane-&gt;state-&gt;fb)-&gt;obj;</span>
<span class="p_add">+			old_bo = gem_to_qxl_bo(obj);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (old_bo &amp;&amp; old_bo-&gt;shadow &amp;&amp;</span>
<span class="p_add">+		    user_bo-&gt;gem_base.size == old_bo-&gt;gem_base.size &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;crtc     == new_state-&gt;crtc &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;crtc_w   == new_state-&gt;crtc_w &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;crtc_h   == new_state-&gt;crtc_h &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;src_x    == new_state-&gt;src_x &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;src_y    == new_state-&gt;src_y &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;src_w    == new_state-&gt;src_w &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;src_h    == new_state-&gt;src_h &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;rotation == new_state-&gt;rotation &amp;&amp;</span>
<span class="p_add">+		    plane-&gt;state-&gt;zpos     == new_state-&gt;zpos) {</span>
<span class="p_add">+			drm_gem_object_get(&amp;old_bo-&gt;shadow-&gt;gem_base);</span>
<span class="p_add">+			user_bo-&gt;shadow = old_bo-&gt;shadow;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			qxl_bo_create(qdev, user_bo-&gt;gem_base.size,</span>
<span class="p_add">+				      true, true, QXL_GEM_DOMAIN_VRAM, NULL,</span>
<span class="p_add">+				      &amp;user_bo-&gt;shadow);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	ret = qxl_bo_pin(user_bo, QXL_GEM_DOMAIN_CPU, NULL);
 	if (ret)
 		return ret;
<span class="p_chunk">@@ -713,6 +812,11 @@</span> <span class="p_context"> static void qxl_plane_cleanup_fb(struct drm_plane *plane,</span>
 	obj = to_qxl_framebuffer(old_state-&gt;fb)-&gt;obj;
 	user_bo = gem_to_qxl_bo(obj);
 	qxl_bo_unpin(user_bo);
<span class="p_add">+</span>
<span class="p_add">+	if (user_bo-&gt;shadow &amp;&amp; !user_bo-&gt;is_primary) {</span>
<span class="p_add">+		drm_gem_object_put_unlocked(&amp;user_bo-&gt;shadow-&gt;gem_base);</span>
<span class="p_add">+		user_bo-&gt;shadow = NULL;</span>
<span class="p_add">+	}</span>
 }
 
 static const uint32_t qxl_cursor_plane_formats[] = {
<span class="p_header">diff --git a/drivers/gpu/drm/qxl/qxl_drv.h b/drivers/gpu/drm/qxl/qxl_drv.h</span>
<span class="p_header">index 3397a1907336..c0a927efa653 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/qxl/qxl_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/qxl/qxl_drv.h</span>
<span class="p_chunk">@@ -113,6 +113,8 @@</span> <span class="p_context"> struct qxl_bo {</span>
 	/* Constant after initialization */
 	struct drm_gem_object		gem_base;
 	bool is_primary; /* is this now a primary surface */
<span class="p_add">+	bool is_dumb;</span>
<span class="p_add">+	struct qxl_bo *shadow;</span>
 	bool hw_surf_alloc;
 	struct qxl_surface surf;
 	uint32_t surface_id;
<span class="p_chunk">@@ -133,6 +135,8 @@</span> <span class="p_context"> struct qxl_bo_list {</span>
 struct qxl_crtc {
 	struct drm_crtc base;
 	int index;
<span class="p_add">+</span>
<span class="p_add">+	struct qxl_bo *cursor_bo;</span>
 };
 
 struct qxl_output {
<span class="p_header">diff --git a/drivers/gpu/drm/qxl/qxl_dumb.c b/drivers/gpu/drm/qxl/qxl_dumb.c</span>
<span class="p_header">index 5e65d5d2d937..11085ab01374 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/qxl/qxl_dumb.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/qxl/qxl_dumb.c</span>
<span class="p_chunk">@@ -63,6 +63,7 @@</span> <span class="p_context"> int qxl_mode_dumb_create(struct drm_file *file_priv,</span>
 					      &amp;handle);
 	if (r)
 		return r;
<span class="p_add">+	qobj-&gt;is_dumb = true;</span>
 	args-&gt;pitch = pitch;
 	args-&gt;handle = handle;
 	return 0;
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_uvd.c b/drivers/gpu/drm/radeon/radeon_uvd.c</span>
<span class="p_header">index d34d1cf33895..95f4db70dd22 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_uvd.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_uvd.c</span>
<span class="p_chunk">@@ -995,7 +995,7 @@</span> <span class="p_context"> int radeon_uvd_calc_upll_dividers(struct radeon_device *rdev,</span>
 		/* calc dclk divider with current vco freq */
 		dclk_div = radeon_uvd_calc_upll_post_div(vco_freq, dclk,
 							 pd_min, pd_even);
<span class="p_del">-		if (vclk_div &gt; pd_max)</span>
<span class="p_add">+		if (dclk_div &gt; pd_max)</span>
 			break; /* vco is too big, it has to stop */
 
 		/* calc score with current vco freq */
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/si_dpm.c b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">index ee3e74266a13..97a0a639dad9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_chunk">@@ -2984,6 +2984,11 @@</span> <span class="p_context"> static void si_apply_state_adjust_rules(struct radeon_device *rdev,</span>
 		    (rdev-&gt;pdev-&gt;device == 0x6667)) {
 			max_sclk = 75000;
 		}
<span class="p_add">+		if ((rdev-&gt;pdev-&gt;revision == 0xC3) ||</span>
<span class="p_add">+		    (rdev-&gt;pdev-&gt;device == 0x6665)) {</span>
<span class="p_add">+			max_sclk = 60000;</span>
<span class="p_add">+			max_mclk = 80000;</span>
<span class="p_add">+		}</span>
 	} else if (rdev-&gt;family == CHIP_OLAND) {
 		if ((rdev-&gt;pdev-&gt;revision == 0xC7) ||
 		    (rdev-&gt;pdev-&gt;revision == 0x80) ||
<span class="p_header">diff --git a/drivers/gpu/drm/ttm/ttm_bo.c b/drivers/gpu/drm/ttm/ttm_bo.c</span>
<span class="p_header">index c088703777e2..68eed684dff5 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/ttm/ttm_bo.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/ttm/ttm_bo.c</span>
<span class="p_chunk">@@ -175,7 +175,8 @@</span> <span class="p_context"> void ttm_bo_add_to_lru(struct ttm_buffer_object *bo)</span>
 		list_add_tail(&amp;bo-&gt;lru, &amp;man-&gt;lru[bo-&gt;priority]);
 		kref_get(&amp;bo-&gt;list_kref);
 
<span class="p_del">-		if (bo-&gt;ttm &amp;&amp; !(bo-&gt;ttm-&gt;page_flags &amp; TTM_PAGE_FLAG_SG)) {</span>
<span class="p_add">+		if (bo-&gt;ttm &amp;&amp; !(bo-&gt;ttm-&gt;page_flags &amp;</span>
<span class="p_add">+				 (TTM_PAGE_FLAG_SG | TTM_PAGE_FLAG_SWAPPED))) {</span>
 			list_add_tail(&amp;bo-&gt;swap,
 				      &amp;bo-&gt;glob-&gt;swap_lru[bo-&gt;priority]);
 			kref_get(&amp;bo-&gt;list_kref);
<span class="p_header">diff --git a/drivers/gpu/drm/ttm/ttm_bo_vm.c b/drivers/gpu/drm/ttm/ttm_bo_vm.c</span>
<span class="p_header">index c8ebb757e36b..b17d0d38f290 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/ttm/ttm_bo_vm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/ttm/ttm_bo_vm.c</span>
<span class="p_chunk">@@ -299,7 +299,7 @@</span> <span class="p_context"> static void ttm_bo_vm_close(struct vm_area_struct *vma)</span>
 
 static int ttm_bo_vm_access_kmap(struct ttm_buffer_object *bo,
 				 unsigned long offset,
<span class="p_del">-				 void *buf, int len, int write)</span>
<span class="p_add">+				 uint8_t *buf, int len, int write)</span>
 {
 	unsigned long page = offset &gt;&gt; PAGE_SHIFT;
 	unsigned long bytes_left = len;
<span class="p_chunk">@@ -328,6 +328,7 @@</span> <span class="p_context"> static int ttm_bo_vm_access_kmap(struct ttm_buffer_object *bo,</span>
 		ttm_bo_kunmap(&amp;map);
 
 		page++;
<span class="p_add">+		buf += bytes;</span>
 		bytes_left -= bytes;
 		offset = 0;
 	} while (bytes_left);
<span class="p_header">diff --git a/drivers/hwmon/coretemp.c b/drivers/hwmon/coretemp.c</span>
<span class="p_header">index c13a4fd86b3c..a42744c7665b 100644</span>
<span class="p_header">--- a/drivers/hwmon/coretemp.c</span>
<span class="p_header">+++ b/drivers/hwmon/coretemp.c</span>
<span class="p_chunk">@@ -268,13 +268,13 @@</span> <span class="p_context"> static int adjust_tjmax(struct cpuinfo_x86 *c, u32 id, struct device *dev)</span>
 	for (i = 0; i &lt; ARRAY_SIZE(tjmax_model_table); i++) {
 		const struct tjmax_model *tm = &amp;tjmax_model_table[i];
 		if (c-&gt;x86_model == tm-&gt;model &amp;&amp;
<span class="p_del">-		    (tm-&gt;mask == ANY || c-&gt;x86_mask == tm-&gt;mask))</span>
<span class="p_add">+		    (tm-&gt;mask == ANY || c-&gt;x86_stepping == tm-&gt;mask))</span>
 			return tm-&gt;tjmax;
 	}
 
 	/* Early chips have no MSR for TjMax */
 
<span class="p_del">-	if (c-&gt;x86_model == 0xf &amp;&amp; c-&gt;x86_mask &lt; 4)</span>
<span class="p_add">+	if (c-&gt;x86_model == 0xf &amp;&amp; c-&gt;x86_stepping &lt; 4)</span>
 		usemsr_ee = 0;
 
 	if (c-&gt;x86_model &gt; 0xe &amp;&amp; usemsr_ee) {
<span class="p_chunk">@@ -425,7 +425,7 @@</span> <span class="p_context"> static int chk_ucode_version(unsigned int cpu)</span>
 	 * Readings might stop update when processor visited too deep sleep,
 	 * fixed for stepping D0 (6EC).
 	 */
<span class="p_del">-	if (c-&gt;x86_model == 0xe &amp;&amp; c-&gt;x86_mask &lt; 0xc &amp;&amp; c-&gt;microcode &lt; 0x39) {</span>
<span class="p_add">+	if (c-&gt;x86_model == 0xe &amp;&amp; c-&gt;x86_stepping &lt; 0xc &amp;&amp; c-&gt;microcode &lt; 0x39) {</span>
 		pr_err(&quot;Errata AE18 not fixed, update BIOS or microcode of the CPU!\n&quot;);
 		return -ENODEV;
 	}
<span class="p_header">diff --git a/drivers/hwmon/hwmon-vid.c b/drivers/hwmon/hwmon-vid.c</span>
<span class="p_header">index ef91b8a67549..84e91286fc4f 100644</span>
<span class="p_header">--- a/drivers/hwmon/hwmon-vid.c</span>
<span class="p_header">+++ b/drivers/hwmon/hwmon-vid.c</span>
<span class="p_chunk">@@ -293,7 +293,7 @@</span> <span class="p_context"> u8 vid_which_vrm(void)</span>
 	if (c-&gt;x86 &lt; 6)		/* Any CPU with family lower than 6 */
 		return 0;	/* doesn&#39;t have VID */
 
<span class="p_del">-	vrm_ret = find_vrm(c-&gt;x86, c-&gt;x86_model, c-&gt;x86_mask, c-&gt;x86_vendor);</span>
<span class="p_add">+	vrm_ret = find_vrm(c-&gt;x86, c-&gt;x86_model, c-&gt;x86_stepping, c-&gt;x86_vendor);</span>
 	if (vrm_ret == 134)
 		vrm_ret = get_via_model_d_vrm();
 	if (vrm_ret == 0)
<span class="p_header">diff --git a/drivers/hwmon/k10temp.c b/drivers/hwmon/k10temp.c</span>
<span class="p_header">index ce3b91f22e30..5c740996aa62 100644</span>
<span class="p_header">--- a/drivers/hwmon/k10temp.c</span>
<span class="p_header">+++ b/drivers/hwmon/k10temp.c</span>
<span class="p_chunk">@@ -179,7 +179,7 @@</span> <span class="p_context"> static bool has_erratum_319(struct pci_dev *pdev)</span>
 	 * and AM3 formats, but that&#39;s the best we can do.
 	 */
 	return boot_cpu_data.x86_model &lt; 4 ||
<span class="p_del">-	       (boot_cpu_data.x86_model == 4 &amp;&amp; boot_cpu_data.x86_mask &lt;= 2);</span>
<span class="p_add">+	       (boot_cpu_data.x86_model == 4 &amp;&amp; boot_cpu_data.x86_stepping &lt;= 2);</span>
 }
 
 static int k10temp_probe(struct pci_dev *pdev,
<span class="p_header">diff --git a/drivers/hwmon/k8temp.c b/drivers/hwmon/k8temp.c</span>
<span class="p_header">index 5a632bcf869b..e59f9113fb93 100644</span>
<span class="p_header">--- a/drivers/hwmon/k8temp.c</span>
<span class="p_header">+++ b/drivers/hwmon/k8temp.c</span>
<span class="p_chunk">@@ -187,7 +187,7 @@</span> <span class="p_context"> static int k8temp_probe(struct pci_dev *pdev,</span>
 		return -ENOMEM;
 
 	model = boot_cpu_data.x86_model;
<span class="p_del">-	stepping = boot_cpu_data.x86_mask;</span>
<span class="p_add">+	stepping = boot_cpu_data.x86_stepping;</span>
 
 	/* feature available since SH-C0, exclude older revisions */
 	if ((model == 4 &amp;&amp; stepping == 0) ||
<span class="p_header">diff --git a/drivers/infiniband/core/device.c b/drivers/infiniband/core/device.c</span>
<span class="p_header">index 84fc32a2c8b3..ebfdb5503701 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/device.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/device.c</span>
<span class="p_chunk">@@ -446,7 +446,6 @@</span> <span class="p_context"> int ib_register_device(struct ib_device *device,</span>
 	struct ib_udata uhw = {.outlen = 0, .inlen = 0};
 	struct device *parent = device-&gt;dev.parent;
 
<span class="p_del">-	WARN_ON_ONCE(!parent);</span>
 	WARN_ON_ONCE(device-&gt;dma_device);
 	if (device-&gt;dev.dma_ops) {
 		/*
<span class="p_chunk">@@ -455,16 +454,25 @@</span> <span class="p_context"> int ib_register_device(struct ib_device *device,</span>
 		 * into device-&gt;dev.
 		 */
 		device-&gt;dma_device = &amp;device-&gt;dev;
<span class="p_del">-		if (!device-&gt;dev.dma_mask)</span>
<span class="p_del">-			device-&gt;dev.dma_mask = parent-&gt;dma_mask;</span>
<span class="p_del">-		if (!device-&gt;dev.coherent_dma_mask)</span>
<span class="p_del">-			device-&gt;dev.coherent_dma_mask =</span>
<span class="p_del">-				parent-&gt;coherent_dma_mask;</span>
<span class="p_add">+		if (!device-&gt;dev.dma_mask) {</span>
<span class="p_add">+			if (parent)</span>
<span class="p_add">+				device-&gt;dev.dma_mask = parent-&gt;dma_mask;</span>
<span class="p_add">+			else</span>
<span class="p_add">+				WARN_ON_ONCE(true);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (!device-&gt;dev.coherent_dma_mask) {</span>
<span class="p_add">+			if (parent)</span>
<span class="p_add">+				device-&gt;dev.coherent_dma_mask =</span>
<span class="p_add">+					parent-&gt;coherent_dma_mask;</span>
<span class="p_add">+			else</span>
<span class="p_add">+				WARN_ON_ONCE(true);</span>
<span class="p_add">+		}</span>
 	} else {
 		/*
 		 * The caller did not provide custom DMA operations. Use the
 		 * DMA mapping operations of the parent device.
 		 */
<span class="p_add">+		WARN_ON_ONCE(!parent);</span>
 		device-&gt;dma_device = parent;
 	}
 
<span class="p_header">diff --git a/drivers/infiniband/core/sysfs.c b/drivers/infiniband/core/sysfs.c</span>
<span class="p_header">index abc5ab581f82..0a1e96c25ca3 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/sysfs.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/sysfs.c</span>
<span class="p_chunk">@@ -1262,7 +1262,6 @@</span> <span class="p_context"> int ib_device_register_sysfs(struct ib_device *device,</span>
 	int ret;
 	int i;
 
<span class="p_del">-	WARN_ON_ONCE(!device-&gt;dev.parent);</span>
 	ret = dev_set_name(class_dev, &quot;%s&quot;, device-&gt;name);
 	if (ret)
 		return ret;
<span class="p_header">diff --git a/drivers/infiniband/core/user_mad.c b/drivers/infiniband/core/user_mad.c</span>
<span class="p_header">index 603acaf91828..6511cb21f6e2 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/user_mad.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/user_mad.c</span>
<span class="p_chunk">@@ -500,7 +500,7 @@</span> <span class="p_context"> static ssize_t ib_umad_write(struct file *filp, const char __user *buf,</span>
 	}
 
 	memset(&amp;ah_attr, 0, sizeof ah_attr);
<span class="p_del">-	ah_attr.type = rdma_ah_find_type(file-&gt;port-&gt;ib_dev,</span>
<span class="p_add">+	ah_attr.type = rdma_ah_find_type(agent-&gt;device,</span>
 					 file-&gt;port-&gt;port_num);
 	rdma_ah_set_dlid(&amp;ah_attr, be16_to_cpu(packet-&gt;mad.hdr.lid));
 	rdma_ah_set_sl(&amp;ah_attr, packet-&gt;mad.hdr.sl);
<span class="p_header">diff --git a/drivers/infiniband/core/uverbs_std_types.c b/drivers/infiniband/core/uverbs_std_types.c</span>
<span class="p_header">index 0a98579700ec..5f9321eda1b7 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/uverbs_std_types.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/uverbs_std_types.c</span>
<span class="p_chunk">@@ -315,7 +315,7 @@</span> <span class="p_context"> static int uverbs_create_cq_handler(struct ib_device *ib_dev,</span>
 	cq-&gt;uobject       = &amp;obj-&gt;uobject;
 	cq-&gt;comp_handler  = ib_uverbs_comp_handler;
 	cq-&gt;event_handler = ib_uverbs_cq_event_handler;
<span class="p_del">-	cq-&gt;cq_context    = &amp;ev_file-&gt;ev_queue;</span>
<span class="p_add">+	cq-&gt;cq_context    = ev_file ? &amp;ev_file-&gt;ev_queue : NULL;</span>
 	obj-&gt;uobject.object = cq;
 	obj-&gt;uobject.user_handle = user_handle;
 	atomic_set(&amp;cq-&gt;usecnt, 0);
<span class="p_header">diff --git a/drivers/infiniband/hw/mlx4/main.c b/drivers/infiniband/hw/mlx4/main.c</span>
<span class="p_header">index c636842c5be0..8c681a36e6c7 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/mlx4/main.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/mlx4/main.c</span>
<span class="p_chunk">@@ -2972,9 +2972,8 @@</span> <span class="p_context"> static void *mlx4_ib_add(struct mlx4_dev *dev)</span>
 	kfree(ibdev-&gt;ib_uc_qpns_bitmap);
 
 err_steer_qp_release:
<span class="p_del">-	if (ibdev-&gt;steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED)</span>
<span class="p_del">-		mlx4_qp_release_range(dev, ibdev-&gt;steer_qpn_base,</span>
<span class="p_del">-				      ibdev-&gt;steer_qpn_count);</span>
<span class="p_add">+	mlx4_qp_release_range(dev, ibdev-&gt;steer_qpn_base,</span>
<span class="p_add">+			      ibdev-&gt;steer_qpn_count);</span>
 err_counter:
 	for (i = 0; i &lt; ibdev-&gt;num_ports; ++i)
 		mlx4_ib_delete_counters_table(ibdev, &amp;ibdev-&gt;counters_table[i]);
<span class="p_chunk">@@ -3079,11 +3078,9 @@</span> <span class="p_context"> static void mlx4_ib_remove(struct mlx4_dev *dev, void *ibdev_ptr)</span>
 		ibdev-&gt;iboe.nb.notifier_call = NULL;
 	}
 
<span class="p_del">-	if (ibdev-&gt;steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED) {</span>
<span class="p_del">-		mlx4_qp_release_range(dev, ibdev-&gt;steer_qpn_base,</span>
<span class="p_del">-				      ibdev-&gt;steer_qpn_count);</span>
<span class="p_del">-		kfree(ibdev-&gt;ib_uc_qpns_bitmap);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	mlx4_qp_release_range(dev, ibdev-&gt;steer_qpn_base,</span>
<span class="p_add">+			      ibdev-&gt;steer_qpn_count);</span>
<span class="p_add">+	kfree(ibdev-&gt;ib_uc_qpns_bitmap);</span>
 
 	iounmap(ibdev-&gt;uar_map);
 	for (p = 0; p &lt; ibdev-&gt;num_ports; ++p)
<span class="p_header">diff --git a/drivers/infiniband/hw/qib/qib_rc.c b/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_header">index e9a91736b12d..d80b61a71eb8 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_chunk">@@ -434,13 +434,13 @@</span> <span class="p_context"> int qib_make_rc_req(struct rvt_qp *qp, unsigned long *flags)</span>
 				qp-&gt;s_state = OP(COMPARE_SWAP);
 				put_ib_ateth_swap(wqe-&gt;atomic_wr.swap,
 						  &amp;ohdr-&gt;u.atomic_eth);
<span class="p_del">-				put_ib_ateth_swap(wqe-&gt;atomic_wr.compare_add,</span>
<span class="p_del">-						  &amp;ohdr-&gt;u.atomic_eth);</span>
<span class="p_add">+				put_ib_ateth_compare(wqe-&gt;atomic_wr.compare_add,</span>
<span class="p_add">+						     &amp;ohdr-&gt;u.atomic_eth);</span>
 			} else {
 				qp-&gt;s_state = OP(FETCH_ADD);
 				put_ib_ateth_swap(wqe-&gt;atomic_wr.compare_add,
 						  &amp;ohdr-&gt;u.atomic_eth);
<span class="p_del">-				put_ib_ateth_swap(0, &amp;ohdr-&gt;u.atomic_eth);</span>
<span class="p_add">+				put_ib_ateth_compare(0, &amp;ohdr-&gt;u.atomic_eth);</span>
 			}
 			put_ib_ateth_vaddr(wqe-&gt;atomic_wr.remote_addr,
 					   &amp;ohdr-&gt;u.atomic_eth);
<span class="p_header">diff --git a/drivers/infiniband/sw/rxe/rxe_loc.h b/drivers/infiniband/sw/rxe/rxe_loc.h</span>
<span class="p_header">index 77b3ed0df936..7f945f65d8cd 100644</span>
<span class="p_header">--- a/drivers/infiniband/sw/rxe/rxe_loc.h</span>
<span class="p_header">+++ b/drivers/infiniband/sw/rxe/rxe_loc.h</span>
<span class="p_chunk">@@ -237,7 +237,6 @@</span> <span class="p_context"> int rxe_srq_from_attr(struct rxe_dev *rxe, struct rxe_srq *srq,</span>
 
 void rxe_release(struct kref *kref);
 
<span class="p_del">-void rxe_drain_req_pkts(struct rxe_qp *qp, bool notify);</span>
 int rxe_completer(void *arg);
 int rxe_requester(void *arg);
 int rxe_responder(void *arg);
<span class="p_header">diff --git a/drivers/infiniband/sw/rxe/rxe_qp.c b/drivers/infiniband/sw/rxe/rxe_qp.c</span>
<span class="p_header">index 00bda9380a2e..aeea994b04c4 100644</span>
<span class="p_header">--- a/drivers/infiniband/sw/rxe/rxe_qp.c</span>
<span class="p_header">+++ b/drivers/infiniband/sw/rxe/rxe_qp.c</span>
<span class="p_chunk">@@ -824,9 +824,9 @@</span> <span class="p_context"> void rxe_qp_destroy(struct rxe_qp *qp)</span>
 }
 
 /* called when the last reference to the qp is dropped */
<span class="p_del">-void rxe_qp_cleanup(struct rxe_pool_entry *arg)</span>
<span class="p_add">+static void rxe_qp_do_cleanup(struct work_struct *work)</span>
 {
<span class="p_del">-	struct rxe_qp *qp = container_of(arg, typeof(*qp), pelem);</span>
<span class="p_add">+	struct rxe_qp *qp = container_of(work, typeof(*qp), cleanup_work.work);</span>
 
 	rxe_drop_all_mcast_groups(qp);
 
<span class="p_chunk">@@ -859,3 +859,11 @@</span> <span class="p_context"> void rxe_qp_cleanup(struct rxe_pool_entry *arg)</span>
 	kernel_sock_shutdown(qp-&gt;sk, SHUT_RDWR);
 	sock_release(qp-&gt;sk);
 }
<span class="p_add">+</span>
<span class="p_add">+/* called when the last reference to the qp is dropped */</span>
<span class="p_add">+void rxe_qp_cleanup(struct rxe_pool_entry *arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rxe_qp *qp = container_of(arg, typeof(*qp), pelem);</span>
<span class="p_add">+</span>
<span class="p_add">+	execute_in_process_context(rxe_qp_do_cleanup, &amp;qp-&gt;cleanup_work);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/infiniband/sw/rxe/rxe_req.c b/drivers/infiniband/sw/rxe/rxe_req.c</span>
<span class="p_header">index d84222f9d5d2..44b838ec9420 100644</span>
<span class="p_header">--- a/drivers/infiniband/sw/rxe/rxe_req.c</span>
<span class="p_header">+++ b/drivers/infiniband/sw/rxe/rxe_req.c</span>
<span class="p_chunk">@@ -594,15 +594,8 @@</span> <span class="p_context"> int rxe_requester(void *arg)</span>
 	rxe_add_ref(qp);
 
 next_wqe:
<span class="p_del">-	if (unlikely(!qp-&gt;valid)) {</span>
<span class="p_del">-		rxe_drain_req_pkts(qp, true);</span>
<span class="p_add">+	if (unlikely(!qp-&gt;valid || qp-&gt;req.state == QP_STATE_ERROR))</span>
 		goto exit;
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(qp-&gt;req.state == QP_STATE_ERROR)) {</span>
<span class="p_del">-		rxe_drain_req_pkts(qp, true);</span>
<span class="p_del">-		goto exit;</span>
<span class="p_del">-	}</span>
 
 	if (unlikely(qp-&gt;req.state == QP_STATE_RESET)) {
 		qp-&gt;req.wqe_index = consumer_index(qp-&gt;sq.queue);
<span class="p_header">diff --git a/drivers/infiniband/sw/rxe/rxe_resp.c b/drivers/infiniband/sw/rxe/rxe_resp.c</span>
<span class="p_header">index 4240866a5331..01f926fd9029 100644</span>
<span class="p_header">--- a/drivers/infiniband/sw/rxe/rxe_resp.c</span>
<span class="p_header">+++ b/drivers/infiniband/sw/rxe/rxe_resp.c</span>
<span class="p_chunk">@@ -1210,7 +1210,7 @@</span> <span class="p_context"> static enum resp_states do_class_d1e_error(struct rxe_qp *qp)</span>
 	}
 }
 
<span class="p_del">-void rxe_drain_req_pkts(struct rxe_qp *qp, bool notify)</span>
<span class="p_add">+static void rxe_drain_req_pkts(struct rxe_qp *qp, bool notify)</span>
 {
 	struct sk_buff *skb;
 
<span class="p_header">diff --git a/drivers/infiniband/sw/rxe/rxe_verbs.c b/drivers/infiniband/sw/rxe/rxe_verbs.c</span>
<span class="p_header">index 0b362f49a10a..afbf701dc9a7 100644</span>
<span class="p_header">--- a/drivers/infiniband/sw/rxe/rxe_verbs.c</span>
<span class="p_header">+++ b/drivers/infiniband/sw/rxe/rxe_verbs.c</span>
<span class="p_chunk">@@ -813,6 +813,8 @@</span> <span class="p_context"> static int rxe_post_send_kernel(struct rxe_qp *qp, struct ib_send_wr *wr,</span>
 			(queue_count(qp-&gt;sq.queue) &gt; 1);
 
 	rxe_run_task(&amp;qp-&gt;req.task, must_sched);
<span class="p_add">+	if (unlikely(qp-&gt;req.state == QP_STATE_ERROR))</span>
<span class="p_add">+		rxe_run_task(&amp;qp-&gt;comp.task, 1);</span>
 
 	return err;
 }
<span class="p_header">diff --git a/drivers/infiniband/sw/rxe/rxe_verbs.h b/drivers/infiniband/sw/rxe/rxe_verbs.h</span>
<span class="p_header">index 0c2dbe45c729..1019f5e7dbdd 100644</span>
<span class="p_header">--- a/drivers/infiniband/sw/rxe/rxe_verbs.h</span>
<span class="p_header">+++ b/drivers/infiniband/sw/rxe/rxe_verbs.h</span>
<span class="p_chunk">@@ -35,6 +35,7 @@</span> <span class="p_context"></span>
 #define RXE_VERBS_H
 
 #include &lt;linux/interrupt.h&gt;
<span class="p_add">+#include &lt;linux/workqueue.h&gt;</span>
 #include &lt;rdma/rdma_user_rxe.h&gt;
 #include &quot;rxe_pool.h&quot;
 #include &quot;rxe_task.h&quot;
<span class="p_chunk">@@ -281,6 +282,8 @@</span> <span class="p_context"> struct rxe_qp {</span>
 	struct timer_list rnr_nak_timer;
 
 	spinlock_t		state_lock; /* guard requester and completer */
<span class="p_add">+</span>
<span class="p_add">+	struct execute_work	cleanup_work;</span>
 };
 
 enum rxe_mem_state {
<span class="p_header">diff --git a/drivers/md/dm.c b/drivers/md/dm.c</span>
<span class="p_header">index 804419635cc7..1dfc855ac708 100644</span>
<span class="p_header">--- a/drivers/md/dm.c</span>
<span class="p_header">+++ b/drivers/md/dm.c</span>
<span class="p_chunk">@@ -815,7 +815,8 @@</span> <span class="p_context"> static void dec_pending(struct dm_io *io, blk_status_t error)</span>
 			queue_io(md, bio);
 		} else {
 			/* done with normal IO or empty flush */
<span class="p_del">-			bio-&gt;bi_status = io_error;</span>
<span class="p_add">+			if (io_error)</span>
<span class="p_add">+				bio-&gt;bi_status = io_error;</span>
 			bio_endio(bio);
 		}
 	}
<span class="p_header">diff --git a/drivers/media/tuners/r820t.c b/drivers/media/tuners/r820t.c</span>
<span class="p_header">index ba80376a3b86..d097eb04a0e9 100644</span>
<span class="p_header">--- a/drivers/media/tuners/r820t.c</span>
<span class="p_header">+++ b/drivers/media/tuners/r820t.c</span>
<span class="p_chunk">@@ -396,9 +396,11 @@</span> <span class="p_context"> static int r820t_write(struct r820t_priv *priv, u8 reg, const u8 *val,</span>
 	return 0;
 }
 
<span class="p_del">-static int r820t_write_reg(struct r820t_priv *priv, u8 reg, u8 val)</span>
<span class="p_add">+static inline int r820t_write_reg(struct r820t_priv *priv, u8 reg, u8 val)</span>
 {
<span class="p_del">-	return r820t_write(priv, reg, &amp;val, 1);</span>
<span class="p_add">+	u8 tmp = val; /* work around GCC PR81715 with asan-stack=1 */</span>
<span class="p_add">+</span>
<span class="p_add">+	return r820t_write(priv, reg, &amp;tmp, 1);</span>
 }
 
 static int r820t_read_cache_reg(struct r820t_priv *priv, int reg)
<span class="p_chunk">@@ -411,17 +413,18 @@</span> <span class="p_context"> static int r820t_read_cache_reg(struct r820t_priv *priv, int reg)</span>
 		return -EINVAL;
 }
 
<span class="p_del">-static int r820t_write_reg_mask(struct r820t_priv *priv, u8 reg, u8 val,</span>
<span class="p_add">+static inline int r820t_write_reg_mask(struct r820t_priv *priv, u8 reg, u8 val,</span>
 				u8 bit_mask)
 {
<span class="p_add">+	u8 tmp = val;</span>
 	int rc = r820t_read_cache_reg(priv, reg);
 
 	if (rc &lt; 0)
 		return rc;
 
<span class="p_del">-	val = (rc &amp; ~bit_mask) | (val &amp; bit_mask);</span>
<span class="p_add">+	tmp = (rc &amp; ~bit_mask) | (tmp &amp; bit_mask);</span>
 
<span class="p_del">-	return r820t_write(priv, reg, &amp;val, 1);</span>
<span class="p_add">+	return r820t_write(priv, reg, &amp;tmp, 1);</span>
 }
 
 static int r820t_read(struct r820t_priv *priv, u8 reg, u8 *val, int len)
<span class="p_header">diff --git a/drivers/misc/c2port/core.c b/drivers/misc/c2port/core.c</span>
<span class="p_header">index 1922cb8f6b88..1c5b7aec13d4 100644</span>
<span class="p_header">--- a/drivers/misc/c2port/core.c</span>
<span class="p_header">+++ b/drivers/misc/c2port/core.c</span>
<span class="p_chunk">@@ -15,7 +15,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/errno.h&gt;
 #include &lt;linux/err.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/ctype.h&gt;
 #include &lt;linux/delay.h&gt;
 #include &lt;linux/idr.h&gt;
<span class="p_chunk">@@ -904,7 +903,6 @@</span> <span class="p_context"> struct c2port_device *c2port_device_register(char *name,</span>
 		return ERR_PTR(-EINVAL);
 
 	c2dev = kmalloc(sizeof(struct c2port_device), GFP_KERNEL);
<span class="p_del">-	kmemcheck_annotate_bitfield(c2dev, flags);</span>
 	if (unlikely(!c2dev))
 		return ERR_PTR(-ENOMEM);
 
<span class="p_header">diff --git a/drivers/mmc/host/bcm2835.c b/drivers/mmc/host/bcm2835.c</span>
<span class="p_header">index 229dc18f0581..768972af8b85 100644</span>
<span class="p_header">--- a/drivers/mmc/host/bcm2835.c</span>
<span class="p_header">+++ b/drivers/mmc/host/bcm2835.c</span>
<span class="p_chunk">@@ -1265,7 +1265,8 @@</span> <span class="p_context"> static int bcm2835_add_host(struct bcm2835_host *host)</span>
 	char pio_limit_string[20];
 	int ret;
 
<span class="p_del">-	mmc-&gt;f_max = host-&gt;max_clk;</span>
<span class="p_add">+	if (!mmc-&gt;f_max || mmc-&gt;f_max &gt; host-&gt;max_clk)</span>
<span class="p_add">+		mmc-&gt;f_max = host-&gt;max_clk;</span>
 	mmc-&gt;f_min = host-&gt;max_clk / SDCDIV_MAX_CDIV;
 
 	mmc-&gt;max_busy_timeout = ~0 / (mmc-&gt;f_max / 1000);
<span class="p_header">diff --git a/drivers/mmc/host/meson-gx-mmc.c b/drivers/mmc/host/meson-gx-mmc.c</span>
<span class="p_header">index 85745ef179e2..08a55c2e96e1 100644</span>
<span class="p_header">--- a/drivers/mmc/host/meson-gx-mmc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/meson-gx-mmc.c</span>
<span class="p_chunk">@@ -716,22 +716,6 @@</span> <span class="p_context"> static int meson_mmc_clk_phase_tuning(struct mmc_host *mmc, u32 opcode,</span>
 static int meson_mmc_execute_tuning(struct mmc_host *mmc, u32 opcode)
 {
 	struct meson_host *host = mmc_priv(mmc);
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If this is the initial tuning, try to get a sane Rx starting</span>
<span class="p_del">-	 * phase before doing the actual tuning.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!mmc-&gt;doing_retune) {</span>
<span class="p_del">-		ret = meson_mmc_clk_phase_tuning(mmc, opcode, host-&gt;rx_clk);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			return ret;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = meson_mmc_clk_phase_tuning(mmc, opcode, host-&gt;tx_clk);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
 
 	return meson_mmc_clk_phase_tuning(mmc, opcode, host-&gt;rx_clk);
 }
<span class="p_chunk">@@ -762,9 +746,8 @@</span> <span class="p_context"> static void meson_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)</span>
 		if (!IS_ERR(mmc-&gt;supply.vmmc))
 			mmc_regulator_set_ocr(mmc, mmc-&gt;supply.vmmc, ios-&gt;vdd);
 
<span class="p_del">-		/* Reset phases */</span>
<span class="p_add">+		/* Reset rx phase */</span>
 		clk_set_phase(host-&gt;rx_clk, 0);
<span class="p_del">-		clk_set_phase(host-&gt;tx_clk, 270);</span>
 
 		break;
 
<span class="p_header">diff --git a/drivers/mmc/host/sdhci-of-esdhc.c b/drivers/mmc/host/sdhci-of-esdhc.c</span>
<span class="p_header">index d96a057a7db8..4ffa6b173a21 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci-of-esdhc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci-of-esdhc.c</span>
<span class="p_chunk">@@ -458,6 +458,33 @@</span> <span class="p_context"> static unsigned int esdhc_of_get_min_clock(struct sdhci_host *host)</span>
 	return clock / 256 / 16;
 }
 
<span class="p_add">+static void esdhc_clock_enable(struct sdhci_host *host, bool enable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 val;</span>
<span class="p_add">+	ktime_t timeout;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = sdhci_readl(host, ESDHC_SYSTEM_CONTROL);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (enable)</span>
<span class="p_add">+		val |= ESDHC_CLOCK_SDCLKEN;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		val &amp;= ~ESDHC_CLOCK_SDCLKEN;</span>
<span class="p_add">+</span>
<span class="p_add">+	sdhci_writel(host, val, ESDHC_SYSTEM_CONTROL);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Wait max 20 ms */</span>
<span class="p_add">+	timeout = ktime_add_ms(ktime_get(), 20);</span>
<span class="p_add">+	val = ESDHC_CLOCK_STABLE;</span>
<span class="p_add">+	while (!(sdhci_readl(host, ESDHC_PRSSTAT) &amp; val)) {</span>
<span class="p_add">+		if (ktime_after(ktime_get(), timeout)) {</span>
<span class="p_add">+			pr_err(&quot;%s: Internal clock never stabilised.\n&quot;,</span>
<span class="p_add">+				mmc_hostname(host-&gt;mmc));</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		udelay(10);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void esdhc_of_set_clock(struct sdhci_host *host, unsigned int clock)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
<span class="p_chunk">@@ -469,8 +496,10 @@</span> <span class="p_context"> static void esdhc_of_set_clock(struct sdhci_host *host, unsigned int clock)</span>
 
 	host-&gt;mmc-&gt;actual_clock = 0;
 
<span class="p_del">-	if (clock == 0)</span>
<span class="p_add">+	if (clock == 0) {</span>
<span class="p_add">+		esdhc_clock_enable(host, false);</span>
 		return;
<span class="p_add">+	}</span>
 
 	/* Workaround to start pre_div at 2 for VNN &lt; VENDOR_V_23 */
 	if (esdhc-&gt;vendor_ver &lt; VENDOR_V_23)
<span class="p_chunk">@@ -558,39 +587,20 @@</span> <span class="p_context"> static void esdhc_pltfm_set_bus_width(struct sdhci_host *host, int width)</span>
 	sdhci_writel(host, ctrl, ESDHC_PROCTL);
 }
 
<span class="p_del">-static void esdhc_clock_enable(struct sdhci_host *host, bool enable)</span>
<span class="p_add">+static void esdhc_reset(struct sdhci_host *host, u8 mask)</span>
 {
 	u32 val;
<span class="p_del">-	ktime_t timeout;</span>
<span class="p_del">-</span>
<span class="p_del">-	val = sdhci_readl(host, ESDHC_SYSTEM_CONTROL);</span>
 
<span class="p_del">-	if (enable)</span>
<span class="p_del">-		val |= ESDHC_CLOCK_SDCLKEN;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		val &amp;= ~ESDHC_CLOCK_SDCLKEN;</span>
<span class="p_del">-</span>
<span class="p_del">-	sdhci_writel(host, val, ESDHC_SYSTEM_CONTROL);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Wait max 20 ms */</span>
<span class="p_del">-	timeout = ktime_add_ms(ktime_get(), 20);</span>
<span class="p_del">-	val = ESDHC_CLOCK_STABLE;</span>
<span class="p_del">-	while (!(sdhci_readl(host, ESDHC_PRSSTAT) &amp; val)) {</span>
<span class="p_del">-		if (ktime_after(ktime_get(), timeout)) {</span>
<span class="p_del">-			pr_err(&quot;%s: Internal clock never stabilised.\n&quot;,</span>
<span class="p_del">-				mmc_hostname(host-&gt;mmc));</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		udelay(10);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void esdhc_reset(struct sdhci_host *host, u8 mask)</span>
<span class="p_del">-{</span>
 	sdhci_reset(host, mask);
 
 	sdhci_writel(host, host-&gt;ier, SDHCI_INT_ENABLE);
 	sdhci_writel(host, host-&gt;ier, SDHCI_SIGNAL_ENABLE);
<span class="p_add">+</span>
<span class="p_add">+	if (mask &amp; SDHCI_RESET_ALL) {</span>
<span class="p_add">+		val = sdhci_readl(host, ESDHC_TBCTL);</span>
<span class="p_add">+		val &amp;= ~ESDHC_TB_EN;</span>
<span class="p_add">+		sdhci_writel(host, val, ESDHC_TBCTL);</span>
<span class="p_add">+	}</span>
 }
 
 /* The SCFG, Supplemental Configuration Unit, provides SoC specific
<span class="p_header">diff --git a/drivers/mmc/host/sdhci.c b/drivers/mmc/host/sdhci.c</span>
<span class="p_header">index 6152e83ff935..90cc1977b792 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci.c</span>
<span class="p_chunk">@@ -21,6 +21,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/dma-mapping.h&gt;
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_add">+#include &lt;linux/sizes.h&gt;</span>
 #include &lt;linux/swiotlb.h&gt;
 #include &lt;linux/regulator/consumer.h&gt;
 #include &lt;linux/pm_runtime.h&gt;
<span class="p_chunk">@@ -502,8 +503,35 @@</span> <span class="p_context"> static int sdhci_pre_dma_transfer(struct sdhci_host *host,</span>
 	if (data-&gt;host_cookie == COOKIE_PRE_MAPPED)
 		return data-&gt;sg_count;
 
<span class="p_del">-	sg_count = dma_map_sg(mmc_dev(host-&gt;mmc), data-&gt;sg, data-&gt;sg_len,</span>
<span class="p_del">-			      mmc_get_dma_dir(data));</span>
<span class="p_add">+	/* Bounce write requests to the bounce buffer */</span>
<span class="p_add">+	if (host-&gt;bounce_buffer) {</span>
<span class="p_add">+		unsigned int length = data-&gt;blksz * data-&gt;blocks;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (length &gt; host-&gt;bounce_buffer_size) {</span>
<span class="p_add">+			pr_err(&quot;%s: asked for transfer of %u bytes exceeds bounce buffer %u bytes\n&quot;,</span>
<span class="p_add">+			       mmc_hostname(host-&gt;mmc), length,</span>
<span class="p_add">+			       host-&gt;bounce_buffer_size);</span>
<span class="p_add">+			return -EIO;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (mmc_get_dma_dir(data) == DMA_TO_DEVICE) {</span>
<span class="p_add">+			/* Copy the data to the bounce buffer */</span>
<span class="p_add">+			sg_copy_to_buffer(data-&gt;sg, data-&gt;sg_len,</span>
<span class="p_add">+					  host-&gt;bounce_buffer,</span>
<span class="p_add">+					  length);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		/* Switch ownership to the DMA */</span>
<span class="p_add">+		dma_sync_single_for_device(host-&gt;mmc-&gt;parent,</span>
<span class="p_add">+					   host-&gt;bounce_addr,</span>
<span class="p_add">+					   host-&gt;bounce_buffer_size,</span>
<span class="p_add">+					   mmc_get_dma_dir(data));</span>
<span class="p_add">+		/* Just a dummy value */</span>
<span class="p_add">+		sg_count = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* Just access the data directly from memory */</span>
<span class="p_add">+		sg_count = dma_map_sg(mmc_dev(host-&gt;mmc),</span>
<span class="p_add">+				      data-&gt;sg, data-&gt;sg_len,</span>
<span class="p_add">+				      mmc_get_dma_dir(data));</span>
<span class="p_add">+	}</span>
 
 	if (sg_count == 0)
 		return -ENOSPC;
<span class="p_chunk">@@ -673,6 +701,14 @@</span> <span class="p_context"> static void sdhci_adma_table_post(struct sdhci_host *host,</span>
 	}
 }
 
<span class="p_add">+static u32 sdhci_sdma_address(struct sdhci_host *host)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (host-&gt;bounce_buffer)</span>
<span class="p_add">+		return host-&gt;bounce_addr;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return sg_dma_address(host-&gt;data-&gt;sg);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static u8 sdhci_calc_timeout(struct sdhci_host *host, struct mmc_command *cmd)
 {
 	u8 count;
<span class="p_chunk">@@ -858,8 +894,8 @@</span> <span class="p_context"> static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)</span>
 					     SDHCI_ADMA_ADDRESS_HI);
 		} else {
 			WARN_ON(sg_cnt != 1);
<span class="p_del">-			sdhci_writel(host, sg_dma_address(data-&gt;sg),</span>
<span class="p_del">-				SDHCI_DMA_ADDRESS);</span>
<span class="p_add">+			sdhci_writel(host, sdhci_sdma_address(host),</span>
<span class="p_add">+				     SDHCI_DMA_ADDRESS);</span>
 		}
 	}
 
<span class="p_chunk">@@ -2248,7 +2284,12 @@</span> <span class="p_context"> static void sdhci_pre_req(struct mmc_host *mmc, struct mmc_request *mrq)</span>
 
 	mrq-&gt;data-&gt;host_cookie = COOKIE_UNMAPPED;
 
<span class="p_del">-	if (host-&gt;flags &amp; SDHCI_REQ_USE_DMA)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * No pre-mapping in the pre hook if we&#39;re using the bounce buffer,</span>
<span class="p_add">+	 * for that we would need two bounce buffers since one buffer is</span>
<span class="p_add">+	 * in flight when this is getting called.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (host-&gt;flags &amp; SDHCI_REQ_USE_DMA &amp;&amp; !host-&gt;bounce_buffer)</span>
 		sdhci_pre_dma_transfer(host, mrq-&gt;data, COOKIE_PRE_MAPPED);
 }
 
<span class="p_chunk">@@ -2352,8 +2393,45 @@</span> <span class="p_context"> static bool sdhci_request_done(struct sdhci_host *host)</span>
 		struct mmc_data *data = mrq-&gt;data;
 
 		if (data &amp;&amp; data-&gt;host_cookie == COOKIE_MAPPED) {
<span class="p_del">-			dma_unmap_sg(mmc_dev(host-&gt;mmc), data-&gt;sg, data-&gt;sg_len,</span>
<span class="p_del">-				     mmc_get_dma_dir(data));</span>
<span class="p_add">+			if (host-&gt;bounce_buffer) {</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * On reads, copy the bounced data into the</span>
<span class="p_add">+				 * sglist</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (mmc_get_dma_dir(data) == DMA_FROM_DEVICE) {</span>
<span class="p_add">+					unsigned int length = data-&gt;bytes_xfered;</span>
<span class="p_add">+</span>
<span class="p_add">+					if (length &gt; host-&gt;bounce_buffer_size) {</span>
<span class="p_add">+						pr_err(&quot;%s: bounce buffer is %u bytes but DMA claims to have transferred %u bytes\n&quot;,</span>
<span class="p_add">+						       mmc_hostname(host-&gt;mmc),</span>
<span class="p_add">+						       host-&gt;bounce_buffer_size,</span>
<span class="p_add">+						       data-&gt;bytes_xfered);</span>
<span class="p_add">+						/* Cap it down and continue */</span>
<span class="p_add">+						length = host-&gt;bounce_buffer_size;</span>
<span class="p_add">+					}</span>
<span class="p_add">+					dma_sync_single_for_cpu(</span>
<span class="p_add">+						host-&gt;mmc-&gt;parent,</span>
<span class="p_add">+						host-&gt;bounce_addr,</span>
<span class="p_add">+						host-&gt;bounce_buffer_size,</span>
<span class="p_add">+						DMA_FROM_DEVICE);</span>
<span class="p_add">+					sg_copy_from_buffer(data-&gt;sg,</span>
<span class="p_add">+						data-&gt;sg_len,</span>
<span class="p_add">+						host-&gt;bounce_buffer,</span>
<span class="p_add">+						length);</span>
<span class="p_add">+				} else {</span>
<span class="p_add">+					/* No copying, just switch ownership */</span>
<span class="p_add">+					dma_sync_single_for_cpu(</span>
<span class="p_add">+						host-&gt;mmc-&gt;parent,</span>
<span class="p_add">+						host-&gt;bounce_addr,</span>
<span class="p_add">+						host-&gt;bounce_buffer_size,</span>
<span class="p_add">+						mmc_get_dma_dir(data));</span>
<span class="p_add">+				}</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				/* Unmap the raw data */</span>
<span class="p_add">+				dma_unmap_sg(mmc_dev(host-&gt;mmc), data-&gt;sg,</span>
<span class="p_add">+					     data-&gt;sg_len,</span>
<span class="p_add">+					     mmc_get_dma_dir(data));</span>
<span class="p_add">+			}</span>
 			data-&gt;host_cookie = COOKIE_UNMAPPED;
 		}
 	}
<span class="p_chunk">@@ -2636,7 +2714,8 @@</span> <span class="p_context"> static void sdhci_data_irq(struct sdhci_host *host, u32 intmask)</span>
 		 */
 		if (intmask &amp; SDHCI_INT_DMA_END) {
 			u32 dmastart, dmanow;
<span class="p_del">-			dmastart = sg_dma_address(host-&gt;data-&gt;sg);</span>
<span class="p_add">+</span>
<span class="p_add">+			dmastart = sdhci_sdma_address(host);</span>
 			dmanow = dmastart + host-&gt;data-&gt;bytes_xfered;
 			/*
 			 * Force update to the next DMA block boundary.
<span class="p_chunk">@@ -3217,6 +3296,68 @@</span> <span class="p_context"> void __sdhci_read_caps(struct sdhci_host *host, u16 *ver, u32 *caps, u32 *caps1)</span>
 }
 EXPORT_SYMBOL_GPL(__sdhci_read_caps);
 
<span class="p_add">+static int sdhci_allocate_bounce_buffer(struct sdhci_host *host)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mmc_host *mmc = host-&gt;mmc;</span>
<span class="p_add">+	unsigned int max_blocks;</span>
<span class="p_add">+	unsigned int bounce_size;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Cap the bounce buffer at 64KB. Using a bigger bounce buffer</span>
<span class="p_add">+	 * has diminishing returns, this is probably because SD/MMC</span>
<span class="p_add">+	 * cards are usually optimized to handle this size of requests.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	bounce_size = SZ_64K;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Adjust downwards to maximum request size if this is less</span>
<span class="p_add">+	 * than our segment size, else hammer down the maximum</span>
<span class="p_add">+	 * request size to the maximum buffer size.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (mmc-&gt;max_req_size &lt; bounce_size)</span>
<span class="p_add">+		bounce_size = mmc-&gt;max_req_size;</span>
<span class="p_add">+	max_blocks = bounce_size / 512;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When we just support one segment, we can get significant</span>
<span class="p_add">+	 * speedups by the help of a bounce buffer to group scattered</span>
<span class="p_add">+	 * reads/writes together.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	host-&gt;bounce_buffer = devm_kmalloc(mmc-&gt;parent,</span>
<span class="p_add">+					   bounce_size,</span>
<span class="p_add">+					   GFP_KERNEL);</span>
<span class="p_add">+	if (!host-&gt;bounce_buffer) {</span>
<span class="p_add">+		pr_err(&quot;%s: failed to allocate %u bytes for bounce buffer, falling back to single segments\n&quot;,</span>
<span class="p_add">+		       mmc_hostname(mmc),</span>
<span class="p_add">+		       bounce_size);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Exiting with zero here makes sure we proceed with</span>
<span class="p_add">+		 * mmc-&gt;max_segs == 1.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	host-&gt;bounce_addr = dma_map_single(mmc-&gt;parent,</span>
<span class="p_add">+					   host-&gt;bounce_buffer,</span>
<span class="p_add">+					   bounce_size,</span>
<span class="p_add">+					   DMA_BIDIRECTIONAL);</span>
<span class="p_add">+	ret = dma_mapping_error(mmc-&gt;parent, host-&gt;bounce_addr);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		/* Again fall back to max_segs == 1 */</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	host-&gt;bounce_buffer_size = bounce_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Lie about this since we&#39;re bouncing */</span>
<span class="p_add">+	mmc-&gt;max_segs = max_blocks;</span>
<span class="p_add">+	mmc-&gt;max_seg_size = bounce_size;</span>
<span class="p_add">+	mmc-&gt;max_req_size = bounce_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;%s bounce up to %u segments into one, max segment size %u bytes\n&quot;,</span>
<span class="p_add">+		mmc_hostname(mmc), max_blocks, bounce_size);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int sdhci_setup_host(struct sdhci_host *host)
 {
 	struct mmc_host *mmc;
<span class="p_chunk">@@ -3713,6 +3854,13 @@</span> <span class="p_context"> int sdhci_setup_host(struct sdhci_host *host)</span>
 	 */
 	mmc-&gt;max_blk_count = (host-&gt;quirks &amp; SDHCI_QUIRK_NO_MULTIBLOCK) ? 1 : 65535;
 
<span class="p_add">+	if (mmc-&gt;max_segs == 1) {</span>
<span class="p_add">+		/* This may alter mmc-&gt;*_blk_* parameters */</span>
<span class="p_add">+		ret = sdhci_allocate_bounce_buffer(host);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return 0;
 
 unreg:
<span class="p_header">diff --git a/drivers/mmc/host/sdhci.h b/drivers/mmc/host/sdhci.h</span>
<span class="p_header">index 54bc444c317f..1d7d61e25dbf 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci.h</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci.h</span>
<span class="p_chunk">@@ -440,6 +440,9 @@</span> <span class="p_context"> struct sdhci_host {</span>
 
 	int irq;		/* Device IRQ */
 	void __iomem *ioaddr;	/* Mapped address */
<span class="p_add">+	char *bounce_buffer;	/* For packing SDMA reads/writes */</span>
<span class="p_add">+	dma_addr_t bounce_addr;</span>
<span class="p_add">+	unsigned int bounce_buffer_size;</span>
 
 	const struct sdhci_ops *ops;	/* Low level hw interface */
 
<span class="p_header">diff --git a/drivers/mtd/nand/vf610_nfc.c b/drivers/mtd/nand/vf610_nfc.c</span>
<span class="p_header">index 8037d4b48a05..e2583a539b41 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/vf610_nfc.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/vf610_nfc.c</span>
<span class="p_chunk">@@ -752,10 +752,8 @@</span> <span class="p_context"> static int vf610_nfc_probe(struct platform_device *pdev)</span>
 		if (mtd-&gt;oobsize &gt; 64)
 			mtd-&gt;oobsize = 64;
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * mtd-&gt;ecclayout is not specified here because we&#39;re using the</span>
<span class="p_del">-		 * default large page ECC layout defined in NAND core.</span>
<span class="p_del">-		 */</span>
<span class="p_add">+		/* Use default large page ECC layout defined in NAND core */</span>
<span class="p_add">+		mtd_set_ooblayout(mtd, &amp;nand_ooblayout_lp_ops);</span>
 		if (chip-&gt;ecc.strength == 32) {
 			nfc-&gt;ecc_mode = ECC_60_BYTE;
 			chip-&gt;ecc.bytes = 60;
<span class="p_header">diff --git a/drivers/net/ethernet/marvell/mvpp2.c b/drivers/net/ethernet/marvell/mvpp2.c</span>
<span class="p_header">index 1dd3a1264a53..06f3fe429d82 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/marvell/mvpp2.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/marvell/mvpp2.c</span>
<span class="p_chunk">@@ -6888,6 +6888,7 @@</span> <span class="p_context"> static void mvpp2_set_rx_mode(struct net_device *dev)</span>
 	int id = port-&gt;id;
 	bool allmulti = dev-&gt;flags &amp; IFF_ALLMULTI;
 
<span class="p_add">+retry:</span>
 	mvpp2_prs_mac_promisc_set(priv, id, dev-&gt;flags &amp; IFF_PROMISC);
 	mvpp2_prs_mac_multi_set(priv, id, MVPP2_PE_MAC_MC_ALL, allmulti);
 	mvpp2_prs_mac_multi_set(priv, id, MVPP2_PE_MAC_MC_IP6, allmulti);
<span class="p_chunk">@@ -6895,9 +6896,13 @@</span> <span class="p_context"> static void mvpp2_set_rx_mode(struct net_device *dev)</span>
 	/* Remove all port-&gt;id&#39;s mcast enries */
 	mvpp2_prs_mcast_del_all(priv, id);
 
<span class="p_del">-	if (allmulti &amp;&amp; !netdev_mc_empty(dev)) {</span>
<span class="p_del">-		netdev_for_each_mc_addr(ha, dev)</span>
<span class="p_del">-			mvpp2_prs_mac_da_accept(priv, id, ha-&gt;addr, true);</span>
<span class="p_add">+	if (!allmulti) {</span>
<span class="p_add">+		netdev_for_each_mc_addr(ha, dev) {</span>
<span class="p_add">+			if (mvpp2_prs_mac_da_accept(priv, id, ha-&gt;addr, true)) {</span>
<span class="p_add">+				allmulti = true;</span>
<span class="p_add">+				goto retry;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
 	}
 }
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx4/qp.c b/drivers/net/ethernet/mellanox/mlx4/qp.c</span>
<span class="p_header">index 728a2fb1f5c0..22a3bfe1ed8f 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx4/qp.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx4/qp.c</span>
<span class="p_chunk">@@ -287,6 +287,9 @@</span> <span class="p_context"> void mlx4_qp_release_range(struct mlx4_dev *dev, int base_qpn, int cnt)</span>
 	u64 in_param = 0;
 	int err;
 
<span class="p_add">+	if (!cnt)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (mlx4_is_mfunc(dev)) {
 		set_param_l(&amp;in_param, base_qpn);
 		set_param_h(&amp;in_param, cnt);
<span class="p_header">diff --git a/drivers/net/wireless/marvell/mwifiex/pcie.c b/drivers/net/wireless/marvell/mwifiex/pcie.c</span>
<span class="p_header">index cd314946452c..9511f5fe62f4 100644</span>
<span class="p_header">--- a/drivers/net/wireless/marvell/mwifiex/pcie.c</span>
<span class="p_header">+++ b/drivers/net/wireless/marvell/mwifiex/pcie.c</span>
<span class="p_chunk">@@ -2781,7 +2781,10 @@</span> <span class="p_context"> static void mwifiex_pcie_card_reset_work(struct mwifiex_adapter *adapter)</span>
 {
 	struct pcie_service_card *card = adapter-&gt;card;
 
<span class="p_del">-	pci_reset_function(card-&gt;dev);</span>
<span class="p_add">+	/* We can&#39;t afford to wait here; remove() might be waiting on us. If we</span>
<span class="p_add">+	 * can&#39;t grab the device lock, maybe we&#39;ll get another chance later.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pci_try_reset_function(card-&gt;dev);</span>
 }
 
 static void mwifiex_pcie_work(struct work_struct *work)
<span class="p_header">diff --git a/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c b/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c</span>
<span class="p_header">index 9ac1511de7ba..b82e5b363c05 100644</span>
<span class="p_header">--- a/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c</span>
<span class="p_header">+++ b/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c</span>
<span class="p_chunk">@@ -1122,7 +1122,7 @@</span> <span class="p_context"> static u8 _rtl8821ae_dbi_read(struct rtl_priv *rtlpriv, u16 addr)</span>
 	}
 	if (0 == tmp) {
 		read_addr = REG_DBI_RDATA + addr % 4;
<span class="p_del">-		ret = rtl_read_word(rtlpriv, read_addr);</span>
<span class="p_add">+		ret = rtl_read_byte(rtlpriv, read_addr);</span>
 	}
 	return ret;
 }
<span class="p_chunk">@@ -1164,7 +1164,8 @@</span> <span class="p_context"> static void _rtl8821ae_enable_aspm_back_door(struct ieee80211_hw *hw)</span>
 	}
 
 	tmp = _rtl8821ae_dbi_read(rtlpriv, 0x70f);
<span class="p_del">-	_rtl8821ae_dbi_write(rtlpriv, 0x70f, tmp | BIT(7));</span>
<span class="p_add">+	_rtl8821ae_dbi_write(rtlpriv, 0x70f, tmp | BIT(7) |</span>
<span class="p_add">+			     ASPM_L1_LATENCY &lt;&lt; 3);</span>
 
 	tmp = _rtl8821ae_dbi_read(rtlpriv, 0x719);
 	_rtl8821ae_dbi_write(rtlpriv, 0x719, tmp | BIT(3) | BIT(4));
<span class="p_header">diff --git a/drivers/net/wireless/realtek/rtlwifi/wifi.h b/drivers/net/wireless/realtek/rtlwifi/wifi.h</span>
<span class="p_header">index 1ab1024330fb..25c4e3e55921 100644</span>
<span class="p_header">--- a/drivers/net/wireless/realtek/rtlwifi/wifi.h</span>
<span class="p_header">+++ b/drivers/net/wireless/realtek/rtlwifi/wifi.h</span>
<span class="p_chunk">@@ -99,6 +99,7 @@</span> <span class="p_context"></span>
 #define RTL_USB_MAX_RX_COUNT			100
 #define QBSS_LOAD_SIZE				5
 #define MAX_WMMELE_LENGTH			64
<span class="p_add">+#define ASPM_L1_LATENCY				7</span>
 
 #define TOTAL_CAM_ENTRY				32
 
<span class="p_header">diff --git a/drivers/pci/dwc/pci-keystone.c b/drivers/pci/dwc/pci-keystone.c</span>
<span class="p_header">index 5bee3af47588..39405598b22d 100644</span>
<span class="p_header">--- a/drivers/pci/dwc/pci-keystone.c</span>
<span class="p_header">+++ b/drivers/pci/dwc/pci-keystone.c</span>
<span class="p_chunk">@@ -178,7 +178,7 @@</span> <span class="p_context"> static int ks_pcie_get_irq_controller_info(struct keystone_pcie *ks_pcie,</span>
 	}
 
 	/* interrupt controller is in a child node */
<span class="p_del">-	*np_temp = of_find_node_by_name(np_pcie, controller);</span>
<span class="p_add">+	*np_temp = of_get_child_by_name(np_pcie, controller);</span>
 	if (!(*np_temp)) {
 		dev_err(dev, &quot;Node for %s is absent\n&quot;, controller);
 		return -EINVAL;
<span class="p_chunk">@@ -187,6 +187,7 @@</span> <span class="p_context"> static int ks_pcie_get_irq_controller_info(struct keystone_pcie *ks_pcie,</span>
 	temp = of_irq_count(*np_temp);
 	if (!temp) {
 		dev_err(dev, &quot;No IRQ entries in %s\n&quot;, controller);
<span class="p_add">+		of_node_put(*np_temp);</span>
 		return -EINVAL;
 	}
 
<span class="p_chunk">@@ -204,6 +205,8 @@</span> <span class="p_context"> static int ks_pcie_get_irq_controller_info(struct keystone_pcie *ks_pcie,</span>
 			break;
 	}
 
<span class="p_add">+	of_node_put(*np_temp);</span>
<span class="p_add">+</span>
 	if (temp) {
 		*num_irqs = temp;
 		return 0;
<span class="p_header">diff --git a/drivers/pci/host/pcie-iproc-platform.c b/drivers/pci/host/pcie-iproc-platform.c</span>
<span class="p_header">index a5073a921a04..32228d41f746 100644</span>
<span class="p_header">--- a/drivers/pci/host/pcie-iproc-platform.c</span>
<span class="p_header">+++ b/drivers/pci/host/pcie-iproc-platform.c</span>
<span class="p_chunk">@@ -92,6 +92,13 @@</span> <span class="p_context"> static int iproc_pcie_pltfm_probe(struct platform_device *pdev)</span>
 		pcie-&gt;need_ob_cfg = true;
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * DT nodes are not used by all platforms that use the iProc PCIe</span>
<span class="p_add">+	 * core driver. For platforms that require explict inbound mapping</span>
<span class="p_add">+	 * configuration, &quot;dma-ranges&quot; would have been present in DT</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pcie-&gt;need_ib_cfg = of_property_read_bool(np, &quot;dma-ranges&quot;);</span>
<span class="p_add">+</span>
 	/* PHY use is optional */
 	pcie-&gt;phy = devm_phy_get(dev, &quot;pcie-phy&quot;);
 	if (IS_ERR(pcie-&gt;phy)) {
<span class="p_header">diff --git a/drivers/pci/host/pcie-iproc.c b/drivers/pci/host/pcie-iproc.c</span>
<span class="p_header">index 3a8b9d20ee57..c0ecc9f35667 100644</span>
<span class="p_header">--- a/drivers/pci/host/pcie-iproc.c</span>
<span class="p_header">+++ b/drivers/pci/host/pcie-iproc.c</span>
<span class="p_chunk">@@ -1396,9 +1396,11 @@</span> <span class="p_context"> int iproc_pcie_setup(struct iproc_pcie *pcie, struct list_head *res)</span>
 		}
 	}
 
<span class="p_del">-	ret = iproc_pcie_map_dma_ranges(pcie);</span>
<span class="p_del">-	if (ret &amp;&amp; ret != -ENOENT)</span>
<span class="p_del">-		goto err_power_off_phy;</span>
<span class="p_add">+	if (pcie-&gt;need_ib_cfg) {</span>
<span class="p_add">+		ret = iproc_pcie_map_dma_ranges(pcie);</span>
<span class="p_add">+		if (ret &amp;&amp; ret != -ENOENT)</span>
<span class="p_add">+			goto err_power_off_phy;</span>
<span class="p_add">+	}</span>
 
 #ifdef CONFIG_ARM
 	pcie-&gt;sysdata.private_data = pcie;
<span class="p_header">diff --git a/drivers/pci/host/pcie-iproc.h b/drivers/pci/host/pcie-iproc.h</span>
<span class="p_header">index a6b55cec9a66..4ac6282f2bfd 100644</span>
<span class="p_header">--- a/drivers/pci/host/pcie-iproc.h</span>
<span class="p_header">+++ b/drivers/pci/host/pcie-iproc.h</span>
<span class="p_chunk">@@ -74,6 +74,7 @@</span> <span class="p_context"> struct iproc_msi;</span>
  * @ob: outbound mapping related parameters
  * @ob_map: outbound mapping related parameters specific to the controller
  *
<span class="p_add">+ * @need_ib_cfg: indicates SW needs to configure the inbound mapping window</span>
  * @ib: inbound mapping related parameters
  * @ib_map: outbound mapping region related parameters
  *
<span class="p_chunk">@@ -101,6 +102,7 @@</span> <span class="p_context"> struct iproc_pcie {</span>
 	struct iproc_pcie_ob ob;
 	const struct iproc_pcie_ob_map *ob_map;
 
<span class="p_add">+	bool need_ib_cfg;</span>
 	struct iproc_pcie_ib ib;
 	const struct iproc_pcie_ib_map *ib_map;
 
<span class="p_header">diff --git a/drivers/pci/quirks.c b/drivers/pci/quirks.c</span>
<span class="p_header">index f66f9375177c..4c3feb96f391 100644</span>
<span class="p_header">--- a/drivers/pci/quirks.c</span>
<span class="p_header">+++ b/drivers/pci/quirks.c</span>
<span class="p_chunk">@@ -1636,8 +1636,8 @@</span> <span class="p_context"> static void quirk_pcie_mch(struct pci_dev *pdev)</span>
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_INTEL,	PCI_DEVICE_ID_INTEL_E7520_MCH,	quirk_pcie_mch);
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_INTEL,	PCI_DEVICE_ID_INTEL_E7320_MCH,	quirk_pcie_mch);
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_INTEL,	PCI_DEVICE_ID_INTEL_E7525_MCH,	quirk_pcie_mch);
<span class="p_del">-DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_HUAWEI,	0x1610,	quirk_pcie_mch);</span>
 
<span class="p_add">+DECLARE_PCI_FIXUP_CLASS_FINAL(PCI_VENDOR_ID_HUAWEI, 0x1610, PCI_CLASS_BRIDGE_PCI, 8, quirk_pcie_mch);</span>
 
 /*
  * It&#39;s possible for the MSI to get corrupted if shpc and acpi
<span class="p_header">diff --git a/drivers/platform/x86/apple-gmux.c b/drivers/platform/x86/apple-gmux.c</span>
<span class="p_header">index 623d322447a2..7c4eb86c851e 100644</span>
<span class="p_header">--- a/drivers/platform/x86/apple-gmux.c</span>
<span class="p_header">+++ b/drivers/platform/x86/apple-gmux.c</span>
<span class="p_chunk">@@ -24,7 +24,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/delay.h&gt;
 #include &lt;linux/pci.h&gt;
 #include &lt;linux/vga_switcheroo.h&gt;
<span class="p_del">-#include &lt;linux/vgaarb.h&gt;</span>
 #include &lt;acpi/video.h&gt;
 #include &lt;asm/io.h&gt;
 
<span class="p_chunk">@@ -54,7 +53,6 @@</span> <span class="p_context"> struct apple_gmux_data {</span>
 	bool indexed;
 	struct mutex index_lock;
 
<span class="p_del">-	struct pci_dev *pdev;</span>
 	struct backlight_device *bdev;
 
 	/* switcheroo data */
<span class="p_chunk">@@ -599,23 +597,6 @@</span> <span class="p_context"> static int gmux_resume(struct device *dev)</span>
 	return 0;
 }
 
<span class="p_del">-static struct pci_dev *gmux_get_io_pdev(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct pci_dev *pdev = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	while ((pdev = pci_get_class(PCI_CLASS_DISPLAY_VGA &lt;&lt; 8, pdev))) {</span>
<span class="p_del">-		u16 cmd;</span>
<span class="p_del">-</span>
<span class="p_del">-		pci_read_config_word(pdev, PCI_COMMAND, &amp;cmd);</span>
<span class="p_del">-		if (!(cmd &amp; PCI_COMMAND_IO))</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		return pdev;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return NULL;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int is_thunderbolt(struct device *dev, void *data)
 {
 	return to_pci_dev(dev)-&gt;is_thunderbolt;
<span class="p_chunk">@@ -631,7 +612,6 @@</span> <span class="p_context"> static int gmux_probe(struct pnp_dev *pnp, const struct pnp_device_id *id)</span>
 	int ret = -ENXIO;
 	acpi_status status;
 	unsigned long long gpe;
<span class="p_del">-	struct pci_dev *pdev = NULL;</span>
 
 	if (apple_gmux_data)
 		return -EBUSY;
<span class="p_chunk">@@ -682,7 +662,7 @@</span> <span class="p_context"> static int gmux_probe(struct pnp_dev *pnp, const struct pnp_device_id *id)</span>
 			ver_minor = (version &gt;&gt; 16) &amp; 0xff;
 			ver_release = (version &gt;&gt; 8) &amp; 0xff;
 		} else {
<span class="p_del">-			pr_info(&quot;gmux device not present or IO disabled\n&quot;);</span>
<span class="p_add">+			pr_info(&quot;gmux device not present\n&quot;);</span>
 			ret = -ENODEV;
 			goto err_release;
 		}
<span class="p_chunk">@@ -690,23 +670,6 @@</span> <span class="p_context"> static int gmux_probe(struct pnp_dev *pnp, const struct pnp_device_id *id)</span>
 	pr_info(&quot;Found gmux version %d.%d.%d [%s]\n&quot;, ver_major, ver_minor,
 		ver_release, (gmux_data-&gt;indexed ? &quot;indexed&quot; : &quot;classic&quot;));
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Apple systems with gmux are EFI based and normally don&#39;t use</span>
<span class="p_del">-	 * VGA. In addition changing IO+MEM ownership between IGP and dGPU</span>
<span class="p_del">-	 * disables IO/MEM used for backlight control on some systems.</span>
<span class="p_del">-	 * Lock IO+MEM to GPU with active IO to prevent switch.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	pdev = gmux_get_io_pdev();</span>
<span class="p_del">-	if (pdev &amp;&amp; vga_tryget(pdev,</span>
<span class="p_del">-			       VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM)) {</span>
<span class="p_del">-		pr_err(&quot;IO+MEM vgaarb-locking for PCI:%s failed\n&quot;,</span>
<span class="p_del">-			pci_name(pdev));</span>
<span class="p_del">-		ret = -EBUSY;</span>
<span class="p_del">-		goto err_release;</span>
<span class="p_del">-	} else if (pdev)</span>
<span class="p_del">-		pr_info(&quot;locked IO for PCI:%s\n&quot;, pci_name(pdev));</span>
<span class="p_del">-	gmux_data-&gt;pdev = pdev;</span>
<span class="p_del">-</span>
 	memset(&amp;props, 0, sizeof(props));
 	props.type = BACKLIGHT_PLATFORM;
 	props.max_brightness = gmux_read32(gmux_data, GMUX_PORT_MAX_BRIGHTNESS);
<span class="p_chunk">@@ -822,10 +785,6 @@</span> <span class="p_context"> static int gmux_probe(struct pnp_dev *pnp, const struct pnp_device_id *id)</span>
 err_notify:
 	backlight_device_unregister(bdev);
 err_release:
<span class="p_del">-	if (gmux_data-&gt;pdev)</span>
<span class="p_del">-		vga_put(gmux_data-&gt;pdev,</span>
<span class="p_del">-			VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM);</span>
<span class="p_del">-	pci_dev_put(pdev);</span>
 	release_region(gmux_data-&gt;iostart, gmux_data-&gt;iolen);
 err_free:
 	kfree(gmux_data);
<span class="p_chunk">@@ -845,11 +804,6 @@</span> <span class="p_context"> static void gmux_remove(struct pnp_dev *pnp)</span>
 					   &amp;gmux_notify_handler);
 	}
 
<span class="p_del">-	if (gmux_data-&gt;pdev) {</span>
<span class="p_del">-		vga_put(gmux_data-&gt;pdev,</span>
<span class="p_del">-			VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM);</span>
<span class="p_del">-		pci_dev_put(gmux_data-&gt;pdev);</span>
<span class="p_del">-	}</span>
 	backlight_device_unregister(gmux_data-&gt;bdev);
 
 	release_region(gmux_data-&gt;iostart, gmux_data-&gt;iolen);
<span class="p_header">diff --git a/drivers/rtc/rtc-opal.c b/drivers/rtc/rtc-opal.c</span>
<span class="p_header">index e2a946c0e667..304e891e35fc 100644</span>
<span class="p_header">--- a/drivers/rtc/rtc-opal.c</span>
<span class="p_header">+++ b/drivers/rtc/rtc-opal.c</span>
<span class="p_chunk">@@ -58,6 +58,7 @@</span> <span class="p_context"> static void tm_to_opal(struct rtc_time *tm, u32 *y_m_d, u64 *h_m_s_ms)</span>
 static int opal_get_rtc_time(struct device *dev, struct rtc_time *tm)
 {
 	long rc = OPAL_BUSY;
<span class="p_add">+	int retries = 10;</span>
 	u32 y_m_d;
 	u64 h_m_s_ms;
 	__be32 __y_m_d;
<span class="p_chunk">@@ -67,8 +68,11 @@</span> <span class="p_context"> static int opal_get_rtc_time(struct device *dev, struct rtc_time *tm)</span>
 		rc = opal_rtc_read(&amp;__y_m_d, &amp;__h_m_s_ms);
 		if (rc == OPAL_BUSY_EVENT)
 			opal_poll_events(NULL);
<span class="p_del">-		else</span>
<span class="p_add">+		else if (retries-- &amp;&amp; (rc == OPAL_HARDWARE</span>
<span class="p_add">+				       || rc == OPAL_INTERNAL_ERROR))</span>
 			msleep(10);
<span class="p_add">+		else if (rc != OPAL_BUSY &amp;&amp; rc != OPAL_BUSY_EVENT)</span>
<span class="p_add">+			break;</span>
 	}
 
 	if (rc != OPAL_SUCCESS)
<span class="p_chunk">@@ -84,6 +88,7 @@</span> <span class="p_context"> static int opal_get_rtc_time(struct device *dev, struct rtc_time *tm)</span>
 static int opal_set_rtc_time(struct device *dev, struct rtc_time *tm)
 {
 	long rc = OPAL_BUSY;
<span class="p_add">+	int retries = 10;</span>
 	u32 y_m_d = 0;
 	u64 h_m_s_ms = 0;
 
<span class="p_chunk">@@ -92,8 +97,11 @@</span> <span class="p_context"> static int opal_set_rtc_time(struct device *dev, struct rtc_time *tm)</span>
 		rc = opal_rtc_write(y_m_d, h_m_s_ms);
 		if (rc == OPAL_BUSY_EVENT)
 			opal_poll_events(NULL);
<span class="p_del">-		else</span>
<span class="p_add">+		else if (retries-- &amp;&amp; (rc == OPAL_HARDWARE</span>
<span class="p_add">+				       || rc == OPAL_INTERNAL_ERROR))</span>
 			msleep(10);
<span class="p_add">+		else if (rc != OPAL_BUSY &amp;&amp; rc != OPAL_BUSY_EVENT)</span>
<span class="p_add">+			break;</span>
 	}
 
 	return rc == OPAL_SUCCESS ? 0 : -EIO;
<span class="p_header">diff --git a/drivers/scsi/scsi_sysfs.c b/drivers/scsi/scsi_sysfs.c</span>
<span class="p_header">index f796bd61f3f0..40406c162d0d 100644</span>
<span class="p_header">--- a/drivers/scsi/scsi_sysfs.c</span>
<span class="p_header">+++ b/drivers/scsi/scsi_sysfs.c</span>
<span class="p_chunk">@@ -1383,7 +1383,10 @@</span> <span class="p_context"> static void __scsi_remove_target(struct scsi_target *starget)</span>
 		 * check.
 		 */
 		if (sdev-&gt;channel != starget-&gt;channel ||
<span class="p_del">-		    sdev-&gt;id != starget-&gt;id ||</span>
<span class="p_add">+		    sdev-&gt;id != starget-&gt;id)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		if (sdev-&gt;sdev_state == SDEV_DEL ||</span>
<span class="p_add">+		    sdev-&gt;sdev_state == SDEV_CANCEL ||</span>
 		    !get_device(&amp;sdev-&gt;sdev_gendev))
 			continue;
 		spin_unlock_irqrestore(shost-&gt;host_lock, flags);
<span class="p_header">diff --git a/drivers/scsi/smartpqi/Makefile b/drivers/scsi/smartpqi/Makefile</span>
<span class="p_header">index 0f42a225a664..e6b779930230 100644</span>
<span class="p_header">--- a/drivers/scsi/smartpqi/Makefile</span>
<span class="p_header">+++ b/drivers/scsi/smartpqi/Makefile</span>
<span class="p_chunk">@@ -1,3 +1,3 @@</span> <span class="p_context"></span>
 ccflags-y += -I.
<span class="p_del">-obj-m		+= smartpqi.o</span>
<span class="p_add">+obj-$(CONFIG_SCSI_SMARTPQI) += smartpqi.o</span>
 smartpqi-objs := smartpqi_init.o smartpqi_sis.o smartpqi_sas_transport.o
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_auth.c b/drivers/target/iscsi/iscsi_target_auth.c</span>
<span class="p_header">index f9bc8ec6fb6b..9518ffd8b8ba 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_auth.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_auth.c</span>
<span class="p_chunk">@@ -421,7 +421,8 @@</span> <span class="p_context"> static int chap_server_compute_md5(</span>
 	auth_ret = 0;
 out:
 	kzfree(desc);
<span class="p_del">-	crypto_free_shash(tfm);</span>
<span class="p_add">+	if (tfm)</span>
<span class="p_add">+		crypto_free_shash(tfm);</span>
 	kfree(challenge);
 	kfree(challenge_binhex);
 	return auth_ret;
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_nego.c b/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_header">index 7a6751fecd32..87248a2512e5 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_chunk">@@ -432,6 +432,9 @@</span> <span class="p_context"> static void iscsi_target_sk_data_ready(struct sock *sk)</span>
 	if (test_and_set_bit(LOGIN_FLAGS_READ_ACTIVE, &amp;conn-&gt;login_flags)) {
 		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
 		pr_debug(&quot;Got LOGIN_FLAGS_READ_ACTIVE=1, conn: %p &gt;&gt;&gt;&gt;\n&quot;, conn);
<span class="p_add">+		if (iscsi_target_sk_data_ready == conn-&gt;orig_data_ready)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		conn-&gt;orig_data_ready(sk);</span>
 		return;
 	}
 
<span class="p_header">diff --git a/drivers/usb/Kconfig b/drivers/usb/Kconfig</span>
<span class="p_header">index 939a63bca82f..72eb3e41e3b6 100644</span>
<span class="p_header">--- a/drivers/usb/Kconfig</span>
<span class="p_header">+++ b/drivers/usb/Kconfig</span>
<span class="p_chunk">@@ -19,6 +19,14 @@</span> <span class="p_context"> config USB_EHCI_BIG_ENDIAN_MMIO</span>
 config USB_EHCI_BIG_ENDIAN_DESC
 	bool
 
<span class="p_add">+config USB_UHCI_BIG_ENDIAN_MMIO</span>
<span class="p_add">+	bool</span>
<span class="p_add">+	default y if SPARC_LEON</span>
<span class="p_add">+</span>
<span class="p_add">+config USB_UHCI_BIG_ENDIAN_DESC</span>
<span class="p_add">+	bool</span>
<span class="p_add">+	default y if SPARC_LEON</span>
<span class="p_add">+</span>
 menuconfig USB_SUPPORT
 	bool &quot;USB support&quot;
 	depends on HAS_IOMEM
<span class="p_header">diff --git a/drivers/usb/host/Kconfig b/drivers/usb/host/Kconfig</span>
<span class="p_header">index fa5692dec832..92b19721b595 100644</span>
<span class="p_header">--- a/drivers/usb/host/Kconfig</span>
<span class="p_header">+++ b/drivers/usb/host/Kconfig</span>
<span class="p_chunk">@@ -637,14 +637,6 @@</span> <span class="p_context"> config USB_UHCI_ASPEED</span>
        bool
        default y if ARCH_ASPEED
 
<span class="p_del">-config USB_UHCI_BIG_ENDIAN_MMIO</span>
<span class="p_del">-	bool</span>
<span class="p_del">-	default y if SPARC_LEON</span>
<span class="p_del">-</span>
<span class="p_del">-config USB_UHCI_BIG_ENDIAN_DESC</span>
<span class="p_del">-	bool</span>
<span class="p_del">-	default y if SPARC_LEON</span>
<span class="p_del">-</span>
 config USB_FHCI_HCD
 	tristate &quot;Freescale QE USB Host Controller support&quot;
 	depends on OF_GPIO &amp;&amp; QE_GPIO &amp;&amp; QUICC_ENGINE
<span class="p_header">diff --git a/drivers/video/console/dummycon.c b/drivers/video/console/dummycon.c</span>
<span class="p_header">index 9269d5685239..b90ef96e43d6 100644</span>
<span class="p_header">--- a/drivers/video/console/dummycon.c</span>
<span class="p_header">+++ b/drivers/video/console/dummycon.c</span>
<span class="p_chunk">@@ -67,7 +67,6 @@</span> <span class="p_context"> const struct consw dummy_con = {</span>
     .con_switch =	DUMMY,
     .con_blank =	DUMMY,
     .con_font_set =	DUMMY,
<span class="p_del">-    .con_font_get =	DUMMY,</span>
     .con_font_default =	DUMMY,
     .con_font_copy =	DUMMY,
 };
<span class="p_header">diff --git a/drivers/video/fbdev/atmel_lcdfb.c b/drivers/video/fbdev/atmel_lcdfb.c</span>
<span class="p_header">index e06358da4b99..3dee267d7c75 100644</span>
<span class="p_header">--- a/drivers/video/fbdev/atmel_lcdfb.c</span>
<span class="p_header">+++ b/drivers/video/fbdev/atmel_lcdfb.c</span>
<span class="p_chunk">@@ -1119,7 +1119,7 @@</span> <span class="p_context"> static int atmel_lcdfb_of_init(struct atmel_lcdfb_info *sinfo)</span>
 		goto put_display_node;
 	}
 
<span class="p_del">-	timings_np = of_find_node_by_name(display_np, &quot;display-timings&quot;);</span>
<span class="p_add">+	timings_np = of_get_child_by_name(display_np, &quot;display-timings&quot;);</span>
 	if (!timings_np) {
 		dev_err(dev, &quot;failed to find display-timings node\n&quot;);
 		ret = -ENODEV;
<span class="p_chunk">@@ -1140,6 +1140,12 @@</span> <span class="p_context"> static int atmel_lcdfb_of_init(struct atmel_lcdfb_info *sinfo)</span>
 		fb_add_videomode(&amp;fb_vm, &amp;info-&gt;modelist);
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * FIXME: Make sure we are not referencing any fields in display_np</span>
<span class="p_add">+	 * and timings_np and drop our references to them before returning to</span>
<span class="p_add">+	 * avoid leaking the nodes on probe deferral and driver unbind.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
 	return 0;
 
 put_timings_node:
<span class="p_header">diff --git a/drivers/video/fbdev/geode/video_gx.c b/drivers/video/fbdev/geode/video_gx.c</span>
<span class="p_header">index 6082f653c68a..67773e8bbb95 100644</span>
<span class="p_header">--- a/drivers/video/fbdev/geode/video_gx.c</span>
<span class="p_header">+++ b/drivers/video/fbdev/geode/video_gx.c</span>
<span class="p_chunk">@@ -127,7 +127,7 @@</span> <span class="p_context"> void gx_set_dclk_frequency(struct fb_info *info)</span>
 	int timeout = 1000;
 
 	/* Rev. 1 Geode GXs use a 14 MHz reference clock instead of 48 MHz. */
<span class="p_del">-	if (cpu_data(0).x86_mask == 1) {</span>
<span class="p_add">+	if (cpu_data(0).x86_stepping == 1) {</span>
 		pll_table = gx_pll_table_14MHz;
 		pll_table_len = ARRAY_SIZE(gx_pll_table_14MHz);
 	} else {
<span class="p_header">diff --git a/drivers/xen/xenbus/xenbus.h b/drivers/xen/xenbus/xenbus.h</span>
<span class="p_header">index 149c5e7efc89..092981171df1 100644</span>
<span class="p_header">--- a/drivers/xen/xenbus/xenbus.h</span>
<span class="p_header">+++ b/drivers/xen/xenbus/xenbus.h</span>
<span class="p_chunk">@@ -76,6 +76,7 @@</span> <span class="p_context"> struct xb_req_data {</span>
 	struct list_head list;
 	wait_queue_head_t wq;
 	struct xsd_sockmsg msg;
<span class="p_add">+	uint32_t caller_req_id;</span>
 	enum xsd_sockmsg_type type;
 	char *body;
 	const struct kvec *vec;
<span class="p_header">diff --git a/drivers/xen/xenbus/xenbus_comms.c b/drivers/xen/xenbus/xenbus_comms.c</span>
<span class="p_header">index 5b081a01779d..d239fc3c5e3d 100644</span>
<span class="p_header">--- a/drivers/xen/xenbus/xenbus_comms.c</span>
<span class="p_header">+++ b/drivers/xen/xenbus/xenbus_comms.c</span>
<span class="p_chunk">@@ -309,6 +309,7 @@</span> <span class="p_context"> static int process_msg(void)</span>
 			goto out;
 
 		if (req-&gt;state == xb_req_state_wait_reply) {
<span class="p_add">+			req-&gt;msg.req_id = req-&gt;caller_req_id;</span>
 			req-&gt;msg.type = state.msg.type;
 			req-&gt;msg.len = state.msg.len;
 			req-&gt;body = state.body;
<span class="p_header">diff --git a/drivers/xen/xenbus/xenbus_xs.c b/drivers/xen/xenbus/xenbus_xs.c</span>
<span class="p_header">index 3e59590c7254..3f3b29398ab8 100644</span>
<span class="p_header">--- a/drivers/xen/xenbus/xenbus_xs.c</span>
<span class="p_header">+++ b/drivers/xen/xenbus/xenbus_xs.c</span>
<span class="p_chunk">@@ -227,6 +227,8 @@</span> <span class="p_context"> static void xs_send(struct xb_req_data *req, struct xsd_sockmsg *msg)</span>
 	req-&gt;state = xb_req_state_queued;
 	init_waitqueue_head(&amp;req-&gt;wq);
 
<span class="p_add">+	/* Save the caller req_id and restore it later in the reply */</span>
<span class="p_add">+	req-&gt;caller_req_id = req-&gt;msg.req_id;</span>
 	req-&gt;msg.req_id = xs_request_enter(req);
 
 	mutex_lock(&amp;xb_write_mutex);
<span class="p_chunk">@@ -310,6 +312,7 @@</span> <span class="p_context"> static void *xs_talkv(struct xenbus_transaction t,</span>
 	req-&gt;num_vecs = num_vecs;
 	req-&gt;cb = xs_wake_up;
 
<span class="p_add">+	msg.req_id = 0;</span>
 	msg.tx_id = t.id;
 	msg.type = type;
 	msg.len = 0;
<span class="p_header">diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c</span>
<span class="p_header">index 5eaedff28a32..1ae61f82e54b 100644</span>
<span class="p_header">--- a/fs/btrfs/inode.c</span>
<span class="p_header">+++ b/fs/btrfs/inode.c</span>
<span class="p_chunk">@@ -1330,8 +1330,11 @@</span> <span class="p_context"> static noinline int run_delalloc_nocow(struct inode *inode,</span>
 		leaf = path-&gt;nodes[0];
 		if (path-&gt;slots[0] &gt;= btrfs_header_nritems(leaf)) {
 			ret = btrfs_next_leaf(root, path);
<span class="p_del">-			if (ret &lt; 0)</span>
<span class="p_add">+			if (ret &lt; 0) {</span>
<span class="p_add">+				if (cow_start != (u64)-1)</span>
<span class="p_add">+					cur_offset = cow_start;</span>
 				goto error;
<span class="p_add">+			}</span>
 			if (ret &gt; 0)
 				break;
 			leaf = path-&gt;nodes[0];
<span class="p_chunk">@@ -3368,6 +3371,11 @@</span> <span class="p_context"> int btrfs_orphan_add(struct btrfs_trans_handle *trans,</span>
 		ret = btrfs_orphan_reserve_metadata(trans, inode);
 		ASSERT(!ret);
 		if (ret) {
<span class="p_add">+			/*</span>
<span class="p_add">+			 * dec doesn&#39;t need spin_lock as -&gt;orphan_block_rsv</span>
<span class="p_add">+			 * would be released only if -&gt;orphan_inodes is</span>
<span class="p_add">+			 * zero.</span>
<span class="p_add">+			 */</span>
 			atomic_dec(&amp;root-&gt;orphan_inodes);
 			clear_bit(BTRFS_INODE_ORPHAN_META_RESERVED,
 				  &amp;inode-&gt;runtime_flags);
<span class="p_chunk">@@ -3382,12 +3390,17 @@</span> <span class="p_context"> int btrfs_orphan_add(struct btrfs_trans_handle *trans,</span>
 	if (insert &gt;= 1) {
 		ret = btrfs_insert_orphan_item(trans, root, btrfs_ino(inode));
 		if (ret) {
<span class="p_del">-			atomic_dec(&amp;root-&gt;orphan_inodes);</span>
 			if (reserve) {
 				clear_bit(BTRFS_INODE_ORPHAN_META_RESERVED,
 					  &amp;inode-&gt;runtime_flags);
 				btrfs_orphan_release_metadata(inode);
 			}
<span class="p_add">+			/*</span>
<span class="p_add">+			 * btrfs_orphan_commit_root may race with us and set</span>
<span class="p_add">+			 * -&gt;orphan_block_rsv to zero, in order to avoid that,</span>
<span class="p_add">+			 * decrease -&gt;orphan_inodes after everything is done.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			atomic_dec(&amp;root-&gt;orphan_inodes);</span>
 			if (ret != -EEXIST) {
 				clear_bit(BTRFS_INODE_HAS_ORPHAN_ITEM,
 					  &amp;inode-&gt;runtime_flags);
<span class="p_chunk">@@ -3419,28 +3432,26 @@</span> <span class="p_context"> static int btrfs_orphan_del(struct btrfs_trans_handle *trans,</span>
 {
 	struct btrfs_root *root = inode-&gt;root;
 	int delete_item = 0;
<span class="p_del">-	int release_rsv = 0;</span>
 	int ret = 0;
 
<span class="p_del">-	spin_lock(&amp;root-&gt;orphan_lock);</span>
 	if (test_and_clear_bit(BTRFS_INODE_HAS_ORPHAN_ITEM,
 			       &amp;inode-&gt;runtime_flags))
 		delete_item = 1;
 
<span class="p_add">+	if (delete_item &amp;&amp; trans)</span>
<span class="p_add">+		ret = btrfs_del_orphan_item(trans, root, btrfs_ino(inode));</span>
<span class="p_add">+</span>
 	if (test_and_clear_bit(BTRFS_INODE_ORPHAN_META_RESERVED,
 			       &amp;inode-&gt;runtime_flags))
<span class="p_del">-		release_rsv = 1;</span>
<span class="p_del">-	spin_unlock(&amp;root-&gt;orphan_lock);</span>
<span class="p_add">+		btrfs_orphan_release_metadata(inode);</span>
 
<span class="p_del">-	if (delete_item) {</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * btrfs_orphan_commit_root may race with us and set -&gt;orphan_block_rsv</span>
<span class="p_add">+	 * to zero, in order to avoid that, decrease -&gt;orphan_inodes after</span>
<span class="p_add">+	 * everything is done.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (delete_item)</span>
 		atomic_dec(&amp;root-&gt;orphan_inodes);
<span class="p_del">-		if (trans)</span>
<span class="p_del">-			ret = btrfs_del_orphan_item(trans, root,</span>
<span class="p_del">-						    btrfs_ino(inode));</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (release_rsv)</span>
<span class="p_del">-		btrfs_orphan_release_metadata(inode);</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -5315,7 +5326,7 @@</span> <span class="p_context"> void btrfs_evict_inode(struct inode *inode)</span>
 	trace_btrfs_inode_evict(inode);
 
 	if (!root) {
<span class="p_del">-		kmem_cache_free(btrfs_inode_cachep, BTRFS_I(inode));</span>
<span class="p_add">+		clear_inode(inode);</span>
 		return;
 	}
 
<span class="p_header">diff --git a/fs/btrfs/tree-log.c b/fs/btrfs/tree-log.c</span>
<span class="p_header">index d3002842d7f6..b6dfe7af7a1f 100644</span>
<span class="p_header">--- a/fs/btrfs/tree-log.c</span>
<span class="p_header">+++ b/fs/btrfs/tree-log.c</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"></span>
 #include &quot;hash.h&quot;
 #include &quot;compression.h&quot;
 #include &quot;qgroup.h&quot;
<span class="p_add">+#include &quot;inode-map.h&quot;</span>
 
 /* magic values for the inode_only field in btrfs_log_inode:
  *
<span class="p_chunk">@@ -2494,6 +2495,9 @@</span> <span class="p_context"> static noinline int walk_down_log_tree(struct btrfs_trans_handle *trans,</span>
 					clean_tree_block(fs_info, next);
 					btrfs_wait_tree_block_writeback(next);
 					btrfs_tree_unlock(next);
<span class="p_add">+				} else {</span>
<span class="p_add">+					if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &amp;next-&gt;bflags))</span>
<span class="p_add">+						clear_extent_buffer_dirty(next);</span>
 				}
 
 				WARN_ON(root_owner !=
<span class="p_chunk">@@ -2574,6 +2578,9 @@</span> <span class="p_context"> static noinline int walk_up_log_tree(struct btrfs_trans_handle *trans,</span>
 					clean_tree_block(fs_info, next);
 					btrfs_wait_tree_block_writeback(next);
 					btrfs_tree_unlock(next);
<span class="p_add">+				} else {</span>
<span class="p_add">+					if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &amp;next-&gt;bflags))</span>
<span class="p_add">+						clear_extent_buffer_dirty(next);</span>
 				}
 
 				WARN_ON(root_owner != BTRFS_TREE_LOG_OBJECTID);
<span class="p_chunk">@@ -2652,6 +2659,9 @@</span> <span class="p_context"> static int walk_log_tree(struct btrfs_trans_handle *trans,</span>
 				clean_tree_block(fs_info, next);
 				btrfs_wait_tree_block_writeback(next);
 				btrfs_tree_unlock(next);
<span class="p_add">+			} else {</span>
<span class="p_add">+				if (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &amp;next-&gt;bflags))</span>
<span class="p_add">+					clear_extent_buffer_dirty(next);</span>
 			}
 
 			WARN_ON(log-&gt;root_key.objectid !=
<span class="p_chunk">@@ -3038,13 +3048,14 @@</span> <span class="p_context"> static void free_log_tree(struct btrfs_trans_handle *trans,</span>
 
 	while (1) {
 		ret = find_first_extent_bit(&amp;log-&gt;dirty_log_pages,
<span class="p_del">-				0, &amp;start, &amp;end, EXTENT_DIRTY | EXTENT_NEW,</span>
<span class="p_add">+				0, &amp;start, &amp;end,</span>
<span class="p_add">+				EXTENT_DIRTY | EXTENT_NEW | EXTENT_NEED_WAIT,</span>
 				NULL);
 		if (ret)
 			break;
 
 		clear_extent_bits(&amp;log-&gt;dirty_log_pages, start, end,
<span class="p_del">-				  EXTENT_DIRTY | EXTENT_NEW);</span>
<span class="p_add">+				  EXTENT_DIRTY | EXTENT_NEW | EXTENT_NEED_WAIT);</span>
 	}
 
 	/*
<span class="p_chunk">@@ -5705,6 +5716,23 @@</span> <span class="p_context"> int btrfs_recover_log_trees(struct btrfs_root *log_root_tree)</span>
 						      path);
 		}
 
<span class="p_add">+		if (!ret &amp;&amp; wc.stage == LOG_WALK_REPLAY_ALL) {</span>
<span class="p_add">+			struct btrfs_root *root = wc.replay_dest;</span>
<span class="p_add">+</span>
<span class="p_add">+			btrfs_release_path(path);</span>
<span class="p_add">+</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * We have just replayed everything, and the highest</span>
<span class="p_add">+			 * objectid of fs roots probably has changed in case</span>
<span class="p_add">+			 * some inode_item&#39;s got replayed.</span>
<span class="p_add">+			 *</span>
<span class="p_add">+			 * root-&gt;objectid_mutex is not acquired as log replay</span>
<span class="p_add">+			 * could only happen during mount.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			ret = btrfs_find_highest_objectid(root,</span>
<span class="p_add">+						  &amp;root-&gt;highest_objectid);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		key.offset = found_key.offset - 1;
 		wc.replay_dest-&gt;log_root = NULL;
 		free_extent_buffer(log-&gt;node);
<span class="p_header">diff --git a/fs/dcache.c b/fs/dcache.c</span>
<span class="p_header">index 34c852af215c..b8d999a5768b 100644</span>
<span class="p_header">--- a/fs/dcache.c</span>
<span class="p_header">+++ b/fs/dcache.c</span>
<span class="p_chunk">@@ -2705,8 +2705,6 @@</span> <span class="p_context"> static void swap_names(struct dentry *dentry, struct dentry *target)</span>
 			 */
 			unsigned int i;
 			BUILD_BUG_ON(!IS_ALIGNED(DNAME_INLINE_LEN, sizeof(long)));
<span class="p_del">-			kmemcheck_mark_initialized(dentry-&gt;d_iname, DNAME_INLINE_LEN);</span>
<span class="p_del">-			kmemcheck_mark_initialized(target-&gt;d_iname, DNAME_INLINE_LEN);</span>
 			for (i = 0; i &lt; DNAME_INLINE_LEN / sizeof(long); i++) {
 				swap(((long *) &amp;dentry-&gt;d_iname)[i],
 				     ((long *) &amp;target-&gt;d_iname)[i]);
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index ea2ccc524bd9..0b9f3f284799 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -3724,10 +3724,18 @@</span> <span class="p_context"> static ssize_t ext4_direct_IO_write(struct kiocb *iocb, struct iov_iter *iter)</span>
 		/* Credits for sb + inode write */
 		handle = ext4_journal_start(inode, EXT4_HT_INODE, 2);
 		if (IS_ERR(handle)) {
<span class="p_del">-			/* This is really bad luck. We&#39;ve written the data</span>
<span class="p_del">-			 * but cannot extend i_size. Bail out and pretend</span>
<span class="p_del">-			 * the write failed... */</span>
<span class="p_del">-			ret = PTR_ERR(handle);</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * We wrote the data but cannot extend</span>
<span class="p_add">+			 * i_size. Bail out. In async io case, we do</span>
<span class="p_add">+			 * not return error here because we have</span>
<span class="p_add">+			 * already submmitted the corresponding</span>
<span class="p_add">+			 * bio. Returning error here makes the caller</span>
<span class="p_add">+			 * think that this IO is done and failed</span>
<span class="p_add">+			 * resulting in race with bio&#39;s completion</span>
<span class="p_add">+			 * handler.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (!ret)</span>
<span class="p_add">+				ret = PTR_ERR(handle);</span>
 			if (inode-&gt;i_nlink)
 				ext4_orphan_del(NULL, inode);
 
<span class="p_header">diff --git a/fs/ext4/super.c b/fs/ext4/super.c</span>
<span class="p_header">index f29351c66610..16d247f056e2 100644</span>
<span class="p_header">--- a/fs/ext4/super.c</span>
<span class="p_header">+++ b/fs/ext4/super.c</span>
<span class="p_chunk">@@ -742,6 +742,7 @@</span> <span class="p_context"> __acquires(bitlock)</span>
 	}
 
 	ext4_unlock_group(sb, grp);
<span class="p_add">+	ext4_commit_super(sb, 1);</span>
 	ext4_handle_error(sb);
 	/*
 	 * We only get here in the ERRORS_RO case; relocking the group
<span class="p_header">diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c</span>
<span class="p_header">index 8b08044b3120..c0681814c379 100644</span>
<span class="p_header">--- a/fs/jbd2/transaction.c</span>
<span class="p_header">+++ b/fs/jbd2/transaction.c</span>
<span class="p_chunk">@@ -495,8 +495,10 @@</span> <span class="p_context"> void jbd2_journal_free_reserved(handle_t *handle)</span>
 EXPORT_SYMBOL(jbd2_journal_free_reserved);
 
 /**
<span class="p_del">- * int jbd2_journal_start_reserved(handle_t *handle) - start reserved handle</span>
<span class="p_add">+ * int jbd2_journal_start_reserved() - start reserved handle</span>
  * @handle: handle to start
<span class="p_add">+ * @type: for handle statistics</span>
<span class="p_add">+ * @line_no: for handle statistics</span>
  *
  * Start handle that has been previously reserved with jbd2_journal_reserve().
  * This attaches @handle to the running transaction (or creates one if there&#39;s
<span class="p_chunk">@@ -626,6 +628,7 @@</span> <span class="p_context"> int jbd2_journal_extend(handle_t *handle, int nblocks)</span>
  * int jbd2_journal_restart() - restart a handle .
  * @handle:  handle to restart
  * @nblocks: nr credits requested
<span class="p_add">+ * @gfp_mask: memory allocation flags (for start_this_handle)</span>
  *
  * Restart a handle for a multi-transaction filesystem
  * operation.
<span class="p_header">diff --git a/fs/mbcache.c b/fs/mbcache.c</span>
<span class="p_header">index d818fd236787..49c5b25bfa8c 100644</span>
<span class="p_header">--- a/fs/mbcache.c</span>
<span class="p_header">+++ b/fs/mbcache.c</span>
<span class="p_chunk">@@ -94,6 +94,7 @@</span> <span class="p_context"> int mb_cache_entry_create(struct mb_cache *cache, gfp_t mask, u32 key,</span>
 	entry-&gt;e_key = key;
 	entry-&gt;e_value = value;
 	entry-&gt;e_reusable = reusable;
<span class="p_add">+	entry-&gt;e_referenced = 0;</span>
 	head = mb_cache_entry_head(cache, key);
 	hlist_bl_lock(head);
 	hlist_bl_for_each_entry(dup, dup_node, head, e_hash_list) {
<span class="p_header">diff --git a/fs/ocfs2/dlmglue.c b/fs/ocfs2/dlmglue.c</span>
<span class="p_header">index 4689940a953c..5193218f5889 100644</span>
<span class="p_header">--- a/fs/ocfs2/dlmglue.c</span>
<span class="p_header">+++ b/fs/ocfs2/dlmglue.c</span>
<span class="p_chunk">@@ -2486,6 +2486,15 @@</span> <span class="p_context"> int ocfs2_inode_lock_with_page(struct inode *inode,</span>
 	ret = ocfs2_inode_lock_full(inode, ret_bh, ex, OCFS2_LOCK_NONBLOCK);
 	if (ret == -EAGAIN) {
 		unlock_page(page);
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If we can&#39;t get inode lock immediately, we should not return</span>
<span class="p_add">+		 * directly here, since this will lead to a softlockup problem.</span>
<span class="p_add">+		 * The method is to get a blocking lock and immediately unlock</span>
<span class="p_add">+		 * before returning, this can avoid CPU resource waste due to</span>
<span class="p_add">+		 * lots of retries, and benefits fairness in getting lock.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (ocfs2_inode_lock(inode, ret_bh, ex) == 0)</span>
<span class="p_add">+			ocfs2_inode_unlock(inode, ex);</span>
 		ret = AOP_TRUNCATED_PAGE;
 	}
 
<span class="p_header">diff --git a/fs/overlayfs/inode.c b/fs/overlayfs/inode.c</span>
<span class="p_header">index 321511ed8c42..d60900b615f9 100644</span>
<span class="p_header">--- a/fs/overlayfs/inode.c</span>
<span class="p_header">+++ b/fs/overlayfs/inode.c</span>
<span class="p_chunk">@@ -579,6 +579,16 @@</span> <span class="p_context"> static int ovl_inode_set(struct inode *inode, void *data)</span>
 static bool ovl_verify_inode(struct inode *inode, struct dentry *lowerdentry,
 			     struct dentry *upperdentry)
 {
<span class="p_add">+	if (S_ISDIR(inode-&gt;i_mode)) {</span>
<span class="p_add">+		/* Real lower dir moved to upper layer under us? */</span>
<span class="p_add">+		if (!lowerdentry &amp;&amp; ovl_inode_lower(inode))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Lookup of an uncovered redirect origin? */</span>
<span class="p_add">+		if (!upperdentry &amp;&amp; ovl_inode_upper(inode))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/*
 	 * Allow non-NULL lower inode in ovl_inode even if lowerdentry is NULL.
 	 * This happens when finding a copied up overlay inode for a renamed
<span class="p_chunk">@@ -606,6 +616,8 @@</span> <span class="p_context"> struct inode *ovl_get_inode(struct dentry *dentry, struct dentry *upperdentry,</span>
 	struct inode *inode;
 	/* Already indexed or could be indexed on copy up? */
 	bool indexed = (index || (ovl_indexdir(dentry-&gt;d_sb) &amp;&amp; !upperdentry));
<span class="p_add">+	struct dentry *origin = indexed ? lowerdentry : NULL;</span>
<span class="p_add">+	bool is_dir;</span>
 
 	if (WARN_ON(upperdentry &amp;&amp; indexed &amp;&amp; !lowerdentry))
 		return ERR_PTR(-EIO);
<span class="p_chunk">@@ -614,15 +626,19 @@</span> <span class="p_context"> struct inode *ovl_get_inode(struct dentry *dentry, struct dentry *upperdentry,</span>
 		realinode = d_inode(lowerdentry);
 
 	/*
<span class="p_del">-	 * Copy up origin (lower) may exist for non-indexed upper, but we must</span>
<span class="p_del">-	 * not use lower as hash key in that case.</span>
<span class="p_del">-	 * Hash inodes that are or could be indexed by origin inode and</span>
<span class="p_del">-	 * non-indexed upper inodes that could be hard linked by upper inode.</span>
<span class="p_add">+	 * Copy up origin (lower) may exist for non-indexed non-dir upper, but</span>
<span class="p_add">+	 * we must not use lower as hash key in that case.</span>
<span class="p_add">+	 * Hash non-dir that is or could be indexed by origin inode.</span>
<span class="p_add">+	 * Hash dir that is or could be merged by origin inode.</span>
<span class="p_add">+	 * Hash pure upper and non-indexed non-dir by upper inode.</span>
 	 */
<span class="p_del">-	if (!S_ISDIR(realinode-&gt;i_mode) &amp;&amp; (upperdentry || indexed)) {</span>
<span class="p_del">-		struct inode *key = d_inode(indexed ? lowerdentry :</span>
<span class="p_del">-						      upperdentry);</span>
<span class="p_del">-		unsigned int nlink;</span>
<span class="p_add">+	is_dir = S_ISDIR(realinode-&gt;i_mode);</span>
<span class="p_add">+	if (is_dir)</span>
<span class="p_add">+		origin = lowerdentry;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (upperdentry || origin) {</span>
<span class="p_add">+		struct inode *key = d_inode(origin ?: upperdentry);</span>
<span class="p_add">+		unsigned int nlink = is_dir ? 1 : realinode-&gt;i_nlink;</span>
 
 		inode = iget5_locked(dentry-&gt;d_sb, (unsigned long) key,
 				     ovl_inode_test, ovl_inode_set, key);
<span class="p_chunk">@@ -643,8 +659,9 @@</span> <span class="p_context"> struct inode *ovl_get_inode(struct dentry *dentry, struct dentry *upperdentry,</span>
 			goto out;
 		}
 
<span class="p_del">-		nlink = ovl_get_nlink(lowerdentry, upperdentry,</span>
<span class="p_del">-				      realinode-&gt;i_nlink);</span>
<span class="p_add">+		/* Recalculate nlink for non-dir due to indexing */</span>
<span class="p_add">+		if (!is_dir)</span>
<span class="p_add">+			nlink = ovl_get_nlink(lowerdentry, upperdentry, nlink);</span>
 		set_nlink(inode, nlink);
 	} else {
 		inode = new_inode(dentry-&gt;d_sb);
<span class="p_header">diff --git a/fs/overlayfs/super.c b/fs/overlayfs/super.c</span>
<span class="p_header">index f5738e96a052..b8f8d666e8d4 100644</span>
<span class="p_header">--- a/fs/overlayfs/super.c</span>
<span class="p_header">+++ b/fs/overlayfs/super.c</span>
<span class="p_chunk">@@ -200,6 +200,7 @@</span> <span class="p_context"> static void ovl_destroy_inode(struct inode *inode)</span>
 	struct ovl_inode *oi = OVL_I(inode);
 
 	dput(oi-&gt;__upperdentry);
<span class="p_add">+	iput(oi-&gt;lower);</span>
 	kfree(oi-&gt;redirect);
 	ovl_dir_cache_free(inode);
 	mutex_destroy(&amp;oi-&gt;lock);
<span class="p_header">diff --git a/fs/overlayfs/util.c b/fs/overlayfs/util.c</span>
<span class="p_header">index b9b239fa5cfd..f60ce2e04df0 100644</span>
<span class="p_header">--- a/fs/overlayfs/util.c</span>
<span class="p_header">+++ b/fs/overlayfs/util.c</span>
<span class="p_chunk">@@ -253,7 +253,7 @@</span> <span class="p_context"> void ovl_inode_init(struct inode *inode, struct dentry *upperdentry,</span>
 	if (upperdentry)
 		OVL_I(inode)-&gt;__upperdentry = upperdentry;
 	if (lowerdentry)
<span class="p_del">-		OVL_I(inode)-&gt;lower = d_inode(lowerdentry);</span>
<span class="p_add">+		OVL_I(inode)-&gt;lower = igrab(d_inode(lowerdentry));</span>
 
 	ovl_copyattr(d_inode(upperdentry ?: lowerdentry), inode);
 }
<span class="p_chunk">@@ -269,7 +269,7 @@</span> <span class="p_context"> void ovl_inode_update(struct inode *inode, struct dentry *upperdentry)</span>
 	 */
 	smp_wmb();
 	OVL_I(inode)-&gt;__upperdentry = upperdentry;
<span class="p_del">-	if (!S_ISDIR(upperinode-&gt;i_mode) &amp;&amp; inode_unhashed(inode)) {</span>
<span class="p_add">+	if (inode_unhashed(inode)) {</span>
 		inode-&gt;i_private = upperinode;
 		__insert_inode_hash(inode, (unsigned long) upperinode);
 	}
<span class="p_header">diff --git a/fs/seq_file.c b/fs/seq_file.c</span>
<span class="p_header">index 4be761c1a03d..eea09f6d8830 100644</span>
<span class="p_header">--- a/fs/seq_file.c</span>
<span class="p_header">+++ b/fs/seq_file.c</span>
<span class="p_chunk">@@ -181,8 +181,11 @@</span> <span class="p_context"> ssize_t seq_read(struct file *file, char __user *buf, size_t size, loff_t *ppos)</span>
 	 * if request is to read from zero offset, reset iterator to first
 	 * record as it might have been already advanced by previous requests
 	 */
<span class="p_del">-	if (*ppos == 0)</span>
<span class="p_add">+	if (*ppos == 0) {</span>
 		m-&gt;index = 0;
<span class="p_add">+		m-&gt;version = 0;</span>
<span class="p_add">+		m-&gt;count = 0;</span>
<span class="p_add">+	}</span>
 
 	/* Don&#39;t assume *ppos is where we left it */
 	if (unlikely(*ppos != m-&gt;read_pos)) {
<span class="p_header">diff --git a/include/drm/i915_pciids.h b/include/drm/i915_pciids.h</span>
<span class="p_header">index 34c8f5600ce0..c65e4489006d 100644</span>
<span class="p_header">--- a/include/drm/i915_pciids.h</span>
<span class="p_header">+++ b/include/drm/i915_pciids.h</span>
<span class="p_chunk">@@ -118,92 +118,125 @@</span> <span class="p_context"></span>
 #define INTEL_IRONLAKE_M_IDS(info) \
 	INTEL_VGA_DEVICE(0x0046, info)
 
<span class="p_del">-#define INTEL_SNB_D_IDS(info) \</span>
<span class="p_add">+#define INTEL_SNB_D_GT1_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x0102, info), \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0112, info), \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0122, info), \</span>
 	INTEL_VGA_DEVICE(0x010A, info)
 
<span class="p_del">-#define INTEL_SNB_M_IDS(info) \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0106, info), \</span>
<span class="p_add">+#define INTEL_SNB_D_GT2_IDS(info) \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0112, info), \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0122, info)</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_SNB_D_IDS(info) \</span>
<span class="p_add">+	INTEL_SNB_D_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_SNB_D_GT2_IDS(info)</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_SNB_M_GT1_IDS(info) \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0106, info)</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_SNB_M_GT2_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x0116, info), \
 	INTEL_VGA_DEVICE(0x0126, info)
 
<span class="p_add">+#define INTEL_SNB_M_IDS(info) \</span>
<span class="p_add">+	INTEL_SNB_M_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_SNB_M_GT2_IDS(info)</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_IVB_M_GT1_IDS(info) \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0156, info) /* GT1 mobile */</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_IVB_M_GT2_IDS(info) \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0166, info) /* GT2 mobile */</span>
<span class="p_add">+</span>
 #define INTEL_IVB_M_IDS(info) \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0156, info), /* GT1 mobile */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0166, info)  /* GT2 mobile */</span>
<span class="p_add">+	INTEL_IVB_M_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_IVB_M_GT2_IDS(info)</span>
 
<span class="p_del">-#define INTEL_IVB_D_IDS(info) \</span>
<span class="p_add">+#define INTEL_IVB_D_GT1_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x0152, info), /* GT1 desktop */ \
<span class="p_add">+	INTEL_VGA_DEVICE(0x015a, info)  /* GT1 server */</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_IVB_D_GT2_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x0162, info), /* GT2 desktop */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x015a, info), /* GT1 server */ \</span>
 	INTEL_VGA_DEVICE(0x016a, info)  /* GT2 server */
 
<span class="p_add">+#define INTEL_IVB_D_IDS(info) \</span>
<span class="p_add">+	INTEL_IVB_D_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_IVB_D_GT2_IDS(info)</span>
<span class="p_add">+</span>
 #define INTEL_IVB_Q_IDS(info) \
 	INTEL_QUANTA_VGA_DEVICE(info) /* Quanta transcode */
 
<span class="p_del">-#define INTEL_HSW_IDS(info) \</span>
<span class="p_add">+#define INTEL_HSW_GT1_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x0402, info), /* GT1 desktop */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0412, info), /* GT2 desktop */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0422, info), /* GT3 desktop */ \</span>
 	INTEL_VGA_DEVICE(0x040a, info), /* GT1 server */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x041a, info), /* GT2 server */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x042a, info), /* GT3 server */ \</span>
 	INTEL_VGA_DEVICE(0x040B, info), /* GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x041B, info), /* GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x042B, info), /* GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x040E, info), /* GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x041E, info), /* GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x042E, info), /* GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0C02, info), /* SDV GT1 desktop */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C12, info), /* SDV GT2 desktop */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C22, info), /* SDV GT3 desktop */ \</span>
 	INTEL_VGA_DEVICE(0x0C0A, info), /* SDV GT1 server */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C1A, info), /* SDV GT2 server */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C2A, info), /* SDV GT3 server */ \</span>
 	INTEL_VGA_DEVICE(0x0C0B, info), /* SDV GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C1B, info), /* SDV GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C2B, info), /* SDV GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0C0E, info), /* SDV GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C1E, info), /* SDV GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C2E, info), /* SDV GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0A02, info), /* ULT GT1 desktop */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A12, info), /* ULT GT2 desktop */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A22, info), /* ULT GT3 desktop */ \</span>
 	INTEL_VGA_DEVICE(0x0A0A, info), /* ULT GT1 server */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A1A, info), /* ULT GT2 server */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A2A, info), /* ULT GT3 server */ \</span>
 	INTEL_VGA_DEVICE(0x0A0B, info), /* ULT GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A1B, info), /* ULT GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A2B, info), /* ULT GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0D02, info), /* CRW GT1 desktop */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D12, info), /* CRW GT2 desktop */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D22, info), /* CRW GT3 desktop */ \</span>
 	INTEL_VGA_DEVICE(0x0D0A, info), /* CRW GT1 server */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D1A, info), /* CRW GT2 server */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D2A, info), /* CRW GT3 server */ \</span>
 	INTEL_VGA_DEVICE(0x0D0B, info), /* CRW GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D1B, info), /* CRW GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D2B, info), /* CRW GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0D0E, info), /* CRW GT1 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D1E, info), /* CRW GT2 reserved */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D2E, info),  /* CRW GT3 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0406, info), /* GT1 mobile */ \
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C06, info), /* SDV GT1 mobile */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A06, info), /* ULT GT1 mobile */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A0E, info), /* ULX GT1 mobile */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D06, info)  /* CRW GT1 mobile */</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_HSW_GT2_IDS(info) \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0412, info), /* GT2 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x041a, info), /* GT2 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x041B, info), /* GT2 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x041E, info), /* GT2 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C12, info), /* SDV GT2 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C1A, info), /* SDV GT2 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C1B, info), /* SDV GT2 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C1E, info), /* SDV GT2 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A12, info), /* ULT GT2 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A1A, info), /* ULT GT2 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A1B, info), /* ULT GT2 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D12, info), /* CRW GT2 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D1A, info), /* CRW GT2 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D1B, info), /* CRW GT2 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D1E, info), /* CRW GT2 reserved */ \</span>
 	INTEL_VGA_DEVICE(0x0416, info), /* GT2 mobile */ \
 	INTEL_VGA_DEVICE(0x0426, info), /* GT2 mobile */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C06, info), /* SDV GT1 mobile */ \</span>
 	INTEL_VGA_DEVICE(0x0C16, info), /* SDV GT2 mobile */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0C26, info), /* SDV GT3 mobile */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A06, info), /* ULT GT1 mobile */ \</span>
 	INTEL_VGA_DEVICE(0x0A16, info), /* ULT GT2 mobile */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A26, info), /* ULT GT3 mobile */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0A0E, info), /* ULX GT1 mobile */ \</span>
 	INTEL_VGA_DEVICE(0x0A1E, info), /* ULX GT2 mobile */ \
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D16, info)  /* CRW GT2 mobile */</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_HSW_GT3_IDS(info) \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0422, info), /* GT3 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x042a, info), /* GT3 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x042B, info), /* GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x042E, info), /* GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C22, info), /* SDV GT3 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C2A, info), /* SDV GT3 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C2B, info), /* SDV GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C2E, info), /* SDV GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A22, info), /* ULT GT3 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A2A, info), /* ULT GT3 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A2B, info), /* ULT GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D22, info), /* CRW GT3 desktop */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D2A, info), /* CRW GT3 server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D2B, info), /* CRW GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0D2E, info), /* CRW GT3 reserved */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0C26, info), /* SDV GT3 mobile */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x0A26, info), /* ULT GT3 mobile */ \</span>
 	INTEL_VGA_DEVICE(0x0A2E, info), /* ULT GT3 reserved */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D06, info), /* CRW GT1 mobile */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x0D16, info), /* CRW GT2 mobile */ \</span>
 	INTEL_VGA_DEVICE(0x0D26, info)  /* CRW GT3 mobile */
 
<span class="p_add">+#define INTEL_HSW_IDS(info) \</span>
<span class="p_add">+	INTEL_HSW_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_HSW_GT2_IDS(info), \</span>
<span class="p_add">+	INTEL_HSW_GT3_IDS(info)</span>
<span class="p_add">+</span>
 #define INTEL_VLV_IDS(info) \
 	INTEL_VGA_DEVICE(0x0f30, info), \
 	INTEL_VGA_DEVICE(0x0f31, info), \
<span class="p_chunk">@@ -212,17 +245,19 @@</span> <span class="p_context"></span>
 	INTEL_VGA_DEVICE(0x0157, info), \
 	INTEL_VGA_DEVICE(0x0155, info)
 
<span class="p_del">-#define INTEL_BDW_GT12_IDS(info)  \</span>
<span class="p_add">+#define INTEL_BDW_GT1_IDS(info)  \</span>
 	INTEL_VGA_DEVICE(0x1602, info), /* GT1 ULT */ \
 	INTEL_VGA_DEVICE(0x1606, info), /* GT1 ULT */ \
 	INTEL_VGA_DEVICE(0x160B, info), /* GT1 Iris */ \
 	INTEL_VGA_DEVICE(0x160E, info), /* GT1 ULX */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x1612, info), /* GT2 Halo */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x160A, info), /* GT1 Server */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x160D, info)  /* GT1 Workstation */</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_BDW_GT2_IDS(info)  \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x1612, info), /* GT2 Halo */	\</span>
 	INTEL_VGA_DEVICE(0x1616, info), /* GT2 ULT */ \
 	INTEL_VGA_DEVICE(0x161B, info), /* GT2 ULT */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x161E, info),  /* GT2 ULX */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x160A, info), /* GT1 Server */ \</span>
<span class="p_del">-	INTEL_VGA_DEVICE(0x160D, info), /* GT1 Workstation */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x161E, info), /* GT2 ULX */ \</span>
 	INTEL_VGA_DEVICE(0x161A, info), /* GT2 Server */ \
 	INTEL_VGA_DEVICE(0x161D, info)  /* GT2 Workstation */
 
<span class="p_chunk">@@ -243,7 +278,8 @@</span> <span class="p_context"></span>
 	INTEL_VGA_DEVICE(0x163D, info)  /* Workstation */
 
 #define INTEL_BDW_IDS(info) \
<span class="p_del">-	INTEL_BDW_GT12_IDS(info), \</span>
<span class="p_add">+	INTEL_BDW_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_BDW_GT2_IDS(info), \</span>
 	INTEL_BDW_GT3_IDS(info), \
 	INTEL_BDW_RSVD_IDS(info)
 
<span class="p_chunk">@@ -303,7 +339,6 @@</span> <span class="p_context"></span>
 #define INTEL_KBL_GT1_IDS(info)	\
 	INTEL_VGA_DEVICE(0x5913, info), /* ULT GT1.5 */ \
 	INTEL_VGA_DEVICE(0x5915, info), /* ULX GT1.5 */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x5917, info), /* DT  GT1.5 */ \</span>
 	INTEL_VGA_DEVICE(0x5906, info), /* ULT GT1 */ \
 	INTEL_VGA_DEVICE(0x590E, info), /* ULX GT1 */ \
 	INTEL_VGA_DEVICE(0x5902, info), /* DT  GT1 */ \
<span class="p_chunk">@@ -313,6 +348,7 @@</span> <span class="p_context"></span>
 
 #define INTEL_KBL_GT2_IDS(info)	\
 	INTEL_VGA_DEVICE(0x5916, info), /* ULT GT2 */ \
<span class="p_add">+	INTEL_VGA_DEVICE(0x5917, info), /* Mobile GT2 */ \</span>
 	INTEL_VGA_DEVICE(0x5921, info), /* ULT GT2F */ \
 	INTEL_VGA_DEVICE(0x591E, info), /* ULX GT2 */ \
 	INTEL_VGA_DEVICE(0x5912, info), /* DT  GT2 */ \
<span class="p_chunk">@@ -335,25 +371,33 @@</span> <span class="p_context"></span>
 	INTEL_KBL_GT4_IDS(info)
 
 /* CFL S */
<span class="p_del">-#define INTEL_CFL_S_IDS(info) \</span>
<span class="p_add">+#define INTEL_CFL_S_GT1_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x3E90, info), /* SRV GT1 */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x3E93, info), /* SRV GT1 */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x3E93, info)  /* SRV GT1 */</span>
<span class="p_add">+</span>
<span class="p_add">+#define INTEL_CFL_S_GT2_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x3E91, info), /* SRV GT2 */ \
 	INTEL_VGA_DEVICE(0x3E92, info), /* SRV GT2 */ \
 	INTEL_VGA_DEVICE(0x3E96, info)  /* SRV GT2 */
 
 /* CFL H */
<span class="p_del">-#define INTEL_CFL_H_IDS(info) \</span>
<span class="p_add">+#define INTEL_CFL_H_GT2_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x3E9B, info), /* Halo GT2 */ \
 	INTEL_VGA_DEVICE(0x3E94, info)  /* Halo GT2 */
 
 /* CFL U */
<span class="p_del">-#define INTEL_CFL_U_IDS(info) \</span>
<span class="p_add">+#define INTEL_CFL_U_GT3_IDS(info) \</span>
 	INTEL_VGA_DEVICE(0x3EA6, info), /* ULT GT3 */ \
 	INTEL_VGA_DEVICE(0x3EA7, info), /* ULT GT3 */ \
 	INTEL_VGA_DEVICE(0x3EA8, info), /* ULT GT3 */ \
 	INTEL_VGA_DEVICE(0x3EA5, info)  /* ULT GT3 */
 
<span class="p_add">+#define INTEL_CFL_IDS(info) \</span>
<span class="p_add">+	INTEL_CFL_S_GT1_IDS(info), \</span>
<span class="p_add">+	INTEL_CFL_S_GT2_IDS(info), \</span>
<span class="p_add">+	INTEL_CFL_H_GT2_IDS(info), \</span>
<span class="p_add">+	INTEL_CFL_U_GT3_IDS(info)</span>
<span class="p_add">+</span>
 /* CNL U 2+2 */
 #define INTEL_CNL_U_GT2_IDS(info) \
 	INTEL_VGA_DEVICE(0x5A52, info), \
<span class="p_header">diff --git a/include/linux/c2port.h b/include/linux/c2port.h</span>
<span class="p_header">index 4efabcb51347..f2736348ca26 100644</span>
<span class="p_header">--- a/include/linux/c2port.h</span>
<span class="p_header">+++ b/include/linux/c2port.h</span>
<span class="p_chunk">@@ -9,8 +9,6 @@</span> <span class="p_context"></span>
  * the Free Software Foundation
  */
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-</span>
 #define C2PORT_NAME_LEN			32
 
 struct device;
<span class="p_chunk">@@ -22,10 +20,8 @@</span> <span class="p_context"> struct device;</span>
 /* Main struct */
 struct c2port_ops;
 struct c2port_device {
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	unsigned int access:1;
 	unsigned int flash_access:1;
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 
 	int id;
 	char name[C2PORT_NAME_LEN];
<span class="p_header">diff --git a/include/linux/compiler-gcc.h b/include/linux/compiler-gcc.h</span>
<span class="p_header">index 2272ded07496..bf09213895f7 100644</span>
<span class="p_header">--- a/include/linux/compiler-gcc.h</span>
<span class="p_header">+++ b/include/linux/compiler-gcc.h</span>
<span class="p_chunk">@@ -167,8 +167,6 @@</span> <span class="p_context"></span>
 
 #if GCC_VERSION &gt;= 40100
 # define __compiletime_object_size(obj) __builtin_object_size(obj, 0)
<span class="p_del">-</span>
<span class="p_del">-#define __nostackprotector	__attribute__((__optimize__(&quot;no-stack-protector&quot;)))</span>
 #endif
 
 #if GCC_VERSION &gt;= 40300
<span class="p_chunk">@@ -196,6 +194,11 @@</span> <span class="p_context"></span>
 #endif /* __CHECKER__ */
 #endif /* GCC_VERSION &gt;= 40300 */
 
<span class="p_add">+#if GCC_VERSION &gt;= 40400</span>
<span class="p_add">+#define __optimize(level)	__attribute__((__optimize__(level)))</span>
<span class="p_add">+#define __nostackprotector	__optimize(&quot;no-stack-protector&quot;)</span>
<span class="p_add">+#endif /* GCC_VERSION &gt;= 40400 */</span>
<span class="p_add">+</span>
 #if GCC_VERSION &gt;= 40500
 
 #ifndef __CHECKER__
<span class="p_header">diff --git a/include/linux/compiler.h b/include/linux/compiler.h</span>
<span class="p_header">index fab5dc250c61..e8c9cd18bb05 100644</span>
<span class="p_header">--- a/include/linux/compiler.h</span>
<span class="p_header">+++ b/include/linux/compiler.h</span>
<span class="p_chunk">@@ -266,6 +266,10 @@</span> <span class="p_context"> static __always_inline void __write_once_size(volatile void *p, void *res, int s</span>
 
 #endif /* __ASSEMBLY__ */
 
<span class="p_add">+#ifndef __optimize</span>
<span class="p_add">+# define __optimize(level)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 /* Compile time object size, -1 for unknown */
 #ifndef __compiletime_object_size
 # define __compiletime_object_size(obj) -1
<span class="p_header">diff --git a/include/linux/cpuidle.h b/include/linux/cpuidle.h</span>
<span class="p_header">index 8f7788d23b57..a6989e02d0a0 100644</span>
<span class="p_header">--- a/include/linux/cpuidle.h</span>
<span class="p_header">+++ b/include/linux/cpuidle.h</span>
<span class="p_chunk">@@ -225,7 +225,7 @@</span> <span class="p_context"> static inline void cpuidle_coupled_parallel_barrier(struct cpuidle_device *dev,</span>
 }
 #endif
 
<span class="p_del">-#ifdef CONFIG_ARCH_HAS_CPU_RELAX</span>
<span class="p_add">+#if defined(CONFIG_CPU_IDLE) &amp;&amp; defined(CONFIG_ARCH_HAS_CPU_RELAX)</span>
 void cpuidle_poll_state_init(struct cpuidle_driver *drv);
 #else
 static inline void cpuidle_poll_state_init(struct cpuidle_driver *drv) {}
<span class="p_header">diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="p_header">index 46930f82a988..7bf3b99e6fbb 100644</span>
<span class="p_header">--- a/include/linux/dma-mapping.h</span>
<span class="p_header">+++ b/include/linux/dma-mapping.h</span>
<span class="p_chunk">@@ -9,7 +9,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;linux/dma-direction.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/bug.h&gt;
 #include &lt;linux/mem_encrypt.h&gt;
 
<span class="p_chunk">@@ -230,7 +229,6 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
 
<span class="p_del">-	kmemcheck_mark_initialized(ptr, size);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	addr = ops-&gt;map_page(dev, virt_to_page(ptr),
 			     offset_in_page(ptr), size,
<span class="p_chunk">@@ -263,11 +261,8 @@</span> <span class="p_context"> static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
 				   unsigned long attrs)
 {
 	const struct dma_map_ops *ops = get_dma_ops(dev);
<span class="p_del">-	int i, ents;</span>
<span class="p_del">-	struct scatterlist *s;</span>
<span class="p_add">+	int ents;</span>
 
<span class="p_del">-	for_each_sg(sg, s, nents, i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(sg_virt(s), s-&gt;length);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	ents = ops-&gt;map_sg(dev, sg, nents, dir, attrs);
 	BUG_ON(ents &lt; 0);
<span class="p_chunk">@@ -297,7 +292,6 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_page_attrs(struct device *dev,</span>
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
 
<span class="p_del">-	kmemcheck_mark_initialized(page_address(page) + offset, size);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	addr = ops-&gt;map_page(dev, page, offset, size, dir, attrs);
 	debug_dma_map_page(dev, page, offset, size, dir, addr, false);
<span class="p_header">diff --git a/include/linux/filter.h b/include/linux/filter.h</span>
<span class="p_header">index 48ec57e70f9f..42197b16dd78 100644</span>
<span class="p_header">--- a/include/linux/filter.h</span>
<span class="p_header">+++ b/include/linux/filter.h</span>
<span class="p_chunk">@@ -454,13 +454,11 @@</span> <span class="p_context"> struct bpf_binary_header {</span>
 
 struct bpf_prog {
 	u16			pages;		/* Number of allocated pages */
<span class="p_del">-	kmemcheck_bitfield_begin(meta);</span>
 	u16			jited:1,	/* Is our filter JIT&#39;ed? */
 				locked:1,	/* Program image locked? */
 				gpl_compatible:1, /* Is filter GPL compatible? */
 				cb_access:1,	/* Is control block accessed? */
 				dst_needed:1;	/* Do we need dst entry? */
<span class="p_del">-	kmemcheck_bitfield_end(meta);</span>
 	enum bpf_prog_type	type;		/* Type of BPF program */
 	u32			len;		/* Number of filter blocks */
 	u32			jited_len;	/* Size of jited insns in bytes */
<span class="p_header">diff --git a/include/linux/gfp.h b/include/linux/gfp.h</span>
<span class="p_header">index 710143741eb5..b041f94678de 100644</span>
<span class="p_header">--- a/include/linux/gfp.h</span>
<span class="p_header">+++ b/include/linux/gfp.h</span>
<span class="p_chunk">@@ -37,7 +37,6 @@</span> <span class="p_context"> struct vm_area_struct;</span>
 #define ___GFP_THISNODE		0x40000u
 #define ___GFP_ATOMIC		0x80000u
 #define ___GFP_ACCOUNT		0x100000u
<span class="p_del">-#define ___GFP_NOTRACK		0x200000u</span>
 #define ___GFP_DIRECT_RECLAIM	0x400000u
 #define ___GFP_WRITE		0x800000u
 #define ___GFP_KSWAPD_RECLAIM	0x1000000u
<span class="p_chunk">@@ -201,19 +200,11 @@</span> <span class="p_context"> struct vm_area_struct;</span>
  * __GFP_COMP address compound page metadata.
  *
  * __GFP_ZERO returns a zeroed page on success.
<span class="p_del">- *</span>
<span class="p_del">- * __GFP_NOTRACK avoids tracking with kmemcheck.</span>
<span class="p_del">- *</span>
<span class="p_del">- * __GFP_NOTRACK_FALSE_POSITIVE is an alias of __GFP_NOTRACK. It&#39;s a means of</span>
<span class="p_del">- *   distinguishing in the source between false positives and allocations that</span>
<span class="p_del">- *   cannot be supported (e.g. page tables).</span>
  */
 #define __GFP_COLD	((__force gfp_t)___GFP_COLD)
 #define __GFP_NOWARN	((__force gfp_t)___GFP_NOWARN)
 #define __GFP_COMP	((__force gfp_t)___GFP_COMP)
 #define __GFP_ZERO	((__force gfp_t)___GFP_ZERO)
<span class="p_del">-#define __GFP_NOTRACK	((__force gfp_t)___GFP_NOTRACK)</span>
<span class="p_del">-#define __GFP_NOTRACK_FALSE_POSITIVE (__GFP_NOTRACK)</span>
 
 /* Disable lockdep for GFP context tracking */
 #define __GFP_NOLOCKDEP ((__force gfp_t)___GFP_NOLOCKDEP)
<span class="p_header">diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h</span>
<span class="p_header">index baeb872283d9..69c238210325 100644</span>
<span class="p_header">--- a/include/linux/interrupt.h</span>
<span class="p_header">+++ b/include/linux/interrupt.h</span>
<span class="p_chunk">@@ -594,21 +594,6 @@</span> <span class="p_context"> static inline void tasklet_hi_schedule(struct tasklet_struct *t)</span>
 		__tasklet_hi_schedule(t);
 }
 
<span class="p_del">-extern void __tasklet_hi_schedule_first(struct tasklet_struct *t);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This version avoids touching any other tasklets. Needed for kmemcheck</span>
<span class="p_del">- * in order not to take any page faults while enqueueing this tasklet;</span>
<span class="p_del">- * consider VERY carefully whether you really need this or</span>
<span class="p_del">- * tasklet_hi_schedule()...</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!test_and_set_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state))</span>
<span class="p_del">-		__tasklet_hi_schedule_first(t);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
 static inline void tasklet_disable_nosync(struct tasklet_struct *t)
 {
 	atomic_inc(&amp;t-&gt;count);
<span class="p_header">diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h</span>
<span class="p_header">index 606b6bce3a5b..29290bfb94a8 100644</span>
<span class="p_header">--- a/include/linux/jbd2.h</span>
<span class="p_header">+++ b/include/linux/jbd2.h</span>
<span class="p_chunk">@@ -418,26 +418,41 @@</span> <span class="p_context"> static inline void jbd_unlock_bh_journal_head(struct buffer_head *bh)</span>
 #define JI_WAIT_DATA (1 &lt;&lt; __JI_WAIT_DATA)
 
 /**
<span class="p_del">- * struct jbd_inode is the structure linking inodes in ordered mode</span>
<span class="p_del">- *   present in a transaction so that we can sync them during commit.</span>
<span class="p_add">+ * struct jbd_inode - The jbd_inode type is the structure linking inodes in</span>
<span class="p_add">+ * ordered mode present in a transaction so that we can sync them during commit.</span>
  */
 struct jbd2_inode {
<span class="p_del">-	/* Which transaction does this inode belong to? Either the running</span>
<span class="p_del">-	 * transaction or the committing one. [j_list_lock] */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @i_transaction:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Which transaction does this inode belong to? Either the running</span>
<span class="p_add">+	 * transaction or the committing one. [j_list_lock]</span>
<span class="p_add">+	 */</span>
 	transaction_t *i_transaction;
 
<span class="p_del">-	/* Pointer to the running transaction modifying inode&#39;s data in case</span>
<span class="p_del">-	 * there is already a committing transaction touching it. [j_list_lock] */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @i_next_transaction:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Pointer to the running transaction modifying inode&#39;s data in case</span>
<span class="p_add">+	 * there is already a committing transaction touching it. [j_list_lock]</span>
<span class="p_add">+	 */</span>
 	transaction_t *i_next_transaction;
 
<span class="p_del">-	/* List of inodes in the i_transaction [j_list_lock] */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @i_list: List of inodes in the i_transaction [j_list_lock]</span>
<span class="p_add">+	 */</span>
 	struct list_head i_list;
 
<span class="p_del">-	/* VFS inode this inode belongs to [constant during the lifetime</span>
<span class="p_del">-	 * of the structure] */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @i_vfs_inode:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * VFS inode this inode belongs to [constant for lifetime of structure]</span>
<span class="p_add">+	 */</span>
 	struct inode *i_vfs_inode;
 
<span class="p_del">-	/* Flags of inode [j_list_lock] */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @i_flags: Flags of inode [j_list_lock]</span>
<span class="p_add">+	 */</span>
 	unsigned long i_flags;
 };
 
<span class="p_chunk">@@ -447,12 +462,20 @@</span> <span class="p_context"> struct jbd2_revoke_table_s;</span>
  * struct handle_s - The handle_s type is the concrete type associated with
  *     handle_t.
  * @h_transaction: Which compound transaction is this update a part of?
<span class="p_add">+ * @h_journal: Which journal handle belongs to - used iff h_reserved set.</span>
<span class="p_add">+ * @h_rsv_handle: Handle reserved for finishing the logical operation.</span>
  * @h_buffer_credits: Number of remaining buffers we are allowed to dirty.
<span class="p_del">- * @h_ref: Reference count on this handle</span>
<span class="p_del">- * @h_err: Field for caller&#39;s use to track errors through large fs operations</span>
<span class="p_del">- * @h_sync: flag for sync-on-close</span>
<span class="p_del">- * @h_jdata: flag to force data journaling</span>
<span class="p_del">- * @h_aborted: flag indicating fatal error on handle</span>
<span class="p_add">+ * @h_ref: Reference count on this handle.</span>
<span class="p_add">+ * @h_err: Field for caller&#39;s use to track errors through large fs operations.</span>
<span class="p_add">+ * @h_sync: Flag for sync-on-close.</span>
<span class="p_add">+ * @h_jdata: Flag to force data journaling.</span>
<span class="p_add">+ * @h_reserved: Flag for handle for reserved credits.</span>
<span class="p_add">+ * @h_aborted: Flag indicating fatal error on handle.</span>
<span class="p_add">+ * @h_type: For handle statistics.</span>
<span class="p_add">+ * @h_line_no: For handle statistics.</span>
<span class="p_add">+ * @h_start_jiffies: Handle Start time.</span>
<span class="p_add">+ * @h_requested_credits: Holds @h_buffer_credits after handle is started.</span>
<span class="p_add">+ * @saved_alloc_context: Saved context while transaction is open.</span>
  **/
 
 /* Docbook can&#39;t yet cope with the bit fields, but will leave the documentation
<span class="p_chunk">@@ -462,32 +485,23 @@</span> <span class="p_context"> struct jbd2_revoke_table_s;</span>
 struct jbd2_journal_handle
 {
 	union {
<span class="p_del">-		/* Which compound transaction is this update a part of? */</span>
 		transaction_t	*h_transaction;
 		/* Which journal handle belongs to - used iff h_reserved set */
 		journal_t	*h_journal;
 	};
 
<span class="p_del">-	/* Handle reserved for finishing the logical operation */</span>
 	handle_t		*h_rsv_handle;
<span class="p_del">-</span>
<span class="p_del">-	/* Number of remaining buffers we are allowed to dirty: */</span>
 	int			h_buffer_credits;
<span class="p_del">-</span>
<span class="p_del">-	/* Reference count on this handle */</span>
 	int			h_ref;
<span class="p_del">-</span>
<span class="p_del">-	/* Field for caller&#39;s use to track errors through large fs */</span>
<span class="p_del">-	/* operations */</span>
 	int			h_err;
 
 	/* Flags [no locking] */
<span class="p_del">-	unsigned int	h_sync:		1;	/* sync-on-close */</span>
<span class="p_del">-	unsigned int	h_jdata:	1;	/* force data journaling */</span>
<span class="p_del">-	unsigned int	h_reserved:	1;	/* handle with reserved credits */</span>
<span class="p_del">-	unsigned int	h_aborted:	1;	/* fatal error on handle */</span>
<span class="p_del">-	unsigned int	h_type:		8;	/* for handle statistics */</span>
<span class="p_del">-	unsigned int	h_line_no:	16;	/* for handle statistics */</span>
<span class="p_add">+	unsigned int	h_sync:		1;</span>
<span class="p_add">+	unsigned int	h_jdata:	1;</span>
<span class="p_add">+	unsigned int	h_reserved:	1;</span>
<span class="p_add">+	unsigned int	h_aborted:	1;</span>
<span class="p_add">+	unsigned int	h_type:		8;</span>
<span class="p_add">+	unsigned int	h_line_no:	16;</span>
 
 	unsigned long		h_start_jiffies;
 	unsigned int		h_requested_credits;
<span class="p_chunk">@@ -729,228 +743,253 @@</span> <span class="p_context"> jbd2_time_diff(unsigned long start, unsigned long end)</span>
 /**
  * struct journal_s - The journal_s type is the concrete type associated with
  *     journal_t.
<span class="p_del">- * @j_flags:  General journaling state flags</span>
<span class="p_del">- * @j_errno:  Is there an outstanding uncleared error on the journal (from a</span>
<span class="p_del">- *     prior abort)?</span>
<span class="p_del">- * @j_sb_buffer: First part of superblock buffer</span>
<span class="p_del">- * @j_superblock: Second part of superblock buffer</span>
<span class="p_del">- * @j_format_version: Version of the superblock format</span>
<span class="p_del">- * @j_state_lock: Protect the various scalars in the journal</span>
<span class="p_del">- * @j_barrier_count:  Number of processes waiting to create a barrier lock</span>
<span class="p_del">- * @j_barrier: The barrier lock itself</span>
<span class="p_del">- * @j_running_transaction: The current running transaction..</span>
<span class="p_del">- * @j_committing_transaction: the transaction we are pushing to disk</span>
<span class="p_del">- * @j_checkpoint_transactions: a linked circular list of all transactions</span>
<span class="p_del">- *  waiting for checkpointing</span>
<span class="p_del">- * @j_wait_transaction_locked: Wait queue for waiting for a locked transaction</span>
<span class="p_del">- *  to start committing, or for a barrier lock to be released</span>
<span class="p_del">- * @j_wait_done_commit: Wait queue for waiting for commit to complete</span>
<span class="p_del">- * @j_wait_commit: Wait queue to trigger commit</span>
<span class="p_del">- * @j_wait_updates: Wait queue to wait for updates to complete</span>
<span class="p_del">- * @j_wait_reserved: Wait queue to wait for reserved buffer credits to drop</span>
<span class="p_del">- * @j_checkpoint_mutex: Mutex for locking against concurrent checkpoints</span>
<span class="p_del">- * @j_head: Journal head - identifies the first unused block in the journal</span>
<span class="p_del">- * @j_tail: Journal tail - identifies the oldest still-used block in the</span>
<span class="p_del">- *  journal.</span>
<span class="p_del">- * @j_free: Journal free - how many free blocks are there in the journal?</span>
<span class="p_del">- * @j_first: The block number of the first usable block</span>
<span class="p_del">- * @j_last: The block number one beyond the last usable block</span>
<span class="p_del">- * @j_dev: Device where we store the journal</span>
<span class="p_del">- * @j_blocksize: blocksize for the location where we store the journal.</span>
<span class="p_del">- * @j_blk_offset: starting block offset for into the device where we store the</span>
<span class="p_del">- *     journal</span>
<span class="p_del">- * @j_fs_dev: Device which holds the client fs.  For internal journal this will</span>
<span class="p_del">- *     be equal to j_dev</span>
<span class="p_del">- * @j_reserved_credits: Number of buffers reserved from the running transaction</span>
<span class="p_del">- * @j_maxlen: Total maximum capacity of the journal region on disk.</span>
<span class="p_del">- * @j_list_lock: Protects the buffer lists and internal buffer state.</span>
<span class="p_del">- * @j_inode: Optional inode where we store the journal.  If present, all journal</span>
<span class="p_del">- *     block numbers are mapped into this inode via bmap().</span>
<span class="p_del">- * @j_tail_sequence:  Sequence number of the oldest transaction in the log</span>
<span class="p_del">- * @j_transaction_sequence: Sequence number of the next transaction to grant</span>
<span class="p_del">- * @j_commit_sequence: Sequence number of the most recently committed</span>
<span class="p_del">- *  transaction</span>
<span class="p_del">- * @j_commit_request: Sequence number of the most recent transaction wanting</span>
<span class="p_del">- *     commit</span>
<span class="p_del">- * @j_uuid: Uuid of client object.</span>
<span class="p_del">- * @j_task: Pointer to the current commit thread for this journal</span>
<span class="p_del">- * @j_max_transaction_buffers:  Maximum number of metadata buffers to allow in a</span>
<span class="p_del">- *     single compound commit transaction</span>
<span class="p_del">- * @j_commit_interval: What is the maximum transaction lifetime before we begin</span>
<span class="p_del">- *  a commit?</span>
<span class="p_del">- * @j_commit_timer:  The timer used to wakeup the commit thread</span>
<span class="p_del">- * @j_revoke_lock: Protect the revoke table</span>
<span class="p_del">- * @j_revoke: The revoke table - maintains the list of revoked blocks in the</span>
<span class="p_del">- *     current transaction.</span>
<span class="p_del">- * @j_revoke_table: alternate revoke tables for j_revoke</span>
<span class="p_del">- * @j_wbuf: array of buffer_heads for jbd2_journal_commit_transaction</span>
<span class="p_del">- * @j_wbufsize: maximum number of buffer_heads allowed in j_wbuf, the</span>
<span class="p_del">- *	number that will fit in j_blocksize</span>
<span class="p_del">- * @j_last_sync_writer: most recent pid which did a synchronous write</span>
<span class="p_del">- * @j_history_lock: Protect the transactions statistics history</span>
<span class="p_del">- * @j_proc_entry: procfs entry for the jbd statistics directory</span>
<span class="p_del">- * @j_stats: Overall statistics</span>
<span class="p_del">- * @j_private: An opaque pointer to fs-private information.</span>
<span class="p_del">- * @j_trans_commit_map: Lockdep entity to track transaction commit dependencies</span>
  */
<span class="p_del">-</span>
 struct journal_s
 {
<span class="p_del">-	/* General journaling state flags [j_state_lock] */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_flags: General journaling state flags [j_state_lock]</span>
<span class="p_add">+	 */</span>
 	unsigned long		j_flags;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_errno:</span>
<span class="p_add">+	 *</span>
 	 * Is there an outstanding uncleared error on the journal (from a prior
 	 * abort)? [j_state_lock]
 	 */
 	int			j_errno;
 
<span class="p_del">-	/* The superblock buffer */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_sb_buffer: The first part of the superblock buffer.</span>
<span class="p_add">+	 */</span>
 	struct buffer_head	*j_sb_buffer;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_superblock: The second part of the superblock buffer.</span>
<span class="p_add">+	 */</span>
 	journal_superblock_t	*j_superblock;
 
<span class="p_del">-	/* Version of the superblock format */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_format_version: Version of the superblock format.</span>
<span class="p_add">+	 */</span>
 	int			j_format_version;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Protect the various scalars in the journal</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_state_lock: Protect the various scalars in the journal.</span>
 	 */
 	rwlock_t		j_state_lock;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_barrier_count:</span>
<span class="p_add">+	 *</span>
 	 * Number of processes waiting to create a barrier lock [j_state_lock]
 	 */
 	int			j_barrier_count;
 
<span class="p_del">-	/* The barrier lock itself */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_barrier: The barrier lock itself.</span>
<span class="p_add">+	 */</span>
 	struct mutex		j_barrier;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_running_transaction:</span>
<span class="p_add">+	 *</span>
 	 * Transactions: The current running transaction...
 	 * [j_state_lock] [caller holding open handle]
 	 */
 	transaction_t		*j_running_transaction;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_committing_transaction:</span>
<span class="p_add">+	 *</span>
 	 * the transaction we are pushing to disk
 	 * [j_state_lock] [caller holding open handle]
 	 */
 	transaction_t		*j_committing_transaction;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_checkpoint_transactions:</span>
<span class="p_add">+	 *</span>
 	 * ... and a linked circular list of all transactions waiting for
 	 * checkpointing. [j_list_lock]
 	 */
 	transaction_t		*j_checkpoint_transactions;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wait_transaction_locked:</span>
<span class="p_add">+	 *</span>
 	 * Wait queue for waiting for a locked transaction to start committing,
<span class="p_del">-	 * or for a barrier lock to be released</span>
<span class="p_add">+	 * or for a barrier lock to be released.</span>
 	 */
 	wait_queue_head_t	j_wait_transaction_locked;
 
<span class="p_del">-	/* Wait queue for waiting for commit to complete */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wait_done_commit: Wait queue for waiting for commit to complete.</span>
<span class="p_add">+	 */</span>
 	wait_queue_head_t	j_wait_done_commit;
 
<span class="p_del">-	/* Wait queue to trigger commit */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wait_commit: Wait queue to trigger commit.</span>
<span class="p_add">+	 */</span>
 	wait_queue_head_t	j_wait_commit;
 
<span class="p_del">-	/* Wait queue to wait for updates to complete */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wait_updates: Wait queue to wait for updates to complete.</span>
<span class="p_add">+	 */</span>
 	wait_queue_head_t	j_wait_updates;
 
<span class="p_del">-	/* Wait queue to wait for reserved buffer credits to drop */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wait_reserved:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Wait queue to wait for reserved buffer credits to drop.</span>
<span class="p_add">+	 */</span>
 	wait_queue_head_t	j_wait_reserved;
 
<span class="p_del">-	/* Semaphore for locking against concurrent checkpoints */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_checkpoint_mutex:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Semaphore for locking against concurrent checkpoints.</span>
<span class="p_add">+	 */</span>
 	struct mutex		j_checkpoint_mutex;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_chkpt_bhs:</span>
<span class="p_add">+	 *</span>
 	 * List of buffer heads used by the checkpoint routine.  This
 	 * was moved from jbd2_log_do_checkpoint() to reduce stack
 	 * usage.  Access to this array is controlled by the
<span class="p_del">-	 * j_checkpoint_mutex.  [j_checkpoint_mutex]</span>
<span class="p_add">+	 * @j_checkpoint_mutex.  [j_checkpoint_mutex]</span>
 	 */
 	struct buffer_head	*j_chkpt_bhs[JBD2_NR_BATCH];
<span class="p_del">-	</span>
<span class="p_del">-	/*</span>
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_head:</span>
<span class="p_add">+	 *</span>
 	 * Journal head: identifies the first unused block in the journal.
 	 * [j_state_lock]
 	 */
 	unsigned long		j_head;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_tail:</span>
<span class="p_add">+	 *</span>
 	 * Journal tail: identifies the oldest still-used block in the journal.
 	 * [j_state_lock]
 	 */
 	unsigned long		j_tail;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_free:</span>
<span class="p_add">+	 *</span>
 	 * Journal free: how many free blocks are there in the journal?
 	 * [j_state_lock]
 	 */
 	unsigned long		j_free;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Journal start and end: the block numbers of the first usable block</span>
<span class="p_del">-	 * and one beyond the last usable block in the journal. [j_state_lock]</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_first:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The block number of the first usable block in the journal</span>
<span class="p_add">+	 * [j_state_lock].</span>
 	 */
 	unsigned long		j_first;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_last:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The block number one beyond the last usable block in the journal</span>
<span class="p_add">+	 * [j_state_lock].</span>
<span class="p_add">+	 */</span>
 	unsigned long		j_last;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Device, blocksize and starting block offset for the location where we</span>
<span class="p_del">-	 * store the journal.</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_dev: Device where we store the journal.</span>
 	 */
 	struct block_device	*j_dev;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_blocksize: Block size for the location where we store the journal.</span>
<span class="p_add">+	 */</span>
 	int			j_blocksize;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_blk_offset:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Starting block offset into the device where we store the journal.</span>
<span class="p_add">+	 */</span>
 	unsigned long long	j_blk_offset;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_devname: Journal device name.</span>
<span class="p_add">+	 */</span>
 	char			j_devname[BDEVNAME_SIZE+24];
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_fs_dev:</span>
<span class="p_add">+	 *</span>
 	 * Device which holds the client fs.  For internal journal this will be
 	 * equal to j_dev.
 	 */
 	struct block_device	*j_fs_dev;
 
<span class="p_del">-	/* Total maximum capacity of the journal region on disk. */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_maxlen: Total maximum capacity of the journal region on disk.</span>
<span class="p_add">+	 */</span>
 	unsigned int		j_maxlen;
 
<span class="p_del">-	/* Number of buffers reserved from the running transaction */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_reserved_credits:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Number of buffers reserved from the running transaction.</span>
<span class="p_add">+	 */</span>
 	atomic_t		j_reserved_credits;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Protects the buffer lists and internal buffer state.</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_list_lock: Protects the buffer lists and internal buffer state.</span>
 	 */
 	spinlock_t		j_list_lock;
 
<span class="p_del">-	/* Optional inode where we store the journal.  If present, all */</span>
<span class="p_del">-	/* journal block numbers are mapped into this inode via */</span>
<span class="p_del">-	/* bmap(). */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_inode:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Optional inode where we store the journal.  If present, all</span>
<span class="p_add">+	 * journal block numbers are mapped into this inode via bmap().</span>
<span class="p_add">+	 */</span>
 	struct inode		*j_inode;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_tail_sequence:</span>
<span class="p_add">+	 *</span>
 	 * Sequence number of the oldest transaction in the log [j_state_lock]
 	 */
 	tid_t			j_tail_sequence;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_transaction_sequence:</span>
<span class="p_add">+	 *</span>
 	 * Sequence number of the next transaction to grant [j_state_lock]
 	 */
 	tid_t			j_transaction_sequence;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_commit_sequence:</span>
<span class="p_add">+	 *</span>
 	 * Sequence number of the most recently committed transaction
 	 * [j_state_lock].
 	 */
 	tid_t			j_commit_sequence;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_commit_request:</span>
<span class="p_add">+	 *</span>
 	 * Sequence number of the most recent transaction wanting commit
 	 * [j_state_lock]
 	 */
 	tid_t			j_commit_request;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_uuid:</span>
<span class="p_add">+	 *</span>
 	 * Journal uuid: identifies the object (filesystem, LVM volume etc)
 	 * backed by this journal.  This will eventually be replaced by an array
 	 * of uuids, allowing us to index multiple devices within a single
<span class="p_chunk">@@ -958,85 +997,151 @@</span> <span class="p_context"> struct journal_s</span>
 	 */
 	__u8			j_uuid[16];
 
<span class="p_del">-	/* Pointer to the current commit thread for this journal */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_task: Pointer to the current commit thread for this journal.</span>
<span class="p_add">+	 */</span>
 	struct task_struct	*j_task;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_max_transaction_buffers:</span>
<span class="p_add">+	 *</span>
 	 * Maximum number of metadata buffers to allow in a single compound
<span class="p_del">-	 * commit transaction</span>
<span class="p_add">+	 * commit transaction.</span>
 	 */
 	int			j_max_transaction_buffers;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_commit_interval:</span>
<span class="p_add">+	 *</span>
 	 * What is the maximum transaction lifetime before we begin a commit?
 	 */
 	unsigned long		j_commit_interval;
 
<span class="p_del">-	/* The timer used to wakeup the commit thread: */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_commit_timer: The timer used to wakeup the commit thread.</span>
<span class="p_add">+	 */</span>
 	struct timer_list	j_commit_timer;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The revoke table: maintains the list of revoked blocks in the</span>
<span class="p_del">-	 * current transaction.  [j_revoke_lock]</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_revoke_lock: Protect the revoke table.</span>
 	 */
 	spinlock_t		j_revoke_lock;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_revoke:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The revoke table - maintains the list of revoked blocks in the</span>
<span class="p_add">+	 * current transaction.</span>
<span class="p_add">+	 */</span>
 	struct jbd2_revoke_table_s *j_revoke;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_revoke_table: Alternate revoke tables for j_revoke.</span>
<span class="p_add">+	 */</span>
 	struct jbd2_revoke_table_s *j_revoke_table[2];
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * array of bhs for jbd2_journal_commit_transaction</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wbuf: Array of bhs for jbd2_journal_commit_transaction.</span>
 	 */
 	struct buffer_head	**j_wbuf;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_wbufsize:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Size of @j_wbuf array.</span>
<span class="p_add">+	 */</span>
 	int			j_wbufsize;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * this is the pid of hte last person to run a synchronous operation</span>
<span class="p_del">-	 * through the journal</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_last_sync_writer:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The pid of the last person to run a synchronous operation</span>
<span class="p_add">+	 * through the journal.</span>
 	 */
 	pid_t			j_last_sync_writer;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * the average amount of time in nanoseconds it takes to commit a</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_average_commit_time:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The average amount of time in nanoseconds it takes to commit a</span>
 	 * transaction to disk. [j_state_lock]
 	 */
 	u64			j_average_commit_time;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * minimum and maximum times that we should wait for</span>
<span class="p_del">-	 * additional filesystem operations to get batched into a</span>
<span class="p_del">-	 * synchronous handle in microseconds</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_min_batch_time:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Minimum time that we should wait for additional filesystem operations</span>
<span class="p_add">+	 * to get batched into a synchronous handle in microseconds.</span>
 	 */
 	u32			j_min_batch_time;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_max_batch_time:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Maximum time that we should wait for additional filesystem operations</span>
<span class="p_add">+	 * to get batched into a synchronous handle in microseconds.</span>
<span class="p_add">+	 */</span>
 	u32			j_max_batch_time;
 
<span class="p_del">-	/* This function is called when a transaction is closed */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_commit_callback:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * This function is called when a transaction is closed.</span>
<span class="p_add">+	 */</span>
 	void			(*j_commit_callback)(journal_t *,
 						     transaction_t *);
 
 	/*
 	 * Journal statistics
 	 */
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_history_lock: Protect the transactions statistics history.</span>
<span class="p_add">+	 */</span>
 	spinlock_t		j_history_lock;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_proc_entry: procfs entry for the jbd statistics directory.</span>
<span class="p_add">+	 */</span>
 	struct proc_dir_entry	*j_proc_entry;
<span class="p_add">+</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_stats: Overall statistics.</span>
<span class="p_add">+	 */</span>
 	struct transaction_stats_s j_stats;
 
<span class="p_del">-	/* Failed journal commit ID */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_failed_commit: Failed journal commit ID.</span>
<span class="p_add">+	 */</span>
 	unsigned int		j_failed_commit;
 
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_private:</span>
<span class="p_add">+	 *</span>
 	 * An opaque pointer to fs-private information.  ext3 puts its
<span class="p_del">-	 * superblock pointer here</span>
<span class="p_add">+	 * superblock pointer here.</span>
 	 */
 	void *j_private;
 
<span class="p_del">-	/* Reference to checksum algorithm driver via cryptoapi */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_chksum_driver:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Reference to checksum algorithm driver via cryptoapi.</span>
<span class="p_add">+	 */</span>
 	struct crypto_shash *j_chksum_driver;
 
<span class="p_del">-	/* Precomputed journal UUID checksum for seeding other checksums */</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_csum_seed:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Precomputed journal UUID checksum for seeding other checksums.</span>
<span class="p_add">+	 */</span>
 	__u32 j_csum_seed;
 
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
<span class="p_del">-	/*</span>
<span class="p_add">+	/**</span>
<span class="p_add">+	 * @j_trans_commit_map:</span>
<span class="p_add">+	 *</span>
 	 * Lockdep entity to track transaction commit dependencies. Handles
 	 * hold this &quot;lock&quot; for read, when we wait for commit, we acquire the
 	 * &quot;lock&quot; for writing. This matches the properties of jbd2 journalling
<span class="p_header">diff --git a/include/linux/kmemcheck.h b/include/linux/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index 7b1d7bead7d9..000000000000</span>
<span class="p_header">--- a/include/linux/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,172 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef LINUX_KMEMCHECK_H</span>
<span class="p_del">-#define LINUX_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-extern int kmemcheck_enabled;</span>
<span class="p_del">-</span>
<span class="p_del">-/* The slab-related functions. */</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node);</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order);</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size);</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *p, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address);</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Bitfield annotations</span>
<span class="p_del">- *</span>
<span class="p_del">- * How to use: If you have a struct using bitfields, for example</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a {</span>
<span class="p_del">- *             int x:8, y:8;</span>
<span class="p_del">- *     };</span>
<span class="p_del">- *</span>
<span class="p_del">- * then this should be rewritten as</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a {</span>
<span class="p_del">- *             kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">- *             int x:8, y:8;</span>
<span class="p_del">- *             kmemcheck_bitfield_end(flags);</span>
<span class="p_del">- *     };</span>
<span class="p_del">- *</span>
<span class="p_del">- * Now the &quot;flags_begin&quot; and &quot;flags_end&quot; members may be used to refer to the</span>
<span class="p_del">- * beginning and end, respectively, of the bitfield (and things like</span>
<span class="p_del">- * &amp;x.flags_begin is allowed). As soon as the struct is allocated, the bit-</span>
<span class="p_del">- * fields should be annotated:</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a *a = kmalloc(sizeof(struct a), GFP_KERNEL);</span>
<span class="p_del">- *     kmemcheck_annotate_bitfield(a, flags);</span>
<span class="p_del">- */</span>
<span class="p_del">-#define kmemcheck_bitfield_begin(name)	\</span>
<span class="p_del">-	int name##_begin[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)	\</span>
<span class="p_del">-	int name##_end[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		int _n;							\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		if (!ptr)						\</span>
<span class="p_del">-			break;						\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		_n = (long) &amp;((ptr)-&gt;name##_end)			\</span>
<span class="p_del">-			- (long) &amp;((ptr)-&gt;name##_begin);		\</span>
<span class="p_del">-		BUILD_BUG_ON(_n &lt; 0);					\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;((ptr)-&gt;name##_begin), _n);	\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;(var), sizeof(var));	\</span>
<span class="p_del">-	} while (0)							\</span>
<span class="p_del">-</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define kmemcheck_enabled 0</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-		     size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_slab_free(struct kmem_cache *s, void *object,</span>
<span class="p_del">-				       size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_pagealloc_alloc(struct page *p,</span>
<span class="p_del">-	unsigned int order, gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_unallocated_pages(struct page *p,</span>
<span class="p_del">-						    unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_uninitialized_pages(struct page *p,</span>
<span class="p_del">-						      unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized_pages(struct page *p,</span>
<span class="p_del">-						    unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_begin(name)</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)	\</span>
<span class="p_del">-	do {					\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)	\</span>
<span class="p_del">-	do {					\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* LINUX_KMEMCHECK_H */</span>
<span class="p_header">diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h</span>
<span class="p_header">index a13525daf09b..ae15864c8708 100644</span>
<span class="p_header">--- a/include/linux/mlx5/driver.h</span>
<span class="p_header">+++ b/include/linux/mlx5/driver.h</span>
<span class="p_chunk">@@ -1201,7 +1201,7 @@</span> <span class="p_context"> mlx5_get_vector_affinity(struct mlx5_core_dev *dev, int vector)</span>
 	int eqn;
 	int err;
 
<span class="p_del">-	err = mlx5_vector2eqn(dev, vector, &amp;eqn, &amp;irq);</span>
<span class="p_add">+	err = mlx5_vector2eqn(dev, MLX5_EQ_VEC_COMP_BASE + vector, &amp;eqn, &amp;irq);</span>
 	if (err)
 		return NULL;
 
<span class="p_header">diff --git a/include/linux/mm_inline.h b/include/linux/mm_inline.h</span>
<span class="p_header">index c30b32e3c862..10191c28fc04 100644</span>
<span class="p_header">--- a/include/linux/mm_inline.h</span>
<span class="p_header">+++ b/include/linux/mm_inline.h</span>
<span class="p_chunk">@@ -127,10 +127,4 @@</span> <span class="p_context"> static __always_inline enum lru_list page_lru(struct page *page)</span>
 
 #define lru_to_page(head) (list_entry((head)-&gt;prev, struct page, lru))
 
<span class="p_del">-#ifdef arch_unmap_kpfn</span>
<span class="p_del">-extern void arch_unmap_kpfn(unsigned long pfn);</span>
<span class="p_del">-#else</span>
<span class="p_del">-static __always_inline void arch_unmap_kpfn(unsigned long pfn) { }</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #endif
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index c85f11dafd56..9f0bb908e2b5 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -207,14 +207,6 @@</span> <span class="p_context"> struct page {</span>
 					   not kmapped, ie. highmem) */
 #endif /* WANT_PAGE_VIRTUAL */
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * kmemcheck wants to track the status of each byte in a page; this</span>
<span class="p_del">-	 * is a pointer to such a status block. NULL if not tracked.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS
 	int _last_cpupid;
 #endif
<span class="p_header">diff --git a/include/linux/net.h b/include/linux/net.h</span>
<span class="p_header">index d97d80d7fdf8..caeb159abda5 100644</span>
<span class="p_header">--- a/include/linux/net.h</span>
<span class="p_header">+++ b/include/linux/net.h</span>
<span class="p_chunk">@@ -22,7 +22,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/random.h&gt;
 #include &lt;linux/wait.h&gt;
 #include &lt;linux/fcntl.h&gt;	/* For O_CLOEXEC and O_NONBLOCK */
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/rcupdate.h&gt;
 #include &lt;linux/once.h&gt;
 #include &lt;linux/fs.h&gt;
<span class="p_chunk">@@ -111,9 +110,7 @@</span> <span class="p_context"> struct socket_wq {</span>
 struct socket {
 	socket_state		state;
 
<span class="p_del">-	kmemcheck_bitfield_begin(type);</span>
 	short			type;
<span class="p_del">-	kmemcheck_bitfield_end(type);</span>
 
 	unsigned long		flags;
 
<span class="p_header">diff --git a/include/linux/nospec.h b/include/linux/nospec.h</span>
<span class="p_header">index b99bced39ac2..fbc98e2c8228 100644</span>
<span class="p_header">--- a/include/linux/nospec.h</span>
<span class="p_header">+++ b/include/linux/nospec.h</span>
<span class="p_chunk">@@ -19,20 +19,6 @@</span> <span class="p_context"></span>
 static inline unsigned long array_index_mask_nospec(unsigned long index,
 						    unsigned long size)
 {
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Warn developers about inappropriate array_index_nospec() usage.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Even if the CPU speculates past the WARN_ONCE branch, the</span>
<span class="p_del">-	 * sign bit of @index is taken into account when generating the</span>
<span class="p_del">-	 * mask.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * This warning is compiled out when the compiler can infer that</span>
<span class="p_del">-	 * @index and @size are less than LONG_MAX.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (WARN_ONCE(index &gt; LONG_MAX || size &gt; LONG_MAX,</span>
<span class="p_del">-			&quot;array_index_nospec() limited to range of [0, LONG_MAX]\n&quot;))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
 	/*
 	 * Always calculate and emit the mask even if the compiler
 	 * thinks the mask is not needed. The compiler does not take
<span class="p_chunk">@@ -43,6 +29,26 @@</span> <span class="p_context"> static inline unsigned long array_index_mask_nospec(unsigned long index,</span>
 }
 #endif
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Warn developers about inappropriate array_index_nospec() usage.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Even if the CPU speculates past the WARN_ONCE branch, the</span>
<span class="p_add">+ * sign bit of @index is taken into account when generating the</span>
<span class="p_add">+ * mask.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This warning is compiled out when the compiler can infer that</span>
<span class="p_add">+ * @index and @size are less than LONG_MAX.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define array_index_mask_nospec_check(index, size)				\</span>
<span class="p_add">+({										\</span>
<span class="p_add">+	if (WARN_ONCE(index &gt; LONG_MAX || size &gt; LONG_MAX,			\</span>
<span class="p_add">+	    &quot;array_index_nospec() limited to range of [0, LONG_MAX]\n&quot;))	\</span>
<span class="p_add">+		_mask = 0;							\</span>
<span class="p_add">+	else									\</span>
<span class="p_add">+		_mask = array_index_mask_nospec(index, size);			\</span>
<span class="p_add">+	_mask;									\</span>
<span class="p_add">+})</span>
<span class="p_add">+</span>
 /*
  * array_index_nospec - sanitize an array index after a bounds check
  *
<span class="p_chunk">@@ -61,7 +67,7 @@</span> <span class="p_context"> static inline unsigned long array_index_mask_nospec(unsigned long index,</span>
 ({									\
 	typeof(index) _i = (index);					\
 	typeof(size) _s = (size);					\
<span class="p_del">-	unsigned long _mask = array_index_mask_nospec(_i, _s);		\</span>
<span class="p_add">+	unsigned long _mask = array_index_mask_nospec_check(_i, _s);	\</span>
 									\
 	BUILD_BUG_ON(sizeof(_i) &gt; sizeof(long));			\
 	BUILD_BUG_ON(sizeof(_s) &gt; sizeof(long));			\
<span class="p_header">diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h</span>
<span class="p_header">index fa6ace66fea5..289e4d54e3e0 100644</span>
<span class="p_header">--- a/include/linux/ring_buffer.h</span>
<span class="p_header">+++ b/include/linux/ring_buffer.h</span>
<span class="p_chunk">@@ -2,7 +2,6 @@</span> <span class="p_context"></span>
 #ifndef _LINUX_RING_BUFFER_H
 #define _LINUX_RING_BUFFER_H
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/seq_file.h&gt;
 #include &lt;linux/poll.h&gt;
<span class="p_chunk">@@ -14,9 +13,7 @@</span> <span class="p_context"> struct ring_buffer_iter;</span>
  * Don&#39;t refer to this struct directly, use functions below.
  */
 struct ring_buffer_event {
<span class="p_del">-	kmemcheck_bitfield_begin(bitfield);</span>
 	u32		type_len:5, time_delta:27;
<span class="p_del">-	kmemcheck_bitfield_end(bitfield);</span>
 
 	u32		array[];
 };
<span class="p_header">diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h</span>
<span class="p_header">index 051e0939ec19..be45224b01d7 100644</span>
<span class="p_header">--- a/include/linux/skbuff.h</span>
<span class="p_header">+++ b/include/linux/skbuff.h</span>
<span class="p_chunk">@@ -15,7 +15,6 @@</span> <span class="p_context"></span>
 #define _LINUX_SKBUFF_H
 
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/time.h&gt;
 #include &lt;linux/bug.h&gt;
<span class="p_chunk">@@ -706,7 +705,6 @@</span> <span class="p_context"> struct sk_buff {</span>
 	/* Following fields are _not_ copied in __copy_skb_header()
 	 * Note that queue_mapping is here mostly to fill a hole.
 	 */
<span class="p_del">-	kmemcheck_bitfield_begin(flags1);</span>
 	__u16			queue_mapping;
 
 /* if you move cloned around you also must adapt those constants */
<span class="p_chunk">@@ -725,7 +723,6 @@</span> <span class="p_context"> struct sk_buff {</span>
 				head_frag:1,
 				xmit_more:1,
 				__unused:1; /* one bit hole */
<span class="p_del">-	kmemcheck_bitfield_end(flags1);</span>
 
 	/* fields enclosed in headers_start/headers_end are copied
 	 * using a single memcpy() in __copy_skb_header()
<span class="p_header">diff --git a/include/linux/slab.h b/include/linux/slab.h</span>
<span class="p_header">index af5aa65c7c18..ae5ed6492d54 100644</span>
<span class="p_header">--- a/include/linux/slab.h</span>
<span class="p_header">+++ b/include/linux/slab.h</span>
<span class="p_chunk">@@ -78,12 +78,6 @@</span> <span class="p_context"></span>
 
 #define SLAB_NOLEAKTRACE	0x00800000UL	/* Avoid kmemleak tracing */
 
<span class="p_del">-/* Don&#39;t track use of uninitialized memory */</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-# define SLAB_NOTRACK		0x01000000UL</span>
<span class="p_del">-#else</span>
<span class="p_del">-# define SLAB_NOTRACK		0x00000000UL</span>
<span class="p_del">-#endif</span>
 #ifdef CONFIG_FAILSLAB
 # define SLAB_FAILSLAB		0x02000000UL	/* Fault injection mark */
 #else
<span class="p_header">diff --git a/include/linux/thread_info.h b/include/linux/thread_info.h</span>
<span class="p_header">index 4bcdf00c110f..34f053a150a9 100644</span>
<span class="p_header">--- a/include/linux/thread_info.h</span>
<span class="p_header">+++ b/include/linux/thread_info.h</span>
<span class="p_chunk">@@ -44,10 +44,9 @@</span> <span class="p_context"> enum {</span>
 #endif
 
 #if IS_ENABLED(CONFIG_DEBUG_STACK_USAGE) || IS_ENABLED(CONFIG_DEBUG_KMEMLEAK)
<span class="p_del">-# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_NOTRACK | \</span>
<span class="p_del">-				 __GFP_ZERO)</span>
<span class="p_add">+# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_ZERO)</span>
 #else
<span class="p_del">-# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_NOTRACK)</span>
<span class="p_add">+# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT)</span>
 #endif
 
 /*
<span class="p_header">diff --git a/include/net/inet_sock.h b/include/net/inet_sock.h</span>
<span class="p_header">index db8162dd8c0b..8e51b4a69088 100644</span>
<span class="p_header">--- a/include/net/inet_sock.h</span>
<span class="p_header">+++ b/include/net/inet_sock.h</span>
<span class="p_chunk">@@ -17,7 +17,6 @@</span> <span class="p_context"></span>
 #define _INET_SOCK_H
 
 #include &lt;linux/bitops.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/string.h&gt;
 #include &lt;linux/types.h&gt;
 #include &lt;linux/jhash.h&gt;
<span class="p_chunk">@@ -84,7 +83,6 @@</span> <span class="p_context"> struct inet_request_sock {</span>
 #define ireq_state		req.__req_common.skc_state
 #define ireq_family		req.__req_common.skc_family
 
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	u16			snd_wscale : 4,
 				rcv_wscale : 4,
 				tstamp_ok  : 1,
<span class="p_chunk">@@ -93,7 +91,6 @@</span> <span class="p_context"> struct inet_request_sock {</span>
 				ecn_ok	   : 1,
 				acked	   : 1,
 				no_srccheck: 1;
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 	u32                     ir_mark;
 	union {
 		struct ip_options_rcu __rcu	*ireq_opt;
<span class="p_header">diff --git a/include/net/inet_timewait_sock.h b/include/net/inet_timewait_sock.h</span>
<span class="p_header">index 6a75d67a30fd..1356fa6a7566 100644</span>
<span class="p_header">--- a/include/net/inet_timewait_sock.h</span>
<span class="p_header">+++ b/include/net/inet_timewait_sock.h</span>
<span class="p_chunk">@@ -15,8 +15,6 @@</span> <span class="p_context"></span>
 #ifndef _INET_TIMEWAIT_SOCK_
 #define _INET_TIMEWAIT_SOCK_
 
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/list.h&gt;
 #include &lt;linux/timer.h&gt;
 #include &lt;linux/types.h&gt;
<span class="p_chunk">@@ -69,14 +67,12 @@</span> <span class="p_context"> struct inet_timewait_sock {</span>
 	/* Socket demultiplex comparisons on incoming packets. */
 	/* these three are in inet_sock */
 	__be16			tw_sport;
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	/* And these are ours. */
 	unsigned int		tw_kill		: 1,
 				tw_transparent  : 1,
 				tw_flowlabel	: 20,
 				tw_pad		: 2,	/* 2 bits hole */
 				tw_tos		: 8;
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 	struct timer_list	tw_timer;
 	struct inet_bind_bucket	*tw_tb;
 };
<span class="p_header">diff --git a/include/net/sock.h b/include/net/sock.h</span>
<span class="p_header">index 006580155a87..9bd5d68076d9 100644</span>
<span class="p_header">--- a/include/net/sock.h</span>
<span class="p_header">+++ b/include/net/sock.h</span>
<span class="p_chunk">@@ -436,7 +436,6 @@</span> <span class="p_context"> struct sock {</span>
 #define SK_FL_TYPE_MASK    0xffff0000
 #endif
 
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	unsigned int		sk_padding : 1,
 				sk_kern_sock : 1,
 				sk_no_check_tx : 1,
<span class="p_chunk">@@ -445,8 +444,6 @@</span> <span class="p_context"> struct sock {</span>
 				sk_protocol  : 8,
 				sk_type      : 16;
 #define SK_PROTOCOL_MAX U8_MAX
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
<span class="p_del">-</span>
 	u16			sk_gso_max_segs;
 	unsigned long	        sk_lingertime;
 	struct proto		*sk_prot_creator;
<span class="p_header">diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h</span>
<span class="p_header">index e8608b2dc844..6533aa64f009 100644</span>
<span class="p_header">--- a/include/rdma/ib_verbs.h</span>
<span class="p_header">+++ b/include/rdma/ib_verbs.h</span>
<span class="p_chunk">@@ -971,9 +971,9 @@</span> <span class="p_context"> struct ib_wc {</span>
 		u32		invalidate_rkey;
 	} ex;
 	u32			src_qp;
<span class="p_add">+	u32			slid;</span>
 	int			wc_flags;
 	u16			pkey_index;
<span class="p_del">-	u32			slid;</span>
 	u8			sl;
 	u8			dlid_path_bits;
 	u8			port_num;	/* valid only for DR SMPs on switches */
<span class="p_header">diff --git a/include/trace/events/mmflags.h b/include/trace/events/mmflags.h</span>
<span class="p_header">index 648cbf603736..72162f3a03fa 100644</span>
<span class="p_header">--- a/include/trace/events/mmflags.h</span>
<span class="p_header">+++ b/include/trace/events/mmflags.h</span>
<span class="p_chunk">@@ -46,7 +46,6 @@</span> <span class="p_context"></span>
 	{(unsigned long)__GFP_RECLAIMABLE,	&quot;__GFP_RECLAIMABLE&quot;},	\
 	{(unsigned long)__GFP_MOVABLE,		&quot;__GFP_MOVABLE&quot;},	\
 	{(unsigned long)__GFP_ACCOUNT,		&quot;__GFP_ACCOUNT&quot;},	\
<span class="p_del">-	{(unsigned long)__GFP_NOTRACK,		&quot;__GFP_NOTRACK&quot;},	\</span>
 	{(unsigned long)__GFP_WRITE,		&quot;__GFP_WRITE&quot;},		\
 	{(unsigned long)__GFP_RECLAIM,		&quot;__GFP_RECLAIM&quot;},	\
 	{(unsigned long)__GFP_DIRECT_RECLAIM,	&quot;__GFP_DIRECT_RECLAIM&quot;},\
<span class="p_header">diff --git a/include/trace/events/xen.h b/include/trace/events/xen.h</span>
<span class="p_header">index a7c8b452aab9..d791863b62fc 100644</span>
<span class="p_header">--- a/include/trace/events/xen.h</span>
<span class="p_header">+++ b/include/trace/events/xen.h</span>
<span class="p_chunk">@@ -365,7 +365,7 @@</span> <span class="p_context"> TRACE_EVENT(xen_mmu_flush_tlb,</span>
 	    TP_printk(&quot;%s&quot;, &quot;&quot;)
 	);
 
<span class="p_del">-TRACE_EVENT(xen_mmu_flush_tlb_single,</span>
<span class="p_add">+TRACE_EVENT(xen_mmu_flush_tlb_one_user,</span>
 	    TP_PROTO(unsigned long addr),
 	    TP_ARGS(addr),
 	    TP_STRUCT__entry(
<span class="p_header">diff --git a/init/do_mounts.c b/init/do_mounts.c</span>
<span class="p_header">index f6d4dd764a52..7cf4f6dafd5f 100644</span>
<span class="p_header">--- a/init/do_mounts.c</span>
<span class="p_header">+++ b/init/do_mounts.c</span>
<span class="p_chunk">@@ -380,8 +380,7 @@</span> <span class="p_context"> static int __init do_mount_root(char *name, char *fs, int flags, void *data)</span>
 
 void __init mount_block_root(char *name, int flags)
 {
<span class="p_del">-	struct page *page = alloc_page(GFP_KERNEL |</span>
<span class="p_del">-					__GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="p_add">+	struct page *page = alloc_page(GFP_KERNEL);</span>
 	char *fs_names = page_address(page);
 	char *p;
 #ifdef CONFIG_BLOCK
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index b32ec72cdf3d..2d355a61dfc5 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -69,7 +69,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/kgdb.h&gt;
 #include &lt;linux/ftrace.h&gt;
 #include &lt;linux/async.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/sfi.h&gt;
 #include &lt;linux/shmem_fs.h&gt;
 #include &lt;linux/slab.h&gt;
<span class="p_header">diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c</span>
<span class="p_header">index 2246115365d9..d203a5d6b726 100644</span>
<span class="p_header">--- a/kernel/bpf/core.c</span>
<span class="p_header">+++ b/kernel/bpf/core.c</span>
<span class="p_chunk">@@ -85,8 +85,6 @@</span> <span class="p_context"> struct bpf_prog *bpf_prog_alloc(unsigned int size, gfp_t gfp_extra_flags)</span>
 	if (fp == NULL)
 		return NULL;
 
<span class="p_del">-	kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="p_del">-</span>
 	aux = kzalloc(sizeof(*aux), GFP_KERNEL | gfp_extra_flags);
 	if (aux == NULL) {
 		vfree(fp);
<span class="p_chunk">@@ -127,8 +125,6 @@</span> <span class="p_context"> struct bpf_prog *bpf_prog_realloc(struct bpf_prog *fp_old, unsigned int size,</span>
 	if (fp == NULL) {
 		__bpf_prog_uncharge(fp_old-&gt;aux-&gt;user, delta);
 	} else {
<span class="p_del">-		kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="p_del">-</span>
 		memcpy(fp, fp_old, fp_old-&gt;pages * PAGE_SIZE);
 		fp-&gt;pages = pages;
 		fp-&gt;aux-&gt;prog = fp;
<span class="p_chunk">@@ -662,8 +658,6 @@</span> <span class="p_context"> static struct bpf_prog *bpf_prog_clone_create(struct bpf_prog *fp_other,</span>
 
 	fp = __vmalloc(fp_other-&gt;pages * PAGE_SIZE, gfp_flags, PAGE_KERNEL);
 	if (fp != NULL) {
<span class="p_del">-		kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="p_del">-</span>
 		/* aux-&gt;prog still points to the fp_other one, so
 		 * when promoting the clone to the real program,
 		 * this still needs to be adapted.
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 500ce64517d9..98c91bd341b4 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -469,7 +469,7 @@</span> <span class="p_context"> void __init fork_init(void)</span>
 	/* create a slab on which task_structs can be allocated */
 	task_struct_cachep = kmem_cache_create(&quot;task_struct&quot;,
 			arch_task_struct_size, align,
<span class="p_del">-			SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT, NULL);</span>
<span class="p_add">+			SLAB_PANIC|SLAB_ACCOUNT, NULL);</span>
 #endif
 
 	/* do the arch specific task caches init */
<span class="p_chunk">@@ -2208,18 +2208,18 @@</span> <span class="p_context"> void __init proc_caches_init(void)</span>
 	sighand_cachep = kmem_cache_create(&quot;sighand_cache&quot;,
 			sizeof(struct sighand_struct), 0,
 			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_TYPESAFE_BY_RCU|
<span class="p_del">-			SLAB_NOTRACK|SLAB_ACCOUNT, sighand_ctor);</span>
<span class="p_add">+			SLAB_ACCOUNT, sighand_ctor);</span>
 	signal_cachep = kmem_cache_create(&quot;signal_cache&quot;,
 			sizeof(struct signal_struct), 0,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	files_cachep = kmem_cache_create(&quot;files_cache&quot;,
 			sizeof(struct files_struct), 0,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	fs_cachep = kmem_cache_create(&quot;fs_cache&quot;,
 			sizeof(struct fs_struct), 0,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	/*
 	 * FIXME! The &quot;sizeof(struct mm_struct)&quot; currently includes the
<span class="p_chunk">@@ -2230,7 +2230,7 @@</span> <span class="p_context"> void __init proc_caches_init(void)</span>
 	 */
 	mm_cachep = kmem_cache_create(&quot;mm_struct&quot;,
 			sizeof(struct mm_struct), ARCH_MIN_MMSTRUCT_ALIGN,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC|SLAB_ACCOUNT);
 	mmap_init();
<span class="p_header">diff --git a/kernel/locking/lockdep.c b/kernel/locking/lockdep.c</span>
<span class="p_header">index e36e652d996f..4d362d3e4571 100644</span>
<span class="p_header">--- a/kernel/locking/lockdep.c</span>
<span class="p_header">+++ b/kernel/locking/lockdep.c</span>
<span class="p_chunk">@@ -47,7 +47,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/stringify.h&gt;
 #include &lt;linux/bitops.h&gt;
 #include &lt;linux/gfp.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/random.h&gt;
 #include &lt;linux/jhash.h&gt;
 
<span class="p_chunk">@@ -3225,8 +3224,6 @@</span> <span class="p_context"> static void __lockdep_init_map(struct lockdep_map *lock, const char *name,</span>
 {
 	int i;
 
<span class="p_del">-	kmemcheck_mark_initialized(lock, sizeof(*lock));</span>
<span class="p_del">-</span>
 	for (i = 0; i &lt; NR_LOCKDEP_CACHING_CLASSES; i++)
 		lock-&gt;class_cache[i] = NULL;
 
<span class="p_header">diff --git a/kernel/memremap.c b/kernel/memremap.c</span>
<span class="p_header">index 403ab9cdb949..4712ce646e04 100644</span>
<span class="p_header">--- a/kernel/memremap.c</span>
<span class="p_header">+++ b/kernel/memremap.c</span>
<span class="p_chunk">@@ -301,7 +301,8 @@</span> <span class="p_context"> static void devm_memremap_pages_release(struct device *dev, void *data)</span>
 
 	/* pages are dead and unused, undo the arch mapping */
 	align_start = res-&gt;start &amp; ~(SECTION_SIZE - 1);
<span class="p_del">-	align_size = ALIGN(resource_size(res), SECTION_SIZE);</span>
<span class="p_add">+	align_size = ALIGN(res-&gt;start + resource_size(res), SECTION_SIZE)</span>
<span class="p_add">+		- align_start;</span>
 
 	mem_hotplug_begin();
 	arch_remove_memory(align_start, align_size);
<span class="p_header">diff --git a/kernel/signal.c b/kernel/signal.c</span>
<span class="p_header">index 1facff1dbbae..6895f6bb98a7 100644</span>
<span class="p_header">--- a/kernel/signal.c</span>
<span class="p_header">+++ b/kernel/signal.c</span>
<span class="p_chunk">@@ -1038,8 +1038,7 @@</span> <span class="p_context"> static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
 	else
 		override_rlimit = 0;
 
<span class="p_del">-	q = __sigqueue_alloc(sig, t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,</span>
<span class="p_del">-		override_rlimit);</span>
<span class="p_add">+	q = __sigqueue_alloc(sig, t, GFP_ATOMIC, override_rlimit);</span>
 	if (q) {
 		list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);
 		switch ((unsigned long) info) {
<span class="p_header">diff --git a/kernel/softirq.c b/kernel/softirq.c</span>
<span class="p_header">index 4e09821f9d9e..e89c3b0cff6d 100644</span>
<span class="p_header">--- a/kernel/softirq.c</span>
<span class="p_header">+++ b/kernel/softirq.c</span>
<span class="p_chunk">@@ -486,16 +486,6 @@</span> <span class="p_context"> void __tasklet_hi_schedule(struct tasklet_struct *t)</span>
 }
 EXPORT_SYMBOL(__tasklet_hi_schedule);
 
<span class="p_del">-void __tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	t-&gt;next = __this_cpu_read(tasklet_hi_vec.head);</span>
<span class="p_del">-	__this_cpu_write(tasklet_hi_vec.head, t);</span>
<span class="p_del">-	__raise_softirq_irqoff(HI_SOFTIRQ);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(__tasklet_hi_schedule_first);</span>
<span class="p_del">-</span>
 static __latent_entropy void tasklet_action(struct softirq_action *a)
 {
 	struct tasklet_struct *list;
<span class="p_header">diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="p_header">index 56aca862c4f5..069550540a39 100644</span>
<span class="p_header">--- a/kernel/sysctl.c</span>
<span class="p_header">+++ b/kernel/sysctl.c</span>
<span class="p_chunk">@@ -30,7 +30,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/proc_fs.h&gt;
 #include &lt;linux/security.h&gt;
 #include &lt;linux/ctype.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/init.h&gt;
<span class="p_chunk">@@ -1173,15 +1172,6 @@</span> <span class="p_context"> static struct ctl_table kern_table[] = {</span>
 		.extra1		= &amp;zero,
 		.extra2		= &amp;one_thousand,
 	},
<span class="p_del">-#endif</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	{</span>
<span class="p_del">-		.procname	= &quot;kmemcheck&quot;,</span>
<span class="p_del">-		.data		= &amp;kmemcheck_enabled,</span>
<span class="p_del">-		.maxlen		= sizeof(int),</span>
<span class="p_del">-		.mode		= 0644,</span>
<span class="p_del">-		.proc_handler	= proc_dointvec,</span>
<span class="p_del">-	},</span>
 #endif
 	{
 		.procname	= &quot;panic_on_warn&quot;,
<span class="p_header">diff --git a/kernel/trace/Kconfig b/kernel/trace/Kconfig</span>
<span class="p_header">index 434c840e2d82..4ad6f6ca18c1 100644</span>
<span class="p_header">--- a/kernel/trace/Kconfig</span>
<span class="p_header">+++ b/kernel/trace/Kconfig</span>
<span class="p_chunk">@@ -343,7 +343,7 @@</span> <span class="p_context"> config PROFILE_ANNOTATED_BRANCHES</span>
 	  on if you need to profile the system&#39;s use of these macros.
 
 config PROFILE_ALL_BRANCHES
<span class="p_del">-	bool &quot;Profile all if conditionals&quot;</span>
<span class="p_add">+	bool &quot;Profile all if conditionals&quot; if !FORTIFY_SOURCE</span>
 	select TRACE_BRANCH_PROFILING
 	help
 	  This tracer profiles all branch conditions. Every if ()
<span class="p_header">diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c</span>
<span class="p_header">index 0476a9372014..39c221454186 100644</span>
<span class="p_header">--- a/kernel/trace/ring_buffer.c</span>
<span class="p_header">+++ b/kernel/trace/ring_buffer.c</span>
<span class="p_chunk">@@ -13,7 +13,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/uaccess.h&gt;
 #include &lt;linux/hardirq.h&gt;
 #include &lt;linux/kthread.h&gt;	/* for self test */
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/percpu.h&gt;
 #include &lt;linux/mutex.h&gt;
<span class="p_chunk">@@ -2059,7 +2058,6 @@</span> <span class="p_context"> rb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,</span>
 	}
 
 	event = __rb_page_index(tail_page, tail);
<span class="p_del">-	kmemcheck_annotate_bitfield(event, bitfield);</span>
 
 	/* account for padding bytes */
 	local_add(BUF_PAGE_SIZE - tail, &amp;cpu_buffer-&gt;entries_bytes);
<span class="p_chunk">@@ -2690,7 +2688,6 @@</span> <span class="p_context"> __rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,</span>
 	/* We reserved something on the buffer */
 
 	event = __rb_page_index(tail_page, tail);
<span class="p_del">-	kmemcheck_annotate_bitfield(event, bitfield);</span>
 	rb_update_event(cpu_buffer, event, info);
 
 	local_inc(&amp;tail_page-&gt;entries);
<span class="p_header">diff --git a/kernel/trace/trace_events_filter.c b/kernel/trace/trace_events_filter.c</span>
<span class="p_header">index 61e7f0678d33..a764aec3c9a1 100644</span>
<span class="p_header">--- a/kernel/trace/trace_events_filter.c</span>
<span class="p_header">+++ b/kernel/trace/trace_events_filter.c</span>
<span class="p_chunk">@@ -400,7 +400,6 @@</span> <span class="p_context"> enum regex_type filter_parse_regex(char *buff, int len, char **search, int *not)</span>
 	for (i = 0; i &lt; len; i++) {
 		if (buff[i] == &#39;*&#39;) {
 			if (!i) {
<span class="p_del">-				*search = buff + 1;</span>
 				type = MATCH_END_ONLY;
 			} else if (i == len - 1) {
 				if (type == MATCH_END_ONLY)
<span class="p_chunk">@@ -410,14 +409,14 @@</span> <span class="p_context"> enum regex_type filter_parse_regex(char *buff, int len, char **search, int *not)</span>
 				buff[i] = 0;
 				break;
 			} else {	/* pattern continues, use full glob */
<span class="p_del">-				type = MATCH_GLOB;</span>
<span class="p_del">-				break;</span>
<span class="p_add">+				return MATCH_GLOB;</span>
 			}
 		} else if (strchr(&quot;[?\\&quot;, buff[i])) {
<span class="p_del">-			type = MATCH_GLOB;</span>
<span class="p_del">-			break;</span>
<span class="p_add">+			return MATCH_GLOB;</span>
 		}
 	}
<span class="p_add">+	if (buff[0] == &#39;*&#39;)</span>
<span class="p_add">+		*search = buff + 1;</span>
 
 	return type;
 }
<span class="p_header">diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug</span>
<span class="p_header">index 00cb02daeddd..62d0e25c054c 100644</span>
<span class="p_header">--- a/lib/Kconfig.debug</span>
<span class="p_header">+++ b/lib/Kconfig.debug</span>
<span class="p_chunk">@@ -504,7 +504,7 @@</span> <span class="p_context"> config DEBUG_OBJECTS_ENABLE_DEFAULT</span>
 
 config DEBUG_SLAB
 	bool &quot;Debug slab memory allocations&quot;
<span class="p_del">-	depends on DEBUG_KERNEL &amp;&amp; SLAB &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on DEBUG_KERNEL &amp;&amp; SLAB</span>
 	help
 	  Say Y here to have the kernel do limited verification on memory
 	  allocation as well as poisoning memory on free to catch use of freed
<span class="p_chunk">@@ -516,7 +516,7 @@</span> <span class="p_context"> config DEBUG_SLAB_LEAK</span>
 
 config SLUB_DEBUG_ON
 	bool &quot;SLUB debugging on by default&quot;
<span class="p_del">-	depends on SLUB &amp;&amp; SLUB_DEBUG &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on SLUB &amp;&amp; SLUB_DEBUG</span>
 	default n
 	help
 	  Boot with debugging on by default. SLUB boots by default with
<span class="p_chunk">@@ -730,8 +730,6 @@</span> <span class="p_context"> config DEBUG_STACKOVERFLOW</span>
 
 	  If in doubt, say &quot;N&quot;.
 
<span class="p_del">-source &quot;lib/Kconfig.kmemcheck&quot;</span>
<span class="p_del">-</span>
 source &quot;lib/Kconfig.kasan&quot;
 
 endmenu # &quot;Memory Debugging&quot;
<span class="p_header">diff --git a/lib/Kconfig.kmemcheck b/lib/Kconfig.kmemcheck</span>
deleted file mode 100644
<span class="p_header">index 846e039a86b4..000000000000</span>
<span class="p_header">--- a/lib/Kconfig.kmemcheck</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,94 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-config HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-	bool</span>
<span class="p_del">-</span>
<span class="p_del">-if HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-menuconfig KMEMCHECK</span>
<span class="p_del">-	bool &quot;kmemcheck: trap use of uninitialized memory&quot;</span>
<span class="p_del">-	depends on DEBUG_KERNEL</span>
<span class="p_del">-	depends on !X86_USE_3DNOW</span>
<span class="p_del">-	depends on SLUB || SLAB</span>
<span class="p_del">-	depends on !CC_OPTIMIZE_FOR_SIZE</span>
<span class="p_del">-	depends on !FUNCTION_TRACER</span>
<span class="p_del">-	select FRAME_POINTER</span>
<span class="p_del">-	select STACKTRACE</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option enables tracing of dynamically allocated kernel memory</span>
<span class="p_del">-	  to see if memory is used before it has been given an initial value.</span>
<span class="p_del">-	  Be aware that this requires half of your memory for bookkeeping and</span>
<span class="p_del">-	  will insert extra code at *every* read and write to tracked memory</span>
<span class="p_del">-	  thus slow down the kernel code (but user code is unaffected).</span>
<span class="p_del">-</span>
<span class="p_del">-	  The kernel may be started with kmemcheck=0 or kmemcheck=1 to disable</span>
<span class="p_del">-	  or enable kmemcheck at boot-time. If the kernel is started with</span>
<span class="p_del">-	  kmemcheck=0, the large memory and CPU overhead is not incurred.</span>
<span class="p_del">-</span>
<span class="p_del">-choice</span>
<span class="p_del">-	prompt &quot;kmemcheck: default mode at boot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option controls the default behaviour of kmemcheck when the</span>
<span class="p_del">-	  kernel boots and no kmemcheck= parameter is given.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;disabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;enabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;one-shot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  In one-shot mode, only the first error detected is reported before</span>
<span class="p_del">-	  kmemcheck is disabled.</span>
<span class="p_del">-</span>
<span class="p_del">-endchoice</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_QUEUE_SIZE</span>
<span class="p_del">-	int &quot;kmemcheck: error queue size&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default 64</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the maximum number of errors to store in the queue. Since</span>
<span class="p_del">-	  errors can occur virtually anywhere and in any context, we need a</span>
<span class="p_del">-	  temporary storage area which is guarantueed not to generate any</span>
<span class="p_del">-	  other faults. The queue will be emptied as soon as a tasklet may</span>
<span class="p_del">-	  be scheduled. If the queue is full, new error reports will be</span>
<span class="p_del">-	  lost.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_SHADOW_COPY_SHIFT</span>
<span class="p_del">-	int &quot;kmemcheck: shadow copy size (5 =&gt; 32 bytes, 6 =&gt; 64 bytes)&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	range 2 8</span>
<span class="p_del">-	default 5</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the number of shadow bytes to save along with each entry of</span>
<span class="p_del">-	  the queue. These bytes indicate what parts of an allocation are</span>
<span class="p_del">-	  initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	  error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow partially uninitialized memory&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default y</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option works around certain GCC optimizations that produce</span>
<span class="p_del">-	  32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	  thrown away afterwards. This may of course also hide some real</span>
<span class="p_del">-	  bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow bit-field manipulation&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	  accesses where not all the bits are initialized at the same time.</span>
<span class="p_del">-	  This may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-endif</span>
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 8c6c83ef57a4..20df2fd9b150 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -585,7 +585,7 @@</span> <span class="p_context"> phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,</span>
 
 not_found:
 	spin_unlock_irqrestore(&amp;io_tlb_lock, flags);
<span class="p_del">-	if (printk_ratelimit())</span>
<span class="p_add">+	if (!(attrs &amp; DMA_ATTR_NO_WARN) &amp;&amp; printk_ratelimit())</span>
 		dev_warn(hwdev, &quot;swiotlb buffer is full (sz: %zd bytes)\n&quot;, size);
 	return SWIOTLB_MAP_ERROR;
 found:
<span class="p_chunk">@@ -712,6 +712,7 @@</span> <span class="p_context"> void *</span>
 swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 		       dma_addr_t *dma_handle, gfp_t flags)
 {
<span class="p_add">+	bool warn = !(flags &amp; __GFP_NOWARN);</span>
 	dma_addr_t dev_addr;
 	void *ret;
 	int order = get_order(size);
<span class="p_chunk">@@ -737,8 +738,8 @@</span> <span class="p_context"> swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
 		 * GFP_DMA memory; fall back on map_single(), which
 		 * will grab memory from the lowest available address range.
 		 */
<span class="p_del">-		phys_addr_t paddr = map_single(hwdev, 0, size,</span>
<span class="p_del">-					       DMA_FROM_DEVICE, 0);</span>
<span class="p_add">+		phys_addr_t paddr = map_single(hwdev, 0, size, DMA_FROM_DEVICE,</span>
<span class="p_add">+					       warn ? 0 : DMA_ATTR_NO_WARN);</span>
 		if (paddr == SWIOTLB_MAP_ERROR)
 			goto err_warn;
 
<span class="p_chunk">@@ -768,9 +769,11 @@</span> <span class="p_context"> swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
 	return ret;
 
 err_warn:
<span class="p_del">-	pr_warn(&quot;swiotlb: coherent allocation failed for device %s size=%zu\n&quot;,</span>
<span class="p_del">-		dev_name(hwdev), size);</span>
<span class="p_del">-	dump_stack();</span>
<span class="p_add">+	if (warn &amp;&amp; printk_ratelimit()) {</span>
<span class="p_add">+		pr_warn(&quot;swiotlb: coherent allocation failed for device %s size=%zu\n&quot;,</span>
<span class="p_add">+			dev_name(hwdev), size);</span>
<span class="p_add">+		dump_stack();</span>
<span class="p_add">+	}</span>
 
 	return NULL;
 }
<span class="p_header">diff --git a/mm/Kconfig.debug b/mm/Kconfig.debug</span>
<span class="p_header">index 5b0adf1435de..e5e606ee5f71 100644</span>
<span class="p_header">--- a/mm/Kconfig.debug</span>
<span class="p_header">+++ b/mm/Kconfig.debug</span>
<span class="p_chunk">@@ -11,7 +11,6 @@</span> <span class="p_context"> config DEBUG_PAGEALLOC</span>
 	bool &quot;Debug page memory allocations&quot;
 	depends on DEBUG_KERNEL
 	depends on !HIBERNATION || ARCH_SUPPORTS_DEBUG_PAGEALLOC &amp;&amp; !PPC &amp;&amp; !SPARC
<span class="p_del">-	depends on !KMEMCHECK</span>
 	select PAGE_EXTENSION
 	select PAGE_POISONING if !ARCH_SUPPORTS_DEBUG_PAGEALLOC
 	---help---
<span class="p_header">diff --git a/mm/Makefile b/mm/Makefile</span>
<span class="p_header">index 4659b93cba43..e7ebd176fb93 100644</span>
<span class="p_header">--- a/mm/Makefile</span>
<span class="p_header">+++ b/mm/Makefile</span>
<span class="p_chunk">@@ -17,7 +17,6 @@</span> <span class="p_context"> KCOV_INSTRUMENT_slub.o := n</span>
 KCOV_INSTRUMENT_page_alloc.o := n
 KCOV_INSTRUMENT_debug-pagealloc.o := n
 KCOV_INSTRUMENT_kmemleak.o := n
<span class="p_del">-KCOV_INSTRUMENT_kmemcheck.o := n</span>
 KCOV_INSTRUMENT_memcontrol.o := n
 KCOV_INSTRUMENT_mmzone.o := n
 KCOV_INSTRUMENT_vmstat.o := n
<span class="p_chunk">@@ -70,7 +69,6 @@</span> <span class="p_context"> obj-$(CONFIG_KSM) += ksm.o</span>
 obj-$(CONFIG_PAGE_POISONING) += page_poison.o
 obj-$(CONFIG_SLAB) += slab.o
 obj-$(CONFIG_SLUB) += slub.o
<span class="p_del">-obj-$(CONFIG_KMEMCHECK) += kmemcheck.o</span>
 obj-$(CONFIG_KASAN)	+= kasan/
 obj-$(CONFIG_FAILSLAB) += failslab.o
 obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o
<span class="p_header">diff --git a/mm/kmemcheck.c b/mm/kmemcheck.c</span>
deleted file mode 100644
<span class="p_header">index 800d64b854ea..000000000000</span>
<span class="p_header">--- a/mm/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,126 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_del">-#include &lt;linux/gfp.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/slab.h&gt;</span>
<span class="p_del">-#include &quot;slab.h&quot;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * With kmemcheck enabled, we need to allocate a memory area for the</span>
<span class="p_del">-	 * shadow bits as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	shadow = alloc_pages_node(node, flags | __GFP_NOTRACK, order);</span>
<span class="p_del">-	if (!shadow) {</span>
<span class="p_del">-		if (printk_ratelimit())</span>
<span class="p_del">-			pr_err(&quot;kmemcheck: failed to allocate shadow bitmap\n&quot;);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = page_address(&amp;shadow[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Mark it as non-present for the MMU so that our accesses to</span>
<span class="p_del">-	 * this memory will trigger a page fault and let us analyze</span>
<span class="p_del">-	 * the memory accesses.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_hide_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_pages(page, pages);</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = virt_to_page(page[0].shadow);</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	__free_pages(shadow, order);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(!object)) /* Skip object if allocation failed */</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Has already been memset(), which initializes the shadow for us</span>
<span class="p_del">-	 * as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* No need to initialize the shadow of a non-tracked slab. */</span>
<span class="p_del">-	if (s-&gt;flags &amp; SLAB_NOTRACK)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_enabled || gfpflags &amp; __GFP_NOTRACK) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Allow notracked objects to be allocated from</span>
<span class="p_del">-		 * tracked caches. Note however that these objects</span>
<span class="p_del">-		 * will still get page faults on access, they just</span>
<span class="p_del">-		 * won&#39;t ever be flagged as uninitialized. If page</span>
<span class="p_del">-		 * faults are not acceptable, the slab cache itself</span>
<span class="p_del">-		 * should be marked NOTRACK.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_initialized(object, size);</span>
<span class="p_del">-	} else if (!s-&gt;ctor) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * New objects should be marked uninitialized before</span>
<span class="p_del">-		 * they&#39;re returned to the called.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(object, size);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* TODO: RCU freeing is unsupported for now; hide false positives. */</span>
<span class="p_del">-	if (!s-&gt;ctor &amp;&amp; !(s-&gt;flags &amp; SLAB_TYPESAFE_BY_RCU))</span>
<span class="p_del">-		kmemcheck_mark_freed(object, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *page, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; (__GFP_HIGHMEM | __GFP_NOTRACK))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * NOTE: We choose to track GFP_ZERO pages too; in fact, they</span>
<span class="p_del">-	 * can become uninitialized by copying uninitialized memory</span>
<span class="p_del">-	 * into them.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* XXX: Can use zone-&gt;node for node? */</span>
<span class="p_del">-	kmemcheck_alloc_shadow(page, order, gfpflags, -1);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		kmemcheck_mark_initialized_pages(page, pages);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/mm/kmemleak.c b/mm/kmemleak.c</span>
<span class="p_header">index a1ba553816eb..bd1374f402cd 100644</span>
<span class="p_header">--- a/mm/kmemleak.c</span>
<span class="p_header">+++ b/mm/kmemleak.c</span>
<span class="p_chunk">@@ -110,7 +110,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/atomic.h&gt;
 
 #include &lt;linux/kasan.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/memory_hotplug.h&gt;
 
<span class="p_chunk">@@ -1238,9 +1237,6 @@</span> <span class="p_context"> static bool update_checksum(struct kmemleak_object *object)</span>
 {
 	u32 old_csum = object-&gt;checksum;
 
<span class="p_del">-	if (!kmemcheck_is_obj_initialized(object-&gt;pointer, object-&gt;size))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
 	kasan_disable_current();
 	object-&gt;checksum = crc32(0, (void *)object-&gt;pointer, object-&gt;size);
 	kasan_enable_current();
<span class="p_chunk">@@ -1314,11 +1310,6 @@</span> <span class="p_context"> static void scan_block(void *_start, void *_end,</span>
 		if (scan_should_stop())
 			break;
 
<span class="p_del">-		/* don&#39;t scan uninitialized memory */</span>
<span class="p_del">-		if (!kmemcheck_is_obj_initialized((unsigned long)ptr,</span>
<span class="p_del">-						  BYTES_PER_POINTER))</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
 		kasan_disable_current();
 		pointer = *ptr;
 		kasan_enable_current();
<span class="p_header">diff --git a/mm/memory-failure.c b/mm/memory-failure.c</span>
<span class="p_header">index 88366626c0b7..1cd3b3569af8 100644</span>
<span class="p_header">--- a/mm/memory-failure.c</span>
<span class="p_header">+++ b/mm/memory-failure.c</span>
<span class="p_chunk">@@ -1146,8 +1146,6 @@</span> <span class="p_context"> int memory_failure(unsigned long pfn, int trapno, int flags)</span>
 		return 0;
 	}
 
<span class="p_del">-	arch_unmap_kpfn(pfn);</span>
<span class="p_del">-</span>
 	orig_head = hpage = compound_head(p);
 	num_poisoned_pages_inc();
 
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index a728bed16c20..fc7779165dcf 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -81,7 +81,7 @@</span> <span class="p_context"></span>
 
 #include &quot;internal.h&quot;
 
<span class="p_del">-#ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS</span>
<span class="p_add">+#if defined(LAST_CPUPID_NOT_IN_PAGE_FLAGS) &amp;&amp; !defined(CONFIG_COMPILE_TEST)</span>
 #warning Unfortunate NUMA and NUMA Balancing config, growing page-frame for last_cpupid.
 #endif
 
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 2de080003693..6627caeeaf82 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -24,7 +24,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/memblock.h&gt;
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/suspend.h&gt;
<span class="p_chunk">@@ -1022,7 +1021,6 @@</span> <span class="p_context"> static __always_inline bool free_pages_prepare(struct page *page,</span>
 	VM_BUG_ON_PAGE(PageTail(page), page);
 
 	trace_mm_page_free(page, order);
<span class="p_del">-	kmemcheck_free_shadow(page, order);</span>
 
 	/*
 	 * Check tail pages before head page information is cleared to
<span class="p_chunk">@@ -2674,15 +2672,6 @@</span> <span class="p_context"> void split_page(struct page *page, unsigned int order)</span>
 	VM_BUG_ON_PAGE(PageCompound(page), page);
 	VM_BUG_ON_PAGE(!page_count(page), page);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Split shadow pages too, because free(page[0]) would</span>
<span class="p_del">-	 * otherwise free the whole shadow.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		split_page(virt_to_page(page[0].shadow), order);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	for (i = 1; i &lt; (1 &lt;&lt; order); i++)
 		set_page_refcounted(page + i);
 	split_page_owner(page, order);
<span class="p_chunk">@@ -4228,9 +4217,6 @@</span> <span class="p_context"> __alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid,</span>
 		page = NULL;
 	}
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp; page)</span>
<span class="p_del">-		kmemcheck_pagealloc_alloc(page, order, gfp_mask);</span>
<span class="p_del">-</span>
 	trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);
 
 	return page;
<span class="p_header">diff --git a/mm/slab.c b/mm/slab.c</span>
<span class="p_header">index b7095884fd93..966839a1ac2c 100644</span>
<span class="p_header">--- a/mm/slab.c</span>
<span class="p_header">+++ b/mm/slab.c</span>
<span class="p_chunk">@@ -114,7 +114,6 @@</span> <span class="p_context"></span>
 #include	&lt;linux/rtmutex.h&gt;
 #include	&lt;linux/reciprocal_div.h&gt;
 #include	&lt;linux/debugobjects.h&gt;
<span class="p_del">-#include	&lt;linux/kmemcheck.h&gt;</span>
 #include	&lt;linux/memory.h&gt;
 #include	&lt;linux/prefetch.h&gt;
 #include	&lt;linux/sched/task_stack.h&gt;
<span class="p_chunk">@@ -1413,7 +1412,7 @@</span> <span class="p_context"> static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)
 		flags |= __GFP_RECLAIMABLE;
 
<span class="p_del">-	page = __alloc_pages_node(nodeid, flags | __GFP_NOTRACK, cachep-&gt;gfporder);</span>
<span class="p_add">+	page = __alloc_pages_node(nodeid, flags, cachep-&gt;gfporder);</span>
 	if (!page) {
 		slab_out_of_memory(cachep, flags, nodeid);
 		return NULL;
<span class="p_chunk">@@ -1435,15 +1434,6 @@</span> <span class="p_context"> static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
 	if (sk_memalloc_socks() &amp;&amp; page_is_pfmemalloc(page))
 		SetPageSlabPfmemalloc(page);
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp; !(cachep-&gt;flags &amp; SLAB_NOTRACK)) {</span>
<span class="p_del">-		kmemcheck_alloc_shadow(page, cachep-&gt;gfporder, flags, nodeid);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (cachep-&gt;ctor)</span>
<span class="p_del">-			kmemcheck_mark_uninitialized_pages(page, nr_pages);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			kmemcheck_mark_unallocated_pages(page, nr_pages);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return page;
 }
 
<span class="p_chunk">@@ -1455,8 +1445,6 @@</span> <span class="p_context"> static void kmem_freepages(struct kmem_cache *cachep, struct page *page)</span>
 	int order = cachep-&gt;gfporder;
 	unsigned long nr_freed = (1 &lt;&lt; order);
 
<span class="p_del">-	kmemcheck_free_shadow(page, order);</span>
<span class="p_del">-</span>
 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)
 		mod_lruvec_page_state(page, NR_SLAB_RECLAIMABLE, -nr_freed);
 	else
<span class="p_chunk">@@ -3516,8 +3504,6 @@</span> <span class="p_context"> void ___cache_free(struct kmem_cache *cachep, void *objp,</span>
 	kmemleak_free_recursive(objp, cachep-&gt;flags);
 	objp = cache_free_debugcheck(cachep, objp, caller);
 
<span class="p_del">-	kmemcheck_slab_free(cachep, objp, cachep-&gt;object_size);</span>
<span class="p_del">-</span>
 	/*
 	 * Skip calling cache_free_alien() when the platform is not numa.
 	 * This will avoid cache misses that happen while accessing slabp (which
<span class="p_header">diff --git a/mm/slab.h b/mm/slab.h</span>
<span class="p_header">index 86d7c7d860f9..485d9fbb8802 100644</span>
<span class="p_header">--- a/mm/slab.h</span>
<span class="p_header">+++ b/mm/slab.h</span>
<span class="p_chunk">@@ -40,7 +40,6 @@</span> <span class="p_context"> struct kmem_cache {</span>
 
 #include &lt;linux/memcontrol.h&gt;
 #include &lt;linux/fault-inject.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/random.h&gt;
<span class="p_chunk">@@ -142,10 +141,10 @@</span> <span class="p_context"> static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
 #if defined(CONFIG_SLAB)
 #define SLAB_CACHE_FLAGS (SLAB_MEM_SPREAD | SLAB_NOLEAKTRACE | \
 			  SLAB_RECLAIM_ACCOUNT | SLAB_TEMPORARY | \
<span class="p_del">-			  SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="p_add">+			  SLAB_ACCOUNT)</span>
 #elif defined(CONFIG_SLUB)
 #define SLAB_CACHE_FLAGS (SLAB_NOLEAKTRACE | SLAB_RECLAIM_ACCOUNT | \
<span class="p_del">-			  SLAB_TEMPORARY | SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="p_add">+			  SLAB_TEMPORARY | SLAB_ACCOUNT)</span>
 #else
 #define SLAB_CACHE_FLAGS (0)
 #endif
<span class="p_chunk">@@ -164,7 +163,6 @@</span> <span class="p_context"> static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
 			      SLAB_NOLEAKTRACE | \
 			      SLAB_RECLAIM_ACCOUNT | \
 			      SLAB_TEMPORARY | \
<span class="p_del">-			      SLAB_NOTRACK | \</span>
 			      SLAB_ACCOUNT)
 
 int __kmem_cache_shutdown(struct kmem_cache *);
<span class="p_chunk">@@ -439,7 +437,6 @@</span> <span class="p_context"> static inline void slab_post_alloc_hook(struct kmem_cache *s, gfp_t flags,</span>
 	for (i = 0; i &lt; size; i++) {
 		void *object = p[i];
 
<span class="p_del">-		kmemcheck_slab_alloc(s, flags, object, slab_ksize(s));</span>
 		kmemleak_alloc_recursive(object, s-&gt;object_size, 1,
 					 s-&gt;flags, flags);
 		kasan_slab_alloc(s, object, flags);
<span class="p_header">diff --git a/mm/slab_common.c b/mm/slab_common.c</span>
<span class="p_header">index 0d7fe71ff5e4..65212caa1f2a 100644</span>
<span class="p_header">--- a/mm/slab_common.c</span>
<span class="p_header">+++ b/mm/slab_common.c</span>
<span class="p_chunk">@@ -44,7 +44,7 @@</span> <span class="p_context"> static DECLARE_WORK(slab_caches_to_rcu_destroy_work,</span>
 		SLAB_FAILSLAB | SLAB_KASAN)
 
 #define SLAB_MERGE_SAME (SLAB_RECLAIM_ACCOUNT | SLAB_CACHE_DMA | \
<span class="p_del">-			 SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="p_add">+			 SLAB_ACCOUNT)</span>
 
 /*
  * Merge control. If this is set then no merging of slab caches will occur.
<span class="p_header">diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="p_header">index 8e1c027a30f4..41c01690d116 100644</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -22,7 +22,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/notifier.h&gt;
 #include &lt;linux/seq_file.h&gt;
 #include &lt;linux/kasan.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/cpu.h&gt;
 #include &lt;linux/cpuset.h&gt;
 #include &lt;linux/mempolicy.h&gt;
<span class="p_chunk">@@ -1370,12 +1369,11 @@</span> <span class="p_context"> static inline void *slab_free_hook(struct kmem_cache *s, void *x)</span>
 	 * So in order to make the debug calls that expect irqs to be
 	 * disabled we need to disable interrupts temporarily.
 	 */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) || defined(CONFIG_LOCKDEP)</span>
<span class="p_add">+#ifdef CONFIG_LOCKDEP</span>
 	{
 		unsigned long flags;
 
 		local_irq_save(flags);
<span class="p_del">-		kmemcheck_slab_free(s, x, s-&gt;object_size);</span>
 		debug_check_no_locks_freed(x, s-&gt;object_size);
 		local_irq_restore(flags);
 	}
<span class="p_chunk">@@ -1399,8 +1397,7 @@</span> <span class="p_context"> static inline void slab_free_freelist_hook(struct kmem_cache *s,</span>
  * Compiler cannot detect this function can be removed if slab_free_hook()
  * evaluates to nothing.  Thus, catch all relevant config debug options here.
  */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) ||		\</span>
<span class="p_del">-	defined(CONFIG_LOCKDEP)	||		\</span>
<span class="p_add">+#if defined(CONFIG_LOCKDEP)	||		\</span>
 	defined(CONFIG_DEBUG_KMEMLEAK) ||	\
 	defined(CONFIG_DEBUG_OBJECTS_FREE) ||	\
 	defined(CONFIG_KASAN)
<span class="p_chunk">@@ -1436,8 +1433,6 @@</span> <span class="p_context"> static inline struct page *alloc_slab_page(struct kmem_cache *s,</span>
 	struct page *page;
 	int order = oo_order(oo);
 
<span class="p_del">-	flags |= __GFP_NOTRACK;</span>
<span class="p_del">-</span>
 	if (node == NUMA_NO_NODE)
 		page = alloc_pages(flags, order);
 	else
<span class="p_chunk">@@ -1596,22 +1591,6 @@</span> <span class="p_context"> static struct page *allocate_slab(struct kmem_cache *s, gfp_t flags, int node)</span>
 		stat(s, ORDER_FALLBACK);
 	}
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp;</span>
<span class="p_del">-	    !(s-&gt;flags &amp; (SLAB_NOTRACK | DEBUG_DEFAULT_FLAGS))) {</span>
<span class="p_del">-		int pages = 1 &lt;&lt; oo_order(oo);</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_alloc_shadow(page, oo_order(oo), alloc_gfp, node);</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Objects from caches that have a constructor don&#39;t get</span>
<span class="p_del">-		 * cleared when they&#39;re allocated, so we need to do it here.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (s-&gt;ctor)</span>
<span class="p_del">-			kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			kmemcheck_mark_unallocated_pages(page, pages);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	page-&gt;objects = oo_objects(oo);
 
 	order = compound_order(page);
<span class="p_chunk">@@ -1687,8 +1666,6 @@</span> <span class="p_context"> static void __free_slab(struct kmem_cache *s, struct page *page)</span>
 			check_object(s, page, p, SLUB_RED_INACTIVE);
 	}
 
<span class="p_del">-	kmemcheck_free_shadow(page, compound_order(page));</span>
<span class="p_del">-</span>
 	mod_lruvec_page_state(page,
 		(s-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT) ?
 		NR_SLAB_RECLAIMABLE : NR_SLAB_UNRECLAIMABLE,
<span class="p_chunk">@@ -3792,7 +3769,7 @@</span> <span class="p_context"> static void *kmalloc_large_node(size_t size, gfp_t flags, int node)</span>
 	struct page *page;
 	void *ptr = NULL;
 
<span class="p_del">-	flags |= __GFP_COMP | __GFP_NOTRACK;</span>
<span class="p_add">+	flags |= __GFP_COMP;</span>
 	page = alloc_pages_node(node, flags, get_order(size));
 	if (page)
 		ptr = page_address(page);
<span class="p_chunk">@@ -5655,8 +5632,6 @@</span> <span class="p_context"> static char *create_unique_id(struct kmem_cache *s)</span>
 		*p++ = &#39;a&#39;;
 	if (s-&gt;flags &amp; SLAB_CONSISTENCY_CHECKS)
 		*p++ = &#39;F&#39;;
<span class="p_del">-	if (!(s-&gt;flags &amp; SLAB_NOTRACK))</span>
<span class="p_del">-		*p++ = &#39;t&#39;;</span>
 	if (s-&gt;flags &amp; SLAB_ACCOUNT)
 		*p++ = &#39;A&#39;;
 	if (p != name + 1)
<span class="p_header">diff --git a/net/9p/trans_virtio.c b/net/9p/trans_virtio.c</span>
<span class="p_header">index f3a4efcf1456..3aa5a93ad107 100644</span>
<span class="p_header">--- a/net/9p/trans_virtio.c</span>
<span class="p_header">+++ b/net/9p/trans_virtio.c</span>
<span class="p_chunk">@@ -160,7 +160,8 @@</span> <span class="p_context"> static void req_done(struct virtqueue *vq)</span>
 		spin_unlock_irqrestore(&amp;chan-&gt;lock, flags);
 		/* Wakeup if anyone waiting for VirtIO ring space. */
 		wake_up(chan-&gt;vc_wq);
<span class="p_del">-		p9_client_cb(chan-&gt;client, req, REQ_STATUS_RCVD);</span>
<span class="p_add">+		if (len)</span>
<span class="p_add">+			p9_client_cb(chan-&gt;client, req, REQ_STATUS_RCVD);</span>
 	}
 }
 
<span class="p_header">diff --git a/net/core/skbuff.c b/net/core/skbuff.c</span>
<span class="p_header">index 15fa5baa8fae..cc811add68c6 100644</span>
<span class="p_header">--- a/net/core/skbuff.c</span>
<span class="p_header">+++ b/net/core/skbuff.c</span>
<span class="p_chunk">@@ -41,7 +41,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/types.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/interrupt.h&gt;
 #include &lt;linux/in.h&gt;
<span class="p_chunk">@@ -234,14 +233,12 @@</span> <span class="p_context"> struct sk_buff *__alloc_skb(unsigned int size, gfp_t gfp_mask,</span>
 	shinfo = skb_shinfo(skb);
 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
 	atomic_set(&amp;shinfo-&gt;dataref, 1);
<span class="p_del">-	kmemcheck_annotate_variable(shinfo-&gt;destructor_arg);</span>
 
 	if (flags &amp; SKB_ALLOC_FCLONE) {
 		struct sk_buff_fclones *fclones;
 
 		fclones = container_of(skb, struct sk_buff_fclones, skb1);
 
<span class="p_del">-		kmemcheck_annotate_bitfield(&amp;fclones-&gt;skb2, flags1);</span>
 		skb-&gt;fclone = SKB_FCLONE_ORIG;
 		refcount_set(&amp;fclones-&gt;fclone_ref, 1);
 
<span class="p_chunk">@@ -301,7 +298,6 @@</span> <span class="p_context"> struct sk_buff *__build_skb(void *data, unsigned int frag_size)</span>
 	shinfo = skb_shinfo(skb);
 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
 	atomic_set(&amp;shinfo-&gt;dataref, 1);
<span class="p_del">-	kmemcheck_annotate_variable(shinfo-&gt;destructor_arg);</span>
 
 	return skb;
 }
<span class="p_chunk">@@ -1284,7 +1280,6 @@</span> <span class="p_context"> struct sk_buff *skb_clone(struct sk_buff *skb, gfp_t gfp_mask)</span>
 		if (!n)
 			return NULL;
 
<span class="p_del">-		kmemcheck_annotate_bitfield(n, flags1);</span>
 		n-&gt;fclone = SKB_FCLONE_UNAVAILABLE;
 	}
 
<span class="p_header">diff --git a/net/core/sock.c b/net/core/sock.c</span>
<span class="p_header">index beb1e299fed3..ec6eb546b228 100644</span>
<span class="p_header">--- a/net/core/sock.c</span>
<span class="p_header">+++ b/net/core/sock.c</span>
<span class="p_chunk">@@ -1469,8 +1469,6 @@</span> <span class="p_context"> static struct sock *sk_prot_alloc(struct proto *prot, gfp_t priority,</span>
 		sk = kmalloc(prot-&gt;obj_size, priority);
 
 	if (sk != NULL) {
<span class="p_del">-		kmemcheck_annotate_bitfield(sk, flags);</span>
<span class="p_del">-</span>
 		if (security_sk_alloc(sk, family, priority))
 			goto out_free;
 
<span class="p_header">diff --git a/net/ipv4/inet_timewait_sock.c b/net/ipv4/inet_timewait_sock.c</span>
<span class="p_header">index 5b039159e67a..d451b9f19b59 100644</span>
<span class="p_header">--- a/net/ipv4/inet_timewait_sock.c</span>
<span class="p_header">+++ b/net/ipv4/inet_timewait_sock.c</span>
<span class="p_chunk">@@ -9,7 +9,6 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;net/inet_hashtables.h&gt;
<span class="p_chunk">@@ -167,8 +166,6 @@</span> <span class="p_context"> struct inet_timewait_sock *inet_twsk_alloc(const struct sock *sk,</span>
 	if (tw) {
 		const struct inet_sock *inet = inet_sk(sk);
 
<span class="p_del">-		kmemcheck_annotate_bitfield(tw, flags);</span>
<span class="p_del">-</span>
 		tw-&gt;tw_dr	    = dr;
 		/* Give us an identity. */
 		tw-&gt;tw_daddr	    = inet-&gt;inet_daddr;
<span class="p_header">diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="p_header">index ff48ac654e5a..d9d215e27b8a 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_input.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_input.c</span>
<span class="p_chunk">@@ -6204,7 +6204,6 @@</span> <span class="p_context"> struct request_sock *inet_reqsk_alloc(const struct request_sock_ops *ops,</span>
 	if (req) {
 		struct inet_request_sock *ireq = inet_rsk(req);
 
<span class="p_del">-		kmemcheck_annotate_bitfield(ireq, flags);</span>
 		ireq-&gt;ireq_opt = NULL;
 #if IS_ENABLED(CONFIG_IPV6)
 		ireq-&gt;pktopts = NULL;
<span class="p_header">diff --git a/net/mpls/af_mpls.c b/net/mpls/af_mpls.c</span>
<span class="p_header">index c5b9ce41d66f..aee385eb72e7 100644</span>
<span class="p_header">--- a/net/mpls/af_mpls.c</span>
<span class="p_header">+++ b/net/mpls/af_mpls.c</span>
<span class="p_chunk">@@ -8,6 +8,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/ipv6.h&gt;
 #include &lt;linux/mpls.h&gt;
 #include &lt;linux/netconf.h&gt;
<span class="p_add">+#include &lt;linux/nospec.h&gt;</span>
 #include &lt;linux/vmalloc.h&gt;
 #include &lt;linux/percpu.h&gt;
 #include &lt;net/ip.h&gt;
<span class="p_chunk">@@ -904,24 +905,27 @@</span> <span class="p_context"> static int mpls_nh_build_multi(struct mpls_route_config *cfg,</span>
 	return err;
 }
 
<span class="p_del">-static bool mpls_label_ok(struct net *net, unsigned int index,</span>
<span class="p_add">+static bool mpls_label_ok(struct net *net, unsigned int *index,</span>
 			  struct netlink_ext_ack *extack)
 {
<span class="p_add">+	bool is_ok = true;</span>
<span class="p_add">+</span>
 	/* Reserved labels may not be set */
<span class="p_del">-	if (index &lt; MPLS_LABEL_FIRST_UNRESERVED) {</span>
<span class="p_add">+	if (*index &lt; MPLS_LABEL_FIRST_UNRESERVED) {</span>
 		NL_SET_ERR_MSG(extack,
 			       &quot;Invalid label - must be MPLS_LABEL_FIRST_UNRESERVED or higher&quot;);
<span class="p_del">-		return false;</span>
<span class="p_add">+		is_ok = false;</span>
 	}
 
 	/* The full 20 bit range may not be supported. */
<span class="p_del">-	if (index &gt;= net-&gt;mpls.platform_labels) {</span>
<span class="p_add">+	if (is_ok &amp;&amp; *index &gt;= net-&gt;mpls.platform_labels) {</span>
 		NL_SET_ERR_MSG(extack,
 			       &quot;Label &gt;= configured maximum in platform_labels&quot;);
<span class="p_del">-		return false;</span>
<span class="p_add">+		is_ok = false;</span>
 	}
 
<span class="p_del">-	return true;</span>
<span class="p_add">+	*index = array_index_nospec(*index, net-&gt;mpls.platform_labels);</span>
<span class="p_add">+	return is_ok;</span>
 }
 
 static int mpls_route_add(struct mpls_route_config *cfg,
<span class="p_chunk">@@ -944,7 +948,7 @@</span> <span class="p_context"> static int mpls_route_add(struct mpls_route_config *cfg,</span>
 		index = find_free_label(net);
 	}
 
<span class="p_del">-	if (!mpls_label_ok(net, index, extack))</span>
<span class="p_add">+	if (!mpls_label_ok(net, &amp;index, extack))</span>
 		goto errout;
 
 	/* Append makes no sense with mpls */
<span class="p_chunk">@@ -1021,7 +1025,7 @@</span> <span class="p_context"> static int mpls_route_del(struct mpls_route_config *cfg,</span>
 
 	index = cfg-&gt;rc_label;
 
<span class="p_del">-	if (!mpls_label_ok(net, index, extack))</span>
<span class="p_add">+	if (!mpls_label_ok(net, &amp;index, extack))</span>
 		goto errout;
 
 	mpls_route_update(net, index, NULL, &amp;cfg-&gt;rc_nlinfo);
<span class="p_chunk">@@ -1779,7 +1783,7 @@</span> <span class="p_context"> static int rtm_to_route_config(struct sk_buff *skb,</span>
 				goto errout;
 
 			if (!mpls_label_ok(cfg-&gt;rc_nlinfo.nl_net,
<span class="p_del">-					   cfg-&gt;rc_label, extack))</span>
<span class="p_add">+					   &amp;cfg-&gt;rc_label, extack))</span>
 				goto errout;
 			break;
 		}
<span class="p_chunk">@@ -2106,7 +2110,7 @@</span> <span class="p_context"> static int mpls_getroute(struct sk_buff *in_skb, struct nlmsghdr *in_nlh,</span>
 			goto errout;
 		}
 
<span class="p_del">-		if (!mpls_label_ok(net, in_label, extack)) {</span>
<span class="p_add">+		if (!mpls_label_ok(net, &amp;in_label, extack)) {</span>
 			err = -EINVAL;
 			goto errout;
 		}
<span class="p_header">diff --git a/net/socket.c b/net/socket.c</span>
<span class="p_header">index d894c7c5fa54..43d2f17f5eea 100644</span>
<span class="p_header">--- a/net/socket.c</span>
<span class="p_header">+++ b/net/socket.c</span>
<span class="p_chunk">@@ -568,7 +568,6 @@</span> <span class="p_context"> struct socket *sock_alloc(void)</span>
 
 	sock = SOCKET_I(inode);
 
<span class="p_del">-	kmemcheck_annotate_bitfield(sock, type);</span>
 	inode-&gt;i_ino = get_next_ino();
 	inode-&gt;i_mode = S_IFSOCK | S_IRWXUGO;
 	inode-&gt;i_uid = current_fsuid();
<span class="p_header">diff --git a/net/sunrpc/xprtrdma/rpc_rdma.c b/net/sunrpc/xprtrdma/rpc_rdma.c</span>
<span class="p_header">index f1889f4d4803..491ae9fc561f 100644</span>
<span class="p_header">--- a/net/sunrpc/xprtrdma/rpc_rdma.c</span>
<span class="p_header">+++ b/net/sunrpc/xprtrdma/rpc_rdma.c</span>
<span class="p_chunk">@@ -142,7 +142,7 @@</span> <span class="p_context"> static bool rpcrdma_args_inline(struct rpcrdma_xprt *r_xprt,</span>
 	if (xdr-&gt;page_len) {
 		remaining = xdr-&gt;page_len;
 		offset = offset_in_page(xdr-&gt;page_base);
<span class="p_del">-		count = 0;</span>
<span class="p_add">+		count = RPCRDMA_MIN_SEND_SGES;</span>
 		while (remaining) {
 			remaining -= min_t(unsigned int,
 					   PAGE_SIZE - offset, remaining);
<span class="p_header">diff --git a/net/sunrpc/xprtrdma/verbs.c b/net/sunrpc/xprtrdma/verbs.c</span>
<span class="p_header">index 11a1fbf7e59e..9e8e1de19b2e 100644</span>
<span class="p_header">--- a/net/sunrpc/xprtrdma/verbs.c</span>
<span class="p_header">+++ b/net/sunrpc/xprtrdma/verbs.c</span>
<span class="p_chunk">@@ -523,7 +523,7 @@</span> <span class="p_context"> rpcrdma_ep_create(struct rpcrdma_ep *ep, struct rpcrdma_ia *ia,</span>
 		pr_warn(&quot;rpcrdma: HCA provides only %d send SGEs\n&quot;, max_sge);
 		return -ENOMEM;
 	}
<span class="p_del">-	ia-&gt;ri_max_send_sges = max_sge - RPCRDMA_MIN_SEND_SGES;</span>
<span class="p_add">+	ia-&gt;ri_max_send_sges = max_sge;</span>
 
 	if (ia-&gt;ri_device-&gt;attrs.max_qp_wr &lt;= RPCRDMA_BACKWARD_WRS) {
 		dprintk(&quot;RPC:       %s: insufficient wqe&#39;s available\n&quot;,
<span class="p_chunk">@@ -1331,6 +1331,9 @@</span> <span class="p_context"> __rpcrdma_dma_map_regbuf(struct rpcrdma_ia *ia, struct rpcrdma_regbuf *rb)</span>
 static void
 rpcrdma_dma_unmap_regbuf(struct rpcrdma_regbuf *rb)
 {
<span class="p_add">+	if (!rb)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (!rpcrdma_regbuf_is_mapped(rb))
 		return;
 
<span class="p_chunk">@@ -1346,9 +1349,6 @@</span> <span class="p_context"> rpcrdma_dma_unmap_regbuf(struct rpcrdma_regbuf *rb)</span>
 void
 rpcrdma_free_regbuf(struct rpcrdma_regbuf *rb)
 {
<span class="p_del">-	if (!rb)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
 	rpcrdma_dma_unmap_regbuf(rb);
 	kfree(rb);
 }
<span class="p_header">diff --git a/scripts/kernel-doc b/scripts/kernel-doc</span>
<span class="p_header">index 9d3eafea58f0..8323ff9dec71 100755</span>
<span class="p_header">--- a/scripts/kernel-doc</span>
<span class="p_header">+++ b/scripts/kernel-doc</span>
<span class="p_chunk">@@ -2182,8 +2182,6 @@</span> <span class="p_context"> sub dump_struct($$) {</span>
 	# strip comments:
 	$members =~ s/\/\*.*?\*\///gos;
 	$nested =~ s/\/\*.*?\*\///gos;
<span class="p_del">-	# strip kmemcheck_bitfield_{begin,end}.*;</span>
<span class="p_del">-	$members =~ s/kmemcheck_bitfield_.*?;//gos;</span>
 	# strip attributes
 	$members =~ s/__attribute__\s*\(\([a-z,_\*\s\(\)]*\)\)//i;
 	$members =~ s/__aligned\s*\([^;]*\)//gos;
<span class="p_header">diff --git a/sound/core/seq/seq_clientmgr.c b/sound/core/seq/seq_clientmgr.c</span>
<span class="p_header">index ac30fc1ab98b..dea11d1babf5 100644</span>
<span class="p_header">--- a/sound/core/seq/seq_clientmgr.c</span>
<span class="p_header">+++ b/sound/core/seq/seq_clientmgr.c</span>
<span class="p_chunk">@@ -999,7 +999,7 @@</span> <span class="p_context"> static ssize_t snd_seq_write(struct file *file, const char __user *buf,</span>
 {
 	struct snd_seq_client *client = file-&gt;private_data;
 	int written = 0, len;
<span class="p_del">-	int err = -EINVAL;</span>
<span class="p_add">+	int err;</span>
 	struct snd_seq_event event;
 
 	if (!(snd_seq_file_flags(file) &amp; SNDRV_SEQ_LFLG_OUTPUT))
<span class="p_chunk">@@ -1014,11 +1014,15 @@</span> <span class="p_context"> static ssize_t snd_seq_write(struct file *file, const char __user *buf,</span>
 
 	/* allocate the pool now if the pool is not allocated yet */ 
 	if (client-&gt;pool-&gt;size &gt; 0 &amp;&amp; !snd_seq_write_pool_allocated(client)) {
<span class="p_del">-		if (snd_seq_pool_init(client-&gt;pool) &lt; 0)</span>
<span class="p_add">+		mutex_lock(&amp;client-&gt;ioctl_mutex);</span>
<span class="p_add">+		err = snd_seq_pool_init(client-&gt;pool);</span>
<span class="p_add">+		mutex_unlock(&amp;client-&gt;ioctl_mutex);</span>
<span class="p_add">+		if (err &lt; 0)</span>
 			return -ENOMEM;
 	}
 
 	/* only process whole events */
<span class="p_add">+	err = -EINVAL;</span>
 	while (count &gt;= sizeof(struct snd_seq_event)) {
 		/* Read in the event header from the user */
 		len = sizeof(event);
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index b2d039537d5e..b7acffdf16a4 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -3355,6 +3355,19 @@</span> <span class="p_context"> static void alc269_fixup_pincfg_no_hp_to_lineout(struct hda_codec *codec,</span>
 		spec-&gt;parse_flags = HDA_PINCFG_NO_HP_FIXUP;
 }
 
<span class="p_add">+static void alc269_fixup_pincfg_U7x7_headset_mic(struct hda_codec *codec,</span>
<span class="p_add">+						 const struct hda_fixup *fix,</span>
<span class="p_add">+						 int action)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cfg_headphone = snd_hda_codec_get_pincfg(codec, 0x21);</span>
<span class="p_add">+	unsigned int cfg_headset_mic = snd_hda_codec_get_pincfg(codec, 0x19);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cfg_headphone &amp;&amp; cfg_headset_mic == 0x411111f0)</span>
<span class="p_add">+		snd_hda_codec_set_pincfg(codec, 0x19,</span>
<span class="p_add">+			(cfg_headphone &amp; ~AC_DEFCFG_DEVICE) |</span>
<span class="p_add">+			(AC_JACK_MIC_IN &lt;&lt; AC_DEFCFG_DEVICE_SHIFT));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void alc269_fixup_hweq(struct hda_codec *codec,
 			       const struct hda_fixup *fix, int action)
 {
<span class="p_chunk">@@ -4827,6 +4840,28 @@</span> <span class="p_context"> static void alc_fixup_tpt440_dock(struct hda_codec *codec,</span>
 	}
 }
 
<span class="p_add">+static void alc_fixup_tpt470_dock(struct hda_codec *codec,</span>
<span class="p_add">+				  const struct hda_fixup *fix, int action)</span>
<span class="p_add">+{</span>
<span class="p_add">+	static const struct hda_pintbl pincfgs[] = {</span>
<span class="p_add">+		{ 0x17, 0x21211010 }, /* dock headphone */</span>
<span class="p_add">+		{ 0x19, 0x21a11010 }, /* dock mic */</span>
<span class="p_add">+		{ }</span>
<span class="p_add">+	};</span>
<span class="p_add">+	struct alc_spec *spec = codec-&gt;spec;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (action == HDA_FIXUP_ACT_PRE_PROBE) {</span>
<span class="p_add">+		spec-&gt;parse_flags = HDA_PINCFG_NO_HP_FIXUP;</span>
<span class="p_add">+		/* Enable DOCK device */</span>
<span class="p_add">+		snd_hda_codec_write(codec, 0x17, 0,</span>
<span class="p_add">+			    AC_VERB_SET_CONFIG_DEFAULT_BYTES_3, 0);</span>
<span class="p_add">+		/* Enable DOCK device */</span>
<span class="p_add">+		snd_hda_codec_write(codec, 0x19, 0,</span>
<span class="p_add">+			    AC_VERB_SET_CONFIG_DEFAULT_BYTES_3, 0);</span>
<span class="p_add">+		snd_hda_apply_pincfgs(codec, pincfgs);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void alc_shutup_dell_xps13(struct hda_codec *codec)
 {
 	struct alc_spec *spec = codec-&gt;spec;
<span class="p_chunk">@@ -5206,6 +5241,7 @@</span> <span class="p_context"> enum {</span>
 	ALC269_FIXUP_LIFEBOOK_EXTMIC,
 	ALC269_FIXUP_LIFEBOOK_HP_PIN,
 	ALC269_FIXUP_LIFEBOOK_NO_HP_TO_LINEOUT,
<span class="p_add">+	ALC255_FIXUP_LIFEBOOK_U7x7_HEADSET_MIC,</span>
 	ALC269_FIXUP_AMIC,
 	ALC269_FIXUP_DMIC,
 	ALC269VB_FIXUP_AMIC,
<span class="p_chunk">@@ -5301,6 +5337,7 @@</span> <span class="p_context"> enum {</span>
 	ALC700_FIXUP_INTEL_REFERENCE,
 	ALC274_FIXUP_DELL_BIND_DACS,
 	ALC274_FIXUP_DELL_AIO_LINEOUT_VERB,
<span class="p_add">+	ALC298_FIXUP_TPT470_DOCK,</span>
 };
 
 static const struct hda_fixup alc269_fixups[] = {
<span class="p_chunk">@@ -5411,6 +5448,10 @@</span> <span class="p_context"> static const struct hda_fixup alc269_fixups[] = {</span>
 		.type = HDA_FIXUP_FUNC,
 		.v.func = alc269_fixup_pincfg_no_hp_to_lineout,
 	},
<span class="p_add">+	[ALC255_FIXUP_LIFEBOOK_U7x7_HEADSET_MIC] = {</span>
<span class="p_add">+		.type = HDA_FIXUP_FUNC,</span>
<span class="p_add">+		.v.func = alc269_fixup_pincfg_U7x7_headset_mic,</span>
<span class="p_add">+	},</span>
 	[ALC269_FIXUP_AMIC] = {
 		.type = HDA_FIXUP_PINS,
 		.v.pins = (const struct hda_pintbl[]) {
<span class="p_chunk">@@ -6126,6 +6167,12 @@</span> <span class="p_context"> static const struct hda_fixup alc269_fixups[] = {</span>
 		.chained = true,
 		.chain_id = ALC274_FIXUP_DELL_BIND_DACS
 	},
<span class="p_add">+	[ALC298_FIXUP_TPT470_DOCK] = {</span>
<span class="p_add">+		.type = HDA_FIXUP_FUNC,</span>
<span class="p_add">+		.v.func = alc_fixup_tpt470_dock,</span>
<span class="p_add">+		.chained = true,</span>
<span class="p_add">+		.chain_id = ALC293_FIXUP_LENOVO_SPK_NOISE</span>
<span class="p_add">+	},</span>
 };
 
 static const struct snd_pci_quirk alc269_fixup_tbl[] = {
<span class="p_chunk">@@ -6176,6 +6223,8 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc269_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x1028, 0x075d, &quot;Dell AIO&quot;, ALC298_FIXUP_SPK_VOLUME),
 	SND_PCI_QUIRK(0x1028, 0x0798, &quot;Dell Inspiron 17 7000 Gaming&quot;, ALC256_FIXUP_DELL_INSPIRON_7559_SUBWOOFER),
 	SND_PCI_QUIRK(0x1028, 0x082a, &quot;Dell XPS 13 9360&quot;, ALC256_FIXUP_DELL_XPS_13_HEADPHONE_NOISE),
<span class="p_add">+	SND_PCI_QUIRK(0x1028, 0x084b, &quot;Dell&quot;, ALC274_FIXUP_DELL_AIO_LINEOUT_VERB),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x1028, 0x084e, &quot;Dell&quot;, ALC274_FIXUP_DELL_AIO_LINEOUT_VERB),</span>
 	SND_PCI_QUIRK(0x1028, 0x164a, &quot;Dell&quot;, ALC293_FIXUP_DELL1_MIC_NO_PRESENCE),
 	SND_PCI_QUIRK(0x1028, 0x164b, &quot;Dell&quot;, ALC293_FIXUP_DELL1_MIC_NO_PRESENCE),
 	SND_PCI_QUIRK(0x103c, 0x1586, &quot;HP&quot;, ALC269_FIXUP_HP_MUTE_LED_MIC2),
<span class="p_chunk">@@ -6277,6 +6326,7 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc269_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x10cf, 0x159f, &quot;Lifebook E780&quot;, ALC269_FIXUP_LIFEBOOK_NO_HP_TO_LINEOUT),
 	SND_PCI_QUIRK(0x10cf, 0x15dc, &quot;Lifebook T731&quot;, ALC269_FIXUP_LIFEBOOK_HP_PIN),
 	SND_PCI_QUIRK(0x10cf, 0x1757, &quot;Lifebook E752&quot;, ALC269_FIXUP_LIFEBOOK_HP_PIN),
<span class="p_add">+	SND_PCI_QUIRK(0x10cf, 0x1629, &quot;Lifebook U7x7&quot;, ALC255_FIXUP_LIFEBOOK_U7x7_HEADSET_MIC),</span>
 	SND_PCI_QUIRK(0x10cf, 0x1845, &quot;Lifebook U904&quot;, ALC269_FIXUP_LIFEBOOK_EXTMIC),
 	SND_PCI_QUIRK(0x10ec, 0x10f2, &quot;Intel Reference board&quot;, ALC700_FIXUP_INTEL_REFERENCE),
 	SND_PCI_QUIRK(0x144d, 0xc109, &quot;Samsung Ativ book 9 (NP900X3G)&quot;, ALC269_FIXUP_INV_DMIC),
<span class="p_chunk">@@ -6305,8 +6355,16 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc269_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x17aa, 0x2218, &quot;Thinkpad X1 Carbon 2nd&quot;, ALC292_FIXUP_TPT440_DOCK),
 	SND_PCI_QUIRK(0x17aa, 0x2223, &quot;ThinkPad T550&quot;, ALC292_FIXUP_TPT440_DOCK),
 	SND_PCI_QUIRK(0x17aa, 0x2226, &quot;ThinkPad X250&quot;, ALC292_FIXUP_TPT440_DOCK),
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x222d, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x222e, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
 	SND_PCI_QUIRK(0x17aa, 0x2231, &quot;Thinkpad T560&quot;, ALC292_FIXUP_TPT460),
 	SND_PCI_QUIRK(0x17aa, 0x2233, &quot;Thinkpad&quot;, ALC292_FIXUP_TPT460),
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x2245, &quot;Thinkpad T470&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x2246, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x2247, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x224b, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x224c, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x224d, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
 	SND_PCI_QUIRK(0x17aa, 0x30bb, &quot;ThinkCentre AIO&quot;, ALC233_FIXUP_LENOVO_LINE2_MIC_HOTKEY),
 	SND_PCI_QUIRK(0x17aa, 0x30e2, &quot;ThinkCentre AIO&quot;, ALC233_FIXUP_LENOVO_LINE2_MIC_HOTKEY),
 	SND_PCI_QUIRK(0x17aa, 0x310c, &quot;ThinkCentre Station&quot;, ALC294_FIXUP_LENOVO_MIC_LOCATION),
<span class="p_chunk">@@ -6327,7 +6385,12 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc269_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x17aa, 0x5050, &quot;Thinkpad T560p&quot;, ALC292_FIXUP_TPT460),
 	SND_PCI_QUIRK(0x17aa, 0x5051, &quot;Thinkpad L460&quot;, ALC292_FIXUP_TPT460),
 	SND_PCI_QUIRK(0x17aa, 0x5053, &quot;Thinkpad T460&quot;, ALC292_FIXUP_TPT460),
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x505d, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x505f, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x5062, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
 	SND_PCI_QUIRK(0x17aa, 0x5109, &quot;Thinkpad&quot;, ALC269_FIXUP_LIMIT_INT_MIC_BOOST),
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x511e, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x511f, &quot;Thinkpad&quot;, ALC298_FIXUP_TPT470_DOCK),</span>
 	SND_PCI_QUIRK(0x17aa, 0x3bf8, &quot;Quanta FL1&quot;, ALC269_FIXUP_PCM_44K),
 	SND_PCI_QUIRK(0x17aa, 0x9e54, &quot;LENOVO NB&quot;, ALC269_FIXUP_LENOVO_EAPD),
 	SND_PCI_QUIRK(0x1b7d, 0xa831, &quot;Ordissimo EVE2 &quot;, ALC269VB_FIXUP_ORDISSIMO_EVE2), /* Also known as Malata PC-B1303 */
<span class="p_chunk">@@ -6584,6 +6647,11 @@</span> <span class="p_context"> static const struct snd_hda_pin_quirk alc269_pin_fixup_tbl[] = {</span>
 		{0x12, 0xb7a60130},
 		{0x14, 0x90170110},
 		{0x21, 0x02211020}),
<span class="p_add">+	SND_HDA_PIN_QUIRK(0x10ec0256, 0x1028, &quot;Dell&quot;, ALC255_FIXUP_DELL1_MIC_NO_PRESENCE,</span>
<span class="p_add">+		{0x12, 0x90a60130},</span>
<span class="p_add">+		{0x14, 0x90170110},</span>
<span class="p_add">+		{0x14, 0x01011020},</span>
<span class="p_add">+		{0x21, 0x0221101f}),</span>
 	SND_HDA_PIN_QUIRK(0x10ec0256, 0x1028, &quot;Dell&quot;, ALC255_FIXUP_DELL1_MIC_NO_PRESENCE,
 		ALC256_STANDARD_PINS),
 	SND_HDA_PIN_QUIRK(0x10ec0256, 0x1043, &quot;ASUS&quot;, ALC256_FIXUP_ASUS_MIC,
<span class="p_chunk">@@ -6653,6 +6721,10 @@</span> <span class="p_context"> static const struct snd_hda_pin_quirk alc269_pin_fixup_tbl[] = {</span>
 		{0x12, 0x90a60120},
 		{0x14, 0x90170110},
 		{0x21, 0x0321101f}),
<span class="p_add">+	SND_HDA_PIN_QUIRK(0x10ec0289, 0x1028, &quot;Dell&quot;, ALC225_FIXUP_DELL1_MIC_NO_PRESENCE,</span>
<span class="p_add">+		{0x12, 0xb7a60130},</span>
<span class="p_add">+		{0x14, 0x90170110},</span>
<span class="p_add">+		{0x21, 0x04211020}),</span>
 	SND_HDA_PIN_QUIRK(0x10ec0290, 0x103c, &quot;HP&quot;, ALC269_FIXUP_HP_MUTE_LED_MIC1,
 		ALC290_STANDARD_PINS,
 		{0x15, 0x04211040},
<span class="p_header">diff --git a/sound/soc/intel/common/sst-match-acpi.c b/sound/soc/intel/common/sst-match-acpi.c</span>
<span class="p_header">index 56d26f36a3cb..b4a929562218 100644</span>
<span class="p_header">--- a/sound/soc/intel/common/sst-match-acpi.c</span>
<span class="p_header">+++ b/sound/soc/intel/common/sst-match-acpi.c</span>
<span class="p_chunk">@@ -83,11 +83,9 @@</span> <span class="p_context"> struct sst_acpi_mach *sst_acpi_find_machine(struct sst_acpi_mach *machines)</span>
 
 	for (mach = machines; mach-&gt;id[0]; mach++) {
 		if (sst_acpi_check_hid(mach-&gt;id) == true) {
<span class="p_del">-			if (mach-&gt;machine_quirk == NULL)</span>
<span class="p_del">-				return mach;</span>
<span class="p_del">-</span>
<span class="p_del">-			if (mach-&gt;machine_quirk(mach) != NULL)</span>
<span class="p_del">-				return mach;</span>
<span class="p_add">+			if (mach-&gt;machine_quirk)</span>
<span class="p_add">+				mach = mach-&gt;machine_quirk(mach);</span>
<span class="p_add">+			return mach;</span>
 		}
 	}
 	return NULL;
<span class="p_header">diff --git a/sound/usb/mixer.c b/sound/usb/mixer.c</span>
<span class="p_header">index 75bce127d768..89efec891e68 100644</span>
<span class="p_header">--- a/sound/usb/mixer.c</span>
<span class="p_header">+++ b/sound/usb/mixer.c</span>
<span class="p_chunk">@@ -347,17 +347,20 @@</span> <span class="p_context"> static int get_ctl_value_v2(struct usb_mixer_elem_info *cval, int request,</span>
 			    int validx, int *value_ret)
 {
 	struct snd_usb_audio *chip = cval-&gt;head.mixer-&gt;chip;
<span class="p_del">-	unsigned char buf[4 + 3 * sizeof(__u32)]; /* enough space for one range */</span>
<span class="p_add">+	/* enough space for one range */</span>
<span class="p_add">+	unsigned char buf[sizeof(__u16) + 3 * sizeof(__u32)];</span>
 	unsigned char *val;
<span class="p_del">-	int idx = 0, ret, size;</span>
<span class="p_add">+	int idx = 0, ret, val_size, size;</span>
 	__u8 bRequest;
 
<span class="p_add">+	val_size = uac2_ctl_value_size(cval-&gt;val_type);</span>
<span class="p_add">+</span>
 	if (request == UAC_GET_CUR) {
 		bRequest = UAC2_CS_CUR;
<span class="p_del">-		size = uac2_ctl_value_size(cval-&gt;val_type);</span>
<span class="p_add">+		size = val_size;</span>
 	} else {
 		bRequest = UAC2_CS_RANGE;
<span class="p_del">-		size = sizeof(buf);</span>
<span class="p_add">+		size = sizeof(__u16) + 3 * val_size;</span>
 	}
 
 	memset(buf, 0, sizeof(buf));
<span class="p_chunk">@@ -390,16 +393,17 @@</span> <span class="p_context"> static int get_ctl_value_v2(struct usb_mixer_elem_info *cval, int request,</span>
 		val = buf + sizeof(__u16);
 		break;
 	case UAC_GET_MAX:
<span class="p_del">-		val = buf + sizeof(__u16) * 2;</span>
<span class="p_add">+		val = buf + sizeof(__u16) + val_size;</span>
 		break;
 	case UAC_GET_RES:
<span class="p_del">-		val = buf + sizeof(__u16) * 3;</span>
<span class="p_add">+		val = buf + sizeof(__u16) + val_size * 2;</span>
 		break;
 	default:
 		return -EINVAL;
 	}
 
<span class="p_del">-	*value_ret = convert_signed_value(cval, snd_usb_combine_bytes(val, sizeof(__u16)));</span>
<span class="p_add">+	*value_ret = convert_signed_value(cval,</span>
<span class="p_add">+					  snd_usb_combine_bytes(val, val_size));</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/sound/usb/pcm.c b/sound/usb/pcm.c</span>
<span class="p_header">index b9c9a19f9588..3cbfae6604f9 100644</span>
<span class="p_header">--- a/sound/usb/pcm.c</span>
<span class="p_header">+++ b/sound/usb/pcm.c</span>
<span class="p_chunk">@@ -352,6 +352,15 @@</span> <span class="p_context"> static int set_sync_ep_implicit_fb_quirk(struct snd_usb_substream *subs,</span>
 		ep = 0x86;
 		iface = usb_ifnum_to_if(dev, 2);
 
<span class="p_add">+		if (!iface || iface-&gt;num_altsetting == 0)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		alts = &amp;iface-&gt;altsetting[1];</span>
<span class="p_add">+		goto add_sync_ep;</span>
<span class="p_add">+	case USB_ID(0x1397, 0x0002):</span>
<span class="p_add">+		ep = 0x81;</span>
<span class="p_add">+		iface = usb_ifnum_to_if(dev, 1);</span>
<span class="p_add">+</span>
 		if (!iface || iface-&gt;num_altsetting == 0)
 			return -EINVAL;
 
<span class="p_header">diff --git a/sound/usb/quirks.c b/sound/usb/quirks.c</span>
<span class="p_header">index 8d7db7cd4f88..ed56cd307059 100644</span>
<span class="p_header">--- a/sound/usb/quirks.c</span>
<span class="p_header">+++ b/sound/usb/quirks.c</span>
<span class="p_chunk">@@ -1369,8 +1369,11 @@</span> <span class="p_context"> u64 snd_usb_interface_dsd_format_quirks(struct snd_usb_audio *chip,</span>
 			return SNDRV_PCM_FMTBIT_DSD_U32_BE;
 		break;
 
<span class="p_del">-	/* Amanero Combo384 USB interface with native DSD support */</span>
<span class="p_del">-	case USB_ID(0x16d0, 0x071a):</span>
<span class="p_add">+	/* Amanero Combo384 USB based DACs with native DSD support */</span>
<span class="p_add">+	case USB_ID(0x16d0, 0x071a):  /* Amanero - Combo384 */</span>
<span class="p_add">+	case USB_ID(0x2ab6, 0x0004):  /* T+A DAC8DSD-V2.0, MP1000E-V2.0, MP2000R-V2.0, MP2500R-V2.0, MP3100HV-V2.0 */</span>
<span class="p_add">+	case USB_ID(0x2ab6, 0x0005):  /* T+A USB HD Audio 1 */</span>
<span class="p_add">+	case USB_ID(0x2ab6, 0x0006):  /* T+A USB HD Audio 2 */</span>
 		if (fp-&gt;altsetting == 2) {
 			switch (le16_to_cpu(chip-&gt;dev-&gt;descriptor.bcdDevice)) {
 			case 0x199:
<span class="p_header">diff --git a/tools/include/linux/kmemcheck.h b/tools/include/linux/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index 2bccd2c7b897..000000000000</span>
<span class="p_header">--- a/tools/include/linux/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,9 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_del">-#ifndef _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="p_del">-#define _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/tools/objtool/check.c b/tools/objtool/check.c</span>
<span class="p_header">index 2e458eb45586..c7fb5c2392ee 100644</span>
<span class="p_header">--- a/tools/objtool/check.c</span>
<span class="p_header">+++ b/tools/objtool/check.c</span>
<span class="p_chunk">@@ -1935,13 +1935,19 @@</span> <span class="p_context"> static bool ignore_unreachable_insn(struct instruction *insn)</span>
 		if (is_kasan_insn(insn) || is_ubsan_insn(insn))
 			return true;
 
<span class="p_del">-		if (insn-&gt;type == INSN_JUMP_UNCONDITIONAL &amp;&amp; insn-&gt;jump_dest) {</span>
<span class="p_del">-			insn = insn-&gt;jump_dest;</span>
<span class="p_del">-			continue;</span>
<span class="p_add">+		if (insn-&gt;type == INSN_JUMP_UNCONDITIONAL) {</span>
<span class="p_add">+			if (insn-&gt;jump_dest &amp;&amp;</span>
<span class="p_add">+			    insn-&gt;jump_dest-&gt;func == insn-&gt;func) {</span>
<span class="p_add">+				insn = insn-&gt;jump_dest;</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			}</span>
<span class="p_add">+</span>
<span class="p_add">+			break;</span>
 		}
 
 		if (insn-&gt;offset + insn-&gt;len &gt;= insn-&gt;func-&gt;offset + insn-&gt;func-&gt;len)
 			break;
<span class="p_add">+</span>
 		insn = list_next_entry(insn, list);
 	}
 
<span class="p_header">diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c</span>
<span class="p_header">index 35d4b9c9a9e8..9e693ce4b73b 100644</span>
<span class="p_header">--- a/tools/perf/builtin-kmem.c</span>
<span class="p_header">+++ b/tools/perf/builtin-kmem.c</span>
<span class="p_chunk">@@ -655,7 +655,6 @@</span> <span class="p_context"> static const struct {</span>
 	{ &quot;__GFP_RECLAIMABLE&quot;,		&quot;RC&quot; },
 	{ &quot;__GFP_MOVABLE&quot;,		&quot;M&quot; },
 	{ &quot;__GFP_ACCOUNT&quot;,		&quot;AC&quot; },
<span class="p_del">-	{ &quot;__GFP_NOTRACK&quot;,		&quot;NT&quot; },</span>
 	{ &quot;__GFP_WRITE&quot;,		&quot;WR&quot; },
 	{ &quot;__GFP_RECLAIM&quot;,		&quot;R&quot; },
 	{ &quot;__GFP_DIRECT_RECLAIM&quot;,	&quot;DR&quot; },
<span class="p_header">diff --git a/tools/testing/selftests/seccomp/seccomp_bpf.c b/tools/testing/selftests/seccomp/seccomp_bpf.c</span>
<span class="p_header">index 24dbf634e2dd..0b457e8e0f0c 100644</span>
<span class="p_header">--- a/tools/testing/selftests/seccomp/seccomp_bpf.c</span>
<span class="p_header">+++ b/tools/testing/selftests/seccomp/seccomp_bpf.c</span>
<span class="p_chunk">@@ -1717,7 +1717,7 @@</span> <span class="p_context"> void tracer_ptrace(struct __test_metadata *_metadata, pid_t tracee,</span>
 
 	if (nr == __NR_getpid)
 		change_syscall(_metadata, tracee, __NR_getppid);
<span class="p_del">-	if (nr == __NR_open)</span>
<span class="p_add">+	if (nr == __NR_openat)</span>
 		change_syscall(_metadata, tracee, -1);
 }
 
<span class="p_chunk">@@ -1792,7 +1792,7 @@</span> <span class="p_context"> TEST_F(TRACE_syscall, ptrace_syscall_dropped)</span>
 					   true);
 
 	/* Tracer should skip the open syscall, resulting in EPERM. */
<span class="p_del">-	EXPECT_SYSCALL_RETURN(EPERM, syscall(__NR_open));</span>
<span class="p_add">+	EXPECT_SYSCALL_RETURN(EPERM, syscall(__NR_openat));</span>
 }
 
 TEST_F(TRACE_syscall, syscall_allowed)
<span class="p_header">diff --git a/tools/testing/selftests/vm/compaction_test.c b/tools/testing/selftests/vm/compaction_test.c</span>
<span class="p_header">index a65b016d4c13..1097f04e4d80 100644</span>
<span class="p_header">--- a/tools/testing/selftests/vm/compaction_test.c</span>
<span class="p_header">+++ b/tools/testing/selftests/vm/compaction_test.c</span>
<span class="p_chunk">@@ -137,6 +137,8 @@</span> <span class="p_context"> int check_compaction(unsigned long mem_free, unsigned int hugepage_size)</span>
 	printf(&quot;No of huge pages allocated = %d\n&quot;,
 	       (atoi(nr_hugepages)));
 
<span class="p_add">+	lseek(fd, 0, SEEK_SET);</span>
<span class="p_add">+</span>
 	if (write(fd, initial_nr_hugepages, strlen(initial_nr_hugepages))
 	    != strlen(initial_nr_hugepages)) {
 		perror(&quot;Failed to write value to /proc/sys/vm/nr_hugepages\n&quot;);
<span class="p_header">diff --git a/tools/testing/selftests/x86/Makefile b/tools/testing/selftests/x86/Makefile</span>
<span class="p_header">index 91fbfa8fdc15..aa6e2d7f6a1f 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/Makefile</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/Makefile</span>
<span class="p_chunk">@@ -5,16 +5,26 @@</span> <span class="p_context"> include ../lib.mk</span>
 
 .PHONY: all all_32 all_64 warn_32bit_failure clean
 
<span class="p_del">-TARGETS_C_BOTHBITS := single_step_syscall sysret_ss_attrs syscall_nt ptrace_syscall test_mremap_vdso \</span>
<span class="p_del">-			check_initial_reg_state sigreturn ldt_gdt iopl mpx-mini-test ioperm \</span>
<span class="p_add">+UNAME_M := $(shell uname -m)</span>
<span class="p_add">+CAN_BUILD_I386 := $(shell ./check_cc.sh $(CC) trivial_32bit_program.c -m32)</span>
<span class="p_add">+CAN_BUILD_X86_64 := $(shell ./check_cc.sh $(CC) trivial_64bit_program.c)</span>
<span class="p_add">+</span>
<span class="p_add">+TARGETS_C_BOTHBITS := single_step_syscall sysret_ss_attrs syscall_nt test_mremap_vdso \</span>
<span class="p_add">+			check_initial_reg_state sigreturn iopl mpx-mini-test ioperm \</span>
 			protection_keys test_vdso test_vsyscall
 TARGETS_C_32BIT_ONLY := entry_from_vm86 syscall_arg_fault test_syscall_vdso unwind_vdso \
 			test_FCMOV test_FCOMI test_FISTTP \
 			vdso_restorer
 TARGETS_C_64BIT_ONLY := fsgsbase sysret_rip
<span class="p_add">+# Some selftests require 32bit support enabled also on 64bit systems</span>
<span class="p_add">+TARGETS_C_32BIT_NEEDED := ldt_gdt ptrace_syscall</span>
 
<span class="p_del">-TARGETS_C_32BIT_ALL := $(TARGETS_C_BOTHBITS) $(TARGETS_C_32BIT_ONLY)</span>
<span class="p_add">+TARGETS_C_32BIT_ALL := $(TARGETS_C_BOTHBITS) $(TARGETS_C_32BIT_ONLY) $(TARGETS_C_32BIT_NEEDED)</span>
 TARGETS_C_64BIT_ALL := $(TARGETS_C_BOTHBITS) $(TARGETS_C_64BIT_ONLY)
<span class="p_add">+ifeq ($(CAN_BUILD_I386)$(CAN_BUILD_X86_64),11)</span>
<span class="p_add">+TARGETS_C_64BIT_ALL += $(TARGETS_C_32BIT_NEEDED)</span>
<span class="p_add">+endif</span>
<span class="p_add">+</span>
 BINARIES_32 := $(TARGETS_C_32BIT_ALL:%=%_32)
 BINARIES_64 := $(TARGETS_C_64BIT_ALL:%=%_64)
 
<span class="p_chunk">@@ -23,18 +33,16 @@</span> <span class="p_context"> BINARIES_64 := $(patsubst %,$(OUTPUT)/%,$(BINARIES_64))</span>
 
 CFLAGS := -O2 -g -std=gnu99 -pthread -Wall -no-pie
 
<span class="p_del">-UNAME_M := $(shell uname -m)</span>
<span class="p_del">-CAN_BUILD_I386 := $(shell ./check_cc.sh $(CC) trivial_32bit_program.c -m32)</span>
<span class="p_del">-CAN_BUILD_X86_64 := $(shell ./check_cc.sh $(CC) trivial_64bit_program.c)</span>
<span class="p_del">-</span>
 ifeq ($(CAN_BUILD_I386),1)
 all: all_32
 TEST_PROGS += $(BINARIES_32)
<span class="p_add">+EXTRA_CFLAGS += -DCAN_BUILD_32</span>
 endif
 
 ifeq ($(CAN_BUILD_X86_64),1)
 all: all_64
 TEST_PROGS += $(BINARIES_64)
<span class="p_add">+EXTRA_CFLAGS += -DCAN_BUILD_64</span>
 endif
 
 all_32: $(BINARIES_32)
<span class="p_header">diff --git a/tools/testing/selftests/x86/mpx-mini-test.c b/tools/testing/selftests/x86/mpx-mini-test.c</span>
<span class="p_header">index ec0f6b45ce8b..9c0325e1ea68 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/mpx-mini-test.c</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/mpx-mini-test.c</span>
<span class="p_chunk">@@ -315,11 +315,39 @@</span> <span class="p_context"> static inline void *__si_bounds_upper(siginfo_t *si)</span>
 	return si-&gt;si_upper;
 }
 #else
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This deals with old version of _sigfault in some distros:</span>
<span class="p_add">+ *</span>
<span class="p_add">+</span>
<span class="p_add">+old _sigfault:</span>
<span class="p_add">+        struct {</span>
<span class="p_add">+            void *si_addr;</span>
<span class="p_add">+	} _sigfault;</span>
<span class="p_add">+</span>
<span class="p_add">+new _sigfault:</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		void __user *_addr;</span>
<span class="p_add">+		int _trapno;</span>
<span class="p_add">+		short _addr_lsb;</span>
<span class="p_add">+		union {</span>
<span class="p_add">+			struct {</span>
<span class="p_add">+				void __user *_lower;</span>
<span class="p_add">+				void __user *_upper;</span>
<span class="p_add">+			} _addr_bnd;</span>
<span class="p_add">+			__u32 _pkey;</span>
<span class="p_add">+		};</span>
<span class="p_add">+	} _sigfault;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
 static inline void **__si_bounds_hack(siginfo_t *si)
 {
 	void *sigfault = &amp;si-&gt;_sifields._sigfault;
 	void *end_sigfault = sigfault + sizeof(si-&gt;_sifields._sigfault);
<span class="p_del">-	void **__si_lower = end_sigfault;</span>
<span class="p_add">+	int *trapno = (int*)end_sigfault;</span>
<span class="p_add">+	/* skip _trapno and _addr_lsb */</span>
<span class="p_add">+	void **__si_lower = (void**)(trapno + 2);</span>
 
 	return __si_lower;
 }
<span class="p_chunk">@@ -331,7 +359,7 @@</span> <span class="p_context"> static inline void *__si_bounds_lower(siginfo_t *si)</span>
 
 static inline void *__si_bounds_upper(siginfo_t *si)
 {
<span class="p_del">-	return (*__si_bounds_hack(si)) + sizeof(void *);</span>
<span class="p_add">+	return *(__si_bounds_hack(si) + 1);</span>
 }
 #endif
 
<span class="p_header">diff --git a/tools/testing/selftests/x86/protection_keys.c b/tools/testing/selftests/x86/protection_keys.c</span>
<span class="p_header">index 7a1cc0e56d2d..6cbb83b47150 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/protection_keys.c</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/protection_keys.c</span>
<span class="p_chunk">@@ -393,34 +393,6 @@</span> <span class="p_context"> pid_t fork_lazy_child(void)</span>
 	return forkret;
 }
 
<span class="p_del">-void davecmp(void *_a, void *_b, int len)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-	unsigned long *a = _a;</span>
<span class="p_del">-	unsigned long *b = _b;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; len / sizeof(*a); i++) {</span>
<span class="p_del">-		if (a[i] == b[i])</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		dprintf3(&quot;[%3d]: a: %016lx b: %016lx\n&quot;, i, a[i], b[i]);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void dumpit(char *f)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int fd = open(f, O_RDONLY);</span>
<span class="p_del">-	char buf[100];</span>
<span class="p_del">-	int nr_read;</span>
<span class="p_del">-</span>
<span class="p_del">-	dprintf2(&quot;maps fd: %d\n&quot;, fd);</span>
<span class="p_del">-	do {</span>
<span class="p_del">-		nr_read = read(fd, &amp;buf[0], sizeof(buf));</span>
<span class="p_del">-		write(1, buf, nr_read);</span>
<span class="p_del">-	} while (nr_read &gt; 0);</span>
<span class="p_del">-	close(fd);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #define PKEY_DISABLE_ACCESS    0x1
 #define PKEY_DISABLE_WRITE     0x2
 
<span class="p_header">diff --git a/tools/testing/selftests/x86/single_step_syscall.c b/tools/testing/selftests/x86/single_step_syscall.c</span>
<span class="p_header">index a48da95c18fd..ddfdd635de16 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/single_step_syscall.c</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/single_step_syscall.c</span>
<span class="p_chunk">@@ -119,7 +119,9 @@</span> <span class="p_context"> static void check_result(void)</span>
 
 int main()
 {
<span class="p_add">+#ifdef CAN_BUILD_32</span>
 	int tmp;
<span class="p_add">+#endif</span>
 
 	sethandler(SIGTRAP, sigtrap, 0);
 
<span class="p_chunk">@@ -139,12 +141,13 @@</span> <span class="p_context"> int main()</span>
 		      : : &quot;c&quot; (post_nop) : &quot;r11&quot;);
 	check_result();
 #endif
<span class="p_del">-</span>
<span class="p_add">+#ifdef CAN_BUILD_32</span>
 	printf(&quot;[RUN]\tSet TF and check int80\n&quot;);
 	set_eflags(get_eflags() | X86_EFLAGS_TF);
 	asm volatile (&quot;int $0x80&quot; : &quot;=a&quot; (tmp) : &quot;a&quot; (SYS_getpid)
 			: INT80_CLOBBERS);
 	check_result();
<span class="p_add">+#endif</span>
 
 	/*
 	 * This test is particularly interesting if fast syscalls use
<span class="p_header">diff --git a/tools/testing/selftests/x86/test_mremap_vdso.c b/tools/testing/selftests/x86/test_mremap_vdso.c</span>
<span class="p_header">index bf0d687c7db7..64f11c8d9b76 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/test_mremap_vdso.c</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/test_mremap_vdso.c</span>
<span class="p_chunk">@@ -90,8 +90,12 @@</span> <span class="p_context"> int main(int argc, char **argv, char **envp)</span>
 			vdso_size += PAGE_SIZE;
 		}
 
<span class="p_add">+#ifdef __i386__</span>
 		/* Glibc is likely to explode now - exit with raw syscall */
 		asm volatile (&quot;int $0x80&quot; : : &quot;a&quot; (__NR_exit), &quot;b&quot; (!!ret));
<span class="p_add">+#else /* __x86_64__ */</span>
<span class="p_add">+		syscall(SYS_exit, ret);</span>
<span class="p_add">+#endif</span>
 	} else {
 		int status;
 
<span class="p_header">diff --git a/tools/testing/selftests/x86/test_vdso.c b/tools/testing/selftests/x86/test_vdso.c</span>
<span class="p_header">index 29973cde06d3..235259011704 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/test_vdso.c</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/test_vdso.c</span>
<span class="p_chunk">@@ -26,20 +26,59 @@</span> <span class="p_context"></span>
 # endif
 #endif
 
<span class="p_add">+/* max length of lines in /proc/self/maps - anything longer is skipped here */</span>
<span class="p_add">+#define MAPS_LINE_LEN 128</span>
<span class="p_add">+</span>
 int nerrs = 0;
 
<span class="p_add">+typedef long (*getcpu_t)(unsigned *, unsigned *, void *);</span>
<span class="p_add">+</span>
<span class="p_add">+getcpu_t vgetcpu;</span>
<span class="p_add">+getcpu_t vdso_getcpu;</span>
<span class="p_add">+</span>
<span class="p_add">+static void *vsyscall_getcpu(void)</span>
<span class="p_add">+{</span>
 #ifdef __x86_64__
<span class="p_del">-# define VSYS(x) (x)</span>
<span class="p_add">+	FILE *maps;</span>
<span class="p_add">+	char line[MAPS_LINE_LEN];</span>
<span class="p_add">+	bool found = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	maps = fopen(&quot;/proc/self/maps&quot;, &quot;r&quot;);</span>
<span class="p_add">+	if (!maps) /* might still be present, but ignore it here, as we test vDSO not vsyscall */</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (fgets(line, MAPS_LINE_LEN, maps)) {</span>
<span class="p_add">+		char r, x;</span>
<span class="p_add">+		void *start, *end;</span>
<span class="p_add">+		char name[MAPS_LINE_LEN];</span>
<span class="p_add">+</span>
<span class="p_add">+		/* sscanf() is safe here as strlen(name) &gt;= strlen(line) */</span>
<span class="p_add">+		if (sscanf(line, &quot;%p-%p %c-%cp %*x %*x:%*x %*u %s&quot;,</span>
<span class="p_add">+			   &amp;start, &amp;end, &amp;r, &amp;x, name) != 5)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (strcmp(name, &quot;[vsyscall]&quot;))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* assume entries are OK, as we test vDSO here not vsyscall */</span>
<span class="p_add">+		found = true;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	fclose(maps);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!found) {</span>
<span class="p_add">+		printf(&quot;Warning: failed to find vsyscall getcpu\n&quot;);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return (void *) (0xffffffffff600800);</span>
 #else
<span class="p_del">-# define VSYS(x) 0</span>
<span class="p_add">+	return NULL;</span>
 #endif
<span class="p_add">+}</span>
 
<span class="p_del">-typedef long (*getcpu_t)(unsigned *, unsigned *, void *);</span>
<span class="p_del">-</span>
<span class="p_del">-const getcpu_t vgetcpu = (getcpu_t)VSYS(0xffffffffff600800);</span>
<span class="p_del">-getcpu_t vdso_getcpu;</span>
 
<span class="p_del">-void fill_function_pointers()</span>
<span class="p_add">+static void fill_function_pointers()</span>
 {
 	void *vdso = dlopen(&quot;linux-vdso.so.1&quot;,
 			    RTLD_LAZY | RTLD_LOCAL | RTLD_NOLOAD);
<span class="p_chunk">@@ -54,6 +93,8 @@</span> <span class="p_context"> void fill_function_pointers()</span>
 	vdso_getcpu = (getcpu_t)dlsym(vdso, &quot;__vdso_getcpu&quot;);
 	if (!vdso_getcpu)
 		printf(&quot;Warning: failed to find getcpu in vDSO\n&quot;);
<span class="p_add">+</span>
<span class="p_add">+	vgetcpu = (getcpu_t) vsyscall_getcpu();</span>
 }
 
 static long sys_getcpu(unsigned * cpu, unsigned * node,
<span class="p_header">diff --git a/tools/testing/selftests/x86/test_vsyscall.c b/tools/testing/selftests/x86/test_vsyscall.c</span>
<span class="p_header">index 6e0bd52ad53d..003b6c55b10e 100644</span>
<span class="p_header">--- a/tools/testing/selftests/x86/test_vsyscall.c</span>
<span class="p_header">+++ b/tools/testing/selftests/x86/test_vsyscall.c</span>
<span class="p_chunk">@@ -33,6 +33,9 @@</span> <span class="p_context"></span>
 # endif
 #endif
 
<span class="p_add">+/* max length of lines in /proc/self/maps - anything longer is skipped here */</span>
<span class="p_add">+#define MAPS_LINE_LEN 128</span>
<span class="p_add">+</span>
 static void sethandler(int sig, void (*handler)(int, siginfo_t *, void *),
 		       int flags)
 {
<span class="p_chunk">@@ -98,7 +101,7 @@</span> <span class="p_context"> static int init_vsys(void)</span>
 #ifdef __x86_64__
 	int nerrs = 0;
 	FILE *maps;
<span class="p_del">-	char line[128];</span>
<span class="p_add">+	char line[MAPS_LINE_LEN];</span>
 	bool found = false;
 
 	maps = fopen(&quot;/proc/self/maps&quot;, &quot;r&quot;);
<span class="p_chunk">@@ -108,10 +111,12 @@</span> <span class="p_context"> static int init_vsys(void)</span>
 		return 0;
 	}
 
<span class="p_del">-	while (fgets(line, sizeof(line), maps)) {</span>
<span class="p_add">+	while (fgets(line, MAPS_LINE_LEN, maps)) {</span>
 		char r, x;
 		void *start, *end;
<span class="p_del">-		char name[128];</span>
<span class="p_add">+		char name[MAPS_LINE_LEN];</span>
<span class="p_add">+</span>
<span class="p_add">+		/* sscanf() is safe here as strlen(name) &gt;= strlen(line) */</span>
 		if (sscanf(line, &quot;%p-%p %c-%cp %*x %*x:%*x %*u %s&quot;,
 			   &amp;start, &amp;end, &amp;r, &amp;x, name) != 5)
 			continue;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



