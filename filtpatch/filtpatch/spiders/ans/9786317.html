
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.9.32 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.9.32</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 14, 2017, 1:47 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170614134700.GB21610@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9786317/mbox/"
   >mbox</a>
|
   <a href="/patch/9786317/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9786317/">/patch/9786317/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E5DD460384 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:47:27 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id BEE8426224
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:47:27 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id B2749283A6; Wed, 14 Jun 2017 13:47:27 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9AE6026224
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:47:20 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752167AbdFNNrS (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 14 Jun 2017 09:47:18 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:56184 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751974AbdFNNrK (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 14 Jun 2017 09:47:10 -0400
Received: from localhost (LFbn-1-12060-104.w90-92.abo.wanadoo.fr
	[90.92.122.104])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 529CF95D;
	Wed, 14 Jun 2017 13:47:08 +0000 (UTC)
Date: Wed, 14 Jun 2017 15:47:00 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.9.32
Message-ID: &lt;20170614134700.GB21610@kroah.com&gt;
References: &lt;20170614134656.GA21610@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170614134656.GA21610@kroah.com&gt;
User-Agent: Mutt/1.8.3 (2017-05-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - June 14, 2017, 1:47 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 3601995f63f9..3d8781997968 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 9
<span class="p_del">-SUBLEVEL = 31</span>
<span class="p_add">+SUBLEVEL = 32</span>
 EXTRAVERSION =
 NAME = Roaring Lionus
 
<span class="p_header">diff --git a/arch/arm/kernel/setup.c b/arch/arm/kernel/setup.c</span>
<span class="p_header">index 34e3f3c45634..f4e54503afa9 100644</span>
<span class="p_header">--- a/arch/arm/kernel/setup.c</span>
<span class="p_header">+++ b/arch/arm/kernel/setup.c</span>
<span class="p_chunk">@@ -81,7 +81,7 @@</span> <span class="p_context"> __setup(&quot;fpe=&quot;, fpe_setup);</span>
 extern void init_default_cache_policy(unsigned long);
 extern void paging_init(const struct machine_desc *desc);
 extern void early_paging_init(const struct machine_desc *);
<span class="p_del">-extern void sanity_check_meminfo(void);</span>
<span class="p_add">+extern void adjust_lowmem_bounds(void);</span>
 extern enum reboot_mode reboot_mode;
 extern void setup_dma_zone(const struct machine_desc *desc);
 
<span class="p_chunk">@@ -1093,8 +1093,14 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 	setup_dma_zone(mdesc);
 	xen_early_init();
 	efi_init();
<span class="p_del">-	sanity_check_meminfo();</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Make sure the calculation for lowmem/highmem is set appropriately</span>
<span class="p_add">+	 * before reserving/allocating any mmeory</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	adjust_lowmem_bounds();</span>
 	arm_memblock_init(mdesc);
<span class="p_add">+	/* Memory may have been removed so recalculate the bounds. */</span>
<span class="p_add">+	adjust_lowmem_bounds();</span>
 
 	early_ioremap_reset();
 
<span class="p_header">diff --git a/arch/arm/kvm/init.S b/arch/arm/kvm/init.S</span>
<span class="p_header">index bf89c919efc1..bd0ee7fc304c 100644</span>
<span class="p_header">--- a/arch/arm/kvm/init.S</span>
<span class="p_header">+++ b/arch/arm/kvm/init.S</span>
<span class="p_chunk">@@ -95,7 +95,6 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	@  - Write permission implies XN: disabled
 	@  - Instruction cache: enabled
 	@  - Data/Unified cache: enabled
<span class="p_del">-	@  - Memory alignment checks: enabled</span>
 	@  - MMU: enabled (this code must be run from an identity mapping)
 	mrc	p15, 4, r0, c1, c0, 0	@ HSCR
 	ldr	r2, =HSCTLR_MASK
<span class="p_chunk">@@ -103,8 +102,8 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	mrc	p15, 0, r1, c1, c0, 0	@ SCTLR
 	ldr	r2, =(HSCTLR_EE | HSCTLR_FI | HSCTLR_I | HSCTLR_C)
 	and	r1, r1, r2
<span class="p_del">- ARM(	ldr	r2, =(HSCTLR_M | HSCTLR_A)			)</span>
<span class="p_del">- THUMB(	ldr	r2, =(HSCTLR_M | HSCTLR_A | HSCTLR_TE)		)</span>
<span class="p_add">+ ARM(	ldr	r2, =(HSCTLR_M)					)</span>
<span class="p_add">+ THUMB(	ldr	r2, =(HSCTLR_M | HSCTLR_TE)			)</span>
 	orr	r1, r1, r2
 	orr	r0, r0, r1
 	mcr	p15, 4, r0, c1, c0, 0	@ HSCR
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index 2fd5c135e8a4..332ce3b5a34f 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -872,6 +872,9 @@</span> <span class="p_context"> static pmd_t *stage2_get_pmd(struct kvm *kvm, struct kvm_mmu_memory_cache *cache</span>
 	pmd_t *pmd;
 
 	pud = stage2_get_pud(kvm, cache, addr);
<span class="p_add">+	if (!pud)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
 	if (stage2_pud_none(*pud)) {
 		if (!cache)
 			return NULL;
<span class="p_header">diff --git a/arch/arm/mm/mmu.c b/arch/arm/mm/mmu.c</span>
<span class="p_header">index 4001dd15818d..5cbfd9f86412 100644</span>
<span class="p_header">--- a/arch/arm/mm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/mm/mmu.c</span>
<span class="p_chunk">@@ -1152,13 +1152,12 @@</span> <span class="p_context"> early_param(&quot;vmalloc&quot;, early_vmalloc);</span>
 
 phys_addr_t arm_lowmem_limit __initdata = 0;
 
<span class="p_del">-void __init sanity_check_meminfo(void)</span>
<span class="p_add">+void __init adjust_lowmem_bounds(void)</span>
 {
 	phys_addr_t memblock_limit = 0;
<span class="p_del">-	int highmem = 0;</span>
 	u64 vmalloc_limit;
 	struct memblock_region *reg;
<span class="p_del">-	bool should_use_highmem = false;</span>
<span class="p_add">+	phys_addr_t lowmem_limit = 0;</span>
 
 	/*
 	 * Let&#39;s use our own (unoptimized) equivalent of __pa() that is
<span class="p_chunk">@@ -1172,43 +1171,18 @@</span> <span class="p_context"> void __init sanity_check_meminfo(void)</span>
 	for_each_memblock(memory, reg) {
 		phys_addr_t block_start = reg-&gt;base;
 		phys_addr_t block_end = reg-&gt;base + reg-&gt;size;
<span class="p_del">-		phys_addr_t size_limit = reg-&gt;size;</span>
 
<span class="p_del">-		if (reg-&gt;base &gt;= vmalloc_limit)</span>
<span class="p_del">-			highmem = 1;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			size_limit = vmalloc_limit - reg-&gt;base;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!IS_ENABLED(CONFIG_HIGHMEM) || cache_is_vipt_aliasing()) {</span>
<span class="p_del">-</span>
<span class="p_del">-			if (highmem) {</span>
<span class="p_del">-				pr_notice(&quot;Ignoring RAM at %pa-%pa (!CONFIG_HIGHMEM)\n&quot;,</span>
<span class="p_del">-					  &amp;block_start, &amp;block_end);</span>
<span class="p_del">-				memblock_remove(reg-&gt;base, reg-&gt;size);</span>
<span class="p_del">-				should_use_highmem = true;</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			if (reg-&gt;size &gt; size_limit) {</span>
<span class="p_del">-				phys_addr_t overlap_size = reg-&gt;size - size_limit;</span>
<span class="p_del">-</span>
<span class="p_del">-				pr_notice(&quot;Truncating RAM at %pa-%pa&quot;,</span>
<span class="p_del">-					  &amp;block_start, &amp;block_end);</span>
<span class="p_del">-				block_end = vmalloc_limit;</span>
<span class="p_del">-				pr_cont(&quot; to -%pa&quot;, &amp;block_end);</span>
<span class="p_del">-				memblock_remove(vmalloc_limit, overlap_size);</span>
<span class="p_del">-				should_use_highmem = true;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!highmem) {</span>
<span class="p_del">-			if (block_end &gt; arm_lowmem_limit) {</span>
<span class="p_del">-				if (reg-&gt;size &gt; size_limit)</span>
<span class="p_del">-					arm_lowmem_limit = vmalloc_limit;</span>
<span class="p_del">-				else</span>
<span class="p_del">-					arm_lowmem_limit = block_end;</span>
<span class="p_del">-			}</span>
<span class="p_add">+		if (reg-&gt;base &lt; vmalloc_limit) {</span>
<span class="p_add">+			if (block_end &gt; lowmem_limit)</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * Compare as u64 to ensure vmalloc_limit does</span>
<span class="p_add">+				 * not get truncated. block_end should always</span>
<span class="p_add">+				 * fit in phys_addr_t so there should be no</span>
<span class="p_add">+				 * issue with assignment.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				lowmem_limit = min_t(u64,</span>
<span class="p_add">+							 vmalloc_limit,</span>
<span class="p_add">+							 block_end);</span>
 
 			/*
 			 * Find the first non-pmd-aligned page, and point
<span class="p_chunk">@@ -1227,14 +1201,13 @@</span> <span class="p_context"> void __init sanity_check_meminfo(void)</span>
 				if (!IS_ALIGNED(block_start, PMD_SIZE))
 					memblock_limit = block_start;
 				else if (!IS_ALIGNED(block_end, PMD_SIZE))
<span class="p_del">-					memblock_limit = arm_lowmem_limit;</span>
<span class="p_add">+					memblock_limit = lowmem_limit;</span>
 			}
 
 		}
 	}
 
<span class="p_del">-	if (should_use_highmem)</span>
<span class="p_del">-		pr_notice(&quot;Consider using a HIGHMEM enabled kernel.\n&quot;);</span>
<span class="p_add">+	arm_lowmem_limit = lowmem_limit;</span>
 
 	high_memory = __va(arm_lowmem_limit - 1) + 1;
 
<span class="p_chunk">@@ -1248,6 +1221,18 @@</span> <span class="p_context"> void __init sanity_check_meminfo(void)</span>
 	if (!memblock_limit)
 		memblock_limit = arm_lowmem_limit;
 
<span class="p_add">+	if (!IS_ENABLED(CONFIG_HIGHMEM) || cache_is_vipt_aliasing()) {</span>
<span class="p_add">+		if (memblock_end_of_DRAM() &gt; arm_lowmem_limit) {</span>
<span class="p_add">+			phys_addr_t end = memblock_end_of_DRAM();</span>
<span class="p_add">+</span>
<span class="p_add">+			pr_notice(&quot;Ignoring RAM at %pa-%pa\n&quot;,</span>
<span class="p_add">+				  &amp;memblock_limit, &amp;end);</span>
<span class="p_add">+			pr_notice(&quot;Consider using a HIGHMEM enabled kernel.\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+			memblock_remove(memblock_limit, end - memblock_limit);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	memblock_set_current_limit(memblock_limit);
 }
 
<span class="p_header">diff --git a/arch/arm/mm/nommu.c b/arch/arm/mm/nommu.c</span>
<span class="p_header">index 2740967727e2..13a25d6282f8 100644</span>
<span class="p_header">--- a/arch/arm/mm/nommu.c</span>
<span class="p_header">+++ b/arch/arm/mm/nommu.c</span>
<span class="p_chunk">@@ -85,7 +85,7 @@</span> <span class="p_context"> static unsigned long irbar_read(void)</span>
 }
 
 /* MPU initialisation functions */
<span class="p_del">-void __init sanity_check_meminfo_mpu(void)</span>
<span class="p_add">+void __init adjust_lowmem_bounds_mpu(void)</span>
 {
 	phys_addr_t phys_offset = PHYS_OFFSET;
 	phys_addr_t aligned_region_size, specified_mem_size, rounded_mem_size;
<span class="p_chunk">@@ -274,7 +274,7 @@</span> <span class="p_context"> void __init mpu_setup(void)</span>
 	}
 }
 #else
<span class="p_del">-static void sanity_check_meminfo_mpu(void) {}</span>
<span class="p_add">+static void adjust_lowmem_bounds_mpu(void) {}</span>
 static void __init mpu_setup(void) {}
 #endif /* CONFIG_ARM_MPU */
 
<span class="p_chunk">@@ -295,10 +295,10 @@</span> <span class="p_context"> void __init arm_mm_memblock_reserve(void)</span>
 #endif
 }
 
<span class="p_del">-void __init sanity_check_meminfo(void)</span>
<span class="p_add">+void __init adjust_lowmem_bounds(void)</span>
 {
 	phys_addr_t end;
<span class="p_del">-	sanity_check_meminfo_mpu();</span>
<span class="p_add">+	adjust_lowmem_bounds_mpu();</span>
 	end = memblock_end_of_DRAM();
 	high_memory = __va(end - 1) + 1;
 	memblock_set_current_limit(end);
<span class="p_header">diff --git a/arch/arm64/include/asm/asm-uaccess.h b/arch/arm64/include/asm/asm-uaccess.h</span>
new file mode 100644
<span class="p_header">index 000000000000..be2d2347d995</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm64/include/asm/asm-uaccess.h</span>
<span class="p_chunk">@@ -0,0 +1,13 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef __ASM_ASM_UACCESS_H</span>
<span class="p_add">+#define __ASM_ASM_UACCESS_H</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Remove the address tag from a virtual address, if present.</span>
<span class="p_add">+ */</span>
<span class="p_add">+	.macro	clear_address_tag, dst, addr</span>
<span class="p_add">+	tst	\addr, #(1 &lt;&lt; 55)</span>
<span class="p_add">+	bic	\dst, \addr, #(0xff &lt;&lt; 56)</span>
<span class="p_add">+	csel	\dst, \dst, \addr, eq</span>
<span class="p_add">+	.endm</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/arm64/include/asm/sysreg.h b/arch/arm64/include/asm/sysreg.h</span>
<span class="p_header">index 6c80b3699cb8..7393cc767edb 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/sysreg.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/sysreg.h</span>
<span class="p_chunk">@@ -94,6 +94,10 @@</span> <span class="p_context"></span>
 #define SCTLR_ELx_A	(1 &lt;&lt; 1)
 #define SCTLR_ELx_M	1
 
<span class="p_add">+#define SCTLR_EL2_RES1	((1 &lt;&lt; 4)  | (1 &lt;&lt; 5)  | (1 &lt;&lt; 11) | (1 &lt;&lt; 16) | \</span>
<span class="p_add">+			 (1 &lt;&lt; 16) | (1 &lt;&lt; 18) | (1 &lt;&lt; 22) | (1 &lt;&lt; 23) | \</span>
<span class="p_add">+			 (1 &lt;&lt; 28) | (1 &lt;&lt; 29))</span>
<span class="p_add">+</span>
 #define SCTLR_ELx_FLAGS	(SCTLR_ELx_M | SCTLR_ELx_A | SCTLR_ELx_C | \
 			 SCTLR_ELx_SA | SCTLR_ELx_I)
 
<span class="p_header">diff --git a/arch/arm64/include/asm/uaccess.h b/arch/arm64/include/asm/uaccess.h</span>
<span class="p_header">index 14cca10aeb4e..811cf16a65f9 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/uaccess.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/uaccess.h</span>
<span class="p_chunk">@@ -105,9 +105,9 @@</span> <span class="p_context"> static inline void set_fs(mm_segment_t fs)</span>
 })
 
 /*
<span class="p_del">- * When dealing with data aborts or instruction traps we may end up with</span>
<span class="p_del">- * a tagged userland pointer. Clear the tag to get a sane pointer to pass</span>
<span class="p_del">- * on to access_ok(), for instance.</span>
<span class="p_add">+ * When dealing with data aborts, watchpoints, or instruction traps we may end</span>
<span class="p_add">+ * up with a tagged userland pointer. Clear the tag to get a sane pointer to</span>
<span class="p_add">+ * pass on to access_ok(), for instance.</span>
  */
 #define untagged_addr(addr)		sign_extend64(addr, 55)
 
<span class="p_header">diff --git a/arch/arm64/kernel/entry.S b/arch/arm64/kernel/entry.S</span>
<span class="p_header">index 79b0fe24d5b7..b4c7db434654 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/entry.S</span>
<span class="p_header">+++ b/arch/arm64/kernel/entry.S</span>
<span class="p_chunk">@@ -30,6 +30,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/irq.h&gt;
 #include &lt;asm/memory.h&gt;
 #include &lt;asm/thread_info.h&gt;
<span class="p_add">+#include &lt;asm/asm-uaccess.h&gt;</span>
 #include &lt;asm/unistd.h&gt;
 
 /*
<span class="p_chunk">@@ -369,12 +370,13 @@</span> <span class="p_context"> el1_da:</span>
 	/*
 	 * Data abort handling
 	 */
<span class="p_del">-	mrs	x0, far_el1</span>
<span class="p_add">+	mrs	x3, far_el1</span>
 	enable_dbg
 	// re-enable interrupts if they were enabled in the aborted context
 	tbnz	x23, #7, 1f			// PSR_I_BIT
 	enable_irq
 1:
<span class="p_add">+	clear_address_tag x0, x3</span>
 	mov	x2, sp				// struct pt_regs
 	bl	do_mem_abort
 
<span class="p_chunk">@@ -535,7 +537,7 @@</span> <span class="p_context"> el0_da:</span>
 	// enable interrupts before calling the main handler
 	enable_dbg_and_irq
 	ct_user_exit
<span class="p_del">-	bic	x0, x26, #(0xff &lt;&lt; 56)</span>
<span class="p_add">+	clear_address_tag x0, x26</span>
 	mov	x1, x25
 	mov	x2, sp
 	bl	do_mem_abort
<span class="p_header">diff --git a/arch/arm64/kernel/hw_breakpoint.c b/arch/arm64/kernel/hw_breakpoint.c</span>
<span class="p_header">index 948b73148d56..0b9e5f6290f9 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/hw_breakpoint.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/hw_breakpoint.c</span>
<span class="p_chunk">@@ -36,6 +36,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/traps.h&gt;
 #include &lt;asm/cputype.h&gt;
 #include &lt;asm/system_misc.h&gt;
<span class="p_add">+#include &lt;asm/uaccess.h&gt;</span>
 
 /* Breakpoint currently in use for each BRP. */
 static DEFINE_PER_CPU(struct perf_event *, bp_on_reg[ARM_MAX_BRP]);
<span class="p_chunk">@@ -696,7 +697,7 @@</span> <span class="p_context"> static int watchpoint_handler(unsigned long addr, unsigned int esr,</span>
 
 		/* Check if the watchpoint value matches. */
 		val = read_wb_reg(AARCH64_DBG_REG_WVR, i);
<span class="p_del">-		if (val != (addr &amp; ~alignment_mask))</span>
<span class="p_add">+		if (val != (untagged_addr(addr) &amp; ~alignment_mask))</span>
 			goto unlock;
 
 		/* Possible match, check the byte address select to confirm. */
<span class="p_header">diff --git a/arch/arm64/kernel/traps.c b/arch/arm64/kernel/traps.c</span>
<span class="p_header">index 11e5eae088ab..f22826135c73 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/traps.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/traps.c</span>
<span class="p_chunk">@@ -435,7 +435,7 @@</span> <span class="p_context"> int cpu_enable_cache_maint_trap(void *__unused)</span>
 }
 
 #define __user_cache_maint(insn, address, res)			\
<span class="p_del">-	if (untagged_addr(address) &gt;= user_addr_max())		\</span>
<span class="p_add">+	if (address &gt;= user_addr_max())				\</span>
 		res = -EFAULT;					\
 	else							\
 		asm volatile (					\
<span class="p_chunk">@@ -458,7 +458,7 @@</span> <span class="p_context"> static void user_cache_maint_handler(unsigned int esr, struct pt_regs *regs)</span>
 	int crm = (esr &amp; ESR_ELx_SYS64_ISS_CRM_MASK) &gt;&gt; ESR_ELx_SYS64_ISS_CRM_SHIFT;
 	int ret = 0;
 
<span class="p_del">-	address = (rt == 31) ? 0 : regs-&gt;regs[rt];</span>
<span class="p_add">+	address = (rt == 31) ? 0 : untagged_addr(regs-&gt;regs[rt]);</span>
 
 	switch (crm) {
 	case ESR_ELx_SYS64_ISS_CRM_DC_CVAU:	/* DC CVAU, gets promoted */
<span class="p_header">diff --git a/arch/arm64/kvm/hyp-init.S b/arch/arm64/kvm/hyp-init.S</span>
<span class="p_header">index 6b29d3d9e1f2..4bbff904169d 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp-init.S</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp-init.S</span>
<span class="p_chunk">@@ -102,10 +102,13 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	tlbi	alle2
 	dsb	sy
 
<span class="p_del">-	mrs	x4, sctlr_el2</span>
<span class="p_del">-	and	x4, x4, #SCTLR_ELx_EE	// preserve endianness of EL2</span>
<span class="p_del">-	ldr	x5, =SCTLR_ELx_FLAGS</span>
<span class="p_del">-	orr	x4, x4, x5</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Preserve all the RES1 bits while setting the default flags,</span>
<span class="p_add">+	 * as well as the EE bit on BE. Drop the A flag since the compiler</span>
<span class="p_add">+	 * is allowed to generate unaligned accesses.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	ldr	x4, =(SCTLR_EL2_RES1 | (SCTLR_ELx_FLAGS &amp; ~SCTLR_ELx_A))</span>
<span class="p_add">+CPU_BE(	orr	x4, x4, #SCTLR_ELx_EE)</span>
 	msr	sctlr_el2, x4
 	isb
 
<span class="p_header">diff --git a/arch/powerpc/include/asm/topology.h b/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">index 8b3b46b7b0f2..329771559cbb 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/topology.h</span>
<span class="p_chunk">@@ -44,8 +44,22 @@</span> <span class="p_context"> extern void __init dump_numa_cpu_topology(void);</span>
 extern int sysfs_add_device_to_node(struct device *dev, int nid);
 extern void sysfs_remove_device_from_node(struct device *dev, int nid);
 
<span class="p_add">+static inline int early_cpu_to_node(int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int nid;</span>
<span class="p_add">+</span>
<span class="p_add">+	nid = numa_cpu_lookup_table[cpu];</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Fall back to node 0 if nid is unset (it should be, except bugs).</span>
<span class="p_add">+	 * This allows callers to safely do NODE_DATA(early_cpu_to_node(cpu)).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return (nid &lt; 0) ? 0 : nid;</span>
<span class="p_add">+}</span>
 #else
 
<span class="p_add">+static inline int early_cpu_to_node(int cpu) { return 0; }</span>
<span class="p_add">+</span>
 static inline void dump_numa_cpu_topology(void) {}
 
 static inline int sysfs_add_device_to_node(struct device *dev, int nid)
<span class="p_header">diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c</span>
<span class="p_header">index c7164739dc75..b249c2fb99c8 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/process.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/process.c</span>
<span class="p_chunk">@@ -1659,6 +1659,7 @@</span> <span class="p_context"> void start_thread(struct pt_regs *regs, unsigned long start, unsigned long sp)</span>
 #ifdef CONFIG_VSX
 	current-&gt;thread.used_vsr = 0;
 #endif
<span class="p_add">+	current-&gt;thread.load_fp = 0;</span>
 	memset(&amp;current-&gt;thread.fp_state, 0, sizeof(current-&gt;thread.fp_state));
 	current-&gt;thread.fp_save_area = NULL;
 #ifdef CONFIG_ALTIVEC
<span class="p_chunk">@@ -1667,6 +1668,7 @@</span> <span class="p_context"> void start_thread(struct pt_regs *regs, unsigned long start, unsigned long sp)</span>
 	current-&gt;thread.vr_save_area = NULL;
 	current-&gt;thread.vrsave = 0;
 	current-&gt;thread.used_vr = 0;
<span class="p_add">+	current-&gt;thread.load_vec = 0;</span>
 #endif /* CONFIG_ALTIVEC */
 #ifdef CONFIG_SPE
 	memset(current-&gt;thread.evr, 0, sizeof(current-&gt;thread.evr));
<span class="p_chunk">@@ -1678,6 +1680,7 @@</span> <span class="p_context"> void start_thread(struct pt_regs *regs, unsigned long start, unsigned long sp)</span>
 	current-&gt;thread.tm_tfhar = 0;
 	current-&gt;thread.tm_texasr = 0;
 	current-&gt;thread.tm_tfiar = 0;
<span class="p_add">+	current-&gt;thread.load_tm = 0;</span>
 #endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
 }
 EXPORT_SYMBOL(start_thread);
<span class="p_header">diff --git a/arch/powerpc/kernel/setup_64.c b/arch/powerpc/kernel/setup_64.c</span>
<span class="p_header">index a12be60181bf..ada71bee176d 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/setup_64.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/setup_64.c</span>
<span class="p_chunk">@@ -595,7 +595,7 @@</span> <span class="p_context"> void __init emergency_stack_init(void)</span>
 
 static void * __init pcpu_fc_alloc(unsigned int cpu, size_t size, size_t align)
 {
<span class="p_del">-	return __alloc_bootmem_node(NODE_DATA(cpu_to_node(cpu)), size, align,</span>
<span class="p_add">+	return __alloc_bootmem_node(NODE_DATA(early_cpu_to_node(cpu)), size, align,</span>
 				    __pa(MAX_DMA_ADDRESS));
 }
 
<span class="p_chunk">@@ -606,7 +606,7 @@</span> <span class="p_context"> static void __init pcpu_fc_free(void *ptr, size_t size)</span>
 
 static int pcpu_cpu_distance(unsigned int from, unsigned int to)
 {
<span class="p_del">-	if (cpu_to_node(from) == cpu_to_node(to))</span>
<span class="p_add">+	if (early_cpu_to_node(from) == early_cpu_to_node(to))</span>
 		return LOCAL_DISTANCE;
 	else
 		return REMOTE_DISTANCE;
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/hotplug-memory.c b/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_header">index 76ec104e88be..c0a0947f43bb 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_chunk">@@ -124,6 +124,7 @@</span> <span class="p_context"> static struct property *dlpar_clone_drconf_property(struct device_node *dn)</span>
 	for (i = 0; i &lt; num_lmbs; i++) {
 		lmbs[i].base_addr = be64_to_cpu(lmbs[i].base_addr);
 		lmbs[i].drc_index = be32_to_cpu(lmbs[i].drc_index);
<span class="p_add">+		lmbs[i].aa_index = be32_to_cpu(lmbs[i].aa_index);</span>
 		lmbs[i].flags = be32_to_cpu(lmbs[i].flags);
 	}
 
<span class="p_chunk">@@ -147,6 +148,7 @@</span> <span class="p_context"> static void dlpar_update_drconf_property(struct device_node *dn,</span>
 	for (i = 0; i &lt; num_lmbs; i++) {
 		lmbs[i].base_addr = cpu_to_be64(lmbs[i].base_addr);
 		lmbs[i].drc_index = cpu_to_be32(lmbs[i].drc_index);
<span class="p_add">+		lmbs[i].aa_index = cpu_to_be32(lmbs[i].aa_index);</span>
 		lmbs[i].flags = cpu_to_be32(lmbs[i].flags);
 	}
 
<span class="p_header">diff --git a/arch/powerpc/sysdev/simple_gpio.c b/arch/powerpc/sysdev/simple_gpio.c</span>
<span class="p_header">index ef470b470b04..6afddae2fb47 100644</span>
<span class="p_header">--- a/arch/powerpc/sysdev/simple_gpio.c</span>
<span class="p_header">+++ b/arch/powerpc/sysdev/simple_gpio.c</span>
<span class="p_chunk">@@ -75,7 +75,8 @@</span> <span class="p_context"> static int u8_gpio_dir_out(struct gpio_chip *gc, unsigned int gpio, int val)</span>
 
 static void u8_gpio_save_regs(struct of_mm_gpio_chip *mm_gc)
 {
<span class="p_del">-	struct u8_gpio_chip *u8_gc = gpiochip_get_data(&amp;mm_gc-&gt;gc);</span>
<span class="p_add">+	struct u8_gpio_chip *u8_gc =</span>
<span class="p_add">+		container_of(mm_gc, struct u8_gpio_chip, mm_gc);</span>
 
 	u8_gc-&gt;data = in_8(mm_gc-&gt;regs);
 }
<span class="p_header">diff --git a/arch/sparc/Kconfig b/arch/sparc/Kconfig</span>
<span class="p_header">index 165ecdd24d22..b27e48e25841 100644</span>
<span class="p_header">--- a/arch/sparc/Kconfig</span>
<span class="p_header">+++ b/arch/sparc/Kconfig</span>
<span class="p_chunk">@@ -187,9 +187,9 @@</span> <span class="p_context"> config NR_CPUS</span>
 	int &quot;Maximum number of CPUs&quot;
 	depends on SMP
 	range 2 32 if SPARC32
<span class="p_del">-	range 2 1024 if SPARC64</span>
<span class="p_add">+	range 2 4096 if SPARC64</span>
 	default 32 if SPARC32
<span class="p_del">-	default 64 if SPARC64</span>
<span class="p_add">+	default 4096 if SPARC64</span>
 
 source kernel/Kconfig.hz
 
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">index f7de0dbc38af..83b36a5371ff 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"></span>
 #define CTX_NR_MASK		TAG_CONTEXT_BITS
 #define CTX_HW_MASK		(CTX_NR_MASK | CTX_PGSZ_MASK)
 
<span class="p_del">-#define CTX_FIRST_VERSION	((_AC(1,UL) &lt;&lt; CTX_VERSION_SHIFT) + _AC(1,UL))</span>
<span class="p_add">+#define CTX_FIRST_VERSION	BIT(CTX_VERSION_SHIFT)</span>
 #define CTX_VALID(__ctx)	\
 	 (!(((__ctx.sparc64_ctx_val) ^ tlb_context_cache) &amp; CTX_VERSION_MASK))
 #define CTX_HWBITS(__ctx)	((__ctx.sparc64_ctx_val) &amp; CTX_HW_MASK)
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index b84be675e507..349dd23e2876 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -17,13 +17,8 @@</span> <span class="p_context"> extern spinlock_t ctx_alloc_lock;</span>
 extern unsigned long tlb_context_cache;
 extern unsigned long mmu_context_bmap[];
 
<span class="p_add">+DECLARE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm);</span>
 void get_new_mmu_context(struct mm_struct *mm);
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-void smp_new_mmu_context_version(void);</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define smp_new_mmu_context_version() do { } while (0)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
 void destroy_context(struct mm_struct *mm);
 
<span class="p_chunk">@@ -74,8 +69,9 @@</span> <span class="p_context"> void __flush_tlb_mm(unsigned long, unsigned long);</span>
 static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, struct task_struct *tsk)
 {
 	unsigned long ctx_valid, flags;
<span class="p_del">-	int cpu;</span>
<span class="p_add">+	int cpu = smp_processor_id();</span>
 
<span class="p_add">+	per_cpu(per_cpu_secondary_mm, cpu) = mm;</span>
 	if (unlikely(mm == &amp;init_mm))
 		return;
 
<span class="p_chunk">@@ -121,7 +117,6 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 	 * for the first time, we must flush that context out of the
 	 * local TLB.
 	 */
<span class="p_del">-	cpu = smp_processor_id();</span>
 	if (!ctx_valid || !cpumask_test_cpu(cpu, mm_cpumask(mm))) {
 		cpumask_set_cpu(cpu, mm_cpumask(mm));
 		__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),
<span class="p_chunk">@@ -131,26 +126,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 }
 
 #define deactivate_mm(tsk,mm)	do { } while (0)
<span class="p_del">-</span>
<span class="p_del">-/* Activate a new MM instance for the current task. */</span>
<span class="p_del">-static inline void activate_mm(struct mm_struct *active_mm, struct mm_struct *mm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-	int cpu;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-	if (!CTX_VALID(mm-&gt;context))</span>
<span class="p_del">-		get_new_mmu_context(mm);</span>
<span class="p_del">-	cpu = smp_processor_id();</span>
<span class="p_del">-	if (!cpumask_test_cpu(cpu, mm_cpumask(mm)))</span>
<span class="p_del">-		cpumask_set_cpu(cpu, mm_cpumask(mm));</span>
<span class="p_del">-</span>
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	__flush_tlb_mm(CTX_HWBITS(mm-&gt;context), SECONDARY_CONTEXT);</span>
<span class="p_del">-	tsb_context_switch(mm);</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_add">+#define activate_mm(active_mm, mm) switch_mm(active_mm, mm, NULL)</span>
 #endif /* !(__ASSEMBLY__) */
 
 #endif /* !(__SPARC64_MMU_CONTEXT_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/pil.h b/arch/sparc/include/asm/pil.h</span>
<span class="p_header">index 266937030546..522b43db2ed3 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pil.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pil.h</span>
<span class="p_chunk">@@ -20,7 +20,6 @@</span> <span class="p_context"></span>
 #define PIL_SMP_CALL_FUNC	1
 #define PIL_SMP_RECEIVE_SIGNAL	2
 #define PIL_SMP_CAPTURE		3
<span class="p_del">-#define PIL_SMP_CTX_NEW_VERSION	4</span>
 #define PIL_DEVICE_IRQ		5
 #define PIL_SMP_CALL_FUNC_SNGL	6
 #define PIL_DEFERRED_PCR_WORK	7
<span class="p_header">diff --git a/arch/sparc/include/asm/vio.h b/arch/sparc/include/asm/vio.h</span>
<span class="p_header">index 8174f6cdbbbb..9dca7a892978 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/vio.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/vio.h</span>
<span class="p_chunk">@@ -327,6 +327,7 @@</span> <span class="p_context"> struct vio_dev {</span>
 	int			compat_len;
 
 	u64			dev_no;
<span class="p_add">+	u64			id;</span>
 
 	unsigned long		channel_id;
 
<span class="p_header">diff --git a/arch/sparc/kernel/irq_64.c b/arch/sparc/kernel/irq_64.c</span>
<span class="p_header">index 34a7930b76ef..e1b1ce63a328 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/irq_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/irq_64.c</span>
<span class="p_chunk">@@ -1034,17 +1034,26 @@</span> <span class="p_context"> static void __init init_cpu_send_mondo_info(struct trap_per_cpu *tb)</span>
 {
 #ifdef CONFIG_SMP
 	unsigned long page;
<span class="p_add">+	void *mondo, *p;</span>
 
<span class="p_del">-	BUILD_BUG_ON((NR_CPUS * sizeof(u16)) &gt; (PAGE_SIZE - 64));</span>
<span class="p_add">+	BUILD_BUG_ON((NR_CPUS * sizeof(u16)) &gt; PAGE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Make sure mondo block is 64byte aligned */</span>
<span class="p_add">+	p = kzalloc(127, GFP_KERNEL);</span>
<span class="p_add">+	if (!p) {</span>
<span class="p_add">+		prom_printf(&quot;SUN4V: Error, cannot allocate mondo block.\n&quot;);</span>
<span class="p_add">+		prom_halt();</span>
<span class="p_add">+	}</span>
<span class="p_add">+	mondo = (void *)(((unsigned long)p + 63) &amp; ~0x3f);</span>
<span class="p_add">+	tb-&gt;cpu_mondo_block_pa = __pa(mondo);</span>
 
 	page = get_zeroed_page(GFP_KERNEL);
 	if (!page) {
<span class="p_del">-		prom_printf(&quot;SUN4V: Error, cannot allocate cpu mondo page.\n&quot;);</span>
<span class="p_add">+		prom_printf(&quot;SUN4V: Error, cannot allocate cpu list page.\n&quot;);</span>
 		prom_halt();
 	}
 
<span class="p_del">-	tb-&gt;cpu_mondo_block_pa = __pa(page);</span>
<span class="p_del">-	tb-&gt;cpu_list_pa = __pa(page + 64);</span>
<span class="p_add">+	tb-&gt;cpu_list_pa = __pa(page);</span>
 #endif
 }
 
<span class="p_header">diff --git a/arch/sparc/kernel/kernel.h b/arch/sparc/kernel/kernel.h</span>
<span class="p_header">index c9804551262c..6ae1e77be0bf 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/kernel.h</span>
<span class="p_header">+++ b/arch/sparc/kernel/kernel.h</span>
<span class="p_chunk">@@ -37,7 +37,6 @@</span> <span class="p_context"> void handle_stdfmna(struct pt_regs *regs, unsigned long sfar, unsigned long sfsr</span>
 /* smp_64.c */
 void __irq_entry smp_call_function_client(int irq, struct pt_regs *regs);
 void __irq_entry smp_call_function_single_client(int irq, struct pt_regs *regs);
<span class="p_del">-void __irq_entry smp_new_mmu_context_version_client(int irq, struct pt_regs *regs);</span>
 void __irq_entry smp_penguin_jailcell(int irq, struct pt_regs *regs);
 void __irq_entry smp_receive_signal_client(int irq, struct pt_regs *regs);
 
<span class="p_header">diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">index 8182f7caf5b1..d5807d24b98f 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/smp_64.c</span>
<span class="p_chunk">@@ -963,37 +963,6 @@</span> <span class="p_context"> void flush_dcache_page_all(struct mm_struct *mm, struct page *page)</span>
 	preempt_enable();
 }
 
<span class="p_del">-void __irq_entry smp_new_mmu_context_version_client(int irq, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct mm_struct *mm;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	clear_softint(1 &lt;&lt; irq);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See if we need to allocate a new TLB context because</span>
<span class="p_del">-	 * the version of the one we are using is now out of date.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	mm = current-&gt;active_mm;</span>
<span class="p_del">-	if (unlikely(!mm || (mm == &amp;init_mm)))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(!CTX_VALID(mm-&gt;context)))</span>
<span class="p_del">-		get_new_mmu_context(mm);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),</span>
<span class="p_del">-		       SECONDARY_CONTEXT);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void smp_new_mmu_context_version(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	smp_cross_call(&amp;xcall_new_mmu_context_version, 0, 0, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KGDB
 void kgdb_roundup_cpus(unsigned long flags)
 {
<span class="p_header">diff --git a/arch/sparc/kernel/tsb.S b/arch/sparc/kernel/tsb.S</span>
<span class="p_header">index d568c8207af7..395ec1800530 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/tsb.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/tsb.S</span>
<span class="p_chunk">@@ -470,13 +470,16 @@</span> <span class="p_context"> __tsb_context_switch:</span>
 	.type	copy_tsb,#function
 copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size
 			 * %o2=new_tsb_base, %o3=new_tsb_size
<span class="p_add">+			 * %o4=page_size_shift</span>
 			 */
 	sethi		%uhi(TSB_PASS_BITS), %g7
 	srlx		%o3, 4, %o3
<span class="p_del">-	add		%o0, %o1, %g1	/* end of old tsb */</span>
<span class="p_add">+	add		%o0, %o1, %o1	/* end of old tsb */</span>
 	sllx		%g7, 32, %g7
 	sub		%o3, 1, %o3	/* %o3 == new tsb hash mask */
 
<span class="p_add">+	mov		%o4, %g1	/* page_size_shift */</span>
<span class="p_add">+</span>
 661:	prefetcha	[%o0] ASI_N, #one_read
 	.section	.tsb_phys_patch, &quot;ax&quot;
 	.word		661b
<span class="p_chunk">@@ -501,9 +504,9 @@</span> <span class="p_context"> copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size</span>
 	/* This can definitely be computed faster... */
 	srlx		%o0, 4, %o5	/* Build index */
 	and		%o5, 511, %o5	/* Mask index */
<span class="p_del">-	sllx		%o5, PAGE_SHIFT, %o5 /* Put into vaddr position */</span>
<span class="p_add">+	sllx		%o5, %g1, %o5	/* Put into vaddr position */</span>
 	or		%o4, %o5, %o4	/* Full VADDR. */
<span class="p_del">-	srlx		%o4, PAGE_SHIFT, %o4 /* Shift down to create index */</span>
<span class="p_add">+	srlx		%o4, %g1, %o4	/* Shift down to create index */</span>
 	and		%o4, %o3, %o4	/* Mask with new_tsb_nents-1 */
 	sllx		%o4, 4, %o4	/* Shift back up into tsb ent offset */
 	TSB_STORE(%o2 + %o4, %g2)	/* Store TAG */
<span class="p_chunk">@@ -511,7 +514,7 @@</span> <span class="p_context"> copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size</span>
 	TSB_STORE(%o2 + %o4, %g3)	/* Store TTE */
 
 80:	add		%o0, 16, %o0
<span class="p_del">-	cmp		%o0, %g1</span>
<span class="p_add">+	cmp		%o0, %o1</span>
 	bne,pt		%xcc, 90b
 	 nop
 
<span class="p_header">diff --git a/arch/sparc/kernel/ttable_64.S b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">index c6dfdaa29e20..170ead662f2a 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> tl0_resv03e:	BTRAP(0x3e) BTRAP(0x3f) BTRAP(0x40)</span>
 tl0_irq1:	TRAP_IRQ(smp_call_function_client, 1)
 tl0_irq2:	TRAP_IRQ(smp_receive_signal_client, 2)
 tl0_irq3:	TRAP_IRQ(smp_penguin_jailcell, 3)
<span class="p_del">-tl0_irq4:	TRAP_IRQ(smp_new_mmu_context_version_client, 4)</span>
<span class="p_add">+tl0_irq4:       BTRAP(0x44)</span>
 #else
 tl0_irq1:	BTRAP(0x41)
 tl0_irq2:	BTRAP(0x42)
<span class="p_header">diff --git a/arch/sparc/kernel/vio.c b/arch/sparc/kernel/vio.c</span>
<span class="p_header">index f6bb857254fc..075d38980dee 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/vio.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/vio.c</span>
<span class="p_chunk">@@ -302,13 +302,16 @@</span> <span class="p_context"> static struct vio_dev *vio_create_one(struct mdesc_handle *hp, u64 mp,</span>
 	if (!id) {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s&quot;, bus_id_name);
 		vdev-&gt;dev_no = ~(u64)0;
<span class="p_add">+		vdev-&gt;id = ~(u64)0;</span>
 	} else if (!cfg_handle) {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s-%llu&quot;, bus_id_name, *id);
 		vdev-&gt;dev_no = *id;
<span class="p_add">+		vdev-&gt;id = ~(u64)0;</span>
 	} else {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s-%llu-%llu&quot;, bus_id_name,
 			     *cfg_handle, *id);
 		vdev-&gt;dev_no = *cfg_handle;
<span class="p_add">+		vdev-&gt;id = *id;</span>
 	}
 
 	vdev-&gt;dev.parent = parent;
<span class="p_chunk">@@ -351,27 +354,84 @@</span> <span class="p_context"> static void vio_add(struct mdesc_handle *hp, u64 node)</span>
 	(void) vio_create_one(hp, node, &amp;root_vdev-&gt;dev);
 }
 
<span class="p_add">+struct vio_md_node_query {</span>
<span class="p_add">+	const char *type;</span>
<span class="p_add">+	u64 dev_no;</span>
<span class="p_add">+	u64 id;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 static int vio_md_node_match(struct device *dev, void *arg)
 {
<span class="p_add">+	struct vio_md_node_query *query = (struct vio_md_node_query *) arg;</span>
 	struct vio_dev *vdev = to_vio_dev(dev);
 
<span class="p_del">-	if (vdev-&gt;mp == (u64) arg)</span>
<span class="p_del">-		return 1;</span>
<span class="p_add">+	if (vdev-&gt;dev_no != query-&gt;dev_no)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (vdev-&gt;id != query-&gt;id)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (strcmp(vdev-&gt;type, query-&gt;type))</span>
<span class="p_add">+		return 0;</span>
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return 1;</span>
 }
 
 static void vio_remove(struct mdesc_handle *hp, u64 node)
 {
<span class="p_add">+	const char *type;</span>
<span class="p_add">+	const u64 *id, *cfg_handle;</span>
<span class="p_add">+	u64 a;</span>
<span class="p_add">+	struct vio_md_node_query query;</span>
 	struct device *dev;
 
<span class="p_del">-	dev = device_find_child(&amp;root_vdev-&gt;dev, (void *) node,</span>
<span class="p_add">+	type = mdesc_get_property(hp, node, &quot;device-type&quot;, NULL);</span>
<span class="p_add">+	if (!type) {</span>
<span class="p_add">+		type = mdesc_get_property(hp, node, &quot;name&quot;, NULL);</span>
<span class="p_add">+		if (!type)</span>
<span class="p_add">+			type = mdesc_node_name(hp, node);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	query.type = type;</span>
<span class="p_add">+</span>
<span class="p_add">+	id = mdesc_get_property(hp, node, &quot;id&quot;, NULL);</span>
<span class="p_add">+	cfg_handle = NULL;</span>
<span class="p_add">+	mdesc_for_each_arc(a, hp, node, MDESC_ARC_TYPE_BACK) {</span>
<span class="p_add">+		u64 target;</span>
<span class="p_add">+</span>
<span class="p_add">+		target = mdesc_arc_target(hp, a);</span>
<span class="p_add">+		cfg_handle = mdesc_get_property(hp, target,</span>
<span class="p_add">+						&quot;cfg-handle&quot;, NULL);</span>
<span class="p_add">+		if (cfg_handle)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!id) {</span>
<span class="p_add">+		query.dev_no = ~(u64)0;</span>
<span class="p_add">+		query.id = ~(u64)0;</span>
<span class="p_add">+	} else if (!cfg_handle) {</span>
<span class="p_add">+		query.dev_no = *id;</span>
<span class="p_add">+		query.id = ~(u64)0;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		query.dev_no = *cfg_handle;</span>
<span class="p_add">+		query.id = *id;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dev = device_find_child(&amp;root_vdev-&gt;dev, &amp;query,</span>
 				vio_md_node_match);
 	if (dev) {
 		printk(KERN_INFO &quot;VIO: Removing device %s\n&quot;, dev_name(dev));
 
 		device_unregister(dev);
 		put_device(dev);
<span class="p_add">+	} else {</span>
<span class="p_add">+		if (!id)</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node.\n&quot;,</span>
<span class="p_add">+			       type);</span>
<span class="p_add">+		else if (!cfg_handle)</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node %llu.\n&quot;,</span>
<span class="p_add">+			       type, *id);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node %llu-%llu.\n&quot;,</span>
<span class="p_add">+			       type, *cfg_handle, *id);</span>
 	}
 }
 
<span class="p_header">diff --git a/arch/sparc/lib/Makefile b/arch/sparc/lib/Makefile</span>
<span class="p_header">index 69912d2f8b54..07c03e72d812 100644</span>
<span class="p_header">--- a/arch/sparc/lib/Makefile</span>
<span class="p_header">+++ b/arch/sparc/lib/Makefile</span>
<span class="p_chunk">@@ -15,6 +15,7 @@</span> <span class="p_context"> lib-$(CONFIG_SPARC32) += copy_user.o locks.o</span>
 lib-$(CONFIG_SPARC64) += atomic_64.o
 lib-$(CONFIG_SPARC32) += lshrdi3.o ashldi3.o
 lib-$(CONFIG_SPARC32) += muldi3.o bitext.o cmpdi2.o
<span class="p_add">+lib-$(CONFIG_SPARC64) += multi3.o</span>
 
 lib-$(CONFIG_SPARC64) += copy_page.o clear_page.o bzero.o
 lib-$(CONFIG_SPARC64) += csum_copy.o csum_copy_from_user.o csum_copy_to_user.o
<span class="p_header">diff --git a/arch/sparc/lib/multi3.S b/arch/sparc/lib/multi3.S</span>
new file mode 100644
<span class="p_header">index 000000000000..d6b6c97fe3c7</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/lib/multi3.S</span>
<span class="p_chunk">@@ -0,0 +1,35 @@</span> <span class="p_context"></span>
<span class="p_add">+#include &lt;linux/linkage.h&gt;</span>
<span class="p_add">+#include &lt;asm/export.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+	.text</span>
<span class="p_add">+	.align	4</span>
<span class="p_add">+ENTRY(__multi3) /* %o0 = u, %o1 = v */</span>
<span class="p_add">+	mov	%o1, %g1</span>
<span class="p_add">+	srl	%o3, 0, %g4</span>
<span class="p_add">+	mulx	%g4, %g1, %o1</span>
<span class="p_add">+	srlx	%g1, 0x20, %g3</span>
<span class="p_add">+	mulx	%g3, %g4, %g5</span>
<span class="p_add">+	sllx	%g5, 0x20, %o5</span>
<span class="p_add">+	srl	%g1, 0, %g4</span>
<span class="p_add">+	sub	%o1, %o5, %o5</span>
<span class="p_add">+	srlx	%o5, 0x20, %o5</span>
<span class="p_add">+	addcc	%g5, %o5, %g5</span>
<span class="p_add">+	srlx	%o3, 0x20, %o5</span>
<span class="p_add">+	mulx	%g4, %o5, %g4</span>
<span class="p_add">+	mulx	%g3, %o5, %o5</span>
<span class="p_add">+	sethi	%hi(0x80000000), %g3</span>
<span class="p_add">+	addcc	%g5, %g4, %g5</span>
<span class="p_add">+	srlx	%g5, 0x20, %g5</span>
<span class="p_add">+	add	%g3, %g3, %g3</span>
<span class="p_add">+	movcc	%xcc, %g0, %g3</span>
<span class="p_add">+	addcc	%o5, %g5, %o5</span>
<span class="p_add">+	sllx	%g4, 0x20, %g4</span>
<span class="p_add">+	add	%o1, %g4, %o1</span>
<span class="p_add">+	add	%o5, %g3, %g2</span>
<span class="p_add">+	mulx	%g1, %o2, %g1</span>
<span class="p_add">+	add	%g1, %g2, %g1</span>
<span class="p_add">+	mulx	%o0, %o3, %o0</span>
<span class="p_add">+	retl</span>
<span class="p_add">+	 add	%g1, %o0, %o0</span>
<span class="p_add">+ENDPROC(__multi3)</span>
<span class="p_add">+EXPORT_SYMBOL(__multi3)</span>
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index bd7e2aa86c45..57154c638e71 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -658,10 +658,58 @@</span> <span class="p_context"> EXPORT_SYMBOL(__flush_dcache_range);</span>
 
 /* get_new_mmu_context() uses &quot;cache + 1&quot;.  */
 DEFINE_SPINLOCK(ctx_alloc_lock);
<span class="p_del">-unsigned long tlb_context_cache = CTX_FIRST_VERSION - 1;</span>
<span class="p_add">+unsigned long tlb_context_cache = CTX_FIRST_VERSION;</span>
 #define MAX_CTX_NR	(1UL &lt;&lt; CTX_NR_BITS)
 #define CTX_BMAP_SLOTS	BITS_TO_LONGS(MAX_CTX_NR)
 DECLARE_BITMAP(mmu_context_bmap, MAX_CTX_NR);
<span class="p_add">+DEFINE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm) = {0};</span>
<span class="p_add">+</span>
<span class="p_add">+static void mmu_context_wrap(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long old_ver = tlb_context_cache &amp; CTX_VERSION_MASK;</span>
<span class="p_add">+	unsigned long new_ver, new_ctx, old_ctx;</span>
<span class="p_add">+	struct mm_struct *mm;</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	bitmap_zero(mmu_context_bmap, 1 &lt;&lt; CTX_NR_BITS);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reserve kernel context */</span>
<span class="p_add">+	set_bit(0, mmu_context_bmap);</span>
<span class="p_add">+</span>
<span class="p_add">+	new_ver = (tlb_context_cache &amp; CTX_VERSION_MASK) + CTX_FIRST_VERSION;</span>
<span class="p_add">+	if (unlikely(new_ver == 0))</span>
<span class="p_add">+		new_ver = CTX_FIRST_VERSION;</span>
<span class="p_add">+	tlb_context_cache = new_ver;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Make sure that any new mm that are added into per_cpu_secondary_mm,</span>
<span class="p_add">+	 * are going to go through get_new_mmu_context() path.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mb();</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Updated versions to current on those CPUs that had valid secondary</span>
<span class="p_add">+	 * contexts</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_online_cpu(cpu) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If a new mm is stored after we took this mm from the array,</span>
<span class="p_add">+		 * it will go into get_new_mmu_context() path, because we</span>
<span class="p_add">+		 * already bumped the version in tlb_context_cache.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		mm = per_cpu(per_cpu_secondary_mm, cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(!mm || mm == &amp;init_mm))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		old_ctx = mm-&gt;context.sparc64_ctx_val;</span>
<span class="p_add">+		if (likely((old_ctx &amp; CTX_VERSION_MASK) == old_ver)) {</span>
<span class="p_add">+			new_ctx = (old_ctx &amp; ~CTX_VERSION_MASK) | new_ver;</span>
<span class="p_add">+			set_bit(new_ctx &amp; CTX_NR_MASK, mmu_context_bmap);</span>
<span class="p_add">+			mm-&gt;context.sparc64_ctx_val = new_ctx;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
 
 /* Caller does TLB context flushing on local CPU if necessary.
  * The caller also ensures that CTX_VALID(mm-&gt;context) is false.
<span class="p_chunk">@@ -677,48 +725,30 @@</span> <span class="p_context"> void get_new_mmu_context(struct mm_struct *mm)</span>
 {
 	unsigned long ctx, new_ctx;
 	unsigned long orig_pgsz_bits;
<span class="p_del">-	int new_version;</span>
 
 	spin_lock(&amp;ctx_alloc_lock);
<span class="p_add">+retry:</span>
<span class="p_add">+	/* wrap might have happened, test again if our context became valid */</span>
<span class="p_add">+	if (unlikely(CTX_VALID(mm-&gt;context)))</span>
<span class="p_add">+		goto out;</span>
 	orig_pgsz_bits = (mm-&gt;context.sparc64_ctx_val &amp; CTX_PGSZ_MASK);
 	ctx = (tlb_context_cache + 1) &amp; CTX_NR_MASK;
 	new_ctx = find_next_zero_bit(mmu_context_bmap, 1 &lt;&lt; CTX_NR_BITS, ctx);
<span class="p_del">-	new_version = 0;</span>
 	if (new_ctx &gt;= (1 &lt;&lt; CTX_NR_BITS)) {
 		new_ctx = find_next_zero_bit(mmu_context_bmap, ctx, 1);
 		if (new_ctx &gt;= ctx) {
<span class="p_del">-			int i;</span>
<span class="p_del">-			new_ctx = (tlb_context_cache &amp; CTX_VERSION_MASK) +</span>
<span class="p_del">-				CTX_FIRST_VERSION;</span>
<span class="p_del">-			if (new_ctx == 1)</span>
<span class="p_del">-				new_ctx = CTX_FIRST_VERSION;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* Don&#39;t call memset, for 16 entries that&#39;s just</span>
<span class="p_del">-			 * plain silly...</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			mmu_context_bmap[0] = 3;</span>
<span class="p_del">-			mmu_context_bmap[1] = 0;</span>
<span class="p_del">-			mmu_context_bmap[2] = 0;</span>
<span class="p_del">-			mmu_context_bmap[3] = 0;</span>
<span class="p_del">-			for (i = 4; i &lt; CTX_BMAP_SLOTS; i += 4) {</span>
<span class="p_del">-				mmu_context_bmap[i + 0] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 1] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 2] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 3] = 0;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			new_version = 1;</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+			mmu_context_wrap();</span>
<span class="p_add">+			goto retry;</span>
 		}
 	}
<span class="p_add">+	if (mm-&gt;context.sparc64_ctx_val)</span>
<span class="p_add">+		cpumask_clear(mm_cpumask(mm));</span>
 	mmu_context_bmap[new_ctx&gt;&gt;6] |= (1UL &lt;&lt; (new_ctx &amp; 63));
 	new_ctx |= (tlb_context_cache &amp; CTX_VERSION_MASK);
<span class="p_del">-out:</span>
 	tlb_context_cache = new_ctx;
 	mm-&gt;context.sparc64_ctx_val = new_ctx | orig_pgsz_bits;
<span class="p_add">+out:</span>
 	spin_unlock(&amp;ctx_alloc_lock);
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(new_version))</span>
<span class="p_del">-		smp_new_mmu_context_version();</span>
 }
 
 static int numa_enabled = 1;
<span class="p_header">diff --git a/arch/sparc/mm/tsb.c b/arch/sparc/mm/tsb.c</span>
<span class="p_header">index e20fbbafb0b0..84cd593117a6 100644</span>
<span class="p_header">--- a/arch/sparc/mm/tsb.c</span>
<span class="p_header">+++ b/arch/sparc/mm/tsb.c</span>
<span class="p_chunk">@@ -451,7 +451,8 @@</span> <span class="p_context"> void tsb_grow(struct mm_struct *mm, unsigned long tsb_index, unsigned long rss)</span>
 		extern void copy_tsb(unsigned long old_tsb_base,
 				     unsigned long old_tsb_size,
 				     unsigned long new_tsb_base,
<span class="p_del">-				     unsigned long new_tsb_size);</span>
<span class="p_add">+				     unsigned long new_tsb_size,</span>
<span class="p_add">+				     unsigned long page_size_shift);</span>
 		unsigned long old_tsb_base = (unsigned long) old_tsb;
 		unsigned long new_tsb_base = (unsigned long) new_tsb;
 
<span class="p_chunk">@@ -459,7 +460,9 @@</span> <span class="p_context"> void tsb_grow(struct mm_struct *mm, unsigned long tsb_index, unsigned long rss)</span>
 			old_tsb_base = __pa(old_tsb_base);
 			new_tsb_base = __pa(new_tsb_base);
 		}
<span class="p_del">-		copy_tsb(old_tsb_base, old_size, new_tsb_base, new_size);</span>
<span class="p_add">+		copy_tsb(old_tsb_base, old_size, new_tsb_base, new_size,</span>
<span class="p_add">+			tsb_index == MM_TSB_BASE ?</span>
<span class="p_add">+			PAGE_SHIFT : REAL_HPAGE_SHIFT);</span>
 	}
 
 	mm-&gt;context.tsb_block[tsb_index].tsb = new_tsb;
<span class="p_header">diff --git a/arch/sparc/mm/ultra.S b/arch/sparc/mm/ultra.S</span>
<span class="p_header">index 5d2fd6cd3189..fcf4d27a38fb 100644</span>
<span class="p_header">--- a/arch/sparc/mm/ultra.S</span>
<span class="p_header">+++ b/arch/sparc/mm/ultra.S</span>
<span class="p_chunk">@@ -971,11 +971,6 @@</span> <span class="p_context"> xcall_capture:</span>
 	wr		%g0, (1 &lt;&lt; PIL_SMP_CAPTURE), %set_softint
 	retry
 
<span class="p_del">-	.globl		xcall_new_mmu_context_version</span>
<span class="p_del">-xcall_new_mmu_context_version:</span>
<span class="p_del">-	wr		%g0, (1 &lt;&lt; PIL_SMP_CTX_NEW_VERSION), %set_softint</span>
<span class="p_del">-	retry</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KGDB
 	.globl		xcall_kgdb_capture
 xcall_kgdb_capture:
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index edbbfc854e39..9cf697ceedbf 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -162,8 +162,8 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 			 */
 			rcu_irq_exit();
 			native_safe_halt();
<span class="p_del">-			rcu_irq_enter();</span>
 			local_irq_disable();
<span class="p_add">+			rcu_irq_enter();</span>
 		}
 	}
 	if (!n.halted)
<span class="p_header">diff --git a/arch/x86/kvm/cpuid.c b/arch/x86/kvm/cpuid.c</span>
<span class="p_header">index 967e459ff1e6..649d8f2c1e40 100644</span>
<span class="p_header">--- a/arch/x86/kvm/cpuid.c</span>
<span class="p_header">+++ b/arch/x86/kvm/cpuid.c</span>
<span class="p_chunk">@@ -765,18 +765,20 @@</span> <span class="p_context"> int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,</span>
 static int move_to_next_stateful_cpuid_entry(struct kvm_vcpu *vcpu, int i)
 {
 	struct kvm_cpuid_entry2 *e = &amp;vcpu-&gt;arch.cpuid_entries[i];
<span class="p_del">-	int j, nent = vcpu-&gt;arch.cpuid_nent;</span>
<span class="p_add">+	struct kvm_cpuid_entry2 *ej;</span>
<span class="p_add">+	int j = i;</span>
<span class="p_add">+	int nent = vcpu-&gt;arch.cpuid_nent;</span>
 
 	e-&gt;flags &amp;= ~KVM_CPUID_FLAG_STATE_READ_NEXT;
 	/* when no next entry is found, the current entry[i] is reselected */
<span class="p_del">-	for (j = i + 1; ; j = (j + 1) % nent) {</span>
<span class="p_del">-		struct kvm_cpuid_entry2 *ej = &amp;vcpu-&gt;arch.cpuid_entries[j];</span>
<span class="p_del">-		if (ej-&gt;function == e-&gt;function) {</span>
<span class="p_del">-			ej-&gt;flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;</span>
<span class="p_del">-			return j;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return 0; /* silence gcc, even though control never reaches here */</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		j = (j + 1) % nent;</span>
<span class="p_add">+		ej = &amp;vcpu-&gt;arch.cpuid_entries[j];</span>
<span class="p_add">+	} while (ej-&gt;function != e-&gt;function);</span>
<span class="p_add">+</span>
<span class="p_add">+	ej-&gt;flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;</span>
<span class="p_add">+</span>
<span class="p_add">+	return j;</span>
 }
 
 /* find an entry with matching function, matching index (if needed), and that
<span class="p_header">diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c</span>
<span class="p_header">index d9c7e986b4e4..5f2412704b81 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.c</span>
<span class="p_chunk">@@ -3489,12 +3489,15 @@</span> <span class="p_context"> static int kvm_arch_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn)</span>
 	return kvm_setup_async_pf(vcpu, gva, kvm_vcpu_gfn_to_hva(vcpu, gfn), &amp;arch);
 }
 
<span class="p_del">-static bool can_do_async_pf(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu)</span>
 {
 	if (unlikely(!lapic_in_kernel(vcpu) ||
 		     kvm_event_needs_reinjection(vcpu)))
 		return false;
 
<span class="p_add">+	if (is_guest_mode(vcpu))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
 	return kvm_x86_ops-&gt;interrupt_allowed(vcpu);
 }
 
<span class="p_chunk">@@ -3510,7 +3513,7 @@</span> <span class="p_context"> static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,</span>
 	if (!async)
 		return false; /* *pfn has correct page already */
 
<span class="p_del">-	if (!prefault &amp;&amp; can_do_async_pf(vcpu)) {</span>
<span class="p_add">+	if (!prefault &amp;&amp; kvm_can_do_async_pf(vcpu)) {</span>
 		trace_kvm_try_async_get_page(gva, gfn);
 		if (kvm_find_async_pf_gfn(vcpu, gfn)) {
 			trace_kvm_async_pf_doublefault(gva, gfn);
<span class="p_header">diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h</span>
<span class="p_header">index ddc56e91f2e4..c92834c55c59 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.h</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.h</span>
<span class="p_chunk">@@ -75,6 +75,7 @@</span> <span class="p_context"> enum {</span>
 int handle_mmio_page_fault(struct kvm_vcpu *vcpu, u64 addr, bool direct);
 void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu);
 void kvm_init_shadow_ept_mmu(struct kvm_vcpu *vcpu, bool execonly);
<span class="p_add">+bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu);</span>
 
 static inline unsigned int kvm_mmu_available_pages(struct kvm *kvm)
 {
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index 81bba3c2137d..62cde4f67c72 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -8444,8 +8444,7 @@</span> <span class="p_context"> bool kvm_arch_can_inject_async_page_present(struct kvm_vcpu *vcpu)</span>
 	if (!(vcpu-&gt;arch.apf.msr_val &amp; KVM_ASYNC_PF_ENABLED))
 		return true;
 	else
<span class="p_del">-		return !kvm_event_needs_reinjection(vcpu) &amp;&amp;</span>
<span class="p_del">-			kvm_x86_ops-&gt;interrupt_allowed(vcpu);</span>
<span class="p_add">+		return kvm_can_do_async_pf(vcpu);</span>
 }
 
 void kvm_arch_start_assignment(struct kvm *kvm)
<span class="p_header">diff --git a/arch/x86/platform/efi/quirks.c b/arch/x86/platform/efi/quirks.c</span>
<span class="p_header">index cdfe8c628959..393a0c0288d1 100644</span>
<span class="p_header">--- a/arch/x86/platform/efi/quirks.c</span>
<span class="p_header">+++ b/arch/x86/platform/efi/quirks.c</span>
<span class="p_chunk">@@ -358,6 +358,9 @@</span> <span class="p_context"> void __init efi_free_boot_services(void)</span>
 		free_bootmem_late(start, size);
 	}
 
<span class="p_add">+	if (!num_entries)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	new_size = efi.memmap.desc_size * num_entries;
 	new_phys = efi_memmap_alloc(num_entries);
 	if (!new_phys) {
<span class="p_header">diff --git a/block/cfq-iosched.c b/block/cfq-iosched.c</span>
<span class="p_header">index 3ab6807773ee..c7c3d4e6bc27 100644</span>
<span class="p_header">--- a/block/cfq-iosched.c</span>
<span class="p_header">+++ b/block/cfq-iosched.c</span>
<span class="p_chunk">@@ -36,9 +36,13 @@</span> <span class="p_context"> static const u64 cfq_target_latency = (u64)NSEC_PER_SEC * 3/10; /* 300 ms */</span>
 static const int cfq_hist_divisor = 4;
 
 /*
<span class="p_del">- * offset from end of service tree</span>
<span class="p_add">+ * offset from end of queue service tree for idle class</span>
  */
 #define CFQ_IDLE_DELAY		(NSEC_PER_SEC / 5)
<span class="p_add">+/* offset from end of group service tree under time slice mode */</span>
<span class="p_add">+#define CFQ_SLICE_MODE_GROUP_DELAY (NSEC_PER_SEC / 5)</span>
<span class="p_add">+/* offset from end of group service under IOPS mode */</span>
<span class="p_add">+#define CFQ_IOPS_MODE_GROUP_DELAY (HZ / 5)</span>
 
 /*
  * below this threshold, we consider thinktime immediate
<span class="p_chunk">@@ -1370,6 +1374,14 @@</span> <span class="p_context"> cfq_group_service_tree_add(struct cfq_rb_root *st, struct cfq_group *cfqg)</span>
 	cfqg-&gt;vfraction = max_t(unsigned, vfr, 1);
 }
 
<span class="p_add">+static inline u64 cfq_get_cfqg_vdisktime_delay(struct cfq_data *cfqd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!iops_mode(cfqd))</span>
<span class="p_add">+		return CFQ_SLICE_MODE_GROUP_DELAY;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return CFQ_IOPS_MODE_GROUP_DELAY;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void
 cfq_group_notify_queue_add(struct cfq_data *cfqd, struct cfq_group *cfqg)
 {
<span class="p_chunk">@@ -1389,7 +1401,8 @@</span> <span class="p_context"> cfq_group_notify_queue_add(struct cfq_data *cfqd, struct cfq_group *cfqg)</span>
 	n = rb_last(&amp;st-&gt;rb);
 	if (n) {
 		__cfqg = rb_entry_cfqg(n);
<span class="p_del">-		cfqg-&gt;vdisktime = __cfqg-&gt;vdisktime + CFQ_IDLE_DELAY;</span>
<span class="p_add">+		cfqg-&gt;vdisktime = __cfqg-&gt;vdisktime +</span>
<span class="p_add">+			cfq_get_cfqg_vdisktime_delay(cfqd);</span>
 	} else
 		cfqg-&gt;vdisktime = st-&gt;min_vdisktime;
 	cfq_group_service_tree_add(st, cfqg);
<span class="p_header">diff --git a/crypto/asymmetric_keys/public_key.c b/crypto/asymmetric_keys/public_key.c</span>
<span class="p_header">index fd76b5fc3b3a..4955eb66e361 100644</span>
<span class="p_header">--- a/crypto/asymmetric_keys/public_key.c</span>
<span class="p_header">+++ b/crypto/asymmetric_keys/public_key.c</span>
<span class="p_chunk">@@ -140,7 +140,7 @@</span> <span class="p_context"> int public_key_verify_signature(const struct public_key *pkey,</span>
 	 * signature and returns that to us.
 	 */
 	ret = crypto_akcipher_verify(req);
<span class="p_del">-	if (ret == -EINPROGRESS) {</span>
<span class="p_add">+	if ((ret == -EINPROGRESS) || (ret == -EBUSY)) {</span>
 		wait_for_completion(&amp;compl.completion);
 		ret = compl.err;
 	}
<span class="p_header">diff --git a/crypto/drbg.c b/crypto/drbg.c</span>
<span class="p_header">index 053035b5c8f8..123d211efa12 100644</span>
<span class="p_header">--- a/crypto/drbg.c</span>
<span class="p_header">+++ b/crypto/drbg.c</span>
<span class="p_chunk">@@ -1768,9 +1768,8 @@</span> <span class="p_context"> static int drbg_kcapi_sym_ctr(struct drbg_state *drbg,</span>
 			break;
 		case -EINPROGRESS:
 		case -EBUSY:
<span class="p_del">-			ret = wait_for_completion_interruptible(</span>
<span class="p_del">-				&amp;drbg-&gt;ctr_completion);</span>
<span class="p_del">-			if (!ret &amp;&amp; !drbg-&gt;ctr_async_err) {</span>
<span class="p_add">+			wait_for_completion(&amp;drbg-&gt;ctr_completion);</span>
<span class="p_add">+			if (!drbg-&gt;ctr_async_err) {</span>
 				reinit_completion(&amp;drbg-&gt;ctr_completion);
 				break;
 			}
<span class="p_header">diff --git a/crypto/gcm.c b/crypto/gcm.c</span>
<span class="p_header">index f624ac98c94e..dd33fbd2d868 100644</span>
<span class="p_header">--- a/crypto/gcm.c</span>
<span class="p_header">+++ b/crypto/gcm.c</span>
<span class="p_chunk">@@ -152,10 +152,8 @@</span> <span class="p_context"> static int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,</span>
 
 	err = crypto_skcipher_encrypt(&amp;data-&gt;req);
 	if (err == -EINPROGRESS || err == -EBUSY) {
<span class="p_del">-		err = wait_for_completion_interruptible(</span>
<span class="p_del">-			&amp;data-&gt;result.completion);</span>
<span class="p_del">-		if (!err)</span>
<span class="p_del">-			err = data-&gt;result.err;</span>
<span class="p_add">+		wait_for_completion(&amp;data-&gt;result.completion);</span>
<span class="p_add">+		err = data-&gt;result.err;</span>
 	}
 
 	if (err)
<span class="p_header">diff --git a/drivers/ata/ahci.c b/drivers/ata/ahci.c</span>
<span class="p_header">index 74f4c662f776..c94038206c3a 100644</span>
<span class="p_header">--- a/drivers/ata/ahci.c</span>
<span class="p_header">+++ b/drivers/ata/ahci.c</span>
<span class="p_chunk">@@ -1362,6 +1362,40 @@</span> <span class="p_context"> static inline void ahci_gtf_filter_workaround(struct ata_host *host)</span>
 {}
 #endif
 
<span class="p_add">+/*</span>
<span class="p_add">+ * On the Acer Aspire Switch Alpha 12, sometimes all SATA ports are detected</span>
<span class="p_add">+ * as DUMMY, or detected but eventually get a &quot;link down&quot; and never get up</span>
<span class="p_add">+ * again. When this happens, CAP.NP may hold a value of 0x00 or 0x01, and the</span>
<span class="p_add">+ * port_map may hold a value of 0x00.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Overriding CAP.NP to 0x02 and the port_map to 0x7 will reveal all 3 ports</span>
<span class="p_add">+ * and can significantly reduce the occurrence of the problem.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * https://bugzilla.kernel.org/show_bug.cgi?id=189471</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void acer_sa5_271_workaround(struct ahci_host_priv *hpriv,</span>
<span class="p_add">+				    struct pci_dev *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	static const struct dmi_system_id sysids[] = {</span>
<span class="p_add">+		{</span>
<span class="p_add">+			.ident = &quot;Acer Switch Alpha 12&quot;,</span>
<span class="p_add">+			.matches = {</span>
<span class="p_add">+				DMI_MATCH(DMI_SYS_VENDOR, &quot;Acer&quot;),</span>
<span class="p_add">+				DMI_MATCH(DMI_PRODUCT_NAME, &quot;Switch SA5-271&quot;)</span>
<span class="p_add">+			},</span>
<span class="p_add">+		},</span>
<span class="p_add">+		{ }</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	if (dmi_check_system(sysids)) {</span>
<span class="p_add">+		dev_info(&amp;pdev-&gt;dev, &quot;enabling Acer Switch Alpha 12 workaround\n&quot;);</span>
<span class="p_add">+		if ((hpriv-&gt;saved_cap &amp; 0xC734FF00) == 0xC734FF00) {</span>
<span class="p_add">+			hpriv-&gt;port_map = 0x7;</span>
<span class="p_add">+			hpriv-&gt;cap = 0xC734FF02;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_ARM64
 /*
  * Due to ERRATA#22536, ThunderX needs to handle HOST_IRQ_STAT differently.
<span class="p_chunk">@@ -1597,6 +1631,10 @@</span> <span class="p_context"> static int ahci_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)</span>
 			 &quot;online status unreliable, applying workaround\n&quot;);
 	}
 
<span class="p_add">+</span>
<span class="p_add">+	/* Acer SA5-271 workaround modifies private_data */</span>
<span class="p_add">+	acer_sa5_271_workaround(hpriv, pdev);</span>
<span class="p_add">+</span>
 	/* CAP.NP sometimes indicate the index of the last enabled
 	 * port, at other times, that of the last possible port, so
 	 * determining the maximum port number requires looking at
<span class="p_header">diff --git a/drivers/char/mem.c b/drivers/char/mem.c</span>
<span class="p_header">index 6e0cbe092220..593a8818aca9 100644</span>
<span class="p_header">--- a/drivers/char/mem.c</span>
<span class="p_header">+++ b/drivers/char/mem.c</span>
<span class="p_chunk">@@ -343,7 +343,7 @@</span> <span class="p_context"> static int mmap_mem(struct file *file, struct vm_area_struct *vma)</span>
 	phys_addr_t offset = (phys_addr_t)vma-&gt;vm_pgoff &lt;&lt; PAGE_SHIFT;
 
 	/* It&#39;s illegal to wrap around the end of the physical address space. */
<span class="p_del">-	if (offset + (phys_addr_t)size &lt; offset)</span>
<span class="p_add">+	if (offset + (phys_addr_t)size - 1 &lt; offset)</span>
 		return -EINVAL;
 
 	if (!valid_mmap_phys_addr_range(vma-&gt;vm_pgoff, size))
<span class="p_header">diff --git a/drivers/cpufreq/cpufreq.c b/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">index 6153b66139d5..286d4d61bd0b 100644</span>
<span class="p_header">--- a/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/cpufreq.c</span>
<span class="p_chunk">@@ -2474,6 +2474,7 @@</span> <span class="p_context"> int cpufreq_register_driver(struct cpufreq_driver *driver_data)</span>
 	if (!(cpufreq_driver-&gt;flags &amp; CPUFREQ_STICKY) &amp;&amp;
 	    list_empty(&amp;cpufreq_policy_list)) {
 		/* if all -&gt;init() calls failed, unregister */
<span class="p_add">+		ret = -ENODEV;</span>
 		pr_debug(&quot;%s: No CPU initialized for driver %s\n&quot;, __func__,
 			 driver_data-&gt;name);
 		goto err_if_unreg;
<span class="p_header">diff --git a/drivers/dma/ep93xx_dma.c b/drivers/dma/ep93xx_dma.c</span>
<span class="p_header">index d37e8dda8079..ec240592f5c8 100644</span>
<span class="p_header">--- a/drivers/dma/ep93xx_dma.c</span>
<span class="p_header">+++ b/drivers/dma/ep93xx_dma.c</span>
<span class="p_chunk">@@ -201,6 +201,7 @@</span> <span class="p_context"> struct ep93xx_dma_engine {</span>
 	struct dma_device	dma_dev;
 	bool			m2m;
 	int			(*hw_setup)(struct ep93xx_dma_chan *);
<span class="p_add">+	void			(*hw_synchronize)(struct ep93xx_dma_chan *);</span>
 	void			(*hw_shutdown)(struct ep93xx_dma_chan *);
 	void			(*hw_submit)(struct ep93xx_dma_chan *);
 	int			(*hw_interrupt)(struct ep93xx_dma_chan *);
<span class="p_chunk">@@ -323,6 +324,8 @@</span> <span class="p_context"> static int m2p_hw_setup(struct ep93xx_dma_chan *edmac)</span>
 		| M2P_CONTROL_ENABLE;
 	m2p_set_control(edmac, control);
 
<span class="p_add">+	edmac-&gt;buffer = 0;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -331,21 +334,27 @@</span> <span class="p_context"> static inline u32 m2p_channel_state(struct ep93xx_dma_chan *edmac)</span>
 	return (readl(edmac-&gt;regs + M2P_STATUS) &gt;&gt; 4) &amp; 0x3;
 }
 
<span class="p_del">-static void m2p_hw_shutdown(struct ep93xx_dma_chan *edmac)</span>
<span class="p_add">+static void m2p_hw_synchronize(struct ep93xx_dma_chan *edmac)</span>
 {
<span class="p_add">+	unsigned long flags;</span>
 	u32 control;
 
<span class="p_add">+	spin_lock_irqsave(&amp;edmac-&gt;lock, flags);</span>
 	control = readl(edmac-&gt;regs + M2P_CONTROL);
 	control &amp;= ~(M2P_CONTROL_STALLINT | M2P_CONTROL_NFBINT);
 	m2p_set_control(edmac, control);
<span class="p_add">+	spin_unlock_irqrestore(&amp;edmac-&gt;lock, flags);</span>
 
 	while (m2p_channel_state(edmac) &gt;= M2P_STATE_ON)
<span class="p_del">-		cpu_relax();</span>
<span class="p_add">+		schedule();</span>
<span class="p_add">+}</span>
 
<span class="p_add">+static void m2p_hw_shutdown(struct ep93xx_dma_chan *edmac)</span>
<span class="p_add">+{</span>
 	m2p_set_control(edmac, 0);
 
<span class="p_del">-	while (m2p_channel_state(edmac) == M2P_STATE_STALL)</span>
<span class="p_del">-		cpu_relax();</span>
<span class="p_add">+	while (m2p_channel_state(edmac) != M2P_STATE_IDLE)</span>
<span class="p_add">+		dev_warn(chan2dev(edmac), &quot;M2P: Not yet IDLE\n&quot;);</span>
 }
 
 static void m2p_fill_desc(struct ep93xx_dma_chan *edmac)
<span class="p_chunk">@@ -1161,6 +1170,26 @@</span> <span class="p_context"> ep93xx_dma_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t dma_addr,</span>
 }
 
 /**
<span class="p_add">+ * ep93xx_dma_synchronize - Synchronizes the termination of transfers to the</span>
<span class="p_add">+ * current context.</span>
<span class="p_add">+ * @chan: channel</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Synchronizes the DMA channel termination to the current context. When this</span>
<span class="p_add">+ * function returns it is guaranteed that all transfers for previously issued</span>
<span class="p_add">+ * descriptors have stopped and and it is safe to free the memory associated</span>
<span class="p_add">+ * with them. Furthermore it is guaranteed that all complete callback functions</span>
<span class="p_add">+ * for a previously submitted descriptor have finished running and it is safe to</span>
<span class="p_add">+ * free resources accessed from within the complete callbacks.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void ep93xx_dma_synchronize(struct dma_chan *chan)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (edmac-&gt;edma-&gt;hw_synchronize)</span>
<span class="p_add">+		edmac-&gt;edma-&gt;hw_synchronize(edmac);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * ep93xx_dma_terminate_all - terminate all transactions
  * @chan: channel
  *
<span class="p_chunk">@@ -1323,6 +1352,7 @@</span> <span class="p_context"> static int __init ep93xx_dma_probe(struct platform_device *pdev)</span>
 	dma_dev-&gt;device_prep_slave_sg = ep93xx_dma_prep_slave_sg;
 	dma_dev-&gt;device_prep_dma_cyclic = ep93xx_dma_prep_dma_cyclic;
 	dma_dev-&gt;device_config = ep93xx_dma_slave_config;
<span class="p_add">+	dma_dev-&gt;device_synchronize = ep93xx_dma_synchronize;</span>
 	dma_dev-&gt;device_terminate_all = ep93xx_dma_terminate_all;
 	dma_dev-&gt;device_issue_pending = ep93xx_dma_issue_pending;
 	dma_dev-&gt;device_tx_status = ep93xx_dma_tx_status;
<span class="p_chunk">@@ -1340,6 +1370,7 @@</span> <span class="p_context"> static int __init ep93xx_dma_probe(struct platform_device *pdev)</span>
 	} else {
 		dma_cap_set(DMA_PRIVATE, dma_dev-&gt;cap_mask);
 
<span class="p_add">+		edma-&gt;hw_synchronize = m2p_hw_synchronize;</span>
 		edma-&gt;hw_setup = m2p_hw_setup;
 		edma-&gt;hw_shutdown = m2p_hw_shutdown;
 		edma-&gt;hw_submit = m2p_hw_submit;
<span class="p_header">diff --git a/drivers/dma/mv_xor_v2.c b/drivers/dma/mv_xor_v2.c</span>
<span class="p_header">index a28a01fcba67..f3e211f8f6c5 100644</span>
<span class="p_header">--- a/drivers/dma/mv_xor_v2.c</span>
<span class="p_header">+++ b/drivers/dma/mv_xor_v2.c</span>
<span class="p_chunk">@@ -161,6 +161,7 @@</span> <span class="p_context"> struct mv_xor_v2_device {</span>
 	struct mv_xor_v2_sw_desc *sw_desq;
 	int desc_size;
 	unsigned int npendings;
<span class="p_add">+	unsigned int hw_queue_idx;</span>
 };
 
 /**
<span class="p_chunk">@@ -214,18 +215,6 @@</span> <span class="p_context"> static void mv_xor_v2_set_data_buffers(struct mv_xor_v2_device *xor_dev,</span>
 }
 
 /*
<span class="p_del">- * Return the next available index in the DESQ.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int mv_xor_v2_get_desq_write_ptr(struct mv_xor_v2_device *xor_dev)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* read the index for the next available descriptor in the DESQ */</span>
<span class="p_del">-	u32 reg = readl(xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_ALLOC_OFF);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ((reg &gt;&gt; MV_XOR_V2_DMA_DESQ_ALLOC_WRPTR_SHIFT)</span>
<span class="p_del">-		&amp; MV_XOR_V2_DMA_DESQ_ALLOC_WRPTR_MASK);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
  * notify the engine of new descriptors, and update the available index.
  */
 static void mv_xor_v2_add_desc_to_desq(struct mv_xor_v2_device *xor_dev,
<span class="p_chunk">@@ -257,22 +246,6 @@</span> <span class="p_context"> static int mv_xor_v2_set_desc_size(struct mv_xor_v2_device *xor_dev)</span>
 	return MV_XOR_V2_EXT_DESC_SIZE;
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Set the IMSG threshold</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline</span>
<span class="p_del">-void mv_xor_v2_set_imsg_thrd(struct mv_xor_v2_device *xor_dev, int thrd_val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	u32 reg;</span>
<span class="p_del">-</span>
<span class="p_del">-	reg = readl(xor_dev-&gt;dma_base + MV_XOR_V2_DMA_IMSG_THRD_OFF);</span>
<span class="p_del">-</span>
<span class="p_del">-	reg &amp;= (~MV_XOR_V2_DMA_IMSG_THRD_MASK &lt;&lt; MV_XOR_V2_DMA_IMSG_THRD_SHIFT);</span>
<span class="p_del">-	reg |= (thrd_val &lt;&lt; MV_XOR_V2_DMA_IMSG_THRD_SHIFT);</span>
<span class="p_del">-</span>
<span class="p_del">-	writel(reg, xor_dev-&gt;dma_base + MV_XOR_V2_DMA_IMSG_THRD_OFF);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static irqreturn_t mv_xor_v2_interrupt_handler(int irq, void *data)
 {
 	struct mv_xor_v2_device *xor_dev = data;
<span class="p_chunk">@@ -288,12 +261,6 @@</span> <span class="p_context"> static irqreturn_t mv_xor_v2_interrupt_handler(int irq, void *data)</span>
 	if (!ndescs)
 		return IRQ_NONE;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Update IMSG threshold, to disable new IMSG interrupts until</span>
<span class="p_del">-	 * end of the tasklet</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	mv_xor_v2_set_imsg_thrd(xor_dev, MV_XOR_V2_DESC_NUM);</span>
<span class="p_del">-</span>
 	/* schedule a tasklet to handle descriptors callbacks */
 	tasklet_schedule(&amp;xor_dev-&gt;irq_tasklet);
 
<span class="p_chunk">@@ -306,7 +273,6 @@</span> <span class="p_context"> static irqreturn_t mv_xor_v2_interrupt_handler(int irq, void *data)</span>
 static dma_cookie_t
 mv_xor_v2_tx_submit(struct dma_async_tx_descriptor *tx)
 {
<span class="p_del">-	int desq_ptr;</span>
 	void *dest_hw_desc;
 	dma_cookie_t cookie;
 	struct mv_xor_v2_sw_desc *sw_desc =
<span class="p_chunk">@@ -322,15 +288,15 @@</span> <span class="p_context"> mv_xor_v2_tx_submit(struct dma_async_tx_descriptor *tx)</span>
 	spin_lock_bh(&amp;xor_dev-&gt;lock);
 	cookie = dma_cookie_assign(tx);
 
<span class="p_del">-	/* get the next available slot in the DESQ */</span>
<span class="p_del">-	desq_ptr = mv_xor_v2_get_desq_write_ptr(xor_dev);</span>
<span class="p_del">-</span>
 	/* copy the HW descriptor from the SW descriptor to the DESQ */
<span class="p_del">-	dest_hw_desc = xor_dev-&gt;hw_desq_virt + desq_ptr;</span>
<span class="p_add">+	dest_hw_desc = xor_dev-&gt;hw_desq_virt + xor_dev-&gt;hw_queue_idx;</span>
 
 	memcpy(dest_hw_desc, &amp;sw_desc-&gt;hw_desc, xor_dev-&gt;desc_size);
 
 	xor_dev-&gt;npendings++;
<span class="p_add">+	xor_dev-&gt;hw_queue_idx++;</span>
<span class="p_add">+	if (xor_dev-&gt;hw_queue_idx &gt;= MV_XOR_V2_DESC_NUM)</span>
<span class="p_add">+		xor_dev-&gt;hw_queue_idx = 0;</span>
 
 	spin_unlock_bh(&amp;xor_dev-&gt;lock);
 
<span class="p_chunk">@@ -344,6 +310,7 @@</span> <span class="p_context"> static struct mv_xor_v2_sw_desc	*</span>
 mv_xor_v2_prep_sw_desc(struct mv_xor_v2_device *xor_dev)
 {
 	struct mv_xor_v2_sw_desc *sw_desc;
<span class="p_add">+	bool found = false;</span>
 
 	/* Lock the channel */
 	spin_lock_bh(&amp;xor_dev-&gt;lock);
<span class="p_chunk">@@ -355,19 +322,23 @@</span> <span class="p_context"> mv_xor_v2_prep_sw_desc(struct mv_xor_v2_device *xor_dev)</span>
 		return NULL;
 	}
 
<span class="p_del">-	/* get a free SW descriptor from the SW DESQ */</span>
<span class="p_del">-	sw_desc = list_first_entry(&amp;xor_dev-&gt;free_sw_desc,</span>
<span class="p_del">-				   struct mv_xor_v2_sw_desc, free_list);</span>
<span class="p_add">+	list_for_each_entry(sw_desc, &amp;xor_dev-&gt;free_sw_desc, free_list) {</span>
<span class="p_add">+		if (async_tx_test_ack(&amp;sw_desc-&gt;async_tx)) {</span>
<span class="p_add">+			found = true;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!found) {</span>
<span class="p_add">+		spin_unlock_bh(&amp;xor_dev-&gt;lock);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	list_del(&amp;sw_desc-&gt;free_list);
 
 	/* Release the channel */
 	spin_unlock_bh(&amp;xor_dev-&gt;lock);
 
<span class="p_del">-	/* set the async tx descriptor */</span>
<span class="p_del">-	dma_async_tx_descriptor_init(&amp;sw_desc-&gt;async_tx, &amp;xor_dev-&gt;dmachan);</span>
<span class="p_del">-	sw_desc-&gt;async_tx.tx_submit = mv_xor_v2_tx_submit;</span>
<span class="p_del">-	async_tx_ack(&amp;sw_desc-&gt;async_tx);</span>
<span class="p_del">-</span>
 	return sw_desc;
 }
 
<span class="p_chunk">@@ -389,6 +360,8 @@</span> <span class="p_context"> mv_xor_v2_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest,</span>
 		__func__, len, &amp;src, &amp;dest, flags);
 
 	sw_desc = mv_xor_v2_prep_sw_desc(xor_dev);
<span class="p_add">+	if (!sw_desc)</span>
<span class="p_add">+		return NULL;</span>
 
 	sw_desc-&gt;async_tx.flags = flags;
 
<span class="p_chunk">@@ -443,6 +416,8 @@</span> <span class="p_context"> mv_xor_v2_prep_dma_xor(struct dma_chan *chan, dma_addr_t dest, dma_addr_t *src,</span>
 		__func__, src_cnt, len, &amp;dest, flags);
 
 	sw_desc = mv_xor_v2_prep_sw_desc(xor_dev);
<span class="p_add">+	if (!sw_desc)</span>
<span class="p_add">+		return NULL;</span>
 
 	sw_desc-&gt;async_tx.flags = flags;
 
<span class="p_chunk">@@ -491,6 +466,8 @@</span> <span class="p_context"> mv_xor_v2_prep_dma_interrupt(struct dma_chan *chan, unsigned long flags)</span>
 		container_of(chan, struct mv_xor_v2_device, dmachan);
 
 	sw_desc = mv_xor_v2_prep_sw_desc(xor_dev);
<span class="p_add">+	if (!sw_desc)</span>
<span class="p_add">+		return NULL;</span>
 
 	/* set the HW descriptor */
 	hw_descriptor = &amp;sw_desc-&gt;hw_desc;
<span class="p_chunk">@@ -554,7 +531,6 @@</span> <span class="p_context"> static void mv_xor_v2_tasklet(unsigned long data)</span>
 {
 	struct mv_xor_v2_device *xor_dev = (struct mv_xor_v2_device *) data;
 	int pending_ptr, num_of_pending, i;
<span class="p_del">-	struct mv_xor_v2_descriptor *next_pending_hw_desc = NULL;</span>
 	struct mv_xor_v2_sw_desc *next_pending_sw_desc = NULL;
 
 	dev_dbg(xor_dev-&gt;dmadev.dev, &quot;%s %d\n&quot;, __func__, __LINE__);
<span class="p_chunk">@@ -562,17 +538,10 @@</span> <span class="p_context"> static void mv_xor_v2_tasklet(unsigned long data)</span>
 	/* get the pending descriptors parameters */
 	num_of_pending = mv_xor_v2_get_pending_params(xor_dev, &amp;pending_ptr);
 
<span class="p_del">-	/* next HW descriptor */</span>
<span class="p_del">-	next_pending_hw_desc = xor_dev-&gt;hw_desq_virt + pending_ptr;</span>
<span class="p_del">-</span>
 	/* loop over free descriptors */
 	for (i = 0; i &lt; num_of_pending; i++) {
<span class="p_del">-</span>
<span class="p_del">-		if (pending_ptr &gt; MV_XOR_V2_DESC_NUM)</span>
<span class="p_del">-			pending_ptr = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (next_pending_sw_desc != NULL)</span>
<span class="p_del">-			next_pending_hw_desc++;</span>
<span class="p_add">+		struct mv_xor_v2_descriptor *next_pending_hw_desc =</span>
<span class="p_add">+			xor_dev-&gt;hw_desq_virt + pending_ptr;</span>
 
 		/* get the SW descriptor related to the HW descriptor */
 		next_pending_sw_desc =
<span class="p_chunk">@@ -608,15 +577,14 @@</span> <span class="p_context"> static void mv_xor_v2_tasklet(unsigned long data)</span>
 
 		/* increment the next descriptor */
 		pending_ptr++;
<span class="p_add">+		if (pending_ptr &gt;= MV_XOR_V2_DESC_NUM)</span>
<span class="p_add">+			pending_ptr = 0;</span>
 	}
 
 	if (num_of_pending != 0) {
 		/* free the descriptores */
 		mv_xor_v2_free_desc_from_desq(xor_dev, num_of_pending);
 	}
<span class="p_del">-</span>
<span class="p_del">-	/* Update IMSG threshold, to enable new IMSG interrupts */</span>
<span class="p_del">-	mv_xor_v2_set_imsg_thrd(xor_dev, 0);</span>
 }
 
 /*
<span class="p_chunk">@@ -648,9 +616,6 @@</span> <span class="p_context"> static int mv_xor_v2_descq_init(struct mv_xor_v2_device *xor_dev)</span>
 	writel((xor_dev-&gt;hw_desq &amp; 0xFFFF00000000) &gt;&gt; 32,
 	       xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_BAHR_OFF);
 
<span class="p_del">-	/* enable the DMA engine */</span>
<span class="p_del">-	writel(0, xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_STOP_OFF);</span>
<span class="p_del">-</span>
 	/*
 	 * This is a temporary solution, until we activate the
 	 * SMMU. Set the attributes for reading &amp; writing data buffers
<span class="p_chunk">@@ -694,6 +659,9 @@</span> <span class="p_context"> static int mv_xor_v2_descq_init(struct mv_xor_v2_device *xor_dev)</span>
 	reg |= MV_XOR_V2_GLOB_PAUSE_AXI_TIME_DIS_VAL;
 	writel(reg, xor_dev-&gt;glob_base + MV_XOR_V2_GLOB_PAUSE);
 
<span class="p_add">+	/* enable the DMA engine */</span>
<span class="p_add">+	writel(0, xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_STOP_OFF);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -725,6 +693,10 @@</span> <span class="p_context"> static int mv_xor_v2_probe(struct platform_device *pdev)</span>
 
 	platform_set_drvdata(pdev, xor_dev);
 
<span class="p_add">+	ret = dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(40));</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
 	xor_dev-&gt;clk = devm_clk_get(&amp;pdev-&gt;dev, NULL);
 	if (IS_ERR(xor_dev-&gt;clk) &amp;&amp; PTR_ERR(xor_dev-&gt;clk) == -EPROBE_DEFER)
 		return -EPROBE_DEFER;
<span class="p_chunk">@@ -785,8 +757,15 @@</span> <span class="p_context"> static int mv_xor_v2_probe(struct platform_device *pdev)</span>
 
 	/* add all SW descriptors to the free list */
 	for (i = 0; i &lt; MV_XOR_V2_DESC_NUM; i++) {
<span class="p_del">-		xor_dev-&gt;sw_desq[i].idx = i;</span>
<span class="p_del">-		list_add(&amp;xor_dev-&gt;sw_desq[i].free_list,</span>
<span class="p_add">+		struct mv_xor_v2_sw_desc *sw_desc =</span>
<span class="p_add">+			xor_dev-&gt;sw_desq + i;</span>
<span class="p_add">+		sw_desc-&gt;idx = i;</span>
<span class="p_add">+		dma_async_tx_descriptor_init(&amp;sw_desc-&gt;async_tx,</span>
<span class="p_add">+					     &amp;xor_dev-&gt;dmachan);</span>
<span class="p_add">+		sw_desc-&gt;async_tx.tx_submit = mv_xor_v2_tx_submit;</span>
<span class="p_add">+		async_tx_ack(&amp;sw_desc-&gt;async_tx);</span>
<span class="p_add">+</span>
<span class="p_add">+		list_add(&amp;sw_desc-&gt;free_list,</span>
 			 &amp;xor_dev-&gt;free_sw_desc);
 	}
 
<span class="p_header">diff --git a/drivers/dma/sh/usb-dmac.c b/drivers/dma/sh/usb-dmac.c</span>
<span class="p_header">index 06ecdc38cee0..6682b3eec2b6 100644</span>
<span class="p_header">--- a/drivers/dma/sh/usb-dmac.c</span>
<span class="p_header">+++ b/drivers/dma/sh/usb-dmac.c</span>
<span class="p_chunk">@@ -117,7 +117,7 @@</span> <span class="p_context"> struct usb_dmac {</span>
 #define USB_DMASWR			0x0008
 #define USB_DMASWR_SWR			(1 &lt;&lt; 0)
 #define USB_DMAOR			0x0060
<span class="p_del">-#define USB_DMAOR_AE			(1 &lt;&lt; 2)</span>
<span class="p_add">+#define USB_DMAOR_AE			(1 &lt;&lt; 1)</span>
 #define USB_DMAOR_DME			(1 &lt;&lt; 0)
 
 #define USB_DMASAR			0x0000
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/ci_dpm.c b/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_header">index 5be788b269e2..1679727c22ef 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_chunk">@@ -900,6 +900,12 @@</span> <span class="p_context"> static bool ci_dpm_vblank_too_short(struct amdgpu_device *adev)</span>
 	u32 vblank_time = amdgpu_dpm_get_vblank_time(adev);
 	u32 switch_limit = adev-&gt;mc.vram_type == AMDGPU_VRAM_TYPE_GDDR5 ? 450 : 300;
 
<span class="p_add">+	/* disable mclk switching if the refresh is &gt;120Hz, even if the</span>
<span class="p_add">+	 * blanking period would allow it</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (amdgpu_dpm_get_vrefresh(adev) &gt; 120)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
 	if (vblank_time &lt; switch_limit)
 		return true;
 	else
<span class="p_header">diff --git a/drivers/gpu/drm/drm_drv.c b/drivers/gpu/drm/drm_drv.c</span>
<span class="p_header">index 6efdba4993fc..0f2fa9044668 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_drv.c</span>
<span class="p_chunk">@@ -379,7 +379,12 @@</span> <span class="p_context"> EXPORT_SYMBOL(drm_put_dev);</span>
 void drm_unplug_dev(struct drm_device *dev)
 {
 	/* for a USB device */
<span class="p_del">-	drm_dev_unregister(dev);</span>
<span class="p_add">+	if (drm_core_check_feature(dev, DRIVER_MODESET))</span>
<span class="p_add">+		drm_modeset_unregister_all(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	drm_minor_unregister(dev, DRM_MINOR_PRIMARY);</span>
<span class="p_add">+	drm_minor_unregister(dev, DRM_MINOR_RENDER);</span>
<span class="p_add">+	drm_minor_unregister(dev, DRM_MINOR_CONTROL);</span>
 
 	mutex_lock(&amp;drm_global_mutex);
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.c b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">index 923150de46cb..ca6efb69ef66 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_chunk">@@ -573,9 +573,7 @@</span> <span class="p_context"> static int i915_load_modeset_init(struct drm_device *dev)</span>
 	if (i915_inject_load_failure())
 		return -ENODEV;
 
<span class="p_del">-	ret = intel_bios_init(dev_priv);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		DRM_INFO(&quot;failed to find VBIOS tables\n&quot;);</span>
<span class="p_add">+	intel_bios_init(dev_priv);</span>
 
 	/* If we have &gt; 1 VGA cards, then we need to arbitrate access
 	 * to the common VGA resources.
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.h b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">index e0d72457b23c..36a665f0e5c9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_chunk">@@ -3584,7 +3584,7 @@</span> <span class="p_context"> static inline bool intel_gmbus_is_forced_bit(struct i2c_adapter *adapter)</span>
 extern void intel_i2c_reset(struct drm_device *dev);
 
 /* intel_bios.c */
<span class="p_del">-int intel_bios_init(struct drm_i915_private *dev_priv);</span>
<span class="p_add">+void intel_bios_init(struct drm_i915_private *dev_priv);</span>
 bool intel_bios_is_valid_vbt(const void *buf, size_t size);
 bool intel_bios_is_tv_present(struct drm_i915_private *dev_priv);
 bool intel_bios_is_lvds_present(struct drm_i915_private *dev_priv, u8 *i2c_pin);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_bios.c b/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_header">index cf2560708e03..4ac36e3c341f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_chunk">@@ -1332,6 +1332,7 @@</span> <span class="p_context"> parse_device_mapping(struct drm_i915_private *dev_priv,</span>
 	return;
 }
 
<span class="p_add">+/* Common defaults which may be overridden by VBT. */</span>
 static void
 init_vbt_defaults(struct drm_i915_private *dev_priv)
 {
<span class="p_chunk">@@ -1368,6 +1369,18 @@</span> <span class="p_context"> init_vbt_defaults(struct drm_i915_private *dev_priv)</span>
 			&amp;dev_priv-&gt;vbt.ddi_port_info[port];
 
 		info-&gt;hdmi_level_shift = HDMI_LEVEL_SHIFT_UNKNOWN;
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Defaults to initialize only if there is no VBT. */</span>
<span class="p_add">+static void</span>
<span class="p_add">+init_vbt_missing_defaults(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	enum port port;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (port = PORT_A; port &lt; I915_MAX_PORTS; port++) {</span>
<span class="p_add">+		struct ddi_vbt_port_info *info =</span>
<span class="p_add">+			&amp;dev_priv-&gt;vbt.ddi_port_info[port];</span>
 
 		info-&gt;supports_dvi = (port != PORT_A &amp;&amp; port != PORT_E);
 		info-&gt;supports_hdmi = info-&gt;supports_dvi;
<span class="p_chunk">@@ -1450,36 +1463,35 @@</span> <span class="p_context"> static const struct vbt_header *find_vbt(void __iomem *bios, size_t size)</span>
  * intel_bios_init - find VBT and initialize settings from the BIOS
  * @dev_priv: i915 device instance
  *
<span class="p_del">- * Loads the Video BIOS and checks that the VBT exists.  Sets scratch registers</span>
<span class="p_del">- * to appropriate values.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Returns 0 on success, nonzero on failure.</span>
<span class="p_add">+ * Parse and initialize settings from the Video BIOS Tables (VBT). If the VBT</span>
<span class="p_add">+ * was not found in ACPI OpRegion, try to find it in PCI ROM first. Also</span>
<span class="p_add">+ * initialize some defaults if the VBT is not present at all.</span>
  */
<span class="p_del">-int</span>
<span class="p_del">-intel_bios_init(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+void intel_bios_init(struct drm_i915_private *dev_priv)</span>
 {
 	struct pci_dev *pdev = dev_priv-&gt;drm.pdev;
 	const struct vbt_header *vbt = dev_priv-&gt;opregion.vbt;
 	const struct bdb_header *bdb;
 	u8 __iomem *bios = NULL;
 
<span class="p_del">-	if (HAS_PCH_NOP(dev_priv))</span>
<span class="p_del">-		return -ENODEV;</span>
<span class="p_add">+	if (HAS_PCH_NOP(dev_priv)) {</span>
<span class="p_add">+		DRM_DEBUG_KMS(&quot;Skipping VBT init due to disabled display.\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
 
 	init_vbt_defaults(dev_priv);
 
<span class="p_add">+	/* If the OpRegion does not have VBT, look in PCI ROM. */</span>
 	if (!vbt) {
 		size_t size;
 
 		bios = pci_map_rom(pdev, &amp;size);
 		if (!bios)
<span class="p_del">-			return -1;</span>
<span class="p_add">+			goto out;</span>
 
 		vbt = find_vbt(bios, size);
<span class="p_del">-		if (!vbt) {</span>
<span class="p_del">-			pci_unmap_rom(pdev, bios);</span>
<span class="p_del">-			return -1;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (!vbt)</span>
<span class="p_add">+			goto out;</span>
 
 		DRM_DEBUG_KMS(&quot;Found valid VBT in PCI ROM\n&quot;);
 	}
<span class="p_chunk">@@ -1504,10 +1516,14 @@</span> <span class="p_context"> intel_bios_init(struct drm_i915_private *dev_priv)</span>
 	parse_mipi_sequence(dev_priv, bdb);
 	parse_ddi_ports(dev_priv, bdb);
 
<span class="p_add">+out:</span>
<span class="p_add">+	if (!vbt) {</span>
<span class="p_add">+		DRM_INFO(&quot;Failed to find VBIOS tables (VBT)\n&quot;);</span>
<span class="p_add">+		init_vbt_missing_defaults(dev_priv);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (bios)
 		pci_unmap_rom(pdev, bios);
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_drv.c b/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_header">index 46568fc80848..6abf315fd6da 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_chunk">@@ -801,6 +801,7 @@</span> <span class="p_context"> static struct drm_driver msm_driver = {</span>
 	.prime_fd_to_handle = drm_gem_prime_fd_to_handle,
 	.gem_prime_export   = drm_gem_prime_export,
 	.gem_prime_import   = drm_gem_prime_import,
<span class="p_add">+	.gem_prime_res_obj  = msm_gem_prime_res_obj,</span>
 	.gem_prime_pin      = msm_gem_prime_pin,
 	.gem_prime_unpin    = msm_gem_prime_unpin,
 	.gem_prime_get_sg_table = msm_gem_prime_get_sg_table,
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_drv.h b/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_header">index d0da52f2a806..bc98d48c47f8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_chunk">@@ -203,6 +203,7 @@</span> <span class="p_context"> struct sg_table *msm_gem_prime_get_sg_table(struct drm_gem_object *obj);</span>
 void *msm_gem_prime_vmap(struct drm_gem_object *obj);
 void msm_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
 int msm_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
<span class="p_add">+struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj);</span>
 struct drm_gem_object *msm_gem_prime_import_sg_table(struct drm_device *dev,
 		struct dma_buf_attachment *attach, struct sg_table *sg);
 int msm_gem_prime_pin(struct drm_gem_object *obj);
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_gem_prime.c b/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_header">index 60bb290700ce..13403c6da6c7 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_chunk">@@ -70,3 +70,10 @@</span> <span class="p_context"> void msm_gem_prime_unpin(struct drm_gem_object *obj)</span>
 	if (!obj-&gt;import_attach)
 		msm_gem_put_pages(obj);
 }
<span class="p_add">+</span>
<span class="p_add">+struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct msm_gem_object *msm_obj = to_msm_bo(obj);</span>
<span class="p_add">+</span>
<span class="p_add">+	return msm_obj-&gt;resv;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h b/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_header">index 82d3e28918fd..7e4f24ae7de8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
 
 struct nvkm_alarm {
 	struct list_head head;
<span class="p_add">+	struct list_head exec;</span>
 	u64 timestamp;
 	void (*func)(struct nvkm_alarm *);
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c b/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_header">index f2a86eae0a0d..2437f7d41ca2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_chunk">@@ -50,7 +50,8 @@</span> <span class="p_context"> nvkm_timer_alarm_trigger(struct nvkm_timer *tmr)</span>
 		/* Move to completed list.  We&#39;ll drop the lock before
 		 * executing the callback so it can reschedule itself.
 		 */
<span class="p_del">-		list_move_tail(&amp;alarm-&gt;head, &amp;exec);</span>
<span class="p_add">+		list_del_init(&amp;alarm-&gt;head);</span>
<span class="p_add">+		list_add(&amp;alarm-&gt;exec, &amp;exec);</span>
 	}
 
 	/* Shut down interrupt if no more pending alarms. */
<span class="p_chunk">@@ -59,8 +60,8 @@</span> <span class="p_context"> nvkm_timer_alarm_trigger(struct nvkm_timer *tmr)</span>
 	spin_unlock_irqrestore(&amp;tmr-&gt;lock, flags);
 
 	/* Execute completed callbacks. */
<span class="p_del">-	list_for_each_entry_safe(alarm, atemp, &amp;exec, head) {</span>
<span class="p_del">-		list_del_init(&amp;alarm-&gt;head);</span>
<span class="p_add">+	list_for_each_entry_safe(alarm, atemp, &amp;exec, exec) {</span>
<span class="p_add">+		list_del(&amp;alarm-&gt;exec);</span>
 		alarm-&gt;func(alarm);
 	}
 }
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_header">index b6a0806b06bf..a1c68e6a689e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_chunk">@@ -368,6 +368,8 @@</span> <span class="p_context"> static void *vmw_local_fifo_reserve(struct vmw_private *dev_priv,</span>
 				return fifo_state-&gt;static_buffer;
 			else {
 				fifo_state-&gt;dynamic_buffer = vmalloc(bytes);
<span class="p_add">+				if (!fifo_state-&gt;dynamic_buffer)</span>
<span class="p_add">+					goto out_err;</span>
 				return fifo_state-&gt;dynamic_buffer;
 			}
 		}
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">index 05fa092c942b..56b803384ea2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_chunk">@@ -1275,11 +1275,14 @@</span> <span class="p_context"> int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 	struct ttm_object_file *tfile = vmw_fpriv(file_priv)-&gt;tfile;
 	int ret;
 	uint32_t size;
<span class="p_del">-	uint32_t backup_handle;</span>
<span class="p_add">+	uint32_t backup_handle = 0;</span>
 
 	if (req-&gt;multisample_count != 0)
 		return -EINVAL;
 
<span class="p_add">+	if (req-&gt;mip_levels &gt; DRM_VMW_MAX_MIP_LEVELS)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	if (unlikely(vmw_user_surface_size == 0))
 		vmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +
 			128;
<span class="p_chunk">@@ -1315,12 +1318,16 @@</span> <span class="p_context"> int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 		ret = vmw_user_dmabuf_lookup(tfile, req-&gt;buffer_handle,
 					     &amp;res-&gt;backup,
 					     &amp;user_srf-&gt;backup_base);
<span class="p_del">-		if (ret == 0 &amp;&amp; res-&gt;backup-&gt;base.num_pages * PAGE_SIZE &lt;</span>
<span class="p_del">-		    res-&gt;backup_size) {</span>
<span class="p_del">-			DRM_ERROR(&quot;Surface backup buffer is too small.\n&quot;);</span>
<span class="p_del">-			vmw_dmabuf_unreference(&amp;res-&gt;backup);</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			goto out_unlock;</span>
<span class="p_add">+		if (ret == 0) {</span>
<span class="p_add">+			if (res-&gt;backup-&gt;base.num_pages * PAGE_SIZE &lt;</span>
<span class="p_add">+			    res-&gt;backup_size) {</span>
<span class="p_add">+				DRM_ERROR(&quot;Surface backup buffer is too small.\n&quot;);</span>
<span class="p_add">+				vmw_dmabuf_unreference(&amp;res-&gt;backup);</span>
<span class="p_add">+				ret = -EINVAL;</span>
<span class="p_add">+				goto out_unlock;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				backup_handle = req-&gt;buffer_handle;</span>
<span class="p_add">+			}</span>
 		}
 	} else if (req-&gt;drm_surface_flags &amp; drm_vmw_surface_flag_create_buffer)
 		ret = vmw_user_dmabuf_alloc(dev_priv, tfile,
<span class="p_header">diff --git a/drivers/iio/adc/bcm_iproc_adc.c b/drivers/iio/adc/bcm_iproc_adc.c</span>
<span class="p_header">index 21d38c8af21e..7f4f9c4150e3 100644</span>
<span class="p_header">--- a/drivers/iio/adc/bcm_iproc_adc.c</span>
<span class="p_header">+++ b/drivers/iio/adc/bcm_iproc_adc.c</span>
<span class="p_chunk">@@ -143,7 +143,7 @@</span> <span class="p_context"> static void iproc_adc_reg_dump(struct iio_dev *indio_dev)</span>
 	iproc_adc_dbg_reg(dev, adc_priv, IPROC_SOFT_BYPASS_DATA);
 }
 
<span class="p_del">-static irqreturn_t iproc_adc_interrupt_handler(int irq, void *data)</span>
<span class="p_add">+static irqreturn_t iproc_adc_interrupt_thread(int irq, void *data)</span>
 {
 	u32 channel_intr_status;
 	u32 intr_status;
<span class="p_chunk">@@ -167,7 +167,7 @@</span> <span class="p_context"> static irqreturn_t iproc_adc_interrupt_handler(int irq, void *data)</span>
 	return IRQ_NONE;
 }
 
<span class="p_del">-static irqreturn_t iproc_adc_interrupt_thread(int irq, void *data)</span>
<span class="p_add">+static irqreturn_t iproc_adc_interrupt_handler(int irq, void *data)</span>
 {
 	irqreturn_t retval = IRQ_NONE;
 	struct iproc_adc_priv *adc_priv;
<span class="p_chunk">@@ -181,7 +181,7 @@</span> <span class="p_context"> static irqreturn_t iproc_adc_interrupt_thread(int irq, void *data)</span>
 	adc_priv = iio_priv(indio_dev);
 
 	regmap_read(adc_priv-&gt;regmap, IPROC_INTERRUPT_STATUS, &amp;intr_status);
<span class="p_del">-	dev_dbg(&amp;indio_dev-&gt;dev, &quot;iproc_adc_interrupt_thread(),INTRPT_STS:%x\n&quot;,</span>
<span class="p_add">+	dev_dbg(&amp;indio_dev-&gt;dev, &quot;iproc_adc_interrupt_handler(),INTRPT_STS:%x\n&quot;,</span>
 			intr_status);
 
 	intr_channels = (intr_status &amp; IPROC_ADC_INTR_MASK) &gt;&gt; IPROC_ADC_INTR;
<span class="p_chunk">@@ -566,8 +566,8 @@</span> <span class="p_context"> static int iproc_adc_probe(struct platform_device *pdev)</span>
 	}
 
 	ret = devm_request_threaded_irq(&amp;pdev-&gt;dev, adc_priv-&gt;irqno,
<span class="p_del">-				iproc_adc_interrupt_thread,</span>
 				iproc_adc_interrupt_handler,
<span class="p_add">+				iproc_adc_interrupt_thread,</span>
 				IRQF_SHARED, &quot;iproc-adc&quot;, indio_dev);
 	if (ret) {
 		dev_err(&amp;pdev-&gt;dev, &quot;request_irq error %d\n&quot;, ret);
<span class="p_header">diff --git a/drivers/iio/light/ltr501.c b/drivers/iio/light/ltr501.c</span>
<span class="p_header">index 3afc53a3d0b6..c298fd86ed86 100644</span>
<span class="p_header">--- a/drivers/iio/light/ltr501.c</span>
<span class="p_header">+++ b/drivers/iio/light/ltr501.c</span>
<span class="p_chunk">@@ -74,9 +74,9 @@</span> <span class="p_context"> static const int int_time_mapping[] = {100000, 50000, 200000, 400000};</span>
 static const struct reg_field reg_field_it =
 				REG_FIELD(LTR501_ALS_MEAS_RATE, 3, 4);
 static const struct reg_field reg_field_als_intr =
<span class="p_del">-				REG_FIELD(LTR501_INTR, 0, 0);</span>
<span class="p_del">-static const struct reg_field reg_field_ps_intr =</span>
 				REG_FIELD(LTR501_INTR, 1, 1);
<span class="p_add">+static const struct reg_field reg_field_ps_intr =</span>
<span class="p_add">+				REG_FIELD(LTR501_INTR, 0, 0);</span>
 static const struct reg_field reg_field_als_rate =
 				REG_FIELD(LTR501_ALS_MEAS_RATE, 0, 2);
 static const struct reg_field reg_field_ps_rate =
<span class="p_header">diff --git a/drivers/iio/proximity/as3935.c b/drivers/iio/proximity/as3935.c</span>
<span class="p_header">index 020459513384..268210ea4990 100644</span>
<span class="p_header">--- a/drivers/iio/proximity/as3935.c</span>
<span class="p_header">+++ b/drivers/iio/proximity/as3935.c</span>
<span class="p_chunk">@@ -40,9 +40,9 @@</span> <span class="p_context"></span>
 #define AS3935_AFE_PWR_BIT	BIT(0)
 
 #define AS3935_INT		0x03
<span class="p_del">-#define AS3935_INT_MASK		0x07</span>
<span class="p_add">+#define AS3935_INT_MASK		0x0f</span>
 #define AS3935_EVENT_INT	BIT(3)
<span class="p_del">-#define AS3935_NOISE_INT	BIT(1)</span>
<span class="p_add">+#define AS3935_NOISE_INT	BIT(0)</span>
 
 #define AS3935_DATA		0x07
 #define AS3935_DATA_MASK	0x3F
<span class="p_chunk">@@ -215,7 +215,7 @@</span> <span class="p_context"> static irqreturn_t as3935_trigger_handler(int irq, void *private)</span>
 
 	st-&gt;buffer[0] = val &amp; AS3935_DATA_MASK;
 	iio_push_to_buffers_with_timestamp(indio_dev, &amp;st-&gt;buffer,
<span class="p_del">-					   pf-&gt;timestamp);</span>
<span class="p_add">+					   iio_get_time_ns(indio_dev));</span>
 err_read:
 	iio_trigger_notify_done(indio_dev-&gt;trig);
 
<span class="p_chunk">@@ -244,7 +244,7 @@</span> <span class="p_context"> static void as3935_event_work(struct work_struct *work)</span>
 
 	switch (val) {
 	case AS3935_EVENT_INT:
<span class="p_del">-		iio_trigger_poll(st-&gt;trig);</span>
<span class="p_add">+		iio_trigger_poll_chained(st-&gt;trig);</span>
 		break;
 	case AS3935_NOISE_INT:
 		dev_warn(&amp;st-&gt;spi-&gt;dev, &quot;noise level is too high\n&quot;);
<span class="p_header">diff --git a/drivers/input/mouse/elantech.c b/drivers/input/mouse/elantech.c</span>
<span class="p_header">index 7826994c45bf..cd834da5934a 100644</span>
<span class="p_header">--- a/drivers/input/mouse/elantech.c</span>
<span class="p_header">+++ b/drivers/input/mouse/elantech.c</span>
<span class="p_chunk">@@ -1118,8 +1118,10 @@</span> <span class="p_context"> static int elantech_get_resolution_v4(struct psmouse *psmouse,</span>
  * Asus UX32VD             0x361f02        00, 15, 0e      clickpad
  * Avatar AVIU-145A2       0x361f00        ?               clickpad
  * Fujitsu LIFEBOOK E544   0x470f00        d0, 12, 09      2 hw buttons
<span class="p_add">+ * Fujitsu LIFEBOOK E546   0x470f00        50, 12, 09      2 hw buttons</span>
  * Fujitsu LIFEBOOK E547   0x470f00        50, 12, 09      2 hw buttons
  * Fujitsu LIFEBOOK E554   0x570f01        40, 14, 0c      2 hw buttons
<span class="p_add">+ * Fujitsu LIFEBOOK E557   0x570f01        40, 14, 0c      2 hw buttons</span>
  * Fujitsu T725            0x470f01        05, 12, 09      2 hw buttons
  * Fujitsu H730            0x570f00        c0, 14, 0c      3 hw buttons (**)
  * Gigabyte U2442          0x450f01        58, 17, 0c      2 hw buttons
<span class="p_chunk">@@ -1525,6 +1527,13 @@</span> <span class="p_context"> static const struct dmi_system_id elantech_dmi_force_crc_enabled[] = {</span>
 		},
 	},
 	{
<span class="p_add">+		/* Fujitsu LIFEBOOK E546  does not work with crc_enabled == 0 */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;LIFEBOOK E546&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		/* Fujitsu LIFEBOOK E547 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),
<span class="p_chunk">@@ -1546,6 +1555,13 @@</span> <span class="p_context"> static const struct dmi_system_id elantech_dmi_force_crc_enabled[] = {</span>
 		},
 	},
 	{
<span class="p_add">+		/* Fujitsu LIFEBOOK E557 does not work with crc_enabled == 0 */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;LIFEBOOK E557&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		/* Fujitsu LIFEBOOK U745 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),
<span class="p_header">diff --git a/drivers/misc/cxl/file.c b/drivers/misc/cxl/file.c</span>
<span class="p_header">index 77080cc5fa0a..afa211397048 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/file.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/file.c</span>
<span class="p_chunk">@@ -155,11 +155,8 @@</span> <span class="p_context"> static long afu_ioctl_start_work(struct cxl_context *ctx,</span>
 
 	/* Do this outside the status_mutex to avoid a circular dependency with
 	 * the locking in cxl_mmap_fault() */
<span class="p_del">-	if (copy_from_user(&amp;work, uwork,</span>
<span class="p_del">-			   sizeof(struct cxl_ioctl_start_work))) {</span>
<span class="p_del">-		rc = -EFAULT;</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (copy_from_user(&amp;work, uwork, sizeof(work)))</span>
<span class="p_add">+		return -EFAULT;</span>
 
 	mutex_lock(&amp;ctx-&gt;status_mutex);
 	if (ctx-&gt;status != OPENED) {
<span class="p_header">diff --git a/drivers/misc/cxl/native.c b/drivers/misc/cxl/native.c</span>
<span class="p_header">index a217a74ccc98..224c7103890c 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/native.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/native.c</span>
<span class="p_chunk">@@ -1066,13 +1066,16 @@</span> <span class="p_context"> int cxl_native_register_psl_err_irq(struct cxl *adapter)</span>
 
 void cxl_native_release_psl_err_irq(struct cxl *adapter)
 {
<span class="p_del">-	if (adapter-&gt;native-&gt;err_virq != irq_find_mapping(NULL, adapter-&gt;native-&gt;err_hwirq))</span>
<span class="p_add">+	if (adapter-&gt;native-&gt;err_virq == 0 ||</span>
<span class="p_add">+	    adapter-&gt;native-&gt;err_virq !=</span>
<span class="p_add">+	    irq_find_mapping(NULL, adapter-&gt;native-&gt;err_hwirq))</span>
 		return;
 
 	cxl_p1_write(adapter, CXL_PSL_ErrIVTE, 0x0000000000000000);
 	cxl_unmap_irq(adapter-&gt;native-&gt;err_virq, adapter);
 	cxl_ops-&gt;release_one_irq(adapter, adapter-&gt;native-&gt;err_hwirq);
 	kfree(adapter-&gt;irq_name);
<span class="p_add">+	adapter-&gt;native-&gt;err_virq = 0;</span>
 }
 
 int cxl_native_register_serr_irq(struct cxl_afu *afu)
<span class="p_chunk">@@ -1102,13 +1105,15 @@</span> <span class="p_context"> int cxl_native_register_serr_irq(struct cxl_afu *afu)</span>
 
 void cxl_native_release_serr_irq(struct cxl_afu *afu)
 {
<span class="p_del">-	if (afu-&gt;serr_virq != irq_find_mapping(NULL, afu-&gt;serr_hwirq))</span>
<span class="p_add">+	if (afu-&gt;serr_virq == 0 ||</span>
<span class="p_add">+	    afu-&gt;serr_virq != irq_find_mapping(NULL, afu-&gt;serr_hwirq))</span>
 		return;
 
 	cxl_p1n_write(afu, CXL_PSL_SERR_An, 0x0000000000000000);
 	cxl_unmap_irq(afu-&gt;serr_virq, afu);
 	cxl_ops-&gt;release_one_irq(afu-&gt;adapter, afu-&gt;serr_hwirq);
 	kfree(afu-&gt;err_irq_name);
<span class="p_add">+	afu-&gt;serr_virq = 0;</span>
 }
 
 int cxl_native_register_psl_irq(struct cxl_afu *afu)
<span class="p_chunk">@@ -1131,12 +1136,15 @@</span> <span class="p_context"> int cxl_native_register_psl_irq(struct cxl_afu *afu)</span>
 
 void cxl_native_release_psl_irq(struct cxl_afu *afu)
 {
<span class="p_del">-	if (afu-&gt;native-&gt;psl_virq != irq_find_mapping(NULL, afu-&gt;native-&gt;psl_hwirq))</span>
<span class="p_add">+	if (afu-&gt;native-&gt;psl_virq == 0 ||</span>
<span class="p_add">+	    afu-&gt;native-&gt;psl_virq !=</span>
<span class="p_add">+	    irq_find_mapping(NULL, afu-&gt;native-&gt;psl_hwirq))</span>
 		return;
 
 	cxl_unmap_irq(afu-&gt;native-&gt;psl_virq, afu);
 	cxl_ops-&gt;release_one_irq(afu-&gt;adapter, afu-&gt;native-&gt;psl_hwirq);
 	kfree(afu-&gt;psl_irq_name);
<span class="p_add">+	afu-&gt;native-&gt;psl_virq = 0;</span>
 }
 
 static void recover_psl_err(struct cxl_afu *afu, u64 errstat)
<span class="p_header">diff --git a/drivers/misc/mei/bus.c b/drivers/misc/mei/bus.c</span>
<span class="p_header">index dbe676de7a19..0c98ed44df05 100644</span>
<span class="p_header">--- a/drivers/misc/mei/bus.c</span>
<span class="p_header">+++ b/drivers/misc/mei/bus.c</span>
<span class="p_chunk">@@ -678,8 +678,10 @@</span> <span class="p_context"> static ssize_t modalias_show(struct device *dev, struct device_attribute *a,</span>
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	const uuid_le *uuid = mei_me_cl_uuid(cldev-&gt;me_cl);
<span class="p_add">+	u8 version = mei_me_cl_ver(cldev-&gt;me_cl);</span>
 
<span class="p_del">-	return scnprintf(buf, PAGE_SIZE, &quot;mei:%s:%pUl:&quot;, cldev-&gt;name, uuid);</span>
<span class="p_add">+	return scnprintf(buf, PAGE_SIZE, &quot;mei:%s:%pUl:%02X:&quot;,</span>
<span class="p_add">+			 cldev-&gt;name, uuid, version);</span>
 }
 static DEVICE_ATTR_RO(modalias);
 
<span class="p_header">diff --git a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_header">index 0a9108cd4c45..0a5ee1d973ac 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_chunk">@@ -1931,7 +1931,7 @@</span> <span class="p_context"> u16 bnx2x_select_queue(struct net_device *dev, struct sk_buff *skb,</span>
 	}
 
 	/* select a non-FCoE queue */
<span class="p_del">-	return fallback(dev, skb) % BNX2X_NUM_ETH_QUEUES(bp);</span>
<span class="p_add">+	return fallback(dev, skb) % (BNX2X_NUM_ETH_QUEUES(bp) * bp-&gt;max_cos);</span>
 }
 
 void bnx2x_set_num_queues(struct bnx2x *bp)
<span class="p_header">diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_header">index 19dc9e25aa72..f9c2feb4a4e7 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_chunk">@@ -2226,10 +2226,14 @@</span> <span class="p_context"> static int cxgb_up(struct adapter *adap)</span>
 		if (err)
 			goto irq_err;
 	}
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;uld_mutex);</span>
 	enable_rx(adap);
 	t4_sge_start(adap);
 	t4_intr_enable(adap);
 	adap-&gt;flags |= FULL_INIT_DONE;
<span class="p_add">+	mutex_unlock(&amp;uld_mutex);</span>
<span class="p_add">+</span>
 	notify_ulds(adap, CXGB4_STATE_UP);
 #if IS_ENABLED(CONFIG_IPV6)
 	update_clip(adap);
<span class="p_header">diff --git a/drivers/net/ethernet/ethoc.c b/drivers/net/ethernet/ethoc.c</span>
<span class="p_header">index c044667a0a25..e31199f3048c 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ethoc.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ethoc.c</span>
<span class="p_chunk">@@ -710,6 +710,8 @@</span> <span class="p_context"> static int ethoc_open(struct net_device *dev)</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	napi_enable(&amp;priv-&gt;napi);</span>
<span class="p_add">+</span>
 	ethoc_init_ring(priv, dev-&gt;mem_start);
 	ethoc_reset(priv);
 
<span class="p_chunk">@@ -722,7 +724,6 @@</span> <span class="p_context"> static int ethoc_open(struct net_device *dev)</span>
 	}
 
 	phy_start(dev-&gt;phydev);
<span class="p_del">-	napi_enable(&amp;priv-&gt;napi);</span>
 
 	if (netif_msg_ifup(priv)) {
 		dev_info(&amp;dev-&gt;dev, &quot;I/O: %08lx Memory: %08lx-%08lx\n&quot;,
<span class="p_header">diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c</span>
<span class="p_header">index b2893fbe25e5..ef6bff820cf6 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c</span>
<span class="p_chunk">@@ -1953,7 +1953,7 @@</span> <span class="p_context"> static void stmmac_tso_allocator(struct stmmac_priv *priv, unsigned int des,</span>
 
 		priv-&gt;hw-&gt;desc-&gt;prepare_tso_tx_desc(desc, 0, buff_size,
 			0, 1,
<span class="p_del">-			(last_segment) &amp;&amp; (buff_size &lt; TSO_MAX_BUFF_SIZE),</span>
<span class="p_add">+			(last_segment) &amp;&amp; (tmp_len &lt;= TSO_MAX_BUFF_SIZE),</span>
 			0, 0);
 
 		tmp_len -= TSO_MAX_BUFF_SIZE;
<span class="p_header">diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c</span>
<span class="p_header">index 3c4c2cf6d444..55c4408892be 100644</span>
<span class="p_header">--- a/drivers/net/vxlan.c</span>
<span class="p_header">+++ b/drivers/net/vxlan.c</span>
<span class="p_chunk">@@ -59,6 +59,8 @@</span> <span class="p_context"> static const u8 all_zeros_mac[ETH_ALEN + 2];</span>
 
 static int vxlan_sock_add(struct vxlan_dev *vxlan);
 
<span class="p_add">+static void vxlan_vs_del_dev(struct vxlan_dev *vxlan);</span>
<span class="p_add">+</span>
 /* per-network namespace private data for this module */
 struct vxlan_net {
 	struct list_head  vxlan_list;
<span class="p_chunk">@@ -717,6 +719,22 @@</span> <span class="p_context"> static void vxlan_fdb_destroy(struct vxlan_dev *vxlan, struct vxlan_fdb *f)</span>
 	call_rcu(&amp;f-&gt;rcu, vxlan_fdb_free);
 }
 
<span class="p_add">+static void vxlan_dst_free(struct rcu_head *head)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vxlan_rdst *rd = container_of(head, struct vxlan_rdst, rcu);</span>
<span class="p_add">+</span>
<span class="p_add">+	dst_cache_destroy(&amp;rd-&gt;dst_cache);</span>
<span class="p_add">+	kfree(rd);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void vxlan_fdb_dst_destroy(struct vxlan_dev *vxlan, struct vxlan_fdb *f,</span>
<span class="p_add">+				  struct vxlan_rdst *rd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	list_del_rcu(&amp;rd-&gt;list);</span>
<span class="p_add">+	vxlan_fdb_notify(vxlan, f, rd, RTM_DELNEIGH);</span>
<span class="p_add">+	call_rcu(&amp;rd-&gt;rcu, vxlan_dst_free);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int vxlan_fdb_parse(struct nlattr *tb[], struct vxlan_dev *vxlan,
 			   union vxlan_addr *ip, __be16 *port, __be32 *vni,
 			   u32 *ifindex)
<span class="p_chunk">@@ -847,9 +865,7 @@</span> <span class="p_context"> static int vxlan_fdb_delete(struct ndmsg *ndm, struct nlattr *tb[],</span>
 	 * otherwise destroy the fdb entry
 	 */
 	if (rd &amp;&amp; !list_is_singular(&amp;f-&gt;remotes)) {
<span class="p_del">-		list_del_rcu(&amp;rd-&gt;list);</span>
<span class="p_del">-		vxlan_fdb_notify(vxlan, f, rd, RTM_DELNEIGH);</span>
<span class="p_del">-		kfree_rcu(rd, rcu);</span>
<span class="p_add">+		vxlan_fdb_dst_destroy(vxlan, f, rd);</span>
 		goto out;
 	}
 
<span class="p_chunk">@@ -1026,6 +1042,8 @@</span> <span class="p_context"> static void vxlan_sock_release(struct vxlan_dev *vxlan)</span>
 	rcu_assign_pointer(vxlan-&gt;vn4_sock, NULL);
 	synchronize_net();
 
<span class="p_add">+	vxlan_vs_del_dev(vxlan);</span>
<span class="p_add">+</span>
 	if (__vxlan_sock_release_prep(sock4)) {
 		udp_tunnel_sock_release(sock4-&gt;sock);
 		kfree(sock4);
<span class="p_chunk">@@ -2286,6 +2304,15 @@</span> <span class="p_context"> static void vxlan_cleanup(unsigned long arg)</span>
 	mod_timer(&amp;vxlan-&gt;age_timer, next_timer);
 }
 
<span class="p_add">+static void vxlan_vs_del_dev(struct vxlan_dev *vxlan)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock(&amp;vn-&gt;sock_lock);</span>
<span class="p_add">+	hlist_del_init_rcu(&amp;vxlan-&gt;hlist);</span>
<span class="p_add">+	spin_unlock(&amp;vn-&gt;sock_lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void vxlan_vs_add_dev(struct vxlan_sock *vs, struct vxlan_dev *vxlan)
 {
 	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);
<span class="p_chunk">@@ -3056,12 +3083,6 @@</span> <span class="p_context"> static int vxlan_newlink(struct net *src_net, struct net_device *dev,</span>
 static void vxlan_dellink(struct net_device *dev, struct list_head *head)
 {
 	struct vxlan_dev *vxlan = netdev_priv(dev);
<span class="p_del">-	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock(&amp;vn-&gt;sock_lock);</span>
<span class="p_del">-	if (!hlist_unhashed(&amp;vxlan-&gt;hlist))</span>
<span class="p_del">-		hlist_del_rcu(&amp;vxlan-&gt;hlist);</span>
<span class="p_del">-	spin_unlock(&amp;vn-&gt;sock_lock);</span>
 
 	gro_cells_destroy(&amp;vxlan-&gt;gro_cells);
 	list_del(&amp;vxlan-&gt;next);
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_bsg.c b/drivers/scsi/qla2xxx/qla_bsg.c</span>
<span class="p_header">index 643014f82f7d..4a6e086279f9 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_bsg.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_bsg.c</span>
<span class="p_chunk">@@ -721,6 +721,8 @@</span> <span class="p_context"> qla2x00_process_loopback(struct fc_bsg_job *bsg_job)</span>
 		return -EIO;
 	}
 
<span class="p_add">+	memset(&amp;elreq, 0, sizeof(elreq));</span>
<span class="p_add">+</span>
 	elreq.req_sg_cnt = dma_map_sg(&amp;ha-&gt;pdev-&gt;dev,
 		bsg_job-&gt;request_payload.sg_list, bsg_job-&gt;request_payload.sg_cnt,
 		DMA_TO_DEVICE);
<span class="p_chunk">@@ -786,10 +788,9 @@</span> <span class="p_context"> qla2x00_process_loopback(struct fc_bsg_job *bsg_job)</span>
 
 	if (atomic_read(&amp;vha-&gt;loop_state) == LOOP_READY &amp;&amp;
 	    (ha-&gt;current_topology == ISP_CFG_F ||
<span class="p_del">-	    ((IS_QLA81XX(ha) || IS_QLA8031(ha) || IS_QLA8044(ha)) &amp;&amp;</span>
<span class="p_del">-	    le32_to_cpu(*(uint32_t *)req_data) == ELS_OPCODE_BYTE</span>
<span class="p_del">-	    &amp;&amp; req_data_len == MAX_ELS_FRAME_PAYLOAD)) &amp;&amp;</span>
<span class="p_del">-		elreq.options == EXTERNAL_LOOPBACK) {</span>
<span class="p_add">+	    (le32_to_cpu(*(uint32_t *)req_data) == ELS_OPCODE_BYTE &amp;&amp;</span>
<span class="p_add">+	     req_data_len == MAX_ELS_FRAME_PAYLOAD)) &amp;&amp;</span>
<span class="p_add">+	    elreq.options == EXTERNAL_LOOPBACK) {</span>
 		type = &quot;FC_BSG_HST_VENDOR_ECHO_DIAG&quot;;
 		ql_dbg(ql_dbg_user, vha, 0x701e,
 		    &quot;BSG request type: %s.\n&quot;, type);
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_dbg.c b/drivers/scsi/qla2xxx/qla_dbg.c</span>
<span class="p_header">index 45af34ddc432..658e4d15cb71 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_dbg.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_dbg.c</span>
<span class="p_chunk">@@ -1131,7 +1131,7 @@</span> <span class="p_context"> qla24xx_fw_dump(scsi_qla_host_t *vha, int hardware_locked)</span>
 
 	/* Mailbox registers. */
 	mbx_reg = &amp;reg-&gt;mailbox0;
<span class="p_del">-	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, dmp_reg++)</span>
<span class="p_add">+	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, mbx_reg++)</span>
 		fw-&gt;mailbox_reg[cnt] = htons(RD_REG_WORD(mbx_reg));
 
 	/* Transfer sequence registers. */
<span class="p_chunk">@@ -2090,7 +2090,7 @@</span> <span class="p_context"> qla83xx_fw_dump(scsi_qla_host_t *vha, int hardware_locked)</span>
 
 	/* Mailbox registers. */
 	mbx_reg = &amp;reg-&gt;mailbox0;
<span class="p_del">-	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, dmp_reg++)</span>
<span class="p_add">+	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, mbx_reg++)</span>
 		fw-&gt;mailbox_reg[cnt] = htons(RD_REG_WORD(mbx_reg));
 
 	/* Transfer sequence registers. */
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_mbx.c b/drivers/scsi/qla2xxx/qla_mbx.c</span>
<span class="p_header">index 23698c998699..a1b01d66c9ab 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_mbx.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_mbx.c</span>
<span class="p_chunk">@@ -4783,9 +4783,9 @@</span> <span class="p_context"> qla2x00_echo_test(scsi_qla_host_t *vha, struct msg_echo_lb *mreq,</span>
 
 	memset(mcp-&gt;mb, 0 , sizeof(mcp-&gt;mb));
 	mcp-&gt;mb[0] = MBC_DIAGNOSTIC_ECHO;
<span class="p_del">-	mcp-&gt;mb[1] = mreq-&gt;options | BIT_6;	/* BIT_6 specifies 64bit address */</span>
<span class="p_add">+	/* BIT_6 specifies 64bit address */</span>
<span class="p_add">+	mcp-&gt;mb[1] = mreq-&gt;options | BIT_15 | BIT_6;</span>
 	if (IS_CNA_CAPABLE(ha)) {
<span class="p_del">-		mcp-&gt;mb[1] |= BIT_15;</span>
 		mcp-&gt;mb[2] = vha-&gt;fcoe_fcf_idx;
 	}
 	mcp-&gt;mb[16] = LSW(mreq-&gt;rcv_dma);
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_os.c b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">index f9b52a4b8c55..94630d4738e6 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_chunk">@@ -2420,10 +2420,10 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 
 	if (mem_only) {
 		if (pci_enable_device_mem(pdev))
<span class="p_del">-			goto probe_out;</span>
<span class="p_add">+			return ret;</span>
 	} else {
 		if (pci_enable_device(pdev))
<span class="p_del">-			goto probe_out;</span>
<span class="p_add">+			return ret;</span>
 	}
 
 	/* This may fail but that&#39;s ok */
<span class="p_chunk">@@ -2433,7 +2433,7 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 	if (!ha) {
 		ql_log_pci(ql_log_fatal, pdev, 0x0009,
 		    &quot;Unable to allocate memory for ha.\n&quot;);
<span class="p_del">-		goto probe_out;</span>
<span class="p_add">+		goto disable_device;</span>
 	}
 	ql_dbg_pci(ql_dbg_init, pdev, 0x000a,
 	    &quot;Memory allocated for ha=%p.\n&quot;, ha);
<span class="p_chunk">@@ -3039,7 +3039,7 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 	kfree(ha);
 	ha = NULL;
 
<span class="p_del">-probe_out:</span>
<span class="p_add">+disable_device:</span>
 	pci_disable_device(pdev);
 	return ret;
 }
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_tmpl.c b/drivers/scsi/qla2xxx/qla_tmpl.c</span>
<span class="p_header">index 36935c9ed669..9c2c7fe61280 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_tmpl.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_tmpl.c</span>
<span class="p_chunk">@@ -371,7 +371,7 @@</span> <span class="p_context"> qla27xx_fwdt_entry_t262(struct scsi_qla_host *vha,</span>
 		goto done;
 	}
 
<span class="p_del">-	if (end &lt;= start || start == 0 || end == 0) {</span>
<span class="p_add">+	if (end &lt; start || start == 0 || end == 0) {</span>
 		ql_dbg(ql_dbg_misc, vha, 0xd023,
 		    &quot;%s: unusable range (start=%x end=%x)\n&quot;, __func__,
 		    ent-&gt;t262.end_addr, ent-&gt;t262.start_addr);
<span class="p_header">diff --git a/drivers/staging/lustre/lustre/lov/lov_pack.c b/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_header">index be6e9857ce2a..a6d1cc804647 100644</span>
<span class="p_header">--- a/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_header">+++ b/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_chunk">@@ -387,18 +387,10 @@</span> <span class="p_context"> int lov_getstripe(struct lov_object *obj, struct lov_stripe_md *lsm,</span>
 	struct lov_mds_md *lmmk = NULL;
 	int rc, lmmk_size, lmm_size;
 	int lum_size;
<span class="p_del">-	mm_segment_t seg;</span>
 
 	if (!lsm)
 		return -ENODATA;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * &quot;Switch to kernel segment&quot; to allow copying from kernel space by</span>
<span class="p_del">-	 * copy_{to,from}_user().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	seg = get_fs();</span>
<span class="p_del">-	set_fs(KERNEL_DS);</span>
<span class="p_del">-</span>
 	/* we only need the header part from user space to get lmm_magic and
 	 * lmm_stripe_count, (the header part is common to v1 and v3)
 	 */
<span class="p_chunk">@@ -478,6 +470,5 @@</span> <span class="p_context"> int lov_getstripe(struct lov_object *obj, struct lov_stripe_md *lsm,</span>
 out_free:
 	kfree(lmmk);
 out:
<span class="p_del">-	set_fs(seg);</span>
 	return rc;
 }
<span class="p_header">diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c</span>
<span class="p_header">index cae4dea6464e..077344cc819f 100644</span>
<span class="p_header">--- a/drivers/target/target_core_transport.c</span>
<span class="p_header">+++ b/drivers/target/target_core_transport.c</span>
<span class="p_chunk">@@ -1182,15 +1182,28 @@</span> <span class="p_context"> target_cmd_size_check(struct se_cmd *cmd, unsigned int size)</span>
 	if (cmd-&gt;unknown_data_length) {
 		cmd-&gt;data_length = size;
 	} else if (size != cmd-&gt;data_length) {
<span class="p_del">-		pr_warn(&quot;TARGET_CORE[%s]: Expected Transfer Length:&quot;</span>
<span class="p_add">+		pr_warn_ratelimited(&quot;TARGET_CORE[%s]: Expected Transfer Length:&quot;</span>
 			&quot; %u does not match SCSI CDB Length: %u for SAM Opcode:&quot;
 			&quot; 0x%02x\n&quot;, cmd-&gt;se_tfo-&gt;get_fabric_name(),
 				cmd-&gt;data_length, size, cmd-&gt;t_task_cdb[0]);
 
<span class="p_del">-		if (cmd-&gt;data_direction == DMA_TO_DEVICE &amp;&amp;</span>
<span class="p_del">-		    cmd-&gt;se_cmd_flags &amp; SCF_SCSI_DATA_CDB) {</span>
<span class="p_del">-			pr_err(&quot;Rejecting underflow/overflow WRITE data\n&quot;);</span>
<span class="p_del">-			return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+		if (cmd-&gt;data_direction == DMA_TO_DEVICE) {</span>
<span class="p_add">+			if (cmd-&gt;se_cmd_flags &amp; SCF_SCSI_DATA_CDB) {</span>
<span class="p_add">+				pr_err_ratelimited(&quot;Rejecting underflow/overflow&quot;</span>
<span class="p_add">+						   &quot; for WRITE data CDB\n&quot;);</span>
<span class="p_add">+				return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Some fabric drivers like iscsi-target still expect to</span>
<span class="p_add">+			 * always reject overflow writes.  Reject this case until</span>
<span class="p_add">+			 * full fabric driver level support for overflow writes</span>
<span class="p_add">+			 * is introduced tree-wide.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (size &gt; cmd-&gt;data_length) {</span>
<span class="p_add">+				pr_err_ratelimited(&quot;Rejecting overflow for&quot;</span>
<span class="p_add">+						   &quot; WRITE control CDB\n&quot;);</span>
<span class="p_add">+				return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+			}</span>
 		}
 		/*
 		 * Reject READ_* or WRITE_* with overflow/underflow for
<span class="p_header">diff --git a/drivers/tty/serial/ifx6x60.c b/drivers/tty/serial/ifx6x60.c</span>
<span class="p_header">index d386346248de..91d2ddd6ef88 100644</span>
<span class="p_header">--- a/drivers/tty/serial/ifx6x60.c</span>
<span class="p_header">+++ b/drivers/tty/serial/ifx6x60.c</span>
<span class="p_chunk">@@ -1381,9 +1381,9 @@</span> <span class="p_context"> static struct spi_driver ifx_spi_driver = {</span>
 static void __exit ifx_spi_exit(void)
 {
 	/* unregister */
<span class="p_add">+	spi_unregister_driver(&amp;ifx_spi_driver);</span>
 	tty_unregister_driver(tty_drv);
 	put_tty_driver(tty_drv);
<span class="p_del">-	spi_unregister_driver(&amp;ifx_spi_driver);</span>
 	unregister_reboot_notifier(&amp;ifx_modem_reboot_notifier_block);
 }
 
<span class="p_header">diff --git a/drivers/tty/serial/sh-sci.c b/drivers/tty/serial/sh-sci.c</span>
<span class="p_header">index 4b26252c2885..ee84f89391ca 100644</span>
<span class="p_header">--- a/drivers/tty/serial/sh-sci.c</span>
<span class="p_header">+++ b/drivers/tty/serial/sh-sci.c</span>
<span class="p_chunk">@@ -1976,11 +1976,13 @@</span> <span class="p_context"> static int sci_startup(struct uart_port *port)</span>
 
 	dev_dbg(port-&gt;dev, &quot;%s(%d)\n&quot;, __func__, port-&gt;line);
 
<span class="p_add">+	sci_request_dma(port);</span>
<span class="p_add">+</span>
 	ret = sci_request_irq(s);
<span class="p_del">-	if (unlikely(ret &lt; 0))</span>
<span class="p_add">+	if (unlikely(ret &lt; 0)) {</span>
<span class="p_add">+		sci_free_dma(port);</span>
 		return ret;
<span class="p_del">-</span>
<span class="p_del">-	sci_request_dma(port);</span>
<span class="p_add">+	}</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -2012,8 +2014,8 @@</span> <span class="p_context"> static void sci_shutdown(struct uart_port *port)</span>
 	}
 #endif
 
<span class="p_del">-	sci_free_dma(port);</span>
 	sci_free_irq(s);
<span class="p_add">+	sci_free_dma(port);</span>
 }
 
 static int sci_sck_calc(struct sci_port *s, unsigned int bps,
<span class="p_header">diff --git a/drivers/usb/chipidea/debug.c b/drivers/usb/chipidea/debug.c</span>
<span class="p_header">index 6d23eede4d8c..1c31e8a08810 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/debug.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/debug.c</span>
<span class="p_chunk">@@ -294,7 +294,8 @@</span> <span class="p_context"> static int ci_role_show(struct seq_file *s, void *data)</span>
 {
 	struct ci_hdrc *ci = s-&gt;private;
 
<span class="p_del">-	seq_printf(s, &quot;%s\n&quot;, ci_role(ci)-&gt;name);</span>
<span class="p_add">+	if (ci-&gt;role != CI_ROLE_END)</span>
<span class="p_add">+		seq_printf(s, &quot;%s\n&quot;, ci_role(ci)-&gt;name);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/usb/chipidea/udc.c b/drivers/usb/chipidea/udc.c</span>
<span class="p_header">index c9e80ad48fdc..6a15b7250e9c 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/udc.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/udc.c</span>
<span class="p_chunk">@@ -1987,6 +1987,7 @@</span> <span class="p_context"> static void udc_id_switch_for_host(struct ci_hdrc *ci)</span>
 int ci_hdrc_gadget_init(struct ci_hdrc *ci)
 {
 	struct ci_role_driver *rdrv;
<span class="p_add">+	int ret;</span>
 
 	if (!hw_read(ci, CAP_DCCPARAMS, DCCPARAMS_DC))
 		return -ENXIO;
<span class="p_chunk">@@ -1999,7 +2000,10 @@</span> <span class="p_context"> int ci_hdrc_gadget_init(struct ci_hdrc *ci)</span>
 	rdrv-&gt;stop	= udc_id_switch_for_host;
 	rdrv-&gt;irq	= udc_irq;
 	rdrv-&gt;name	= &quot;gadget&quot;;
<span class="p_del">-	ci-&gt;roles[CI_ROLE_GADGET] = rdrv;</span>
 
<span class="p_del">-	return udc_start(ci);</span>
<span class="p_add">+	ret = udc_start(ci);</span>
<span class="p_add">+	if (!ret)</span>
<span class="p_add">+		ci-&gt;roles[CI_ROLE_GADGET] = rdrv;</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
<span class="p_header">diff --git a/drivers/usb/gadget/function/f_mass_storage.c b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">index 8f3659b65f53..ccd93c9e26ab 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_chunk">@@ -395,7 +395,11 @@</span> <span class="p_context"> static int fsg_set_halt(struct fsg_dev *fsg, struct usb_ep *ep)</span>
 /* Caller must hold fsg-&gt;lock */
 static void wakeup_thread(struct fsg_common *common)
 {
<span class="p_del">-	smp_wmb();	/* ensure the write of bh-&gt;state is complete */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure the reading of thread_wakeup_needed</span>
<span class="p_add">+	 * and the writing of bh-&gt;state are completed</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 	/* Tell the main thread that something has happened */
 	common-&gt;thread_wakeup_needed = 1;
 	if (common-&gt;thread_task)
<span class="p_chunk">@@ -626,7 +630,12 @@</span> <span class="p_context"> static int sleep_thread(struct fsg_common *common, bool can_freeze)</span>
 	}
 	__set_current_state(TASK_RUNNING);
 	common-&gt;thread_wakeup_needed = 0;
<span class="p_del">-	smp_rmb();	/* ensure the latest bh-&gt;state is visible */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure the writing of thread_wakeup_needed</span>
<span class="p_add">+	 * and the reading of bh-&gt;state are completed</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 	return rc;
 }
 
<span class="p_header">diff --git a/drivers/xen/privcmd.c b/drivers/xen/privcmd.c</span>
<span class="p_header">index 702040fe2001..0e6061496972 100644</span>
<span class="p_header">--- a/drivers/xen/privcmd.c</span>
<span class="p_header">+++ b/drivers/xen/privcmd.c</span>
<span class="p_chunk">@@ -335,8 +335,8 @@</span> <span class="p_context"> static int mmap_batch_fn(void *data, int nr, void *state)</span>
 				st-&gt;global_error = 1;
 		}
 	}
<span class="p_del">-	st-&gt;va += PAGE_SIZE * nr;</span>
<span class="p_del">-	st-&gt;index += nr;</span>
<span class="p_add">+	st-&gt;va += XEN_PAGE_SIZE * nr;</span>
<span class="p_add">+	st-&gt;index += nr / XEN_PFN_PER_PAGE;</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/fs/block_dev.c b/fs/block_dev.c</span>
<span class="p_header">index 2924bddb4a94..07e46b786500 100644</span>
<span class="p_header">--- a/fs/block_dev.c</span>
<span class="p_header">+++ b/fs/block_dev.c</span>
<span class="p_chunk">@@ -713,7 +713,7 @@</span> <span class="p_context"> struct block_device *bdget(dev_t dev)</span>
 		bdev-&gt;bd_contains = NULL;
 		bdev-&gt;bd_super = NULL;
 		bdev-&gt;bd_inode = inode;
<span class="p_del">-		bdev-&gt;bd_block_size = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+		bdev-&gt;bd_block_size = i_blocksize(inode);</span>
 		bdev-&gt;bd_part_count = 0;
 		bdev-&gt;bd_invalidated = 0;
 		inode-&gt;i_mode = S_IFBLK;
<span class="p_header">diff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c</span>
<span class="p_header">index 5909ae8c6731..e46e7fbe1b34 100644</span>
<span class="p_header">--- a/fs/btrfs/extent-tree.c</span>
<span class="p_header">+++ b/fs/btrfs/extent-tree.c</span>
<span class="p_chunk">@@ -3984,6 +3984,7 @@</span> <span class="p_context"> static int update_space_info(struct btrfs_fs_info *info, u64 flags,</span>
 				    info-&gt;space_info_kobj, &quot;%s&quot;,
 				    alloc_name(found-&gt;flags));
 	if (ret) {
<span class="p_add">+		percpu_counter_destroy(&amp;found-&gt;total_bytes_pinned);</span>
 		kfree(found);
 		return ret;
 	}
<span class="p_header">diff --git a/fs/btrfs/file.c b/fs/btrfs/file.c</span>
<span class="p_header">index 3a14c87d9c92..3286a6e47ff0 100644</span>
<span class="p_header">--- a/fs/btrfs/file.c</span>
<span class="p_header">+++ b/fs/btrfs/file.c</span>
<span class="p_chunk">@@ -2842,7 +2842,7 @@</span> <span class="p_context"> static long btrfs_fallocate(struct file *file, int mode,</span>
 		if (!ret)
 			ret = btrfs_prealloc_file_range(inode, mode,
 					range-&gt;start,
<span class="p_del">-					range-&gt;len, 1 &lt;&lt; inode-&gt;i_blkbits,</span>
<span class="p_add">+					range-&gt;len, i_blocksize(inode),</span>
 					offset + len, &amp;alloc_hint);
 		else
 			btrfs_free_reserved_data_space(inode, range-&gt;start,
<span class="p_header">diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c</span>
<span class="p_header">index be4da91d880f..bddbae796941 100644</span>
<span class="p_header">--- a/fs/btrfs/inode.c</span>
<span class="p_header">+++ b/fs/btrfs/inode.c</span>
<span class="p_chunk">@@ -7435,8 +7435,8 @@</span> <span class="p_context"> bool btrfs_page_exists_in_range(struct inode *inode, loff_t start, loff_t end)</span>
 	int found = false;
 	void **pagep = NULL;
 	struct page *page = NULL;
<span class="p_del">-	int start_idx;</span>
<span class="p_del">-	int end_idx;</span>
<span class="p_add">+	unsigned long start_idx;</span>
<span class="p_add">+	unsigned long end_idx;</span>
 
 	start_idx = start &gt;&gt; PAGE_SHIFT;
 
<span class="p_header">diff --git a/fs/buffer.c b/fs/buffer.c</span>
<span class="p_header">index b205a629001d..5d8f496d624e 100644</span>
<span class="p_header">--- a/fs/buffer.c</span>
<span class="p_header">+++ b/fs/buffer.c</span>
<span class="p_chunk">@@ -2353,7 +2353,7 @@</span> <span class="p_context"> static int cont_expand_zero(struct file *file, struct address_space *mapping,</span>
 			    loff_t pos, loff_t *bytes)
 {
 	struct inode *inode = mapping-&gt;host;
<span class="p_del">-	unsigned blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	unsigned int blocksize = i_blocksize(inode);</span>
 	struct page *page;
 	void *fsdata;
 	pgoff_t index, curidx;
<span class="p_chunk">@@ -2433,8 +2433,8 @@</span> <span class="p_context"> int cont_write_begin(struct file *file, struct address_space *mapping,</span>
 			get_block_t *get_block, loff_t *bytes)
 {
 	struct inode *inode = mapping-&gt;host;
<span class="p_del">-	unsigned blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_del">-	unsigned zerofrom;</span>
<span class="p_add">+	unsigned int blocksize = i_blocksize(inode);</span>
<span class="p_add">+	unsigned int zerofrom;</span>
 	int err;
 
 	err = cont_expand_zero(file, mapping, pos, bytes);
<span class="p_chunk">@@ -2796,7 +2796,7 @@</span> <span class="p_context"> int nobh_truncate_page(struct address_space *mapping,</span>
 	struct buffer_head map_bh;
 	int err;
 
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	length = offset &amp; (blocksize - 1);
 
 	/* Block boundary? Nothing to do */
<span class="p_chunk">@@ -2874,7 +2874,7 @@</span> <span class="p_context"> int block_truncate_page(struct address_space *mapping,</span>
 	struct buffer_head *bh;
 	int err;
 
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	length = offset &amp; (blocksize - 1);
 
 	/* Block boundary? Nothing to do */
<span class="p_chunk">@@ -2986,7 +2986,7 @@</span> <span class="p_context"> sector_t generic_block_bmap(struct address_space *mapping, sector_t block,</span>
 	struct inode *inode = mapping-&gt;host;
 	tmp.b_state = 0;
 	tmp.b_blocknr = 0;
<span class="p_del">-	tmp.b_size = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	tmp.b_size = i_blocksize(inode);</span>
 	get_block(inode, block, &amp;tmp, 0);
 	return tmp.b_blocknr;
 }
<span class="p_header">diff --git a/fs/ceph/addr.c b/fs/ceph/addr.c</span>
<span class="p_header">index 18dc18f8af2c..900ffafb85ca 100644</span>
<span class="p_header">--- a/fs/ceph/addr.c</span>
<span class="p_header">+++ b/fs/ceph/addr.c</span>
<span class="p_chunk">@@ -745,7 +745,7 @@</span> <span class="p_context"> static int ceph_writepages_start(struct address_space *mapping,</span>
 	struct pagevec pvec;
 	int done = 0;
 	int rc = 0;
<span class="p_del">-	unsigned wsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	unsigned int wsize = i_blocksize(inode);</span>
 	struct ceph_osd_request *req = NULL;
 	int do_sync = 0;
 	loff_t snap_size, i_size;
<span class="p_header">diff --git a/fs/direct-io.c b/fs/direct-io.c</span>
<span class="p_header">index fb9aa16a7727..c60756e89833 100644</span>
<span class="p_header">--- a/fs/direct-io.c</span>
<span class="p_header">+++ b/fs/direct-io.c</span>
<span class="p_chunk">@@ -587,7 +587,7 @@</span> <span class="p_context"> static int dio_set_defer_completion(struct dio *dio)</span>
 /*
  * Call into the fs to map some more disk blocks.  We record the current number
  * of available blocks at sdio-&gt;blocks_available.  These are in units of the
<span class="p_del">- * fs blocksize, (1 &lt;&lt; inode-&gt;i_blkbits).</span>
<span class="p_add">+ * fs blocksize, i_blocksize(inode).</span>
  *
  * The fs is allowed to map lots of blocks at once.  If it wants to do that,
  * it uses the passed inode-relative block number as the file offset, as usual.
<span class="p_header">diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c</span>
<span class="p_header">index 9fbf92ca358c..a3e0b3b7441d 100644</span>
<span class="p_header">--- a/fs/ext4/extents.c</span>
<span class="p_header">+++ b/fs/ext4/extents.c</span>
<span class="p_chunk">@@ -3413,13 +3413,13 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 	struct ext4_sb_info *sbi;
 	struct ext4_extent_header *eh;
 	struct ext4_map_blocks split_map;
<span class="p_del">-	struct ext4_extent zero_ex;</span>
<span class="p_add">+	struct ext4_extent zero_ex1, zero_ex2;</span>
 	struct ext4_extent *ex, *abut_ex;
 	ext4_lblk_t ee_block, eof_block;
 	unsigned int ee_len, depth, map_len = map-&gt;m_len;
 	int allocated = 0, max_zeroout = 0;
 	int err = 0;
<span class="p_del">-	int split_flag = 0;</span>
<span class="p_add">+	int split_flag = EXT4_EXT_DATA_VALID2;</span>
 
 	ext_debug(&quot;ext4_ext_convert_to_initialized: inode %lu, logical&quot;
 		&quot;block %llu, max_blocks %u\n&quot;, inode-&gt;i_ino,
<span class="p_chunk">@@ -3436,7 +3436,8 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 	ex = path[depth].p_ext;
 	ee_block = le32_to_cpu(ex-&gt;ee_block);
 	ee_len = ext4_ext_get_actual_len(ex);
<span class="p_del">-	zero_ex.ee_len = 0;</span>
<span class="p_add">+	zero_ex1.ee_len = 0;</span>
<span class="p_add">+	zero_ex2.ee_len = 0;</span>
 
 	trace_ext4_ext_convert_to_initialized_enter(inode, map, ex);
 
<span class="p_chunk">@@ -3576,62 +3577,52 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 	if (ext4_encrypted_inode(inode))
 		max_zeroout = 0;
 
<span class="p_del">-	/* If extent is less than s_max_zeroout_kb, zeroout directly */</span>
<span class="p_del">-	if (max_zeroout &amp;&amp; (ee_len &lt;= max_zeroout)) {</span>
<span class="p_del">-		err = ext4_ext_zeroout(inode, ex);</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		zero_ex.ee_block = ex-&gt;ee_block;</span>
<span class="p_del">-		zero_ex.ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex));</span>
<span class="p_del">-		ext4_ext_store_pblock(&amp;zero_ex, ext4_ext_pblock(ex));</span>
<span class="p_del">-</span>
<span class="p_del">-		err = ext4_ext_get_access(handle, inode, path + depth);</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		ext4_ext_mark_initialized(ex);</span>
<span class="p_del">-		ext4_ext_try_to_merge(handle, inode, path, ex);</span>
<span class="p_del">-		err = ext4_ext_dirty(handle, inode, path + path-&gt;p_depth);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	/*
<span class="p_del">-	 * four cases:</span>
<span class="p_add">+	 * five cases:</span>
 	 * 1. split the extent into three extents.
<span class="p_del">-	 * 2. split the extent into two extents, zeroout the first half.</span>
<span class="p_del">-	 * 3. split the extent into two extents, zeroout the second half.</span>
<span class="p_add">+	 * 2. split the extent into two extents, zeroout the head of the first</span>
<span class="p_add">+	 *    extent.</span>
<span class="p_add">+	 * 3. split the extent into two extents, zeroout the tail of the second</span>
<span class="p_add">+	 *    extent.</span>
 	 * 4. split the extent into two extents with out zeroout.
<span class="p_add">+	 * 5. no splitting needed, just possibly zeroout the head and / or the</span>
<span class="p_add">+	 *    tail of the extent.</span>
 	 */
 	split_map.m_lblk = map-&gt;m_lblk;
 	split_map.m_len = map-&gt;m_len;
 
<span class="p_del">-	if (max_zeroout &amp;&amp; (allocated &gt; map-&gt;m_len)) {</span>
<span class="p_add">+	if (max_zeroout &amp;&amp; (allocated &gt; split_map.m_len)) {</span>
 		if (allocated &lt;= max_zeroout) {
<span class="p_del">-			/* case 3 */</span>
<span class="p_del">-			zero_ex.ee_block =</span>
<span class="p_del">-					 cpu_to_le32(map-&gt;m_lblk);</span>
<span class="p_del">-			zero_ex.ee_len = cpu_to_le16(allocated);</span>
<span class="p_del">-			ext4_ext_store_pblock(&amp;zero_ex,</span>
<span class="p_del">-				ext4_ext_pblock(ex) + map-&gt;m_lblk - ee_block);</span>
<span class="p_del">-			err = ext4_ext_zeroout(inode, &amp;zero_ex);</span>
<span class="p_add">+			/* case 3 or 5 */</span>
<span class="p_add">+			zero_ex1.ee_block =</span>
<span class="p_add">+				 cpu_to_le32(split_map.m_lblk +</span>
<span class="p_add">+					     split_map.m_len);</span>
<span class="p_add">+			zero_ex1.ee_len =</span>
<span class="p_add">+				cpu_to_le16(allocated - split_map.m_len);</span>
<span class="p_add">+			ext4_ext_store_pblock(&amp;zero_ex1,</span>
<span class="p_add">+				ext4_ext_pblock(ex) + split_map.m_lblk +</span>
<span class="p_add">+				split_map.m_len - ee_block);</span>
<span class="p_add">+			err = ext4_ext_zeroout(inode, &amp;zero_ex1);</span>
 			if (err)
 				goto out;
<span class="p_del">-			split_map.m_lblk = map-&gt;m_lblk;</span>
 			split_map.m_len = allocated;
<span class="p_del">-		} else if (map-&gt;m_lblk - ee_block + map-&gt;m_len &lt; max_zeroout) {</span>
<span class="p_del">-			/* case 2 */</span>
<span class="p_del">-			if (map-&gt;m_lblk != ee_block) {</span>
<span class="p_del">-				zero_ex.ee_block = ex-&gt;ee_block;</span>
<span class="p_del">-				zero_ex.ee_len = cpu_to_le16(map-&gt;m_lblk -</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (split_map.m_lblk - ee_block + split_map.m_len &lt;</span>
<span class="p_add">+								max_zeroout) {</span>
<span class="p_add">+			/* case 2 or 5 */</span>
<span class="p_add">+			if (split_map.m_lblk != ee_block) {</span>
<span class="p_add">+				zero_ex2.ee_block = ex-&gt;ee_block;</span>
<span class="p_add">+				zero_ex2.ee_len = cpu_to_le16(split_map.m_lblk -</span>
 							ee_block);
<span class="p_del">-				ext4_ext_store_pblock(&amp;zero_ex,</span>
<span class="p_add">+				ext4_ext_store_pblock(&amp;zero_ex2,</span>
 						      ext4_ext_pblock(ex));
<span class="p_del">-				err = ext4_ext_zeroout(inode, &amp;zero_ex);</span>
<span class="p_add">+				err = ext4_ext_zeroout(inode, &amp;zero_ex2);</span>
 				if (err)
 					goto out;
 			}
 
<span class="p_add">+			split_map.m_len += split_map.m_lblk - ee_block;</span>
 			split_map.m_lblk = ee_block;
<span class="p_del">-			split_map.m_len = map-&gt;m_lblk - ee_block + map-&gt;m_len;</span>
 			allocated = map-&gt;m_len;
 		}
 	}
<span class="p_chunk">@@ -3642,8 +3633,11 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 		err = 0;
 out:
 	/* If we have gotten a failure, don&#39;t zero out status tree */
<span class="p_del">-	if (!err)</span>
<span class="p_del">-		err = ext4_zeroout_es(inode, &amp;zero_ex);</span>
<span class="p_add">+	if (!err) {</span>
<span class="p_add">+		err = ext4_zeroout_es(inode, &amp;zero_ex1);</span>
<span class="p_add">+		if (!err)</span>
<span class="p_add">+			err = ext4_zeroout_es(inode, &amp;zero_ex2);</span>
<span class="p_add">+	}</span>
 	return err ? err : allocated;
 }
 
<span class="p_chunk">@@ -4893,6 +4887,8 @@</span> <span class="p_context"> static long ext4_zero_range(struct file *file, loff_t offset,</span>
 
 	/* Zero out partial block at the edges of the range */
 	ret = ext4_zero_partial_blocks(handle, inode, offset, len);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 	if (file-&gt;f_flags &amp; O_SYNC)
 		ext4_handle_sync(handle);
<span class="p_chunk">@@ -5579,6 +5575,7 @@</span> <span class="p_context"> int ext4_collapse_range(struct inode *inode, loff_t offset, loff_t len)</span>
 		ext4_handle_sync(handle);
 	inode-&gt;i_mtime = inode-&gt;i_ctime = ext4_current_time(inode);
 	ext4_mark_inode_dirty(handle, inode);
<span class="p_add">+	ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 out_stop:
 	ext4_journal_stop(handle);
<span class="p_chunk">@@ -5752,6 +5749,8 @@</span> <span class="p_context"> int ext4_insert_range(struct inode *inode, loff_t offset, loff_t len)</span>
 	up_write(&amp;EXT4_I(inode)-&gt;i_data_sem);
 	if (IS_SYNC(inode))
 		ext4_handle_sync(handle);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 out_stop:
 	ext4_journal_stop(handle);
<span class="p_header">diff --git a/fs/ext4/file.c b/fs/ext4/file.c</span>
<span class="p_header">index 2a822d30e73f..9e77c089e8cb 100644</span>
<span class="p_header">--- a/fs/ext4/file.c</span>
<span class="p_header">+++ b/fs/ext4/file.c</span>
<span class="p_chunk">@@ -432,47 +432,27 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 		num = min_t(pgoff_t, end - index, PAGEVEC_SIZE);
 		nr_pages = pagevec_lookup(&amp;pvec, inode-&gt;i_mapping, index,
 					  (pgoff_t)num);
<span class="p_del">-		if (nr_pages == 0) {</span>
<span class="p_del">-			if (whence == SEEK_DATA)</span>
<span class="p_del">-				break;</span>
<span class="p_del">-</span>
<span class="p_del">-			BUG_ON(whence != SEEK_HOLE);</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * If this is the first time to go into the loop and</span>
<span class="p_del">-			 * offset is not beyond the end offset, it will be a</span>
<span class="p_del">-			 * hole at this offset</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (lastoff == startoff || lastoff &lt; endoff)</span>
<span class="p_del">-				found = 1;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * If this is the first time to go into the loop and</span>
<span class="p_del">-		 * offset is smaller than the first page offset, it will be a</span>
<span class="p_del">-		 * hole at this offset.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (lastoff == startoff &amp;&amp; whence == SEEK_HOLE &amp;&amp;</span>
<span class="p_del">-		    lastoff &lt; page_offset(pvec.pages[0])) {</span>
<span class="p_del">-			found = 1;</span>
<span class="p_add">+		if (nr_pages == 0)</span>
 			break;
<span class="p_del">-		}</span>
 
 		for (i = 0; i &lt; nr_pages; i++) {
 			struct page *page = pvec.pages[i];
 			struct buffer_head *bh, *head;
 
 			/*
<span class="p_del">-			 * If the current offset is not beyond the end of given</span>
<span class="p_del">-			 * range, it will be a hole.</span>
<span class="p_add">+			 * If current offset is smaller than the page offset,</span>
<span class="p_add">+			 * there is a hole at this offset.</span>
 			 */
<span class="p_del">-			if (lastoff &lt; endoff &amp;&amp; whence == SEEK_HOLE &amp;&amp;</span>
<span class="p_del">-			    page-&gt;index &gt; end) {</span>
<span class="p_add">+			if (whence == SEEK_HOLE &amp;&amp; lastoff &lt; endoff &amp;&amp;</span>
<span class="p_add">+			    lastoff &lt; page_offset(pvec.pages[i])) {</span>
 				found = 1;
 				*offset = lastoff;
 				goto out;
 			}
 
<span class="p_add">+			if (page-&gt;index &gt; end)</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+</span>
 			lock_page(page);
 
 			if (unlikely(page-&gt;mapping != inode-&gt;i_mapping)) {
<span class="p_chunk">@@ -512,20 +492,18 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 			unlock_page(page);
 		}
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * The no. of pages is less than our desired, that would be a</span>
<span class="p_del">-		 * hole in there.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (nr_pages &lt; num &amp;&amp; whence == SEEK_HOLE) {</span>
<span class="p_del">-			found = 1;</span>
<span class="p_del">-			*offset = lastoff;</span>
<span class="p_add">+		/* The no. of pages is less than our desired, we are done. */</span>
<span class="p_add">+		if (nr_pages &lt; num)</span>
 			break;
<span class="p_del">-		}</span>
 
 		index = pvec.pages[i - 1]-&gt;index + 1;
 		pagevec_release(&amp;pvec);
 	} while (index &lt;= end);
 
<span class="p_add">+	if (whence == SEEK_HOLE &amp;&amp; lastoff &lt; endoff) {</span>
<span class="p_add">+		found = 1;</span>
<span class="p_add">+		*offset = lastoff;</span>
<span class="p_add">+	}</span>
 out:
 	pagevec_release(&amp;pvec);
 	return found;
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index 01329688fb9e..1b29efcab3dc 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -2205,7 +2205,7 @@</span> <span class="p_context"> static int mpage_process_page_bufs(struct mpage_da_data *mpd,</span>
 {
 	struct inode *inode = mpd-&gt;inode;
 	int err;
<span class="p_del">-	ext4_lblk_t blocks = (i_size_read(inode) + (1 &lt;&lt; inode-&gt;i_blkbits) - 1)</span>
<span class="p_add">+	ext4_lblk_t blocks = (i_size_read(inode) + i_blocksize(inode) - 1)</span>
 							&gt;&gt; inode-&gt;i_blkbits;
 
 	do {
<span class="p_chunk">@@ -3454,14 +3454,14 @@</span> <span class="p_context"> static ssize_t ext4_direct_IO_write(struct kiocb *iocb, struct iov_iter *iter)</span>
 		 * writes need zeroing either because they can race with page
 		 * faults or because they use partial blocks.
 		 */
<span class="p_del">-		if (round_down(offset, 1&lt;&lt;inode-&gt;i_blkbits) &gt;= inode-&gt;i_size &amp;&amp;</span>
<span class="p_add">+		if (round_down(offset, i_blocksize(inode)) &gt;= inode-&gt;i_size &amp;&amp;</span>
 		    ext4_aligned_io(inode, offset, count))
 			get_block_func = ext4_dio_get_block;
 		else
 			get_block_func = ext4_dax_get_block;
 		dio_flags = DIO_LOCKING;
 	} else if (!ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS) ||
<span class="p_del">-		   round_down(offset, 1 &lt;&lt; inode-&gt;i_blkbits) &gt;= inode-&gt;i_size) {</span>
<span class="p_add">+		   round_down(offset, i_blocksize(inode)) &gt;= inode-&gt;i_size) {</span>
 		get_block_func = ext4_dio_get_block;
 		dio_flags = DIO_LOCKING | DIO_SKIP_HOLES;
 	} else if (is_sync_kiocb(iocb)) {
<span class="p_chunk">@@ -4044,6 +4044,8 @@</span> <span class="p_context"> int ext4_punch_hole(struct inode *inode, loff_t offset, loff_t length)</span>
 
 	inode-&gt;i_mtime = inode-&gt;i_ctime = ext4_current_time(inode);
 	ext4_mark_inode_dirty(handle, inode);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 out_stop:
 	ext4_journal_stop(handle);
 out_dio:
<span class="p_chunk">@@ -5046,7 +5048,7 @@</span> <span class="p_context"> static void ext4_wait_for_tail_page_commit(struct inode *inode)</span>
 	 * do. We do the check mainly to optimize the common PAGE_SIZE ==
 	 * blocksize case
 	 */
<span class="p_del">-	if (offset &gt; PAGE_SIZE - (1 &lt;&lt; inode-&gt;i_blkbits))</span>
<span class="p_add">+	if (offset &gt; PAGE_SIZE - i_blocksize(inode))</span>
 		return;
 	while (1) {
 		page = find_lock_page(inode-&gt;i_mapping,
<span class="p_chunk">@@ -5441,8 +5443,9 @@</span> <span class="p_context"> static int ext4_expand_extra_isize(struct inode *inode,</span>
 	/* No extended attributes present */
 	if (!ext4_test_inode_state(inode, EXT4_STATE_XATTR) ||
 	    header-&gt;h_magic != cpu_to_le32(EXT4_XATTR_MAGIC)) {
<span class="p_del">-		memset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE, 0,</span>
<span class="p_del">-			new_extra_isize);</span>
<span class="p_add">+		memset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE +</span>
<span class="p_add">+		       EXT4_I(inode)-&gt;i_extra_isize, 0,</span>
<span class="p_add">+		       new_extra_isize - EXT4_I(inode)-&gt;i_extra_isize);</span>
 		EXT4_I(inode)-&gt;i_extra_isize = new_extra_isize;
 		return 0;
 	}
<span class="p_header">diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c</span>
<span class="p_header">index 2e9fc7a61048..846b57ff58de 100644</span>
<span class="p_header">--- a/fs/ext4/mballoc.c</span>
<span class="p_header">+++ b/fs/ext4/mballoc.c</span>
<span class="p_chunk">@@ -838,7 +838,7 @@</span> <span class="p_context"> static int ext4_mb_init_cache(struct page *page, char *incore, gfp_t gfp)</span>
 	inode = page-&gt;mapping-&gt;host;
 	sb = inode-&gt;i_sb;
 	ngroups = ext4_get_groups_count(sb);
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	blocks_per_page = PAGE_SIZE / blocksize;
 
 	groups_per_page = blocks_per_page &gt;&gt; 1;
<span class="p_header">diff --git a/fs/ext4/move_extent.c b/fs/ext4/move_extent.c</span>
<span class="p_header">index 6fc14def0c70..578f8c33fb44 100644</span>
<span class="p_header">--- a/fs/ext4/move_extent.c</span>
<span class="p_header">+++ b/fs/ext4/move_extent.c</span>
<span class="p_chunk">@@ -187,7 +187,7 @@</span> <span class="p_context"> mext_page_mkuptodate(struct page *page, unsigned from, unsigned to)</span>
 	if (PageUptodate(page))
 		return 0;
 
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	if (!page_has_buffers(page))
 		create_empty_buffers(page, blocksize, 0);
 
<span class="p_header">diff --git a/fs/iomap.c b/fs/iomap.c</span>
<span class="p_header">index 814ae8f9587d..798c291cbc75 100644</span>
<span class="p_header">--- a/fs/iomap.c</span>
<span class="p_header">+++ b/fs/iomap.c</span>
<span class="p_chunk">@@ -419,8 +419,8 @@</span> <span class="p_context"> int</span>
 iomap_truncate_page(struct inode *inode, loff_t pos, bool *did_zero,
 		struct iomap_ops *ops)
 {
<span class="p_del">-	unsigned blocksize = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_del">-	unsigned off = pos &amp; (blocksize - 1);</span>
<span class="p_add">+	unsigned int blocksize = i_blocksize(inode);</span>
<span class="p_add">+	unsigned int off = pos &amp; (blocksize - 1);</span>
 
 	/* Block boundary? Nothing to do */
 	if (!off)
<span class="p_header">diff --git a/fs/jfs/super.c b/fs/jfs/super.c</span>
<span class="p_header">index 85671f7f8518..14be95bc0bcd 100644</span>
<span class="p_header">--- a/fs/jfs/super.c</span>
<span class="p_header">+++ b/fs/jfs/super.c</span>
<span class="p_chunk">@@ -758,7 +758,7 @@</span> <span class="p_context"> static ssize_t jfs_quota_read(struct super_block *sb, int type, char *data,</span>
 				sb-&gt;s_blocksize - offset : toread;
 
 		tmp_bh.b_state = 0;
<span class="p_del">-		tmp_bh.b_size = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+		tmp_bh.b_size = i_blocksize(inode);</span>
 		err = jfs_get_block(inode, blk, &amp;tmp_bh, 0);
 		if (err)
 			return err;
<span class="p_chunk">@@ -798,7 +798,7 @@</span> <span class="p_context"> static ssize_t jfs_quota_write(struct super_block *sb, int type,</span>
 				sb-&gt;s_blocksize - offset : towrite;
 
 		tmp_bh.b_state = 0;
<span class="p_del">-		tmp_bh.b_size = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+		tmp_bh.b_size = i_blocksize(inode);</span>
 		err = jfs_get_block(inode, blk, &amp;tmp_bh, 1);
 		if (err)
 			goto out;
<span class="p_header">diff --git a/fs/mpage.c b/fs/mpage.c</span>
<span class="p_header">index d2413af0823a..d2fcb149720d 100644</span>
<span class="p_header">--- a/fs/mpage.c</span>
<span class="p_header">+++ b/fs/mpage.c</span>
<span class="p_chunk">@@ -115,7 +115,7 @@</span> <span class="p_context"> map_buffer_to_page(struct page *page, struct buffer_head *bh, int page_block)</span>
 			SetPageUptodate(page);    
 			return;
 		}
<span class="p_del">-		create_empty_buffers(page, 1 &lt;&lt; inode-&gt;i_blkbits, 0);</span>
<span class="p_add">+		create_empty_buffers(page, i_blocksize(inode), 0);</span>
 	}
 	head = page_buffers(page);
 	page_bh = head;
<span class="p_header">diff --git a/fs/nfsd/blocklayout.c b/fs/nfsd/blocklayout.c</span>
<span class="p_header">index 0780ff864539..3e396dbb1eb9 100644</span>
<span class="p_header">--- a/fs/nfsd/blocklayout.c</span>
<span class="p_header">+++ b/fs/nfsd/blocklayout.c</span>
<span class="p_chunk">@@ -23,7 +23,7 @@</span> <span class="p_context"> nfsd4_block_proc_layoutget(struct inode *inode, const struct svc_fh *fhp,</span>
 {
 	struct nfsd4_layout_seg *seg = &amp;args-&gt;lg_seg;
 	struct super_block *sb = inode-&gt;i_sb;
<span class="p_del">-	u32 block_size = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	u32 block_size = i_blocksize(inode);</span>
 	struct pnfs_block_extent *bex;
 	struct iomap iomap;
 	u32 device_generation = 0;
<span class="p_chunk">@@ -180,7 +180,7 @@</span> <span class="p_context"> nfsd4_block_proc_layoutcommit(struct inode *inode,</span>
 	int nr_iomaps;
 
 	nr_iomaps = nfsd4_block_decode_layoutupdate(lcp-&gt;lc_up_layout,
<span class="p_del">-			lcp-&gt;lc_up_len, &amp;iomaps, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+			lcp-&gt;lc_up_len, &amp;iomaps, i_blocksize(inode));</span>
 	if (nr_iomaps &lt; 0)
 		return nfserrno(nr_iomaps);
 
<span class="p_chunk">@@ -372,7 +372,7 @@</span> <span class="p_context"> nfsd4_scsi_proc_layoutcommit(struct inode *inode,</span>
 	int nr_iomaps;
 
 	nr_iomaps = nfsd4_scsi_decode_layoutupdate(lcp-&gt;lc_up_layout,
<span class="p_del">-			lcp-&gt;lc_up_len, &amp;iomaps, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+			lcp-&gt;lc_up_len, &amp;iomaps, i_blocksize(inode));</span>
 	if (nr_iomaps &lt; 0)
 		return nfserrno(nr_iomaps);
 
<span class="p_header">diff --git a/fs/nfsd/nfs4proc.c b/fs/nfsd/nfs4proc.c</span>
<span class="p_header">index 650226f33298..022d95886d66 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4proc.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4proc.c</span>
<span class="p_chunk">@@ -1783,6 +1783,12 @@</span> <span class="p_context"> nfsd4_proc_compound(struct svc_rqst *rqstp,</span>
 			opdesc-&gt;op_get_currentstateid(cstate, &amp;op-&gt;u);
 		op-&gt;status = opdesc-&gt;op_func(rqstp, cstate, &amp;op-&gt;u);
 
<span class="p_add">+		/* Only from SEQUENCE */</span>
<span class="p_add">+		if (cstate-&gt;status == nfserr_replay_cache) {</span>
<span class="p_add">+			dprintk(&quot;%s NFS4.1 replay from cache\n&quot;, __func__);</span>
<span class="p_add">+			status = op-&gt;status;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
 		if (!op-&gt;status) {
 			if (opdesc-&gt;op_set_currentstateid)
 				opdesc-&gt;op_set_currentstateid(cstate, &amp;op-&gt;u);
<span class="p_chunk">@@ -1793,14 +1799,7 @@</span> <span class="p_context"> nfsd4_proc_compound(struct svc_rqst *rqstp,</span>
 			if (need_wrongsec_check(rqstp))
 				op-&gt;status = check_nfsd_access(current_fh-&gt;fh_export, rqstp);
 		}
<span class="p_del">-</span>
 encode_op:
<span class="p_del">-		/* Only from SEQUENCE */</span>
<span class="p_del">-		if (cstate-&gt;status == nfserr_replay_cache) {</span>
<span class="p_del">-			dprintk(&quot;%s NFS4.1 replay from cache\n&quot;, __func__);</span>
<span class="p_del">-			status = op-&gt;status;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
 		if (op-&gt;status == nfserr_replay_me) {
 			op-&gt;replay = &amp;cstate-&gt;replay_owner-&gt;so_replay;
 			nfsd4_encode_replay(&amp;resp-&gt;xdr, op);
<span class="p_header">diff --git a/fs/nfsd/nfs4xdr.c b/fs/nfsd/nfs4xdr.c</span>
<span class="p_header">index 2ee80e1f5230..4e7a56a0a9b6 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4xdr.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4xdr.c</span>
<span class="p_chunk">@@ -2793,9 +2793,16 @@</span> <span class="p_context"> nfsd4_encode_fattr(struct xdr_stream *xdr, struct svc_fh *fhp,</span>
 	}
 #endif /* CONFIG_NFSD_PNFS */
 	if (bmval2 &amp; FATTR4_WORD2_SUPPATTR_EXCLCREAT) {
<span class="p_del">-		status = nfsd4_encode_bitmap(xdr, NFSD_SUPPATTR_EXCLCREAT_WORD0,</span>
<span class="p_del">-						  NFSD_SUPPATTR_EXCLCREAT_WORD1,</span>
<span class="p_del">-						  NFSD_SUPPATTR_EXCLCREAT_WORD2);</span>
<span class="p_add">+		u32 supp[3];</span>
<span class="p_add">+</span>
<span class="p_add">+		supp[0] = nfsd_suppattrs0(minorversion);</span>
<span class="p_add">+		supp[1] = nfsd_suppattrs1(minorversion);</span>
<span class="p_add">+		supp[2] = nfsd_suppattrs2(minorversion);</span>
<span class="p_add">+		supp[0] &amp;= NFSD_SUPPATTR_EXCLCREAT_WORD0;</span>
<span class="p_add">+		supp[1] &amp;= NFSD_SUPPATTR_EXCLCREAT_WORD1;</span>
<span class="p_add">+		supp[2] &amp;= NFSD_SUPPATTR_EXCLCREAT_WORD2;</span>
<span class="p_add">+</span>
<span class="p_add">+		status = nfsd4_encode_bitmap(xdr, supp[0], supp[1], supp[2]);</span>
 		if (status)
 			goto out;
 	}
<span class="p_header">diff --git a/fs/nilfs2/btnode.c b/fs/nilfs2/btnode.c</span>
<span class="p_header">index d5c23da43513..c21e0b4454a6 100644</span>
<span class="p_header">--- a/fs/nilfs2/btnode.c</span>
<span class="p_header">+++ b/fs/nilfs2/btnode.c</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> nilfs_btnode_create_block(struct address_space *btnc, __u64 blocknr)</span>
 		brelse(bh);
 		BUG();
 	}
<span class="p_del">-	memset(bh-&gt;b_data, 0, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	memset(bh-&gt;b_data, 0, i_blocksize(inode));</span>
 	bh-&gt;b_bdev = inode-&gt;i_sb-&gt;s_bdev;
 	bh-&gt;b_blocknr = blocknr;
 	set_buffer_mapped(bh);
<span class="p_header">diff --git a/fs/nilfs2/inode.c b/fs/nilfs2/inode.c</span>
<span class="p_header">index c7f4fef9ebf5..7ffe71a8dfb9 100644</span>
<span class="p_header">--- a/fs/nilfs2/inode.c</span>
<span class="p_header">+++ b/fs/nilfs2/inode.c</span>
<span class="p_chunk">@@ -51,7 +51,7 @@</span> <span class="p_context"> void nilfs_inode_add_blocks(struct inode *inode, int n)</span>
 {
 	struct nilfs_root *root = NILFS_I(inode)-&gt;i_root;
 
<span class="p_del">-	inode_add_bytes(inode, (1 &lt;&lt; inode-&gt;i_blkbits) * n);</span>
<span class="p_add">+	inode_add_bytes(inode, i_blocksize(inode) * n);</span>
 	if (root)
 		atomic64_add(n, &amp;root-&gt;blocks_count);
 }
<span class="p_chunk">@@ -60,7 +60,7 @@</span> <span class="p_context"> void nilfs_inode_sub_blocks(struct inode *inode, int n)</span>
 {
 	struct nilfs_root *root = NILFS_I(inode)-&gt;i_root;
 
<span class="p_del">-	inode_sub_bytes(inode, (1 &lt;&lt; inode-&gt;i_blkbits) * n);</span>
<span class="p_add">+	inode_sub_bytes(inode, i_blocksize(inode) * n);</span>
 	if (root)
 		atomic64_sub(n, &amp;root-&gt;blocks_count);
 }
<span class="p_header">diff --git a/fs/nilfs2/mdt.c b/fs/nilfs2/mdt.c</span>
<span class="p_header">index d56d3a5bea88..98835ed6bef4 100644</span>
<span class="p_header">--- a/fs/nilfs2/mdt.c</span>
<span class="p_header">+++ b/fs/nilfs2/mdt.c</span>
<span class="p_chunk">@@ -57,7 +57,7 @@</span> <span class="p_context"> nilfs_mdt_insert_new_block(struct inode *inode, unsigned long block,</span>
 	set_buffer_mapped(bh);
 
 	kaddr = kmap_atomic(bh-&gt;b_page);
<span class="p_del">-	memset(kaddr + bh_offset(bh), 0, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	memset(kaddr + bh_offset(bh), 0, i_blocksize(inode));</span>
 	if (init_block)
 		init_block(inode, bh, kaddr);
 	flush_dcache_page(bh-&gt;b_page);
<span class="p_chunk">@@ -501,7 +501,7 @@</span> <span class="p_context"> void nilfs_mdt_set_entry_size(struct inode *inode, unsigned int entry_size,</span>
 	struct nilfs_mdt_info *mi = NILFS_MDT(inode);
 
 	mi-&gt;mi_entry_size = entry_size;
<span class="p_del">-	mi-&gt;mi_entries_per_block = (1 &lt;&lt; inode-&gt;i_blkbits) / entry_size;</span>
<span class="p_add">+	mi-&gt;mi_entries_per_block = i_blocksize(inode) / entry_size;</span>
 	mi-&gt;mi_first_entry_offset = DIV_ROUND_UP(header_size, entry_size);
 }
 
<span class="p_header">diff --git a/fs/nilfs2/segment.c b/fs/nilfs2/segment.c</span>
<span class="p_header">index bedcae2c28e6..7d18d62e8e07 100644</span>
<span class="p_header">--- a/fs/nilfs2/segment.c</span>
<span class="p_header">+++ b/fs/nilfs2/segment.c</span>
<span class="p_chunk">@@ -723,7 +723,7 @@</span> <span class="p_context"> static size_t nilfs_lookup_dirty_data_buffers(struct inode *inode,</span>
 
 		lock_page(page);
 		if (!page_has_buffers(page))
<span class="p_del">-			create_empty_buffers(page, 1 &lt;&lt; inode-&gt;i_blkbits, 0);</span>
<span class="p_add">+			create_empty_buffers(page, i_blocksize(inode), 0);</span>
 		unlock_page(page);
 
 		bh = head = page_buffers(page);
<span class="p_header">diff --git a/fs/ocfs2/aops.c b/fs/ocfs2/aops.c</span>
<span class="p_header">index c5c5b9748ea3..f2961b13e8c5 100644</span>
<span class="p_header">--- a/fs/ocfs2/aops.c</span>
<span class="p_header">+++ b/fs/ocfs2/aops.c</span>
<span class="p_chunk">@@ -599,7 +599,7 @@</span> <span class="p_context"> int ocfs2_map_page_blocks(struct page *page, u64 *p_blkno,</span>
 	int ret = 0;
 	struct buffer_head *head, *bh, *wait[2], **wait_bh = wait;
 	unsigned int block_end, block_start;
<span class="p_del">-	unsigned int bsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	unsigned int bsize = i_blocksize(inode);</span>
 
 	if (!page_has_buffers(page))
 		create_empty_buffers(page, bsize, 0);
<span class="p_header">diff --git a/fs/ocfs2/file.c b/fs/ocfs2/file.c</span>
<span class="p_header">index 000c234d7bbd..0db6f83fdea1 100644</span>
<span class="p_header">--- a/fs/ocfs2/file.c</span>
<span class="p_header">+++ b/fs/ocfs2/file.c</span>
<span class="p_chunk">@@ -808,7 +808,7 @@</span> <span class="p_context"> static int ocfs2_write_zero_page(struct inode *inode, u64 abs_from,</span>
 	/* We know that zero_from is block aligned */
 	for (block_start = zero_from; block_start &lt; zero_to;
 	     block_start = block_end) {
<span class="p_del">-		block_end = block_start + (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+		block_end = block_start + i_blocksize(inode);</span>
 
 		/*
 		 * block_start is block-aligned.  Bump it by one to force
<span class="p_header">diff --git a/fs/orangefs/orangefs-utils.c b/fs/orangefs/orangefs-utils.c</span>
<span class="p_header">index 06af81f71e10..9b96b99539d6 100644</span>
<span class="p_header">--- a/fs/orangefs/orangefs-utils.c</span>
<span class="p_header">+++ b/fs/orangefs/orangefs-utils.c</span>
<span class="p_chunk">@@ -306,7 +306,7 @@</span> <span class="p_context"> int orangefs_inode_getattr(struct inode *inode, int new, int bypass)</span>
 		break;
 	case S_IFDIR:
 		inode-&gt;i_size = PAGE_SIZE;
<span class="p_del">-		orangefs_inode-&gt;blksize = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+		orangefs_inode-&gt;blksize = i_blocksize(inode);</span>
 		spin_lock(&amp;inode-&gt;i_lock);
 		inode_set_bytes(inode, inode-&gt;i_size);
 		spin_unlock(&amp;inode-&gt;i_lock);
<span class="p_chunk">@@ -316,7 +316,7 @@</span> <span class="p_context"> int orangefs_inode_getattr(struct inode *inode, int new, int bypass)</span>
 		if (new) {
 			inode-&gt;i_size = (loff_t)strlen(new_op-&gt;
 			    downcall.resp.getattr.link_target);
<span class="p_del">-			orangefs_inode-&gt;blksize = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+			orangefs_inode-&gt;blksize = i_blocksize(inode);</span>
 			ret = strscpy(orangefs_inode-&gt;link_target,
 			    new_op-&gt;downcall.resp.getattr.link_target,
 			    ORANGEFS_NAME_MAX);
<span class="p_header">diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c</span>
<span class="p_header">index 2f8c5c9bdaf6..b396eb09f288 100644</span>
<span class="p_header">--- a/fs/reiserfs/file.c</span>
<span class="p_header">+++ b/fs/reiserfs/file.c</span>
<span class="p_chunk">@@ -189,7 +189,7 @@</span> <span class="p_context"> int reiserfs_commit_page(struct inode *inode, struct page *page,</span>
 	int ret = 0;
 
 	th.t_trans_id = 0;
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 
 	if (logit) {
 		reiserfs_write_lock(s);
<span class="p_header">diff --git a/fs/reiserfs/inode.c b/fs/reiserfs/inode.c</span>
<span class="p_header">index 58b2dedb2a3a..bd4c727f4610 100644</span>
<span class="p_header">--- a/fs/reiserfs/inode.c</span>
<span class="p_header">+++ b/fs/reiserfs/inode.c</span>
<span class="p_chunk">@@ -524,7 +524,7 @@</span> <span class="p_context"> static int reiserfs_get_blocks_direct_io(struct inode *inode,</span>
 	 * referenced in convert_tail_for_hole() that may be called from
 	 * reiserfs_get_block()
 	 */
<span class="p_del">-	bh_result-&gt;b_size = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	bh_result-&gt;b_size = i_blocksize(inode);</span>
 
 	ret = reiserfs_get_block(inode, iblock, bh_result,
 				 create | GET_BLOCK_NO_DANGLE);
<span class="p_header">diff --git a/fs/stat.c b/fs/stat.c</span>
<span class="p_header">index bc045c7994e1..068fdbcc9e26 100644</span>
<span class="p_header">--- a/fs/stat.c</span>
<span class="p_header">+++ b/fs/stat.c</span>
<span class="p_chunk">@@ -31,7 +31,7 @@</span> <span class="p_context"> void generic_fillattr(struct inode *inode, struct kstat *stat)</span>
 	stat-&gt;atime = inode-&gt;i_atime;
 	stat-&gt;mtime = inode-&gt;i_mtime;
 	stat-&gt;ctime = inode-&gt;i_ctime;
<span class="p_del">-	stat-&gt;blksize = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	stat-&gt;blksize = i_blocksize(inode);</span>
 	stat-&gt;blocks = inode-&gt;i_blocks;
 }
 
<span class="p_chunk">@@ -454,6 +454,7 @@</span> <span class="p_context"> void __inode_add_bytes(struct inode *inode, loff_t bytes)</span>
 		inode-&gt;i_bytes -= 512;
 	}
 }
<span class="p_add">+EXPORT_SYMBOL(__inode_add_bytes);</span>
 
 void inode_add_bytes(struct inode *inode, loff_t bytes)
 {
<span class="p_header">diff --git a/fs/udf/inode.c b/fs/udf/inode.c</span>
<span class="p_header">index aad46401ede5..129b18a29c8f 100644</span>
<span class="p_header">--- a/fs/udf/inode.c</span>
<span class="p_header">+++ b/fs/udf/inode.c</span>
<span class="p_chunk">@@ -1214,7 +1214,7 @@</span> <span class="p_context"> int udf_setsize(struct inode *inode, loff_t newsize)</span>
 {
 	int err;
 	struct udf_inode_info *iinfo;
<span class="p_del">-	int bsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	int bsize = i_blocksize(inode);</span>
 
 	if (!(S_ISREG(inode-&gt;i_mode) || S_ISDIR(inode-&gt;i_mode) ||
 	      S_ISLNK(inode-&gt;i_mode)))
<span class="p_header">diff --git a/fs/ufs/balloc.c b/fs/ufs/balloc.c</span>
<span class="p_header">index 67e085d591d8..a81b97013021 100644</span>
<span class="p_header">--- a/fs/ufs/balloc.c</span>
<span class="p_header">+++ b/fs/ufs/balloc.c</span>
<span class="p_chunk">@@ -81,7 +81,8 @@</span> <span class="p_context"> void ufs_free_fragments(struct inode *inode, u64 fragment, unsigned count)</span>
 			ufs_error (sb, &quot;ufs_free_fragments&quot;,
 				   &quot;bit already cleared for fragment %u&quot;, i);
 	}
<span class="p_del">-	</span>
<span class="p_add">+</span>
<span class="p_add">+	inode_sub_bytes(inode, count &lt;&lt; uspi-&gt;s_fshift);</span>
 	fs32_add(sb, &amp;ucg-&gt;cg_cs.cs_nffree, count);
 	uspi-&gt;cs_total.cs_nffree += count;
 	fs32_add(sb, &amp;UFS_SB(sb)-&gt;fs_cs(cgno).cs_nffree, count);
<span class="p_chunk">@@ -183,6 +184,7 @@</span> <span class="p_context"> void ufs_free_blocks(struct inode *inode, u64 fragment, unsigned count)</span>
 			ufs_error(sb, &quot;ufs_free_blocks&quot;, &quot;freeing free fragment&quot;);
 		}
 		ubh_setblock(UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, blkno);
<span class="p_add">+		inode_sub_bytes(inode, uspi-&gt;s_fpb &lt;&lt; uspi-&gt;s_fshift);</span>
 		if ((UFS_SB(sb)-&gt;s_flags &amp; UFS_CG_MASK) == UFS_CG_44BSD)
 			ufs_clusteracct (sb, ucpi, blkno, 1);
 
<span class="p_chunk">@@ -494,6 +496,20 @@</span> <span class="p_context"> u64 ufs_new_fragments(struct inode *inode, void *p, u64 fragment,</span>
 	return 0;
 }		
 
<span class="p_add">+static bool try_add_frags(struct inode *inode, unsigned frags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned size = frags * i_blocksize(inode);</span>
<span class="p_add">+	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	__inode_add_bytes(inode, size);</span>
<span class="p_add">+	if (unlikely((u32)inode-&gt;i_blocks != inode-&gt;i_blocks)) {</span>
<span class="p_add">+		__inode_sub_bytes(inode, size);</span>
<span class="p_add">+		spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static u64 ufs_add_fragments(struct inode *inode, u64 fragment,
 			     unsigned oldcount, unsigned newcount)
 {
<span class="p_chunk">@@ -530,6 +546,9 @@</span> <span class="p_context"> static u64 ufs_add_fragments(struct inode *inode, u64 fragment,</span>
 	for (i = oldcount; i &lt; newcount; i++)
 		if (ubh_isclr (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, fragno + i))
 			return 0;
<span class="p_add">+</span>
<span class="p_add">+	if (!try_add_frags(inode, count))</span>
<span class="p_add">+		return 0;</span>
 	/*
 	 * Block can be extended
 	 */
<span class="p_chunk">@@ -647,6 +666,7 @@</span> <span class="p_context"> static u64 ufs_alloc_fragments(struct inode *inode, unsigned cgno,</span>
 			ubh_setbit (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, goal + i);
 		i = uspi-&gt;s_fpb - count;
 
<span class="p_add">+		inode_sub_bytes(inode, i &lt;&lt; uspi-&gt;s_fshift);</span>
 		fs32_add(sb, &amp;ucg-&gt;cg_cs.cs_nffree, i);
 		uspi-&gt;cs_total.cs_nffree += i;
 		fs32_add(sb, &amp;UFS_SB(sb)-&gt;fs_cs(cgno).cs_nffree, i);
<span class="p_chunk">@@ -657,6 +677,8 @@</span> <span class="p_context"> static u64 ufs_alloc_fragments(struct inode *inode, unsigned cgno,</span>
 	result = ufs_bitmap_search (sb, ucpi, goal, allocsize);
 	if (result == INVBLOCK)
 		return 0;
<span class="p_add">+	if (!try_add_frags(inode, count))</span>
<span class="p_add">+		return 0;</span>
 	for (i = 0; i &lt; count; i++)
 		ubh_clrbit (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, result + i);
 	
<span class="p_chunk">@@ -716,6 +738,8 @@</span> <span class="p_context"> static u64 ufs_alloccg_block(struct inode *inode,</span>
 		return INVBLOCK;
 	ucpi-&gt;c_rotor = result;
 gotit:
<span class="p_add">+	if (!try_add_frags(inode, uspi-&gt;s_fpb))</span>
<span class="p_add">+		return 0;</span>
 	blkno = ufs_fragstoblks(result);
 	ubh_clrblock (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, blkno);
 	if ((UFS_SB(sb)-&gt;s_flags &amp; UFS_CG_MASK) == UFS_CG_44BSD)
<span class="p_header">diff --git a/fs/ufs/inode.c b/fs/ufs/inode.c</span>
<span class="p_header">index 190d64be22ed..a2760a2869f4 100644</span>
<span class="p_header">--- a/fs/ufs/inode.c</span>
<span class="p_header">+++ b/fs/ufs/inode.c</span>
<span class="p_chunk">@@ -235,7 +235,8 @@</span> <span class="p_context"> ufs_extend_tail(struct inode *inode, u64 writes_to,</span>
 
 	p = ufs_get_direct_data_ptr(uspi, ufsi, block);
 	tmp = ufs_new_fragments(inode, p, lastfrag, ufs_data_ptr_to_cpu(sb, p),
<span class="p_del">-				new_size, err, locked_page);</span>
<span class="p_add">+				new_size - (lastfrag &amp; uspi-&gt;s_fpbmask), err,</span>
<span class="p_add">+				locked_page);</span>
 	return tmp != 0;
 }
 
<span class="p_chunk">@@ -284,7 +285,7 @@</span> <span class="p_context"> ufs_inode_getfrag(struct inode *inode, unsigned index,</span>
 			goal += uspi-&gt;s_fpb;
 	}
 	tmp = ufs_new_fragments(inode, p, ufs_blknum(new_fragment),
<span class="p_del">-				goal, uspi-&gt;s_fpb, err, locked_page);</span>
<span class="p_add">+				goal, nfrags, err, locked_page);</span>
 
 	if (!tmp) {
 		*err = -ENOSPC;
<span class="p_chunk">@@ -402,7 +403,9 @@</span> <span class="p_context"> static int ufs_getfrag_block(struct inode *inode, sector_t fragment, struct buff</span>
 
 	if (!create) {
 		phys64 = ufs_frag_map(inode, offsets, depth);
<span class="p_del">-		goto out;</span>
<span class="p_add">+		if (phys64)</span>
<span class="p_add">+			map_bh(bh_result, sb, phys64 + frag);</span>
<span class="p_add">+		return 0;</span>
 	}
 
         /* This code entered only while writing ....? */
<span class="p_header">diff --git a/fs/ufs/super.c b/fs/ufs/super.c</span>
<span class="p_header">index f3469ad0fef2..351162ff1bfd 100644</span>
<span class="p_header">--- a/fs/ufs/super.c</span>
<span class="p_header">+++ b/fs/ufs/super.c</span>
<span class="p_chunk">@@ -746,6 +746,23 @@</span> <span class="p_context"> static void ufs_put_super(struct super_block *sb)</span>
 	return;
 }
 
<span class="p_add">+static u64 ufs_max_bytes(struct super_block *sb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ufs_sb_private_info *uspi = UFS_SB(sb)-&gt;s_uspi;</span>
<span class="p_add">+	int bits = uspi-&gt;s_apbshift;</span>
<span class="p_add">+	u64 res;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (bits &gt; 21)</span>
<span class="p_add">+		res = ~0ULL;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		res = UFS_NDADDR + (1LL &lt;&lt; bits) + (1LL &lt;&lt; (2*bits)) +</span>
<span class="p_add">+			(1LL &lt;&lt; (3*bits));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (res &gt;= (MAX_LFS_FILESIZE &gt;&gt; uspi-&gt;s_bshift))</span>
<span class="p_add">+		return MAX_LFS_FILESIZE;</span>
<span class="p_add">+	return res &lt;&lt; uspi-&gt;s_bshift;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int ufs_fill_super(struct super_block *sb, void *data, int silent)
 {
 	struct ufs_sb_info * sbi;
<span class="p_chunk">@@ -1211,6 +1228,7 @@</span> <span class="p_context"> static int ufs_fill_super(struct super_block *sb, void *data, int silent)</span>
 			    &quot;fast symlink size (%u)\n&quot;, uspi-&gt;s_maxsymlinklen);
 		uspi-&gt;s_maxsymlinklen = maxsymlen;
 	}
<span class="p_add">+	sb-&gt;s_maxbytes = ufs_max_bytes(sb);</span>
 	sb-&gt;s_max_links = UFS_LINK_MAX;
 
 	inode = ufs_iget(sb, UFS_ROOTINO);
<span class="p_header">diff --git a/fs/ufs/util.h b/fs/ufs/util.h</span>
<span class="p_header">index b7fbf53dbc81..398019fb1448 100644</span>
<span class="p_header">--- a/fs/ufs/util.h</span>
<span class="p_header">+++ b/fs/ufs/util.h</span>
<span class="p_chunk">@@ -473,15 +473,19 @@</span> <span class="p_context"> static inline unsigned _ubh_find_last_zero_bit_(</span>
 static inline int _ubh_isblockset_(struct ufs_sb_private_info * uspi,
 	struct ufs_buffer_head * ubh, unsigned begin, unsigned block)
 {
<span class="p_add">+	u8 mask;</span>
 	switch (uspi-&gt;s_fpb) {
 	case 8:
 	    	return (*ubh_get_addr (ubh, begin + block) == 0xff);
 	case 4:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 1)) == (0x0f &lt;&lt; ((block &amp; 0x01) &lt;&lt; 2)));</span>
<span class="p_add">+		mask = 0x0f &lt;&lt; ((block &amp; 0x01) &lt;&lt; 2);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 1)) &amp; mask) == mask;</span>
 	case 2:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 2)) == (0x03 &lt;&lt; ((block &amp; 0x03) &lt;&lt; 1)));</span>
<span class="p_add">+		mask = 0x03 &lt;&lt; ((block &amp; 0x03) &lt;&lt; 1);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 2)) &amp; mask) == mask;</span>
 	case 1:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 3)) == (0x01 &lt;&lt; (block &amp; 0x07)));</span>
<span class="p_add">+		mask = 0x01 &lt;&lt; (block &amp; 0x07);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 3)) &amp; mask) == mask;</span>
 	}
 	return 0;	
 }
<span class="p_header">diff --git a/fs/xfs/xfs_aops.c b/fs/xfs/xfs_aops.c</span>
<span class="p_header">index 6df0a7ce3e8a..578981412615 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_aops.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_aops.c</span>
<span class="p_chunk">@@ -108,9 +108,9 @@</span> <span class="p_context"> xfs_finish_page_writeback(</span>
 	unsigned int		bsize;
 
 	ASSERT(bvec-&gt;bv_offset &lt; PAGE_SIZE);
<span class="p_del">-	ASSERT((bvec-&gt;bv_offset &amp; ((1 &lt;&lt; inode-&gt;i_blkbits) - 1)) == 0);</span>
<span class="p_add">+	ASSERT((bvec-&gt;bv_offset &amp; (i_blocksize(inode) - 1)) == 0);</span>
 	ASSERT(end &lt; PAGE_SIZE);
<span class="p_del">-	ASSERT((bvec-&gt;bv_len &amp; ((1 &lt;&lt; inode-&gt;i_blkbits) - 1)) == 0);</span>
<span class="p_add">+	ASSERT((bvec-&gt;bv_len &amp; (i_blocksize(inode) - 1)) == 0);</span>
 
 	bh = head = page_buffers(bvec-&gt;bv_page);
 
<span class="p_chunk">@@ -349,7 +349,7 @@</span> <span class="p_context"> xfs_map_blocks(</span>
 {
 	struct xfs_inode	*ip = XFS_I(inode);
 	struct xfs_mount	*mp = ip-&gt;i_mount;
<span class="p_del">-	ssize_t			count = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	ssize_t			count = i_blocksize(inode);</span>
 	xfs_fileoff_t		offset_fsb, end_fsb;
 	int			error = 0;
 	int			bmapi_flags = XFS_BMAPI_ENTIRE;
<span class="p_chunk">@@ -759,7 +759,7 @@</span> <span class="p_context"> xfs_aops_discard_page(</span>
 			break;
 		}
 next_buffer:
<span class="p_del">-		offset += 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+		offset += i_blocksize(inode);</span>
 
 	} while ((bh = bh-&gt;b_this_page) != head);
 
<span class="p_chunk">@@ -847,7 +847,7 @@</span> <span class="p_context"> xfs_writepage_map(</span>
 	LIST_HEAD(submit_list);
 	struct xfs_ioend	*ioend, *next;
 	struct buffer_head	*bh, *head;
<span class="p_del">-	ssize_t			len = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	ssize_t			len = i_blocksize(inode);</span>
 	int			error = 0;
 	int			count = 0;
 	int			uptodate = 1;
<span class="p_chunk">@@ -1250,7 +1250,7 @@</span> <span class="p_context"> xfs_map_trim_size(</span>
 	    offset + mapping_size &gt;= i_size_read(inode)) {
 		/* limit mapping to block that spans EOF */
 		mapping_size = roundup_64(i_size_read(inode) - offset,
<span class="p_del">-					  1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+					  i_blocksize(inode));</span>
 	}
 	if (mapping_size &gt; LONG_MAX)
 		mapping_size = LONG_MAX;
<span class="p_chunk">@@ -1286,7 +1286,7 @@</span> <span class="p_context"> __xfs_get_blocks(</span>
 		return -EIO;
 
 	offset = (xfs_off_t)iblock &lt;&lt; inode-&gt;i_blkbits;
<span class="p_del">-	ASSERT(bh_result-&gt;b_size &gt;= (1 &lt;&lt; inode-&gt;i_blkbits));</span>
<span class="p_add">+	ASSERT(bh_result-&gt;b_size &gt;= i_blocksize(inode));</span>
 	size = bh_result-&gt;b_size;
 
 	if (!create &amp;&amp; offset &gt;= i_size_read(inode))
<span class="p_chunk">@@ -1634,7 +1634,7 @@</span> <span class="p_context"> xfs_vm_set_page_dirty(</span>
 			if (offset &lt; end_offset)
 				set_buffer_dirty(bh);
 			bh = bh-&gt;b_this_page;
<span class="p_del">-			offset += 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+			offset += i_blocksize(inode);</span>
 		} while (bh != head);
 	}
 	/*
<span class="p_header">diff --git a/fs/xfs/xfs_file.c b/fs/xfs/xfs_file.c</span>
<span class="p_header">index a90ec3fad69f..df206cfc21f7 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_file.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_file.c</span>
<span class="p_chunk">@@ -823,7 +823,7 @@</span> <span class="p_context"> xfs_file_fallocate(</span>
 		if (error)
 			goto out_unlock;
 	} else if (mode &amp; FALLOC_FL_COLLAPSE_RANGE) {
<span class="p_del">-		unsigned blksize_mask = (1 &lt;&lt; inode-&gt;i_blkbits) - 1;</span>
<span class="p_add">+		unsigned int blksize_mask = i_blocksize(inode) - 1;</span>
 
 		if (offset &amp; blksize_mask || len &amp; blksize_mask) {
 			error = -EINVAL;
<span class="p_chunk">@@ -845,7 +845,7 @@</span> <span class="p_context"> xfs_file_fallocate(</span>
 		if (error)
 			goto out_unlock;
 	} else if (mode &amp; FALLOC_FL_INSERT_RANGE) {
<span class="p_del">-		unsigned blksize_mask = (1 &lt;&lt; inode-&gt;i_blkbits) - 1;</span>
<span class="p_add">+		unsigned int blksize_mask = i_blocksize(inode) - 1;</span>
 
 		new_size = i_size_read(inode) + len;
 		if (offset &amp; blksize_mask || len &amp; blksize_mask) {
<span class="p_header">diff --git a/include/linux/cgroup-defs.h b/include/linux/cgroup-defs.h</span>
<span class="p_header">index 5b17de62c962..6fb1c34cf805 100644</span>
<span class="p_header">--- a/include/linux/cgroup-defs.h</span>
<span class="p_header">+++ b/include/linux/cgroup-defs.h</span>
<span class="p_chunk">@@ -46,6 +46,7 @@</span> <span class="p_context"> enum {</span>
 	CSS_ONLINE	= (1 &lt;&lt; 1), /* between -&gt;css_online() and -&gt;css_offline() */
 	CSS_RELEASED	= (1 &lt;&lt; 2), /* refcnt reached zero, released */
 	CSS_VISIBLE	= (1 &lt;&lt; 3), /* css is visible to userland */
<span class="p_add">+	CSS_DYING	= (1 &lt;&lt; 4), /* css is dying */</span>
 };
 
 /* bits in struct cgroup flags field */
<span class="p_header">diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h</span>
<span class="p_header">index 307ae63ef262..7620a8bc0493 100644</span>
<span class="p_header">--- a/include/linux/cgroup.h</span>
<span class="p_header">+++ b/include/linux/cgroup.h</span>
<span class="p_chunk">@@ -344,6 +344,26 @@</span> <span class="p_context"> static inline bool css_tryget_online(struct cgroup_subsys_state *css)</span>
 }
 
 /**
<span class="p_add">+ * css_is_dying - test whether the specified css is dying</span>
<span class="p_add">+ * @css: target css</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Test whether @css is in the process of offlining or already offline.  In</span>
<span class="p_add">+ * most cases, -&gt;css_online() and -&gt;css_offline() callbacks should be</span>
<span class="p_add">+ * enough; however, the actual offline operations are RCU delayed and this</span>
<span class="p_add">+ * test returns %true also when @css is scheduled to be offlined.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is useful, for example, when the use case requires synchronous</span>
<span class="p_add">+ * behavior with respect to cgroup removal.  cgroup removal schedules css</span>
<span class="p_add">+ * offlining but the css can seem alive while the operation is being</span>
<span class="p_add">+ * delayed.  If the delay affects user visible semantics, this test can be</span>
<span class="p_add">+ * used to resolve the situation.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool css_is_dying(struct cgroup_subsys_state *css)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !(css-&gt;flags &amp; CSS_NO_REF) &amp;&amp; percpu_ref_is_dying(&amp;css-&gt;refcnt);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * css_put - put a css reference
  * @css: target css
  *
<span class="p_header">diff --git a/include/linux/fs.h b/include/linux/fs.h</span>
<span class="p_header">index dc0478c07b2a..2f63d44368bd 100644</span>
<span class="p_header">--- a/include/linux/fs.h</span>
<span class="p_header">+++ b/include/linux/fs.h</span>
<span class="p_chunk">@@ -705,6 +705,11 @@</span> <span class="p_context"> struct inode {</span>
 	void			*i_private; /* fs or device private pointer */
 };
 
<span class="p_add">+static inline unsigned int i_blocksize(const struct inode *node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (1 &lt;&lt; node-&gt;i_blkbits);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int inode_unhashed(struct inode *inode)
 {
 	return hlist_unhashed(&amp;inode-&gt;i_hash);
<span class="p_header">diff --git a/include/linux/ptrace.h b/include/linux/ptrace.h</span>
<span class="p_header">index e0e539321ab9..d53a23100401 100644</span>
<span class="p_header">--- a/include/linux/ptrace.h</span>
<span class="p_header">+++ b/include/linux/ptrace.h</span>
<span class="p_chunk">@@ -53,7 +53,8 @@</span> <span class="p_context"> extern int ptrace_request(struct task_struct *child, long request,</span>
 			  unsigned long addr, unsigned long data);
 extern void ptrace_notify(int exit_code);
 extern void __ptrace_link(struct task_struct *child,
<span class="p_del">-			  struct task_struct *new_parent);</span>
<span class="p_add">+			  struct task_struct *new_parent,</span>
<span class="p_add">+			  const struct cred *ptracer_cred);</span>
 extern void __ptrace_unlink(struct task_struct *child);
 extern void exit_ptrace(struct task_struct *tracer, struct list_head *dead);
 #define PTRACE_MODE_READ	0x01
<span class="p_chunk">@@ -205,7 +206,7 @@</span> <span class="p_context"> static inline void ptrace_init_task(struct task_struct *child, bool ptrace)</span>
 
 	if (unlikely(ptrace) &amp;&amp; current-&gt;ptrace) {
 		child-&gt;ptrace = current-&gt;ptrace;
<span class="p_del">-		__ptrace_link(child, current-&gt;parent);</span>
<span class="p_add">+		__ptrace_link(child, current-&gt;parent, current-&gt;ptracer_cred);</span>
 
 		if (child-&gt;ptrace &amp; PT_SEIZED)
 			task_set_jobctl_pending(child, JOBCTL_TRAP_STOP);
<span class="p_chunk">@@ -214,6 +215,8 @@</span> <span class="p_context"> static inline void ptrace_init_task(struct task_struct *child, bool ptrace)</span>
 
 		set_tsk_thread_flag(child, TIF_SIGPENDING);
 	}
<span class="p_add">+	else</span>
<span class="p_add">+		child-&gt;ptracer_cred = NULL;</span>
 }
 
 /**
<span class="p_header">diff --git a/include/net/ipv6.h b/include/net/ipv6.h</span>
<span class="p_header">index 7f15f95625e7..91afb4aadaa6 100644</span>
<span class="p_header">--- a/include/net/ipv6.h</span>
<span class="p_header">+++ b/include/net/ipv6.h</span>
<span class="p_chunk">@@ -1001,6 +1001,7 @@</span> <span class="p_context"> int inet6_hash_connect(struct inet_timewait_death_row *death_row,</span>
  */
 extern const struct proto_ops inet6_stream_ops;
 extern const struct proto_ops inet6_dgram_ops;
<span class="p_add">+extern const struct proto_ops inet6_sockraw_ops;</span>
 
 struct group_source_req;
 struct group_filter;
<span class="p_header">diff --git a/kernel/cgroup.c b/kernel/cgroup.c</span>
<span class="p_header">index a3d2aad2443f..1fde8eec9529 100644</span>
<span class="p_header">--- a/kernel/cgroup.c</span>
<span class="p_header">+++ b/kernel/cgroup.c</span>
<span class="p_chunk">@@ -5407,6 +5407,11 @@</span> <span class="p_context"> static void kill_css(struct cgroup_subsys_state *css)</span>
 {
 	lockdep_assert_held(&amp;cgroup_mutex);
 
<span class="p_add">+	if (css-&gt;flags &amp; CSS_DYING)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	css-&gt;flags |= CSS_DYING;</span>
<span class="p_add">+</span>
 	/*
 	 * This must happen before css is disassociated with its cgroup.
 	 * See seq_css() for details.
<span class="p_header">diff --git a/kernel/cpu.c b/kernel/cpu.c</span>
<span class="p_header">index 99c6c568bc55..8f52977aad59 100644</span>
<span class="p_header">--- a/kernel/cpu.c</span>
<span class="p_header">+++ b/kernel/cpu.c</span>
<span class="p_chunk">@@ -1765,13 +1765,13 @@</span> <span class="p_context"> static ssize_t write_cpuhp_target(struct device *dev,</span>
 	ret = !sp-&gt;name || sp-&gt;cant_stop ? -EINVAL : 0;
 	mutex_unlock(&amp;cpuhp_state_mutex);
 	if (ret)
<span class="p_del">-		return ret;</span>
<span class="p_add">+		goto out;</span>
 
 	if (st-&gt;state &lt; target)
 		ret = do_cpu_up(dev-&gt;id, target);
 	else
 		ret = do_cpu_down(dev-&gt;id, target);
<span class="p_del">-</span>
<span class="p_add">+out:</span>
 	unlock_device_hotplug();
 	return ret ? ret : count;
 }
<span class="p_header">diff --git a/kernel/cpuset.c b/kernel/cpuset.c</span>
<span class="p_header">index 29f815d2ef7e..24d175d2b62d 100644</span>
<span class="p_header">--- a/kernel/cpuset.c</span>
<span class="p_header">+++ b/kernel/cpuset.c</span>
<span class="p_chunk">@@ -174,9 +174,9 @@</span> <span class="p_context"> typedef enum {</span>
 } cpuset_flagbits_t;
 
 /* convenient tests for these bits */
<span class="p_del">-static inline bool is_cpuset_online(const struct cpuset *cs)</span>
<span class="p_add">+static inline bool is_cpuset_online(struct cpuset *cs)</span>
 {
<span class="p_del">-	return test_bit(CS_ONLINE, &amp;cs-&gt;flags);</span>
<span class="p_add">+	return test_bit(CS_ONLINE, &amp;cs-&gt;flags) &amp;&amp; !css_is_dying(&amp;cs-&gt;css);</span>
 }
 
 static inline int is_cpu_exclusive(const struct cpuset *cs)
<span class="p_header">diff --git a/kernel/events/core.c b/kernel/events/core.c</span>
<span class="p_header">index 07c0dc806dfc..11cc1d83c770 100644</span>
<span class="p_header">--- a/kernel/events/core.c</span>
<span class="p_header">+++ b/kernel/events/core.c</span>
<span class="p_chunk">@@ -7062,6 +7062,21 @@</span> <span class="p_context"> static void perf_log_itrace_start(struct perf_event *event)</span>
 	perf_output_end(&amp;handle);
 }
 
<span class="p_add">+static bool sample_is_allowed(struct perf_event *event, struct pt_regs *regs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Due to interrupt latency (AKA &quot;skid&quot;), we may enter the</span>
<span class="p_add">+	 * kernel before taking an overflow, even if the PMU is only</span>
<span class="p_add">+	 * counting user events.</span>
<span class="p_add">+	 * To avoid leaking information to userspace, we must always</span>
<span class="p_add">+	 * reject kernel samples when exclude_kernel is set.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (event-&gt;attr.exclude_kernel &amp;&amp; !user_mode(regs))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Generic event overflow handling, sampling.
  */
<span class="p_chunk">@@ -7109,6 +7124,12 @@</span> <span class="p_context"> static int __perf_event_overflow(struct perf_event *event,</span>
 	}
 
 	/*
<span class="p_add">+	 * For security, drop the skid kernel samples if necessary.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!sample_is_allowed(event, regs))</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * XXX event_limit might not quite work as expected on inherited
 	 * events
 	 */
<span class="p_header">diff --git a/kernel/ptrace.c b/kernel/ptrace.c</span>
<span class="p_header">index a5caecef88be..f39a7be98fc1 100644</span>
<span class="p_header">--- a/kernel/ptrace.c</span>
<span class="p_header">+++ b/kernel/ptrace.c</span>
<span class="p_chunk">@@ -57,19 +57,25 @@</span> <span class="p_context"> int ptrace_access_vm(struct task_struct *tsk, unsigned long addr,</span>
 }
 
 
<span class="p_add">+void __ptrace_link(struct task_struct *child, struct task_struct *new_parent,</span>
<span class="p_add">+		   const struct cred *ptracer_cred)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(!list_empty(&amp;child-&gt;ptrace_entry));</span>
<span class="p_add">+	list_add(&amp;child-&gt;ptrace_entry, &amp;new_parent-&gt;ptraced);</span>
<span class="p_add">+	child-&gt;parent = new_parent;</span>
<span class="p_add">+	child-&gt;ptracer_cred = get_cred(ptracer_cred);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * ptrace a task: make the debugger its new parent and
  * move it to the ptrace list.
  *
  * Must be called with the tasklist lock write-held.
  */
<span class="p_del">-void __ptrace_link(struct task_struct *child, struct task_struct *new_parent)</span>
<span class="p_add">+static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)</span>
 {
<span class="p_del">-	BUG_ON(!list_empty(&amp;child-&gt;ptrace_entry));</span>
<span class="p_del">-	list_add(&amp;child-&gt;ptrace_entry, &amp;new_parent-&gt;ptraced);</span>
<span class="p_del">-	child-&gt;parent = new_parent;</span>
 	rcu_read_lock();
<span class="p_del">-	child-&gt;ptracer_cred = get_cred(__task_cred(new_parent));</span>
<span class="p_add">+	__ptrace_link(child, new_parent, __task_cred(new_parent));</span>
 	rcu_read_unlock();
 }
 
<span class="p_chunk">@@ -383,7 +389,7 @@</span> <span class="p_context"> static int ptrace_attach(struct task_struct *task, long request,</span>
 		flags |= PT_SEIZED;
 	task-&gt;ptrace = flags;
 
<span class="p_del">-	__ptrace_link(task, current);</span>
<span class="p_add">+	ptrace_link(task, current);</span>
 
 	/* SEIZE doesn&#39;t trap tracee on attach */
 	if (!seize)
<span class="p_chunk">@@ -456,7 +462,7 @@</span> <span class="p_context"> static int ptrace_traceme(void)</span>
 		 */
 		if (!ret &amp;&amp; !(current-&gt;real_parent-&gt;flags &amp; PF_EXITING)) {
 			current-&gt;ptrace = PT_PTRACED;
<span class="p_del">-			__ptrace_link(current, current-&gt;real_parent);</span>
<span class="p_add">+			ptrace_link(current, current-&gt;real_parent);</span>
 		}
 	}
 	write_unlock_irq(&amp;tasklist_lock);
<span class="p_header">diff --git a/kernel/sched/cpufreq_schedutil.c b/kernel/sched/cpufreq_schedutil.c</span>
<span class="p_header">index 69e06898997d..cb771c76682e 100644</span>
<span class="p_header">--- a/kernel/sched/cpufreq_schedutil.c</span>
<span class="p_header">+++ b/kernel/sched/cpufreq_schedutil.c</span>
<span class="p_chunk">@@ -32,6 +32,7 @@</span> <span class="p_context"> struct sugov_policy {</span>
 	u64 last_freq_update_time;
 	s64 freq_update_delay_ns;
 	unsigned int next_freq;
<span class="p_add">+	unsigned int cached_raw_freq;</span>
 
 	/* The next fields are only needed if fast switch cannot be used. */
 	struct irq_work irq_work;
<span class="p_chunk">@@ -46,7 +47,6 @@</span> <span class="p_context"> struct sugov_cpu {</span>
 	struct update_util_data update_util;
 	struct sugov_policy *sg_policy;
 
<span class="p_del">-	unsigned int cached_raw_freq;</span>
 	unsigned long iowait_boost;
 	unsigned long iowait_boost_max;
 	u64 last_update;
<span class="p_chunk">@@ -140,9 +140,9 @@</span> <span class="p_context"> static unsigned int get_next_freq(struct sugov_cpu *sg_cpu, unsigned long util,</span>
 
 	freq = (freq + (freq &gt;&gt; 2)) * util / max;
 
<span class="p_del">-	if (freq == sg_cpu-&gt;cached_raw_freq &amp;&amp; sg_policy-&gt;next_freq != UINT_MAX)</span>
<span class="p_add">+	if (freq == sg_policy-&gt;cached_raw_freq &amp;&amp; sg_policy-&gt;next_freq != UINT_MAX)</span>
 		return sg_policy-&gt;next_freq;
<span class="p_del">-	sg_cpu-&gt;cached_raw_freq = freq;</span>
<span class="p_add">+	sg_policy-&gt;cached_raw_freq = freq;</span>
 	return cpufreq_driver_resolve_freq(policy, freq);
 }
 
<span class="p_chunk">@@ -502,25 +502,19 @@</span> <span class="p_context"> static int sugov_start(struct cpufreq_policy *policy)</span>
 	sg_policy-&gt;next_freq = UINT_MAX;
 	sg_policy-&gt;work_in_progress = false;
 	sg_policy-&gt;need_freq_update = false;
<span class="p_add">+	sg_policy-&gt;cached_raw_freq = 0;</span>
 
 	for_each_cpu(cpu, policy-&gt;cpus) {
 		struct sugov_cpu *sg_cpu = &amp;per_cpu(sugov_cpu, cpu);
 
<span class="p_add">+		memset(sg_cpu, 0, sizeof(*sg_cpu));</span>
 		sg_cpu-&gt;sg_policy = sg_policy;
<span class="p_del">-		if (policy_is_shared(policy)) {</span>
<span class="p_del">-			sg_cpu-&gt;util = 0;</span>
<span class="p_del">-			sg_cpu-&gt;max = 0;</span>
<span class="p_del">-			sg_cpu-&gt;flags = SCHED_CPUFREQ_RT;</span>
<span class="p_del">-			sg_cpu-&gt;last_update = 0;</span>
<span class="p_del">-			sg_cpu-&gt;cached_raw_freq = 0;</span>
<span class="p_del">-			sg_cpu-&gt;iowait_boost = 0;</span>
<span class="p_del">-			sg_cpu-&gt;iowait_boost_max = policy-&gt;cpuinfo.max_freq;</span>
<span class="p_del">-			cpufreq_add_update_util_hook(cpu, &amp;sg_cpu-&gt;update_util,</span>
<span class="p_del">-						     sugov_update_shared);</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			cpufreq_add_update_util_hook(cpu, &amp;sg_cpu-&gt;update_util,</span>
<span class="p_del">-						     sugov_update_single);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		sg_cpu-&gt;flags = SCHED_CPUFREQ_RT;</span>
<span class="p_add">+		sg_cpu-&gt;iowait_boost_max = policy-&gt;cpuinfo.max_freq;</span>
<span class="p_add">+		cpufreq_add_update_util_hook(cpu, &amp;sg_cpu-&gt;update_util,</span>
<span class="p_add">+					     policy_is_shared(policy) ?</span>
<span class="p_add">+							sugov_update_shared :</span>
<span class="p_add">+							sugov_update_single);</span>
 	}
 	return 0;
 }
<span class="p_header">diff --git a/lib/test_user_copy.c b/lib/test_user_copy.c</span>
<span class="p_header">index 0ecef3e4690e..5e6db6b1e3bd 100644</span>
<span class="p_header">--- a/lib/test_user_copy.c</span>
<span class="p_header">+++ b/lib/test_user_copy.c</span>
<span class="p_chunk">@@ -58,7 +58,9 @@</span> <span class="p_context"> static int __init test_user_copy_init(void)</span>
 	usermem = (char __user *)user_addr;
 	bad_usermem = (char *)user_addr;
 
<span class="p_del">-	/* Legitimate usage: none of these should fail. */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Legitimate usage: none of these copies should fail.</span>
<span class="p_add">+	 */</span>
 	ret |= test(copy_from_user(kmem, usermem, PAGE_SIZE),
 		    &quot;legitimate copy_from_user failed&quot;);
 	ret |= test(copy_to_user(usermem, kmem, PAGE_SIZE),
<span class="p_chunk">@@ -68,19 +70,33 @@</span> <span class="p_context"> static int __init test_user_copy_init(void)</span>
 	ret |= test(put_user(value, (unsigned long __user *)usermem),
 		    &quot;legitimate put_user failed&quot;);
 
<span class="p_del">-	/* Invalid usage: none of these should succeed. */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Invalid usage: none of these copies should succeed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reject kernel-to-kernel copies through copy_from_user(). */</span>
 	ret |= test(!copy_from_user(kmem, (char __user *)(kmem + PAGE_SIZE),
 				    PAGE_SIZE),
 		    &quot;illegal all-kernel copy_from_user passed&quot;);
<span class="p_add">+</span>
<span class="p_add">+#if 0</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When running with SMAP/PAN/etc, this will Oops the kernel</span>
<span class="p_add">+	 * due to the zeroing of userspace memory on failure. This needs</span>
<span class="p_add">+	 * to be tested in LKDTM instead, since this test module does not</span>
<span class="p_add">+	 * expect to explode.</span>
<span class="p_add">+	 */</span>
 	ret |= test(!copy_from_user(bad_usermem, (char __user *)kmem,
 				    PAGE_SIZE),
 		    &quot;illegal reversed copy_from_user passed&quot;);
<span class="p_add">+#endif</span>
 	ret |= test(!copy_to_user((char __user *)kmem, kmem + PAGE_SIZE,
 				  PAGE_SIZE),
 		    &quot;illegal all-kernel copy_to_user passed&quot;);
 	ret |= test(!copy_to_user((char __user *)kmem, bad_usermem,
 				  PAGE_SIZE),
 		    &quot;illegal reversed copy_to_user passed&quot;);
<span class="p_add">+</span>
 	ret |= test(!get_user(value, (unsigned long __user *)kmem),
 		    &quot;illegal get_user passed&quot;);
 	ret |= test(!put_user(value, (unsigned long __user *)kmem),
<span class="p_header">diff --git a/mm/truncate.c b/mm/truncate.c</span>
<span class="p_header">index 8d8c62d89e6d..9c809e7d73c3 100644</span>
<span class="p_header">--- a/mm/truncate.c</span>
<span class="p_header">+++ b/mm/truncate.c</span>
<span class="p_chunk">@@ -753,7 +753,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(truncate_setsize);</span>
  */
 void pagecache_isize_extended(struct inode *inode, loff_t from, loff_t to)
 {
<span class="p_del">-	int bsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	int bsize = i_blocksize(inode);</span>
 	loff_t rounded_from;
 	struct page *page;
 	pgoff_t index;
<span class="p_header">diff --git a/net/bridge/br_stp_if.c b/net/bridge/br_stp_if.c</span>
<span class="p_header">index 5a782f543aff..16b5aa9a91f1 100644</span>
<span class="p_header">--- a/net/bridge/br_stp_if.c</span>
<span class="p_header">+++ b/net/bridge/br_stp_if.c</span>
<span class="p_chunk">@@ -185,7 +185,8 @@</span> <span class="p_context"> static void br_stp_start(struct net_bridge *br)</span>
 		br_debug(br, &quot;using kernel STP\n&quot;);
 
 		/* To start timers on any ports left in blocking */
<span class="p_del">-		mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
<span class="p_add">+		if (br-&gt;dev-&gt;flags &amp; IFF_UP)</span>
<span class="p_add">+			mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
 		br_port_state_selection(br);
 	}
 
<span class="p_header">diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c</span>
<span class="p_header">index 971b9471d427..f60fe82c2c1e 100644</span>
<span class="p_header">--- a/net/ipv4/af_inet.c</span>
<span class="p_header">+++ b/net/ipv4/af_inet.c</span>
<span class="p_chunk">@@ -1015,7 +1015,7 @@</span> <span class="p_context"> static struct inet_protosw inetsw_array[] =</span>
 		.type =       SOCK_DGRAM,
 		.protocol =   IPPROTO_ICMP,
 		.prot =       &amp;ping_prot,
<span class="p_del">-		.ops =        &amp;inet_dgram_ops,</span>
<span class="p_add">+		.ops =        &amp;inet_sockraw_ops,</span>
 		.flags =      INET_PROTOSW_REUSE,
        },
 
<span class="p_header">diff --git a/net/ipv4/tcp_cong.c b/net/ipv4/tcp_cong.c</span>
<span class="p_header">index baea5df43598..0cdbea9b9288 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_cong.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_cong.c</span>
<span class="p_chunk">@@ -179,6 +179,7 @@</span> <span class="p_context"> void tcp_init_congestion_control(struct sock *sk)</span>
 {
 	const struct inet_connection_sock *icsk = inet_csk(sk);
 
<span class="p_add">+	tcp_sk(sk)-&gt;prior_ssthresh = 0;</span>
 	if (icsk-&gt;icsk_ca_ops-&gt;init)
 		icsk-&gt;icsk_ca_ops-&gt;init(sk);
 	if (tcp_ca_needs_ecn(sk))
<span class="p_header">diff --git a/net/ipv6/calipso.c b/net/ipv6/calipso.c</span>
<span class="p_header">index 37ac9de713c6..8d772fea1dde 100644</span>
<span class="p_header">--- a/net/ipv6/calipso.c</span>
<span class="p_header">+++ b/net/ipv6/calipso.c</span>
<span class="p_chunk">@@ -1319,7 +1319,7 @@</span> <span class="p_context"> static int calipso_skbuff_setattr(struct sk_buff *skb,</span>
 	struct ipv6hdr *ip6_hdr;
 	struct ipv6_opt_hdr *hop;
 	unsigned char buf[CALIPSO_MAX_BUFFER];
<span class="p_del">-	int len_delta, new_end, pad;</span>
<span class="p_add">+	int len_delta, new_end, pad, payload;</span>
 	unsigned int start, end;
 
 	ip6_hdr = ipv6_hdr(skb);
<span class="p_chunk">@@ -1346,6 +1346,8 @@</span> <span class="p_context"> static int calipso_skbuff_setattr(struct sk_buff *skb,</span>
 	if (ret_val &lt; 0)
 		return ret_val;
 
<span class="p_add">+	ip6_hdr = ipv6_hdr(skb); /* Reset as skb_cow() may have moved it */</span>
<span class="p_add">+</span>
 	if (len_delta) {
 		if (len_delta &gt; 0)
 			skb_push(skb, len_delta);
<span class="p_chunk">@@ -1355,6 +1357,8 @@</span> <span class="p_context"> static int calipso_skbuff_setattr(struct sk_buff *skb,</span>
 			sizeof(*ip6_hdr) + start);
 		skb_reset_network_header(skb);
 		ip6_hdr = ipv6_hdr(skb);
<span class="p_add">+		payload = ntohs(ip6_hdr-&gt;payload_len);</span>
<span class="p_add">+		ip6_hdr-&gt;payload_len = htons(payload + len_delta);</span>
 	}
 
 	hop = (struct ipv6_opt_hdr *)(ip6_hdr + 1);
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index 013086b248e2..424fbe1f8978 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -116,8 +116,10 @@</span> <span class="p_context"> static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,</span>
 
 		if (udpfrag) {
 			int err = ip6_find_1stfragopt(skb, &amp;prevhdr);
<span class="p_del">-			if (err &lt; 0)</span>
<span class="p_add">+			if (err &lt; 0) {</span>
<span class="p_add">+				kfree_skb_list(segs);</span>
 				return ERR_PTR(err);
<span class="p_add">+			}</span>
 			fptr = (struct frag_hdr *)((u8 *)ipv6h + err);
 			fptr-&gt;frag_off = htons(offset);
 			if (skb-&gt;next)
<span class="p_header">diff --git a/net/ipv6/ping.c b/net/ipv6/ping.c</span>
<span class="p_header">index 66e2d9dfc43a..982868193dbb 100644</span>
<span class="p_header">--- a/net/ipv6/ping.c</span>
<span class="p_header">+++ b/net/ipv6/ping.c</span>
<span class="p_chunk">@@ -198,7 +198,7 @@</span> <span class="p_context"> static struct inet_protosw pingv6_protosw = {</span>
 	.type =      SOCK_DGRAM,
 	.protocol =  IPPROTO_ICMPV6,
 	.prot =      &amp;pingv6_prot,
<span class="p_del">-	.ops =       &amp;inet6_dgram_ops,</span>
<span class="p_add">+	.ops =       &amp;inet6_sockraw_ops,</span>
 	.flags =     INET_PROTOSW_REUSE,
 };
 
<span class="p_header">diff --git a/net/ipv6/raw.c b/net/ipv6/raw.c</span>
<span class="p_header">index 1a2fe5c3a366..71ffa526cb23 100644</span>
<span class="p_header">--- a/net/ipv6/raw.c</span>
<span class="p_header">+++ b/net/ipv6/raw.c</span>
<span class="p_chunk">@@ -1330,7 +1330,7 @@</span> <span class="p_context"> void raw6_proc_exit(void)</span>
 #endif	/* CONFIG_PROC_FS */
 
 /* Same as inet6_dgram_ops, sans udp_poll.  */
<span class="p_del">-static const struct proto_ops inet6_sockraw_ops = {</span>
<span class="p_add">+const struct proto_ops inet6_sockraw_ops = {</span>
 	.family		   = PF_INET6,
 	.owner		   = THIS_MODULE,
 	.release	   = inet6_release,
<span class="p_header">diff --git a/net/ipv6/xfrm6_mode_ro.c b/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_header">index 0e015906f9ca..07d36573f50b 100644</span>
<span class="p_header">--- a/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_header">+++ b/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_chunk">@@ -47,6 +47,8 @@</span> <span class="p_context"> static int xfrm6_ro_output(struct xfrm_state *x, struct sk_buff *skb)</span>
 	iph = ipv6_hdr(skb);
 
 	hdr_len = x-&gt;type-&gt;hdr_offset(x, skb, &amp;prevhdr);
<span class="p_add">+	if (hdr_len &lt; 0)</span>
<span class="p_add">+		return hdr_len;</span>
 	skb_set_mac_header(skb, (prevhdr - x-&gt;props.header_len) - skb-&gt;data);
 	skb_set_network_header(skb, -x-&gt;props.header_len);
 	skb-&gt;transport_header = skb-&gt;network_header + hdr_len;
<span class="p_header">diff --git a/net/ipv6/xfrm6_mode_transport.c b/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_header">index 4e344105b3fd..1d3bbe6e1183 100644</span>
<span class="p_header">--- a/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_header">+++ b/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_chunk">@@ -28,6 +28,8 @@</span> <span class="p_context"> static int xfrm6_transport_output(struct xfrm_state *x, struct sk_buff *skb)</span>
 	iph = ipv6_hdr(skb);
 
 	hdr_len = x-&gt;type-&gt;hdr_offset(x, skb, &amp;prevhdr);
<span class="p_add">+	if (hdr_len &lt; 0)</span>
<span class="p_add">+		return hdr_len;</span>
 	skb_set_mac_header(skb, (prevhdr - x-&gt;props.header_len) - skb-&gt;data);
 	skb_set_network_header(skb, -x-&gt;props.header_len);
 	skb-&gt;transport_header = skb-&gt;network_header + hdr_len;
<span class="p_header">diff --git a/net/netfilter/nft_set_rbtree.c b/net/netfilter/nft_set_rbtree.c</span>
<span class="p_header">index 36493a7cae88..93820e0d8814 100644</span>
<span class="p_header">--- a/net/netfilter/nft_set_rbtree.c</span>
<span class="p_header">+++ b/net/netfilter/nft_set_rbtree.c</span>
<span class="p_chunk">@@ -118,17 +118,17 @@</span> <span class="p_context"> static int __nft_rbtree_insert(const struct net *net, const struct nft_set *set,</span>
 		else if (d &gt; 0)
 			p = &amp;parent-&gt;rb_right;
 		else {
<span class="p_del">-			if (nft_set_elem_active(&amp;rbe-&gt;ext, genmask)) {</span>
<span class="p_del">-				if (nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_del">-				    !nft_rbtree_interval_end(new))</span>
<span class="p_del">-					p = &amp;parent-&gt;rb_left;</span>
<span class="p_del">-				else if (!nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_del">-					 nft_rbtree_interval_end(new))</span>
<span class="p_del">-					p = &amp;parent-&gt;rb_right;</span>
<span class="p_del">-				else {</span>
<span class="p_del">-					*ext = &amp;rbe-&gt;ext;</span>
<span class="p_del">-					return -EEXIST;</span>
<span class="p_del">-				}</span>
<span class="p_add">+			if (nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_add">+			    !nft_rbtree_interval_end(new)) {</span>
<span class="p_add">+				p = &amp;parent-&gt;rb_left;</span>
<span class="p_add">+			} else if (!nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_add">+				   nft_rbtree_interval_end(new)) {</span>
<span class="p_add">+				p = &amp;parent-&gt;rb_right;</span>
<span class="p_add">+			} else if (nft_set_elem_active(&amp;rbe-&gt;ext, genmask)) {</span>
<span class="p_add">+				*ext = &amp;rbe-&gt;ext;</span>
<span class="p_add">+				return -EEXIST;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				p = &amp;parent-&gt;rb_left;</span>
 			}
 		}
 	}
<span class="p_header">diff --git a/security/keys/encrypted-keys/encrypted.c b/security/keys/encrypted-keys/encrypted.c</span>
<span class="p_header">index 17a06105ccb6..56c458dd16a2 100644</span>
<span class="p_header">--- a/security/keys/encrypted-keys/encrypted.c</span>
<span class="p_header">+++ b/security/keys/encrypted-keys/encrypted.c</span>
<span class="p_chunk">@@ -480,12 +480,9 @@</span> <span class="p_context"> static int derived_key_encrypt(struct encrypted_key_payload *epayload,</span>
 	struct skcipher_request *req;
 	unsigned int encrypted_datalen;
 	u8 iv[AES_BLOCK_SIZE];
<span class="p_del">-	unsigned int padlen;</span>
<span class="p_del">-	char pad[16];</span>
 	int ret;
 
 	encrypted_datalen = roundup(epayload-&gt;decrypted_datalen, blksize);
<span class="p_del">-	padlen = encrypted_datalen - epayload-&gt;decrypted_datalen;</span>
 
 	req = init_skcipher_req(derived_key, derived_keylen);
 	ret = PTR_ERR(req);
<span class="p_chunk">@@ -493,11 +490,10 @@</span> <span class="p_context"> static int derived_key_encrypt(struct encrypted_key_payload *epayload,</span>
 		goto out;
 	dump_decrypted_data(epayload);
 
<span class="p_del">-	memset(pad, 0, sizeof pad);</span>
 	sg_init_table(sg_in, 2);
 	sg_set_buf(&amp;sg_in[0], epayload-&gt;decrypted_data,
 		   epayload-&gt;decrypted_datalen);
<span class="p_del">-	sg_set_buf(&amp;sg_in[1], pad, padlen);</span>
<span class="p_add">+	sg_set_page(&amp;sg_in[1], ZERO_PAGE(0), AES_BLOCK_SIZE, 0);</span>
 
 	sg_init_table(sg_out, 1);
 	sg_set_buf(sg_out, epayload-&gt;encrypted_data, encrypted_datalen);
<span class="p_chunk">@@ -584,9 +580,14 @@</span> <span class="p_context"> static int derived_key_decrypt(struct encrypted_key_payload *epayload,</span>
 	struct skcipher_request *req;
 	unsigned int encrypted_datalen;
 	u8 iv[AES_BLOCK_SIZE];
<span class="p_del">-	char pad[16];</span>
<span class="p_add">+	u8 *pad;</span>
 	int ret;
 
<span class="p_add">+	/* Throwaway buffer to hold the unused zero padding at the end */</span>
<span class="p_add">+	pad = kmalloc(AES_BLOCK_SIZE, GFP_KERNEL);</span>
<span class="p_add">+	if (!pad)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
 	encrypted_datalen = roundup(epayload-&gt;decrypted_datalen, blksize);
 	req = init_skcipher_req(derived_key, derived_keylen);
 	ret = PTR_ERR(req);
<span class="p_chunk">@@ -594,13 +595,12 @@</span> <span class="p_context"> static int derived_key_decrypt(struct encrypted_key_payload *epayload,</span>
 		goto out;
 	dump_encrypted_data(epayload, encrypted_datalen);
 
<span class="p_del">-	memset(pad, 0, sizeof pad);</span>
 	sg_init_table(sg_in, 1);
 	sg_init_table(sg_out, 2);
 	sg_set_buf(sg_in, epayload-&gt;encrypted_data, encrypted_datalen);
 	sg_set_buf(&amp;sg_out[0], epayload-&gt;decrypted_data,
 		   epayload-&gt;decrypted_datalen);
<span class="p_del">-	sg_set_buf(&amp;sg_out[1], pad, sizeof pad);</span>
<span class="p_add">+	sg_set_buf(&amp;sg_out[1], pad, AES_BLOCK_SIZE);</span>
 
 	memcpy(iv, epayload-&gt;iv, sizeof(iv));
 	skcipher_request_set_crypt(req, sg_in, sg_out, encrypted_datalen, iv);
<span class="p_chunk">@@ -612,6 +612,7 @@</span> <span class="p_context"> static int derived_key_decrypt(struct encrypted_key_payload *epayload,</span>
 		goto out;
 	dump_decrypted_data(epayload);
 out:
<span class="p_add">+	kfree(pad);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/security/keys/key.c b/security/keys/key.c</span>
<span class="p_header">index 346fbf201c22..2f4ce35ae2aa 100644</span>
<span class="p_header">--- a/security/keys/key.c</span>
<span class="p_header">+++ b/security/keys/key.c</span>
<span class="p_chunk">@@ -962,12 +962,11 @@</span> <span class="p_context"> int key_update(key_ref_t key_ref, const void *payload, size_t plen)</span>
 	/* the key must be writable */
 	ret = key_permission(key_ref, KEY_NEED_WRITE);
 	if (ret &lt; 0)
<span class="p_del">-		goto error;</span>
<span class="p_add">+		return ret;</span>
 
 	/* attempt to update it if supported */
<span class="p_del">-	ret = -EOPNOTSUPP;</span>
 	if (!key-&gt;type-&gt;update)
<span class="p_del">-		goto error;</span>
<span class="p_add">+		return -EOPNOTSUPP;</span>
 
 	memset(&amp;prep, 0, sizeof(prep));
 	prep.data = payload;
<span class="p_header">diff --git a/security/keys/keyctl.c b/security/keys/keyctl.c</span>
<span class="p_header">index dbbfd7735ce5..ada12c3e3ac4 100644</span>
<span class="p_header">--- a/security/keys/keyctl.c</span>
<span class="p_header">+++ b/security/keys/keyctl.c</span>
<span class="p_chunk">@@ -97,7 +97,7 @@</span> <span class="p_context"> SYSCALL_DEFINE5(add_key, const char __user *, _type,</span>
 	/* pull the payload in if one was supplied */
 	payload = NULL;
 
<span class="p_del">-	if (_payload) {</span>
<span class="p_add">+	if (plen) {</span>
 		ret = -ENOMEM;
 		payload = kmalloc(plen, GFP_KERNEL | __GFP_NOWARN);
 		if (!payload) {
<span class="p_chunk">@@ -327,7 +327,7 @@</span> <span class="p_context"> long keyctl_update_key(key_serial_t id,</span>
 
 	/* pull the payload in if one was supplied */
 	payload = NULL;
<span class="p_del">-	if (_payload) {</span>
<span class="p_add">+	if (plen) {</span>
 		ret = -ENOMEM;
 		payload = kmalloc(plen, GFP_KERNEL);
 		if (!payload)
<span class="p_header">diff --git a/sound/core/timer.c b/sound/core/timer.c</span>
<span class="p_header">index ad153149b231..e5ddc475dca4 100644</span>
<span class="p_header">--- a/sound/core/timer.c</span>
<span class="p_header">+++ b/sound/core/timer.c</span>
<span class="p_chunk">@@ -1622,6 +1622,7 @@</span> <span class="p_context"> static int snd_timer_user_tselect(struct file *file,</span>
 	if (err &lt; 0)
 		goto __err;
 
<span class="p_add">+	tu-&gt;qhead = tu-&gt;qtail = tu-&gt;qused = 0;</span>
 	kfree(tu-&gt;queue);
 	tu-&gt;queue = NULL;
 	kfree(tu-&gt;tqueue);
<span class="p_chunk">@@ -1963,6 +1964,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 
 	tu = file-&gt;private_data;
 	unit = tu-&gt;tread ? sizeof(struct snd_timer_tread) : sizeof(struct snd_timer_read);
<span class="p_add">+	mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 	spin_lock_irq(&amp;tu-&gt;qlock);
 	while ((long)count - result &gt;= unit) {
 		while (!tu-&gt;qused) {
<span class="p_chunk">@@ -1978,7 +1980,9 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 			add_wait_queue(&amp;tu-&gt;qchange_sleep, &amp;wait);
 
 			spin_unlock_irq(&amp;tu-&gt;qlock);
<span class="p_add">+			mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 			schedule();
<span class="p_add">+			mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 			spin_lock_irq(&amp;tu-&gt;qlock);
 
 			remove_wait_queue(&amp;tu-&gt;qchange_sleep, &amp;wait);
<span class="p_chunk">@@ -1998,7 +2002,6 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 		tu-&gt;qused--;
 		spin_unlock_irq(&amp;tu-&gt;qlock);
 
<span class="p_del">-		mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 		if (tu-&gt;tread) {
 			if (copy_to_user(buffer, &amp;tu-&gt;tqueue[qhead],
 					 sizeof(struct snd_timer_tread)))
<span class="p_chunk">@@ -2008,7 +2011,6 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 					 sizeof(struct snd_timer_read)))
 				err = -EFAULT;
 		}
<span class="p_del">-		mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 
 		spin_lock_irq(&amp;tu-&gt;qlock);
 		if (err &lt; 0)
<span class="p_chunk">@@ -2018,6 +2020,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 	}
  _error:
 	spin_unlock_irq(&amp;tu-&gt;qlock);
<span class="p_add">+	mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 	return result &gt; 0 ? result : err;
 }
 
<span class="p_header">diff --git a/sound/soc/soc-core.c b/sound/soc/soc-core.c</span>
<span class="p_header">index c0bbcd903261..4e3de566809c 100644</span>
<span class="p_header">--- a/sound/soc/soc-core.c</span>
<span class="p_header">+++ b/sound/soc/soc-core.c</span>
<span class="p_chunk">@@ -2076,6 +2076,9 @@</span> <span class="p_context"> static int soc_cleanup_card_resources(struct snd_soc_card *card)</span>
 	list_for_each_entry(rtd, &amp;card-&gt;rtd_list, list)
 		flush_delayed_work(&amp;rtd-&gt;delayed_work);
 
<span class="p_add">+	/* free the ALSA card at first; this syncs with pending operations */</span>
<span class="p_add">+	snd_card_free(card-&gt;snd_card);</span>
<span class="p_add">+</span>
 	/* remove and free each DAI */
 	soc_remove_dai_links(card);
 	soc_remove_pcm_runtimes(card);
<span class="p_chunk">@@ -2090,9 +2093,7 @@</span> <span class="p_context"> static int soc_cleanup_card_resources(struct snd_soc_card *card)</span>
 	if (card-&gt;remove)
 		card-&gt;remove(card);
 
<span class="p_del">-	snd_card_free(card-&gt;snd_card);</span>
 	return 0;
<span class="p_del">-</span>
 }
 
 /* removes a socdev */
<span class="p_header">diff --git a/virt/kvm/arm/vgic/vgic-v2.c b/virt/kvm/arm/vgic/vgic-v2.c</span>
<span class="p_header">index 834137e7b83f..1ab58f7b5d74 100644</span>
<span class="p_header">--- a/virt/kvm/arm/vgic/vgic-v2.c</span>
<span class="p_header">+++ b/virt/kvm/arm/vgic/vgic-v2.c</span>
<span class="p_chunk">@@ -168,6 +168,13 @@</span> <span class="p_context"> void vgic_v2_populate_lr(struct kvm_vcpu *vcpu, struct vgic_irq *irq, int lr)</span>
 	if (irq-&gt;hw) {
 		val |= GICH_LR_HW;
 		val |= irq-&gt;hwintid &lt;&lt; GICH_LR_PHYSID_CPUID_SHIFT;
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Never set pending+active on a HW interrupt, as the</span>
<span class="p_add">+		 * pending state is kept at the physical distributor</span>
<span class="p_add">+		 * level.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (irq-&gt;active &amp;&amp; irq-&gt;pending)</span>
<span class="p_add">+			val &amp;= ~GICH_LR_PENDING_BIT;</span>
 	} else {
 		if (irq-&gt;config == VGIC_CONFIG_LEVEL)
 			val |= GICH_LR_EOI;
<span class="p_header">diff --git a/virt/kvm/arm/vgic/vgic-v3.c b/virt/kvm/arm/vgic/vgic-v3.c</span>
<span class="p_header">index e6b03fd8c374..f1320063db28 100644</span>
<span class="p_header">--- a/virt/kvm/arm/vgic/vgic-v3.c</span>
<span class="p_header">+++ b/virt/kvm/arm/vgic/vgic-v3.c</span>
<span class="p_chunk">@@ -151,6 +151,13 @@</span> <span class="p_context"> void vgic_v3_populate_lr(struct kvm_vcpu *vcpu, struct vgic_irq *irq, int lr)</span>
 	if (irq-&gt;hw) {
 		val |= ICH_LR_HW;
 		val |= ((u64)irq-&gt;hwintid) &lt;&lt; ICH_LR_PHYS_ID_SHIFT;
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Never set pending+active on a HW interrupt, as the</span>
<span class="p_add">+		 * pending state is kept at the physical distributor</span>
<span class="p_add">+		 * level.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (irq-&gt;active &amp;&amp; irq-&gt;pending)</span>
<span class="p_add">+			val &amp;= ~ICH_LR_PENDING_BIT;</span>
 	} else {
 		if (irq-&gt;config == VGIC_CONFIG_LEVEL)
 			val |= ICH_LR_EOI;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



