
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv2,2/2] arm64: Allow changing of attributes outside of modules - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv2,2/2] arm64: Allow changing of attributes outside of modules</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=130331">Laura Abbott</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 11, 2015, 1:57 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1447207057-11323-3-git-send-email-labbott@fedoraproject.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7593381/mbox/"
   >mbox</a>
|
   <a href="/patch/7593381/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7593381/">/patch/7593381/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 288609F392
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Nov 2015 01:58:07 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 1097E20672
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Nov 2015 01:58:06 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id CFD7120776
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Nov 2015 01:58:04 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752100AbbKKB5y (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 10 Nov 2015 20:57:54 -0500
Received: from mx1.redhat.com ([209.132.183.28]:38830 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751912AbbKKB5r (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 10 Nov 2015 20:57:47 -0500
Received: from int-mx09.intmail.prod.int.phx2.redhat.com
	(int-mx09.intmail.prod.int.phx2.redhat.com [10.5.11.22])
	by mx1.redhat.com (Postfix) with ESMTPS id 81196368E3;
	Wed, 11 Nov 2015 01:57:47 +0000 (UTC)
Received: from labbott-redhat-machine.redhat.com
	(ovpn-112-23.phx2.redhat.com [10.3.112.23])
	by int-mx09.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with
	ESMTP id tAB1vdaN029142; Tue, 10 Nov 2015 20:57:45 -0500
From: Laura Abbott &lt;labbott@fedoraproject.org&gt;
To: Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;,
	Ard Biesheuvel &lt;ard.biesheuvel@linaro.org&gt;,
	Zhong Jiang &lt;zhongjiang@huawei.com&gt;
Cc: Laura Abbott &lt;labbott@fedoraproject.org&gt;,
	linux-arm-kernel@lists.infradead.org, linux-kernel@vger.kernel.org,
	Kees Cook &lt;keescook@chromium.org&gt;, Xishi Qiu &lt;qiuxishi@huawei.com&gt;,
	Mark Rutland &lt;mark.rutland@arm.com&gt;
Subject: [PATCHv2 2/2] arm64: Allow changing of attributes outside of modules
Date: Tue, 10 Nov 2015 17:57:37 -0800
Message-Id: &lt;1447207057-11323-3-git-send-email-labbott@fedoraproject.org&gt;
In-Reply-To: &lt;1447207057-11323-1-git-send-email-labbott@fedoraproject.org&gt;
References: &lt;1447207057-11323-1-git-send-email-labbott@fedoraproject.org&gt;
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.22
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.2 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130331">Laura Abbott</a> - Nov. 11, 2015, 1:57 a.m.</div>
<pre class="content">
Currently, the set_memory_* functions that are implemented for arm64
are restricted to module addresses only. This was mostly done
because arm64 maps normal zone memory with larger page sizes to
improve TLB performance. This has the side effect though of making it
difficult to adjust attributes at the PAGE_SIZE granularity. There are
an increasing number of use cases related to security where it is
necessary to change the attributes of kernel memory. Add functionality
to the page attribute changing code under a Kconfig to let systems
designers decide if they want to make the trade off of security for TLB
pressure.
<span class="signed-off-by">
Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
---
v2: Re-worked to account for the full range of addresses. Will also just
update the section blocks instead of splitting if the addresses are aligned
properly.
---
 arch/arm64/Kconfig       |  12 ++++
 arch/arm64/mm/mm.h       |   3 +
 arch/arm64/mm/mmu.c      |   2 +-
 arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------
 4 files changed, 170 insertions(+), 21 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=146341">zhong jiang</a> - Nov. 12, 2015, 11:55 a.m.</div>
<pre class="content">
On 2015/11/11 9:57, Laura Abbott wrote:
<span class="quote">&gt; Currently, the set_memory_* functions that are implemented for arm64</span>
<span class="quote">&gt; are restricted to module addresses only. This was mostly done</span>
<span class="quote">&gt; because arm64 maps normal zone memory with larger page sizes to</span>
<span class="quote">&gt; improve TLB performance. This has the side effect though of making it</span>
<span class="quote">&gt; difficult to adjust attributes at the PAGE_SIZE granularity. There are</span>
<span class="quote">&gt; an increasing number of use cases related to security where it is</span>
<span class="quote">&gt; necessary to change the attributes of kernel memory. Add functionality</span>
<span class="quote">&gt; to the page attribute changing code under a Kconfig to let systems</span>
<span class="quote">&gt; designers decide if they want to make the trade off of security for TLB</span>
<span class="quote">&gt; pressure.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; v2: Re-worked to account for the full range of addresses. Will also just</span>
<span class="quote">&gt; update the section blocks instead of splitting if the addresses are aligned</span>
<span class="quote">&gt; properly.</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm64/Kconfig       |  12 ++++</span>
<span class="quote">&gt;  arch/arm64/mm/mm.h       |   3 +</span>
<span class="quote">&gt;  arch/arm64/mm/mmu.c      |   2 +-</span>
<span class="quote">&gt;  arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;  4 files changed, 170 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt; index 851fe11..46725e8 100644</span>
<span class="quote">&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt; @@ -521,6 +521,18 @@ config ARCH_HAS_CACHE_LINE_SIZE</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  source &quot;mm/Kconfig&quot;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +config DEBUG_CHANGE_PAGEATTR</span>
<span class="quote">&gt; +	bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="quote">&gt; +	default y</span>
<span class="quote">&gt; +	help</span>
<span class="quote">&gt; +	  If this option is selected, APIs that change page attributes</span>
<span class="quote">&gt; +	  (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="quote">&gt; +	  the kernel space. The trade off is that there may be increased</span>
<span class="quote">&gt; +	  TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="quote">&gt; +	  if security is more important than performance</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	  If in doubt, say Y</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  config SECCOMP</span>
<span class="quote">&gt;  	bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;</span>
<span class="quote">&gt;  	---help---</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt; index ef47d99..7b0dcc4 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/mm.h</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt; @@ -1,3 +1,6 @@</span>
<span class="quote">&gt;  extern void __init bootmem_init(void);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void fixup_init(void);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="quote">&gt; +void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; index 496c3fd..9353e3c 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; @@ -73,7 +73,7 @@ static void __init *early_alloc(unsigned long sz)</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * remap a PMD into pages</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt; +void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned long pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;  	unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt; index 3571c73..4a95fed 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt; @@ -15,25 +15,162 @@</span>
<span class="quote">&gt;  #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -struct page_change_data {</span>
<span class="quote">&gt; -	pgprot_t set_mask;</span>
<span class="quote">&gt; -	pgprot_t clear_mask;</span>
<span class="quote">&gt; -};</span>
<span class="quote">&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="quote">&gt; -			void *data)</span>
<span class="quote">&gt; +static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="quote">&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	struct page_change_data *cdata = data;</span>
<span class="quote">&gt; -	pte_t pte = *ptep;</span>
<span class="quote">&gt; +	pte_t *pte;</span>
<span class="quote">&gt; +	int err = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (pmd_sect(*pmd)) {</span>
<span class="quote">&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt; +			err = -EINVAL;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="quote">&gt; +		if (!pte) {</span>
<span class="quote">&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		split_pmd(pmd, pte);</span>
<span class="quote">&gt; +		__pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; +	if (pte_none(*pte)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		pte_t p = *pte;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		p = clear_pte_bit(p, clear);</span>
<span class="quote">&gt; +		p = set_pte_bit(p, set);</span>
<span class="quote">&gt; +		set_pte(pte, p);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	int err = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (pud_sect(*pud)) {</span>
<span class="quote">&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt; +			err = -EINVAL;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt; +		if (!pmd) {</span>
<span class="quote">&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		split_pud(pud, pmd);</span>
<span class="quote">&gt; +		pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt; -	pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +	if (pmd_none(*pmd)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>

we try to preserve the section area, but the addr | end does not ensure that
physical memory is alignment. In addtion, if numpages cross section area, and
addr points to the physical memory is alignment to the section. In this case,
we should consider to retain the section.
<span class="quote">
&gt; +	do {</span>
<span class="quote">&gt; +		next = pmd_addr_end(addr, end);</span>
<span class="quote">&gt; +		if (((addr | end) &amp; ~SECTION_MASK) == 0) {</span>
<span class="quote">&gt; +			unsigned long paddr = pmd_pfn(*pmd) &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; +			pgprot_t prot = __pgprot((pmd_val(*pmd) ^ paddr));</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="quote">&gt; +			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="quote">&gt; +			set_pmd(pmd, __pmd(paddr | pgprot_val(prot)));</span>
<span class="quote">&gt; +		} else {</span>
<span class="quote">&gt; +			err = update_pte_range(mm, pmd, addr, next, clear, set);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		if (err)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +	} while (pmd++, addr = next, addr != end);</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int update_pud_range(struct mm_struct *mm, pgd_t *pgd,</span>
<span class="quote">&gt; +					unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; +					pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pud_t *pud;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	int err = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +	if (pud_none(*pud)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	set_pte(ptep, pte);</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		next = pud_addr_end(addr, end);</span>
<span class="quote">&gt; +		if (pud_sect(*pud) &amp;&amp; ((addr | next) &amp; ~PUD_MASK) == 0) {</span>
<span class="quote">&gt; +			unsigned long paddr = pud_pfn(*pud) &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; +			pgprot_t prot = __pgprot(pud_val(*pud) ^ paddr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="quote">&gt; +			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="quote">&gt; +			set_pud(pud, __pud(paddr | pgprot_val(prot)));</span>
<span class="quote">&gt; +		} else {</span>
<span class="quote">&gt; +			err = update_pmd_range(mm, pud, addr, next, clear, set);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		if (err)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +	} while (pud++, addr = next, addr != end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int update_page_range(unsigned long addr,</span>
<span class="quote">&gt; +				unsigned long end, pgprot_t clear,</span>
<span class="quote">&gt; +				pgprot_t set)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	int err;</span>
<span class="quote">&gt; +	struct mm_struct *mm = &amp;init_mm;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	BUG_ON(addr &gt;= end);</span>
<span class="quote">&gt; +	pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +	if (pgd_none(*pgd)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		next = pgd_addr_end(addr, end);</span>
<span class="quote">&gt; +		err = update_pud_range(mm, pgd, addr, next, clear, set);</span>
<span class="quote">&gt; +		if (err)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +	} while (pgd++, addr = next, addr != end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt; @@ -43,7 +180,6 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;  	unsigned long size = PAGE_SIZE*numpages;</span>
<span class="quote">&gt;  	unsigned long end = start + size;</span>
<span class="quote">&gt;  	int ret;</span>
<span class="quote">&gt; -	struct page_change_data data;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (!PAGE_ALIGNED(addr)) {</span>
<span class="quote">&gt;  		start &amp;= PAGE_MASK;</span>
<span class="quote">&gt; @@ -51,17 +187,15 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;  		WARN_ON_ONCE(1);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (start &lt; MODULES_VADDR || start &gt;= MODULES_END)</span>
<span class="quote">&gt; +	if (start &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)start) &amp;&amp;</span>
<span class="quote">&gt; +		(start &lt; MODULES_VADDR || start &gt;= MODULES_END))</span>
<span class="quote">&gt;  		return -EINVAL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (end &lt; MODULES_VADDR || end &gt;= MODULES_END)</span>
<span class="quote">&gt; +	if (end &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)end) &amp;&amp;</span>
<span class="quote">&gt; +		(end &lt; MODULES_VADDR || end &gt;= MODULES_END))</span>
<span class="quote">&gt;  		return -EINVAL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	data.set_mask = set_mask;</span>
<span class="quote">&gt; -	data.clear_mask = clear_mask;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	ret = apply_to_page_range(&amp;init_mm, start, size, change_page_range,</span>
<span class="quote">&gt; -					&amp;data);</span>
<span class="quote">&gt; +	ret = update_page_range(addr, end, clear_mask, set_mask);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	flush_tlb_kernel_range(start, end);</span>
<span class="quote">&gt;  	return ret;</span>


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a> - Nov. 12, 2015, 4:31 p.m.</div>
<pre class="content">
On 11/12/2015 03:55 AM, zhong jiang wrote:
<span class="quote">&gt; On 2015/11/11 9:57, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt; Currently, the set_memory_* functions that are implemented for arm64</span>
<span class="quote">&gt;&gt; are restricted to module addresses only. This was mostly done</span>
<span class="quote">&gt;&gt; because arm64 maps normal zone memory with larger page sizes to</span>
<span class="quote">&gt;&gt; improve TLB performance. This has the side effect though of making it</span>
<span class="quote">&gt;&gt; difficult to adjust attributes at the PAGE_SIZE granularity. There are</span>
<span class="quote">&gt;&gt; an increasing number of use cases related to security where it is</span>
<span class="quote">&gt;&gt; necessary to change the attributes of kernel memory. Add functionality</span>
<span class="quote">&gt;&gt; to the page attribute changing code under a Kconfig to let systems</span>
<span class="quote">&gt;&gt; designers decide if they want to make the trade off of security for TLB</span>
<span class="quote">&gt;&gt; pressure.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt; v2: Re-worked to account for the full range of addresses. Will also just</span>
<span class="quote">&gt;&gt; update the section blocks instead of splitting if the addresses are aligned</span>
<span class="quote">&gt;&gt; properly.</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   arch/arm64/Kconfig       |  12 ++++</span>
<span class="quote">&gt;&gt;   arch/arm64/mm/mm.h       |   3 +</span>
<span class="quote">&gt;&gt;   arch/arm64/mm/mmu.c      |   2 +-</span>
<span class="quote">&gt;&gt;   arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;&gt;   4 files changed, 170 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; index 851fe11..46725e8 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; @@ -521,6 +521,18 @@ config ARCH_HAS_CACHE_LINE_SIZE</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   source &quot;mm/Kconfig&quot;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +config DEBUG_CHANGE_PAGEATTR</span>
<span class="quote">&gt;&gt; +	bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="quote">&gt;&gt; +	default y</span>
<span class="quote">&gt;&gt; +	help</span>
<span class="quote">&gt;&gt; +	  If this option is selected, APIs that change page attributes</span>
<span class="quote">&gt;&gt; +	  (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="quote">&gt;&gt; +	  the kernel space. The trade off is that there may be increased</span>
<span class="quote">&gt;&gt; +	  TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="quote">&gt;&gt; +	  if security is more important than performance</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	  If in doubt, say Y</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   config SECCOMP</span>
<span class="quote">&gt;&gt;   	bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;</span>
<span class="quote">&gt;&gt;   	---help---</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt; index ef47d99..7b0dcc4 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt; @@ -1,3 +1,6 @@</span>
<span class="quote">&gt;&gt;   extern void __init bootmem_init(void);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   void fixup_init(void);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="quote">&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; index 496c3fd..9353e3c 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; @@ -73,7 +73,7 @@ static void __init *early_alloc(unsigned long sz)</span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;    * remap a PMD into pages</span>
<span class="quote">&gt;&gt;    */</span>
<span class="quote">&gt;&gt; -static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;   	unsigned long pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;&gt;   	unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt; index 3571c73..4a95fed 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt; @@ -15,25 +15,162 @@</span>
<span class="quote">&gt;&gt;   #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -struct page_change_data {</span>
<span class="quote">&gt;&gt; -	pgprot_t set_mask;</span>
<span class="quote">&gt;&gt; -	pgprot_t clear_mask;</span>
<span class="quote">&gt;&gt; -};</span>
<span class="quote">&gt;&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="quote">&gt;&gt; -			void *data)</span>
<span class="quote">&gt;&gt; +static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="quote">&gt;&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt; -	struct page_change_data *cdata = data;</span>
<span class="quote">&gt;&gt; -	pte_t pte = *ptep;</span>
<span class="quote">&gt;&gt; +	pte_t *pte;</span>
<span class="quote">&gt;&gt; +	int err = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (pmd_sect(*pmd)) {</span>
<span class="quote">&gt;&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt; +			err = -EINVAL;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt; +		if (!pte) {</span>
<span class="quote">&gt;&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		split_pmd(pmd, pte);</span>
<span class="quote">&gt;&gt; +		__pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt;&gt; +	if (pte_none(*pte)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		pte_t p = *pte;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		p = clear_pte_bit(p, clear);</span>
<span class="quote">&gt;&gt; +		p = set_pte_bit(p, set);</span>
<span class="quote">&gt;&gt; +		set_pte(pte, p);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +out:</span>
<span class="quote">&gt;&gt; +	return err;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +	unsigned long next;</span>
<span class="quote">&gt;&gt; +	int err = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (pud_sect(*pud)) {</span>
<span class="quote">&gt;&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt; +			err = -EINVAL;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt; +		if (!pmd) {</span>
<span class="quote">&gt;&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		split_pud(pud, pmd);</span>
<span class="quote">&gt;&gt; +		pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -	pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt;&gt; -	pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt;&gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt; +	if (pmd_none(*pmd)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; we try to preserve the section area, but the addr | end does not ensure that</span>
<span class="quote">&gt; physical memory is alignment. In addtion, if numpages cross section area, and</span>
<span class="quote">&gt; addr points to the physical memory is alignment to the section. In this case,</span>
<span class="quote">&gt; we should consider to retain the section.</span>
<span class="quote">&gt;</span>

I&#39;m not sure what physical memory you are referring to here. The mapping is
already set up so if there is a section mapping we know the physical memory
is going to be set up to be a section size. We aren&#39;t setting up a new mapping
for the physical address so there is no need to check that again. The only
way to get the physical address would be to read it out of the section
entry which wouldn&#39;t give any more information.

I&#39;m also not sure what you are referring to with numpages crossing a section
area. In update_pud_range and update_pmd_range there are checks if a
section can be used. If it can, it updates. The split action is only called
if it isn&#39;t aligned. The loop ensures this will happen across all possible
sections.

Thanks,
Laura

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=146341">zhong jiang</a> - Nov. 13, 2015, 2:05 a.m.</div>
<pre class="content">
On 2015/11/13 0:31, Laura Abbott wrote:
<span class="quote">&gt; On 11/12/2015 03:55 AM, zhong jiang wrote:</span>
<span class="quote">&gt;&gt; On 2015/11/11 9:57, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt;&gt; Currently, the set_memory_* functions that are implemented for arm64</span>
<span class="quote">&gt;&gt;&gt; are restricted to module addresses only. This was mostly done</span>
<span class="quote">&gt;&gt;&gt; because arm64 maps normal zone memory with larger page sizes to</span>
<span class="quote">&gt;&gt;&gt; improve TLB performance. This has the side effect though of making it</span>
<span class="quote">&gt;&gt;&gt; difficult to adjust attributes at the PAGE_SIZE granularity. There are</span>
<span class="quote">&gt;&gt;&gt; an increasing number of use cases related to security where it is</span>
<span class="quote">&gt;&gt;&gt; necessary to change the attributes of kernel memory. Add functionality</span>
<span class="quote">&gt;&gt;&gt; to the page attribute changing code under a Kconfig to let systems</span>
<span class="quote">&gt;&gt;&gt; designers decide if they want to make the trade off of security for TLB</span>
<span class="quote">&gt;&gt;&gt; pressure.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
<span class="quote">&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt; v2: Re-worked to account for the full range of addresses. Will also just</span>
<span class="quote">&gt;&gt;&gt; update the section blocks instead of splitting if the addresses are aligned</span>
<span class="quote">&gt;&gt;&gt; properly.</span>
<span class="quote">&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt;   arch/arm64/Kconfig       |  12 ++++</span>
<span class="quote">&gt;&gt;&gt;   arch/arm64/mm/mm.h       |   3 +</span>
<span class="quote">&gt;&gt;&gt;   arch/arm64/mm/mmu.c      |   2 +-</span>
<span class="quote">&gt;&gt;&gt;   arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;&gt;&gt;   4 files changed, 170 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt;&gt; index 851fe11..46725e8 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt;&gt; @@ -521,6 +521,18 @@ config ARCH_HAS_CACHE_LINE_SIZE</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;   source &quot;mm/Kconfig&quot;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +config DEBUG_CHANGE_PAGEATTR</span>
<span class="quote">&gt;&gt;&gt; +    bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="quote">&gt;&gt;&gt; +    default y</span>
<span class="quote">&gt;&gt;&gt; +    help</span>
<span class="quote">&gt;&gt;&gt; +      If this option is selected, APIs that change page attributes</span>
<span class="quote">&gt;&gt;&gt; +      (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="quote">&gt;&gt;&gt; +      the kernel space. The trade off is that there may be increased</span>
<span class="quote">&gt;&gt;&gt; +      TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="quote">&gt;&gt;&gt; +      if security is more important than performance</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +      If in doubt, say Y</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;   config SECCOMP</span>
<span class="quote">&gt;&gt;&gt;       bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;</span>
<span class="quote">&gt;&gt;&gt;       ---help---</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt;&gt; index ef47d99..7b0dcc4 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt;&gt; @@ -1,3 +1,6 @@</span>
<span class="quote">&gt;&gt;&gt;   extern void __init bootmem_init(void);</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;   void fixup_init(void);</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="quote">&gt;&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt;&gt; index 496c3fd..9353e3c 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt;&gt; @@ -73,7 +73,7 @@ static void __init *early_alloc(unsigned long sz)</span>
<span class="quote">&gt;&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;&gt;    * remap a PMD into pages</span>
<span class="quote">&gt;&gt;&gt;    */</span>
<span class="quote">&gt;&gt;&gt; -static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt;&gt;   {</span>
<span class="quote">&gt;&gt;&gt;       unsigned long pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;&gt;&gt;       unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt;&gt; index 3571c73..4a95fed 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt;&gt; @@ -15,25 +15,162 @@</span>
<span class="quote">&gt;&gt;&gt;   #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt;&gt;&gt;   #include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt;&gt;&gt;   #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;&gt;&gt;   #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; -struct page_change_data {</span>
<span class="quote">&gt;&gt;&gt; -    pgprot_t set_mask;</span>
<span class="quote">&gt;&gt;&gt; -    pgprot_t clear_mask;</span>
<span class="quote">&gt;&gt;&gt; -};</span>
<span class="quote">&gt;&gt;&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; -static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="quote">&gt;&gt;&gt; -            void *data)</span>
<span class="quote">&gt;&gt;&gt; +static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="quote">&gt;&gt;&gt; +                unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt;&gt; +                pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt;&gt;   {</span>
<span class="quote">&gt;&gt;&gt; -    struct page_change_data *cdata = data;</span>
<span class="quote">&gt;&gt;&gt; -    pte_t pte = *ptep;</span>
<span class="quote">&gt;&gt;&gt; +    pte_t *pte;</span>
<span class="quote">&gt;&gt;&gt; +    int err = 0;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +    if (pmd_sect(*pmd)) {</span>
<span class="quote">&gt;&gt;&gt; +        if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt;&gt; +            err = -EINVAL;</span>
<span class="quote">&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt; +        pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt;&gt; +        if (!pte) {</span>
<span class="quote">&gt;&gt;&gt; +            err = -ENOMEM;</span>
<span class="quote">&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt; +        split_pmd(pmd, pte);</span>
<span class="quote">&gt;&gt;&gt; +        __pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="quote">&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +    pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt;&gt;&gt; +    if (pte_none(*pte)) {</span>
<span class="quote">&gt;&gt;&gt; +        err = -EFAULT;</span>
<span class="quote">&gt;&gt;&gt; +        goto out;</span>
<span class="quote">&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +    do {</span>
<span class="quote">&gt;&gt;&gt; +        pte_t p = *pte;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +        p = clear_pte_bit(p, clear);</span>
<span class="quote">&gt;&gt;&gt; +        p = set_pte_bit(p, set);</span>
<span class="quote">&gt;&gt;&gt; +        set_pte(pte, p);</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +    } while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +out:</span>
<span class="quote">&gt;&gt;&gt; +    return err;</span>
<span class="quote">&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;&gt;&gt; +                unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt;&gt; +                pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt; +    pmd_t *pmd;</span>
<span class="quote">&gt;&gt;&gt; +    unsigned long next;</span>
<span class="quote">&gt;&gt;&gt; +    int err = 0;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +    if (pud_sect(*pud)) {</span>
<span class="quote">&gt;&gt;&gt; +        if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt;&gt; +            err = -EINVAL;</span>
<span class="quote">&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt; +        pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt;&gt; +        if (!pmd) {</span>
<span class="quote">&gt;&gt;&gt; +            err = -ENOMEM;</span>
<span class="quote">&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt; +        split_pud(pud, pmd);</span>
<span class="quote">&gt;&gt;&gt; +        pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; -    pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt;&gt;&gt; -    pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt;&gt;&gt; +    pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt;&gt; +    if (pmd_none(*pmd)) {</span>
<span class="quote">&gt;&gt;&gt; +        err = -EFAULT;</span>
<span class="quote">&gt;&gt;&gt; +        goto out;</span>
<span class="quote">&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; we try to preserve the section area, but the addr | end does not ensure that</span>
<span class="quote">&gt;&gt; physical memory is alignment. In addtion, if numpages cross section area, and</span>
<span class="quote">&gt;&gt; addr points to the physical memory is alignment to the section. In this case,</span>
<span class="quote">&gt;&gt; we should consider to retain the section.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;m not sure what physical memory you are referring to here. The mapping is</span>
<span class="quote">&gt; already set up so if there is a section mapping we know the physical memory</span>
<span class="quote">&gt; is going to be set up to be a section size. We aren&#39;t setting up a new mapping</span>
<span class="quote">&gt; for the physical address so there is no need to check that again. The only</span>
<span class="quote">&gt; way to get the physical address would be to read it out of the section</span>
<span class="quote">&gt; entry which wouldn&#39;t give any more information.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;m also not sure what you are referring to with numpages crossing a section</span>
<span class="quote">&gt; area. In update_pud_range and update_pmd_range there are checks if a</span>
<span class="quote">&gt; section can be used. If it can, it updates. The split action is only called</span>
<span class="quote">&gt; if it isn&#39;t aligned. The loop ensures this will happen across all possible</span>
<span class="quote">&gt; sections.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks,</span>
<span class="quote">&gt; Laura</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  </span>

Hi Laura

In pmd_update_range, Is the pmd pointing to large page if addr is alignment ?
I mean that whether it need to add pmd_sect() to guarantee.

Thanks
zhongjiang


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=146341">zhong jiang</a> - Nov. 13, 2015, 2:37 a.m.</div>
<pre class="content">
On 2015/11/12 19:55, zhong jiang wrote:
<span class="quote">&gt; On 2015/11/11 9:57, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt; Currently, the set_memory_* functions that are implemented for arm64</span>
<span class="quote">&gt;&gt; are restricted to module addresses only. This was mostly done</span>
<span class="quote">&gt;&gt; because arm64 maps normal zone memory with larger page sizes to</span>
<span class="quote">&gt;&gt; improve TLB performance. This has the side effect though of making it</span>
<span class="quote">&gt;&gt; difficult to adjust attributes at the PAGE_SIZE granularity. There are</span>
<span class="quote">&gt;&gt; an increasing number of use cases related to security where it is</span>
<span class="quote">&gt;&gt; necessary to change the attributes of kernel memory. Add functionality</span>
<span class="quote">&gt;&gt; to the page attribute changing code under a Kconfig to let systems</span>
<span class="quote">&gt;&gt; designers decide if they want to make the trade off of security for TLB</span>
<span class="quote">&gt;&gt; pressure.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt; v2: Re-worked to account for the full range of addresses. Will also just</span>
<span class="quote">&gt;&gt; update the section blocks instead of splitting if the addresses are aligned</span>
<span class="quote">&gt;&gt; properly.</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  arch/arm64/Kconfig       |  12 ++++</span>
<span class="quote">&gt;&gt;  arch/arm64/mm/mm.h       |   3 +</span>
<span class="quote">&gt;&gt;  arch/arm64/mm/mmu.c      |   2 +-</span>
<span class="quote">&gt;&gt;  arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;&gt;  4 files changed, 170 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; index 851fe11..46725e8 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; @@ -521,6 +521,18 @@ config ARCH_HAS_CACHE_LINE_SIZE</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  source &quot;mm/Kconfig&quot;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +config DEBUG_CHANGE_PAGEATTR</span>
<span class="quote">&gt;&gt; +	bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="quote">&gt;&gt; +	default y</span>
<span class="quote">&gt;&gt; +	help</span>
<span class="quote">&gt;&gt; +	  If this option is selected, APIs that change page attributes</span>
<span class="quote">&gt;&gt; +	  (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="quote">&gt;&gt; +	  the kernel space. The trade off is that there may be increased</span>
<span class="quote">&gt;&gt; +	  TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="quote">&gt;&gt; +	  if security is more important than performance</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	  If in doubt, say Y</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  config SECCOMP</span>
<span class="quote">&gt;&gt;  	bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;</span>
<span class="quote">&gt;&gt;  	---help---</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt; index ef47d99..7b0dcc4 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt; @@ -1,3 +1,6 @@</span>
<span class="quote">&gt;&gt;  extern void __init bootmem_init(void);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  void fixup_init(void);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="quote">&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; index 496c3fd..9353e3c 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; @@ -73,7 +73,7 @@ static void __init *early_alloc(unsigned long sz)</span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * remap a PMD into pages</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt; -static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;  	unsigned long pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;&gt;  	unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt; index 3571c73..4a95fed 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt; @@ -15,25 +15,162 @@</span>
<span class="quote">&gt;&gt;  #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -struct page_change_data {</span>
<span class="quote">&gt;&gt; -	pgprot_t set_mask;</span>
<span class="quote">&gt;&gt; -	pgprot_t clear_mask;</span>
<span class="quote">&gt;&gt; -};</span>
<span class="quote">&gt;&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="quote">&gt;&gt; -			void *data)</span>
<span class="quote">&gt;&gt; +static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="quote">&gt;&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt; -	struct page_change_data *cdata = data;</span>
<span class="quote">&gt;&gt; -	pte_t pte = *ptep;</span>
<span class="quote">&gt;&gt; +	pte_t *pte;</span>
<span class="quote">&gt;&gt; +	int err = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (pmd_sect(*pmd)) {</span>
<span class="quote">&gt;&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt; +			err = -EINVAL;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt; +		if (!pte) {</span>
<span class="quote">&gt;&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		split_pmd(pmd, pte);</span>
<span class="quote">&gt;&gt; +		__pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt;&gt; +	if (pte_none(*pte)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		pte_t p = *pte;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		p = clear_pte_bit(p, clear);</span>
<span class="quote">&gt;&gt; +		p = set_pte_bit(p, set);</span>
<span class="quote">&gt;&gt; +		set_pte(pte, p);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +out:</span>
<span class="quote">&gt;&gt; +	return err;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +	unsigned long next;</span>
<span class="quote">&gt;&gt; +	int err = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (pud_sect(*pud)) {</span>
<span class="quote">&gt;&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt; +			err = -EINVAL;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt; +		if (!pmd) {</span>
<span class="quote">&gt;&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		split_pud(pud, pmd);</span>
<span class="quote">&gt;&gt; +		pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt;&gt; -	pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt;&gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt; +	if (pmd_none(*pmd)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; we try to preserve the section area, but the addr | end does not ensure that</span>
<span class="quote">&gt; physical memory is alignment. In addtion, if numpages cross section area, and</span>
<span class="quote">&gt; addr points to the physical memory is alignment to the section. In this case,</span>
<span class="quote">&gt; we should consider to retain the section.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		next = pmd_addr_end(addr, end);</span>
<span class="quote">&gt;&gt; +		if (((addr | end) &amp; ~SECTION_MASK) == 0) {</span>
<span class="quote">&gt;&gt; +			unsigned long paddr = pmd_pfn(*pmd) &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; +			pgprot_t prot = __pgprot((pmd_val(*pmd) ^ paddr));</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="quote">&gt;&gt; +			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="quote">&gt;&gt; +			set_pmd(pmd, __pmd(paddr | pgprot_val(prot)));</span>
<span class="quote">&gt;&gt; +		} else {</span>
<span class="quote">&gt;&gt; +			err = update_pte_range(mm, pmd, addr, next, clear, set);</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		if (err)</span>
<span class="quote">&gt;&gt; +			break;</span>
<span class="quote">&gt;&gt; +	} while (pmd++, addr = next, addr != end);</span>
<span class="quote">&gt;&gt; +out:</span>
<span class="quote">&gt;&gt; +	return err;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int update_pud_range(struct mm_struct *mm, pgd_t *pgd,</span>
<span class="quote">&gt;&gt; +					unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; +					pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pud_t *pud;</span>
<span class="quote">&gt;&gt; +	unsigned long next;</span>
<span class="quote">&gt;&gt; +	int err = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt;&gt; +	if (pud_none(*pud)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	set_pte(ptep, pte);</span>
<span class="quote">&gt;&gt; -	return 0;</span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		next = pud_addr_end(addr, end);</span>
<span class="quote">&gt;&gt; +		if (pud_sect(*pud) &amp;&amp; ((addr | next) &amp; ~PUD_MASK) == 0) {</span>
<span class="quote">&gt;&gt; +			unsigned long paddr = pud_pfn(*pud) &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; +			pgprot_t prot = __pgprot(pud_val(*pud) ^ paddr);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="quote">&gt;&gt; +			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="quote">&gt;&gt; +			set_pud(pud, __pud(paddr | pgprot_val(prot)));</span>
<span class="quote">&gt;&gt; +		} else {</span>
<span class="quote">&gt;&gt; +			err = update_pmd_range(mm, pud, addr, next, clear, set);</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		if (err)</span>
<span class="quote">&gt;&gt; +			break;</span>
<span class="quote">&gt;&gt; +	} while (pud++, addr = next, addr != end);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +out:</span>
<span class="quote">&gt;&gt; +	return err;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int update_page_range(unsigned long addr,</span>
<span class="quote">&gt;&gt; +				unsigned long end, pgprot_t clear,</span>
<span class="quote">&gt;&gt; +				pgprot_t set)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt;&gt; +	unsigned long next;</span>
<span class="quote">&gt;&gt; +	int err;</span>
<span class="quote">&gt;&gt; +	struct mm_struct *mm = &amp;init_mm;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	BUG_ON(addr &gt;= end);</span>
<span class="quote">&gt;&gt; +	pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +	if (pgd_none(*pgd)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		next = pgd_addr_end(addr, end);</span>
<span class="quote">&gt;&gt; +		err = update_pud_range(mm, pgd, addr, next, clear, set);</span>
<span class="quote">&gt;&gt; +		if (err)</span>
<span class="quote">&gt;&gt; +			break;</span>
<span class="quote">&gt;&gt; +	} while (pgd++, addr = next, addr != end);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +out:</span>
<span class="quote">&gt;&gt; +	return err;</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;&gt; @@ -43,7 +180,6 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;&gt;  	unsigned long size = PAGE_SIZE*numpages;</span>
<span class="quote">&gt;&gt;  	unsigned long end = start + size;</span>
<span class="quote">&gt;&gt;  	int ret;</span>
<span class="quote">&gt;&gt; -	struct page_change_data data;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	if (!PAGE_ALIGNED(addr)) {</span>
<span class="quote">&gt;&gt;  		start &amp;= PAGE_MASK;</span>
<span class="quote">&gt;&gt; @@ -51,17 +187,15 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;&gt;  		WARN_ON_ONCE(1);</span>
<span class="quote">&gt;&gt;  	}</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	if (start &lt; MODULES_VADDR || start &gt;= MODULES_END)</span>
<span class="quote">&gt;&gt; +	if (start &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)start) &amp;&amp;</span>
<span class="quote">&gt;&gt; +		(start &lt; MODULES_VADDR || start &gt;= MODULES_END))</span>
<span class="quote">&gt;&gt;  		return -EINVAL;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	if (end &lt; MODULES_VADDR || end &gt;= MODULES_END)</span>
<span class="quote">&gt;&gt; +	if (end &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)end) &amp;&amp;</span>
<span class="quote">&gt;&gt; +		(end &lt; MODULES_VADDR || end &gt;= MODULES_END))</span>
<span class="quote">&gt;&gt;  		return -EINVAL;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	data.set_mask = set_mask;</span>
<span class="quote">&gt;&gt; -	data.clear_mask = clear_mask;</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -	ret = apply_to_page_range(&amp;init_mm, start, size, change_page_range,</span>
<span class="quote">&gt;&gt; -					&amp;data);</span>
<span class="quote">&gt;&gt; +	ret = update_page_range(addr, end, clear_mask, set_mask);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	flush_tlb_kernel_range(start, end);</span>
<span class="quote">&gt;&gt;  	return ret;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in</span>
<span class="quote">&gt; the body of a message to majordomo@vger.kernel.org</span>
<span class="quote">&gt; More majordomo info at  http://vger.kernel.org/majordomo-info.html</span>
<span class="quote">&gt; Please read the FAQ at  http://www.tux.org/lkml/</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; .</span>
<span class="quote">&gt; </span>

Hi Laura

In change_memory_common, why the address is  so restricted ?


Thanks
zhongjiang


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=55031">Xishi Qiu</a> - Nov. 13, 2015, 8:27 a.m.</div>
<pre class="content">
On 2015/11/11 9:57, Laura Abbott wrote:
<span class="quote">
&gt; Currently, the set_memory_* functions that are implemented for arm64</span>
<span class="quote">&gt; are restricted to module addresses only. This was mostly done</span>
<span class="quote">&gt; because arm64 maps normal zone memory with larger page sizes to</span>
<span class="quote">&gt; improve TLB performance. This has the side effect though of making it</span>
<span class="quote">&gt; difficult to adjust attributes at the PAGE_SIZE granularity. There are</span>
<span class="quote">&gt; an increasing number of use cases related to security where it is</span>
<span class="quote">&gt; necessary to change the attributes of kernel memory. Add functionality</span>
<span class="quote">&gt; to the page attribute changing code under a Kconfig to let systems</span>
<span class="quote">&gt; designers decide if they want to make the trade off of security for TLB</span>
<span class="quote">&gt; pressure.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; v2: Re-worked to account for the full range of addresses. Will also just</span>
<span class="quote">&gt; update the section blocks instead of splitting if the addresses are aligned</span>
<span class="quote">&gt; properly.</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm64/Kconfig       |  12 ++++</span>
<span class="quote">&gt;  arch/arm64/mm/mm.h       |   3 +</span>
<span class="quote">&gt;  arch/arm64/mm/mmu.c      |   2 +-</span>
<span class="quote">&gt;  arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;  4 files changed, 170 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt; index 851fe11..46725e8 100644</span>
<span class="quote">&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt; @@ -521,6 +521,18 @@ config ARCH_HAS_CACHE_LINE_SIZE</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  source &quot;mm/Kconfig&quot;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +config DEBUG_CHANGE_PAGEATTR</span>
<span class="quote">&gt; +	bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="quote">&gt; +	default y</span>
<span class="quote">&gt; +	help</span>
<span class="quote">&gt; +	  If this option is selected, APIs that change page attributes</span>
<span class="quote">&gt; +	  (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="quote">&gt; +	  the kernel space. The trade off is that there may be increased</span>
<span class="quote">&gt; +	  TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="quote">&gt; +	  if security is more important than performance</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	  If in doubt, say Y</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  config SECCOMP</span>
<span class="quote">&gt;  	bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;</span>
<span class="quote">&gt;  	---help---</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt; index ef47d99..7b0dcc4 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/mm.h</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt; @@ -1,3 +1,6 @@</span>
<span class="quote">&gt;  extern void __init bootmem_init(void);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void fixup_init(void);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="quote">&gt; +void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; index 496c3fd..9353e3c 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; @@ -73,7 +73,7 @@ static void __init *early_alloc(unsigned long sz)</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * remap a PMD into pages</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt; +void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned long pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;  	unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt; index 3571c73..4a95fed 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt; @@ -15,25 +15,162 @@</span>
<span class="quote">&gt;  #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -struct page_change_data {</span>
<span class="quote">&gt; -	pgprot_t set_mask;</span>
<span class="quote">&gt; -	pgprot_t clear_mask;</span>
<span class="quote">&gt; -};</span>
<span class="quote">&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="quote">&gt; -			void *data)</span>
<span class="quote">&gt; +static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="quote">&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	struct page_change_data *cdata = data;</span>
<span class="quote">&gt; -	pte_t pte = *ptep;</span>
<span class="quote">&gt; +	pte_t *pte;</span>
<span class="quote">&gt; +	int err = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (pmd_sect(*pmd)) {</span>
<span class="quote">&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt; +			err = -EINVAL;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="quote">&gt; +		if (!pte) {</span>
<span class="quote">&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		split_pmd(pmd, pte);</span>
<span class="quote">&gt; +		__pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; +	if (pte_none(*pte)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		pte_t p = *pte;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		p = clear_pte_bit(p, clear);</span>
<span class="quote">&gt; +		p = set_pte_bit(p, set);</span>
<span class="quote">&gt; +		set_pte(pte, p);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	int err = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (pud_sect(*pud)) {</span>
<span class="quote">&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt; +			err = -EINVAL;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt; +		if (!pmd) {</span>
<span class="quote">&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		split_pud(pud, pmd);</span>
<span class="quote">&gt; +		pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt; -	pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +	if (pmd_none(*pmd)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		next = pmd_addr_end(addr, end);</span>
<span class="quote">&gt; +		if (((addr | end) &amp; ~SECTION_MASK) == 0) {</span>

Hi Laura,

Why not like this?
		if (pmd_sect(*pmd) &amp;&amp; ((addr | nest) &amp; ~SECTION_MASK) == 0) {
<span class="quote">
&gt; +			unsigned long paddr = pmd_pfn(*pmd) &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; +			pgprot_t prot = __pgprot((pmd_val(*pmd) ^ paddr));</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="quote">&gt; +			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="quote">&gt; +			set_pmd(pmd, __pmd(paddr | pgprot_val(prot)));</span>
<span class="quote">&gt; +		} else {</span>
<span class="quote">&gt; +			err = update_pte_range(mm, pmd, addr, next, clear, set);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		if (err)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +	} while (pmd++, addr = next, addr != end);</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int update_pud_range(struct mm_struct *mm, pgd_t *pgd,</span>
<span class="quote">&gt; +					unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; +					pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pud_t *pud;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	int err = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +	if (pud_none(*pud)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	set_pte(ptep, pte);</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		next = pud_addr_end(addr, end);</span>
<span class="quote">&gt; +		if (pud_sect(*pud) &amp;&amp; ((addr | next) &amp; ~PUD_MASK) == 0) {</span>
<span class="quote">&gt; +			unsigned long paddr = pud_pfn(*pud) &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; +			pgprot_t prot = __pgprot(pud_val(*pud) ^ paddr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="quote">&gt; +			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="quote">&gt; +			set_pud(pud, __pud(paddr | pgprot_val(prot)));</span>
<span class="quote">&gt; +		} else {</span>
<span class="quote">&gt; +			err = update_pmd_range(mm, pud, addr, next, clear, set);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		if (err)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +	} while (pud++, addr = next, addr != end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int update_page_range(unsigned long addr,</span>
<span class="quote">&gt; +				unsigned long end, pgprot_t clear,</span>
<span class="quote">&gt; +				pgprot_t set)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	int err;</span>
<span class="quote">&gt; +	struct mm_struct *mm = &amp;init_mm;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	BUG_ON(addr &gt;= end);</span>
<span class="quote">&gt; +	pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +	if (pgd_none(*pgd)) {</span>
<span class="quote">&gt; +		err = -EFAULT;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		next = pgd_addr_end(addr, end);</span>
<span class="quote">&gt; +		err = update_pud_range(mm, pgd, addr, next, clear, set);</span>
<span class="quote">&gt; +		if (err)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +	} while (pgd++, addr = next, addr != end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	return err;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt; @@ -43,7 +180,6 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;  	unsigned long size = PAGE_SIZE*numpages;</span>
<span class="quote">&gt;  	unsigned long end = start + size;</span>
<span class="quote">&gt;  	int ret;</span>
<span class="quote">&gt; -	struct page_change_data data;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (!PAGE_ALIGNED(addr)) {</span>
<span class="quote">&gt;  		start &amp;= PAGE_MASK;</span>
<span class="quote">&gt; @@ -51,17 +187,15 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;  		WARN_ON_ONCE(1);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (start &lt; MODULES_VADDR || start &gt;= MODULES_END)</span>
<span class="quote">&gt; +	if (start &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)start) &amp;&amp;</span>
<span class="quote">&gt; +		(start &lt; MODULES_VADDR || start &gt;= MODULES_END))</span>

How about abstracting &quot;start &lt; MODULES_VADDR || start &gt;= MODULES_END&quot; to a new function?
e.g. is_module_addr(), however it is a little confusion with is_module_address().
<span class="quote">
&gt;  		return -EINVAL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (end &lt; MODULES_VADDR || end &gt;= MODULES_END)</span>
<span class="quote">&gt; +	if (end &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)end) &amp;&amp;</span>
<span class="quote">&gt; +		(end &lt; MODULES_VADDR || end &gt;= MODULES_END))</span>
<span class="quote">&gt;  		return -EINVAL;</span>
<span class="quote">&gt;  </span>

It will not filter this case, start in module range and end in vmalloc range, right?
start and end should be both in one range.

Thanks,
Xishi Qiu
<span class="quote">
&gt; -	data.set_mask = set_mask;</span>
<span class="quote">&gt; -	data.clear_mask = clear_mask;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	ret = apply_to_page_range(&amp;init_mm, start, size, change_page_range,</span>
<span class="quote">&gt; -					&amp;data);</span>
<span class="quote">&gt; +	ret = update_page_range(addr, end, clear_mask, set_mask);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	flush_tlb_kernel_range(start, end);</span>
<span class="quote">&gt;  	return ret;</span>



--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=55031">Xishi Qiu</a> - Nov. 13, 2015, 8:32 a.m.</div>
<pre class="content">
<span class="quote">&gt;&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;&gt; +				unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; +				pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +	unsigned long next;</span>
<span class="quote">&gt;&gt; +	int err = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (pud_sect(*pud)) {</span>
<span class="quote">&gt;&gt; +		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt; +			err = -EINVAL;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt; +		if (!pmd) {</span>
<span class="quote">&gt;&gt; +			err = -ENOMEM;</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		split_pud(pud, pmd);</span>
<span class="quote">&gt;&gt; +		pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt;&gt; -	pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt;&gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt; +	if (pmd_none(*pmd)) {</span>
<span class="quote">&gt;&gt; +		err = -EFAULT;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		next = pmd_addr_end(addr, end);</span>
<span class="quote">&gt;&gt; +		if (((addr | end) &amp; ~SECTION_MASK) == 0) {</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hi Laura,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why not like this?</span>
<span class="quote">&gt; 		if (pmd_sect(*pmd) &amp;&amp; ((addr | nest) &amp; ~SECTION_MASK) == 0) {</span>

Sorry, typo error, nest -&gt; next


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a> - Nov. 13, 2015, 7:05 p.m.</div>
<pre class="content">
On 11/12/2015 06:05 PM, zhong jiang wrote:
<span class="quote">&gt; On 2015/11/13 0:31, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt; On 11/12/2015 03:55 AM, zhong jiang wrote:</span>
<span class="quote">&gt;&gt;&gt; On 2015/11/11 9:57, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; Currently, the set_memory_* functions that are implemented for arm64</span>
<span class="quote">&gt;&gt;&gt;&gt; are restricted to module addresses only. This was mostly done</span>
<span class="quote">&gt;&gt;&gt;&gt; because arm64 maps normal zone memory with larger page sizes to</span>
<span class="quote">&gt;&gt;&gt;&gt; improve TLB performance. This has the side effect though of making it</span>
<span class="quote">&gt;&gt;&gt;&gt; difficult to adjust attributes at the PAGE_SIZE granularity. There are</span>
<span class="quote">&gt;&gt;&gt;&gt; an increasing number of use cases related to security where it is</span>
<span class="quote">&gt;&gt;&gt;&gt; necessary to change the attributes of kernel memory. Add functionality</span>
<span class="quote">&gt;&gt;&gt;&gt; to the page attribute changing code under a Kconfig to let systems</span>
<span class="quote">&gt;&gt;&gt;&gt; designers decide if they want to make the trade off of security for TLB</span>
<span class="quote">&gt;&gt;&gt;&gt; pressure.</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt;&gt; v2: Re-worked to account for the full range of addresses. Will also just</span>
<span class="quote">&gt;&gt;&gt;&gt; update the section blocks instead of splitting if the addresses are aligned</span>
<span class="quote">&gt;&gt;&gt;&gt; properly.</span>
<span class="quote">&gt;&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt;&gt;    arch/arm64/Kconfig       |  12 ++++</span>
<span class="quote">&gt;&gt;&gt;&gt;    arch/arm64/mm/mm.h       |   3 +</span>
<span class="quote">&gt;&gt;&gt;&gt;    arch/arm64/mm/mmu.c      |   2 +-</span>
<span class="quote">&gt;&gt;&gt;&gt;    arch/arm64/mm/pageattr.c | 174 +++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;&gt;&gt;&gt;    4 files changed, 170 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt;&gt;&gt; index 851fe11..46725e8 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -521,6 +521,18 @@ config ARCH_HAS_CACHE_LINE_SIZE</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;    source &quot;mm/Kconfig&quot;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; +config DEBUG_CHANGE_PAGEATTR</span>
<span class="quote">&gt;&gt;&gt;&gt; +    bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    default y</span>
<span class="quote">&gt;&gt;&gt;&gt; +    help</span>
<span class="quote">&gt;&gt;&gt;&gt; +      If this option is selected, APIs that change page attributes</span>
<span class="quote">&gt;&gt;&gt;&gt; +      (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="quote">&gt;&gt;&gt;&gt; +      the kernel space. The trade off is that there may be increased</span>
<span class="quote">&gt;&gt;&gt;&gt; +      TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="quote">&gt;&gt;&gt;&gt; +      if security is more important than performance</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +      If in doubt, say Y</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt;    config SECCOMP</span>
<span class="quote">&gt;&gt;&gt;&gt;        bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;</span>
<span class="quote">&gt;&gt;&gt;&gt;        ---help---</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt;&gt;&gt; index ef47d99..7b0dcc4 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/arm64/mm/mm.h</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -1,3 +1,6 @@</span>
<span class="quote">&gt;&gt;&gt;&gt;    extern void __init bootmem_init(void);</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;    void fixup_init(void);</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="quote">&gt;&gt;&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index 496c3fd..9353e3c 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -73,7 +73,7 @@ static void __init *early_alloc(unsigned long sz)</span>
<span class="quote">&gt;&gt;&gt;&gt;    /*</span>
<span class="quote">&gt;&gt;&gt;&gt;     * remap a PMD into pages</span>
<span class="quote">&gt;&gt;&gt;&gt;     */</span>
<span class="quote">&gt;&gt;&gt;&gt; -static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt;&gt;&gt; +void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="quote">&gt;&gt;&gt;&gt;    {</span>
<span class="quote">&gt;&gt;&gt;&gt;        unsigned long pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;&gt;&gt;&gt;        unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index 3571c73..4a95fed 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/arm64/mm/pageattr.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -15,25 +15,162 @@</span>
<span class="quote">&gt;&gt;&gt;&gt;    #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;    #include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;    #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;    #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; -struct page_change_data {</span>
<span class="quote">&gt;&gt;&gt;&gt; -    pgprot_t set_mask;</span>
<span class="quote">&gt;&gt;&gt;&gt; -    pgprot_t clear_mask;</span>
<span class="quote">&gt;&gt;&gt;&gt; -};</span>
<span class="quote">&gt;&gt;&gt;&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; -static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="quote">&gt;&gt;&gt;&gt; -            void *data)</span>
<span class="quote">&gt;&gt;&gt;&gt; +static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="quote">&gt;&gt;&gt;&gt; +                unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt;&gt;&gt; +                pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt;&gt;&gt;    {</span>
<span class="quote">&gt;&gt;&gt;&gt; -    struct page_change_data *cdata = data;</span>
<span class="quote">&gt;&gt;&gt;&gt; -    pte_t pte = *ptep;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    pte_t *pte;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    int err = 0;</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (pmd_sect(*pmd)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +        if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +            err = -EINVAL;</span>
<span class="quote">&gt;&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt;&gt; +        pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        if (!pte) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +            err = -ENOMEM;</span>
<span class="quote">&gt;&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt;&gt; +        split_pmd(pmd, pte);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        __pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="quote">&gt;&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +    pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (pte_none(*pte)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +        err = -EFAULT;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        goto out;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +    do {</span>
<span class="quote">&gt;&gt;&gt;&gt; +        pte_t p = *pte;</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +        p = clear_pte_bit(p, clear);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        p = set_pte_bit(p, set);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        set_pte(pte, p);</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +    } while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +out:</span>
<span class="quote">&gt;&gt;&gt;&gt; +    return err;</span>
<span class="quote">&gt;&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;&gt;&gt;&gt; +                unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt;&gt;&gt; +                pgprot_t clear, pgprot_t set)</span>
<span class="quote">&gt;&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt;&gt; +    pmd_t *pmd;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    unsigned long next;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    int err = 0;</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (pud_sect(*pud)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +        if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +            err = -EINVAL;</span>
<span class="quote">&gt;&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt;&gt; +        pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        if (!pmd) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +            err = -ENOMEM;</span>
<span class="quote">&gt;&gt;&gt;&gt; +            goto out;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        }</span>
<span class="quote">&gt;&gt;&gt;&gt; +        split_pud(pud, pmd);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="quote">&gt;&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; -    pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="quote">&gt;&gt;&gt;&gt; -    pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="quote">&gt;&gt;&gt;&gt; +    pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (pmd_none(*pmd)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +        err = -EFAULT;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        goto out;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; we try to preserve the section area, but the addr | end does not ensure that</span>
<span class="quote">&gt;&gt;&gt; physical memory is alignment. In addtion, if numpages cross section area, and</span>
<span class="quote">&gt;&gt;&gt; addr points to the physical memory is alignment to the section. In this case,</span>
<span class="quote">&gt;&gt;&gt; we should consider to retain the section.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I&#39;m not sure what physical memory you are referring to here. The mapping is</span>
<span class="quote">&gt;&gt; already set up so if there is a section mapping we know the physical memory</span>
<span class="quote">&gt;&gt; is going to be set up to be a section size. We aren&#39;t setting up a new mapping</span>
<span class="quote">&gt;&gt; for the physical address so there is no need to check that again. The only</span>
<span class="quote">&gt;&gt; way to get the physical address would be to read it out of the section</span>
<span class="quote">&gt;&gt; entry which wouldn&#39;t give any more information.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I&#39;m also not sure what you are referring to with numpages crossing a section</span>
<span class="quote">&gt;&gt; area. In update_pud_range and update_pmd_range there are checks if a</span>
<span class="quote">&gt;&gt; section can be used. If it can, it updates. The split action is only called</span>
<span class="quote">&gt;&gt; if it isn&#39;t aligned. The loop ensures this will happen across all possible</span>
<span class="quote">&gt;&gt; sections.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Thanks,</span>
<span class="quote">&gt;&gt; Laura</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Hi Laura</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; In pmd_update_range, Is the pmd pointing to large page if addr is alignment ?</span>
<span class="quote">&gt; I mean that whether it need to add pmd_sect() to guarantee.</span>
<span class="quote">&gt;</span>

Okay, now I see what you are referring to. Yes, I think you are correct there.
I&#39;ll take a look at that for the next revision.

Thanks,
Laura

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a> - Nov. 13, 2015, 7:09 p.m.</div>
<pre class="content">
On 11/13/2015 12:27 AM, Xishi Qiu wrote:
<span class="quote">&gt; On 2015/11/11 9:57, Laura Abbott wrote:</span>
&lt;snip&gt;
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;&gt; @@ -43,7 +180,6 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;&gt;   	unsigned long size = PAGE_SIZE*numpages;</span>
<span class="quote">&gt;&gt;   	unsigned long end = start + size;</span>
<span class="quote">&gt;&gt;   	int ret;</span>
<span class="quote">&gt;&gt; -	struct page_change_data data;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   	if (!PAGE_ALIGNED(addr)) {</span>
<span class="quote">&gt;&gt;   		start &amp;= PAGE_MASK;</span>
<span class="quote">&gt;&gt; @@ -51,17 +187,15 @@ static int change_memory_common(unsigned long addr, int numpages,</span>
<span class="quote">&gt;&gt;   		WARN_ON_ONCE(1);</span>
<span class="quote">&gt;&gt;   	}</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -	if (start &lt; MODULES_VADDR || start &gt;= MODULES_END)</span>
<span class="quote">&gt;&gt; +	if (start &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)start) &amp;&amp;</span>
<span class="quote">&gt;&gt; +		(start &lt; MODULES_VADDR || start &gt;= MODULES_END))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; How about abstracting &quot;start &lt; MODULES_VADDR || start &gt;= MODULES_END&quot; to a new function?</span>
<span class="quote">&gt; e.g. is_module_addr(), however it is a little confusion with is_module_address().</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt;   		return -EINVAL;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -	if (end &lt; MODULES_VADDR || end &gt;= MODULES_END)</span>
<span class="quote">&gt;&gt; +	if (end &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)end) &amp;&amp;</span>
<span class="quote">&gt;&gt; +		(end &lt; MODULES_VADDR || end &gt;= MODULES_END))</span>
<span class="quote">&gt;&gt;   		return -EINVAL;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It will not filter this case, start in module range and end in vmalloc range, right?</span>
<span class="quote">&gt; start and end should be both in one range.</span>
<span class="quote">&gt;</span>

The goal of this check was to prevent it from being used on userspace addresses. It&#39;s
very complicated and hard to understand. I&#39;m going to give this some more thought about
a better way to do this check.
<span class="quote">
  
&gt; Thanks,</span>
<span class="quote">&gt; Xishi Qiu</span>

Thanks,
Laura
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 851fe11..46725e8 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -521,6 +521,18 @@</span> <span class="p_context"> config ARCH_HAS_CACHE_LINE_SIZE</span>
 
 source &quot;mm/Kconfig&quot;
 
<span class="p_add">+config DEBUG_CHANGE_PAGEATTR</span>
<span class="p_add">+	bool &quot;Allow all kernel memory to have attributes changed&quot;</span>
<span class="p_add">+	default y</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  If this option is selected, APIs that change page attributes</span>
<span class="p_add">+	  (RW &lt;-&gt; RO, X &lt;-&gt; NX) will be valid for all memory mapped in</span>
<span class="p_add">+	  the kernel space. The trade off is that there may be increased</span>
<span class="p_add">+	  TLB pressure from finer grained page mapping. Turn on this option</span>
<span class="p_add">+	  if security is more important than performance</span>
<span class="p_add">+</span>
<span class="p_add">+	  If in doubt, say Y</span>
<span class="p_add">+</span>
 config SECCOMP
 	bool &quot;Enable seccomp to safely compute untrusted bytecode&quot;
 	---help---
<span class="p_header">diff --git a/arch/arm64/mm/mm.h b/arch/arm64/mm/mm.h</span>
<span class="p_header">index ef47d99..7b0dcc4 100644</span>
<span class="p_header">--- a/arch/arm64/mm/mm.h</span>
<span class="p_header">+++ b/arch/arm64/mm/mm.h</span>
<span class="p_chunk">@@ -1,3 +1,6 @@</span> <span class="p_context"></span>
 extern void __init bootmem_init(void);
 
 void fixup_init(void);
<span class="p_add">+</span>
<span class="p_add">+void split_pud(pud_t *old_pud, pmd_t *pmd);</span>
<span class="p_add">+void split_pmd(pmd_t *pmd, pte_t *pte);</span>
<span class="p_header">diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="p_header">index 496c3fd..9353e3c 100644</span>
<span class="p_header">--- a/arch/arm64/mm/mmu.c</span>
<span class="p_header">+++ b/arch/arm64/mm/mmu.c</span>
<span class="p_chunk">@@ -73,7 +73,7 @@</span> <span class="p_context"> static void __init *early_alloc(unsigned long sz)</span>
 /*
  * remap a PMD into pages
  */
<span class="p_del">-static void split_pmd(pmd_t *pmd, pte_t *pte)</span>
<span class="p_add">+void split_pmd(pmd_t *pmd, pte_t *pte)</span>
 {
 	unsigned long pfn = pmd_pfn(*pmd);
 	unsigned long addr = pfn &lt;&lt; PAGE_SHIFT;
<span class="p_header">diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="p_header">index 3571c73..4a95fed 100644</span>
<span class="p_header">--- a/arch/arm64/mm/pageattr.c</span>
<span class="p_header">+++ b/arch/arm64/mm/pageattr.c</span>
<span class="p_chunk">@@ -15,25 +15,162 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/sched.h&gt;
 
<span class="p_add">+#include &lt;asm/pgalloc.h&gt;</span>
 #include &lt;asm/pgtable.h&gt;
 #include &lt;asm/tlbflush.h&gt;
 
<span class="p_del">-struct page_change_data {</span>
<span class="p_del">-	pgprot_t set_mask;</span>
<span class="p_del">-	pgprot_t clear_mask;</span>
<span class="p_del">-};</span>
<span class="p_add">+#include &quot;mm.h&quot;</span>
 
<span class="p_del">-static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
<span class="p_del">-			void *data)</span>
<span class="p_add">+static int update_pte_range(struct mm_struct *mm, pmd_t *pmd,</span>
<span class="p_add">+				unsigned long addr, unsigned long end,</span>
<span class="p_add">+				pgprot_t clear, pgprot_t set)</span>
 {
<span class="p_del">-	struct page_change_data *cdata = data;</span>
<span class="p_del">-	pte_t pte = *ptep;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	int err = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pmd_sect(*pmd)) {</span>
<span class="p_add">+		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="p_add">+			err = -EINVAL;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		pte = pte_alloc_one_kernel(&amp;init_mm, addr);</span>
<span class="p_add">+		if (!pte) {</span>
<span class="p_add">+			err = -ENOMEM;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		split_pmd(pmd, pte);</span>
<span class="p_add">+		__pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+	if (pte_none(*pte)) {</span>
<span class="p_add">+		err = -EFAULT;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		pte_t p = *pte;</span>
<span class="p_add">+</span>
<span class="p_add">+		p = clear_pte_bit(p, clear);</span>
<span class="p_add">+		p = set_pte_bit(p, set);</span>
<span class="p_add">+		set_pte(pte, p);</span>
<span class="p_add">+</span>
<span class="p_add">+	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return err;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static int update_pmd_range(struct mm_struct *mm, pud_t *pud,</span>
<span class="p_add">+				unsigned long addr, unsigned long end,</span>
<span class="p_add">+				pgprot_t clear, pgprot_t set)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	unsigned long next;</span>
<span class="p_add">+	int err = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pud_sect(*pud)) {</span>
<span class="p_add">+		if (!IS_ENABLED(CONFIG_DEBUG_CHANGE_PAGEATTR)) {</span>
<span class="p_add">+			err = -EINVAL;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		pmd = pmd_alloc_one(&amp;init_mm, addr);</span>
<span class="p_add">+		if (!pmd) {</span>
<span class="p_add">+			err = -ENOMEM;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		split_pud(pud, pmd);</span>
<span class="p_add">+		pud_populate(&amp;init_mm, pud, pmd);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 
<span class="p_del">-	pte = clear_pte_bit(pte, cdata-&gt;clear_mask);</span>
<span class="p_del">-	pte = set_pte_bit(pte, cdata-&gt;set_mask);</span>
<span class="p_add">+	pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	if (pmd_none(*pmd)) {</span>
<span class="p_add">+		err = -EFAULT;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		next = pmd_addr_end(addr, end);</span>
<span class="p_add">+		if (((addr | end) &amp; ~SECTION_MASK) == 0) {</span>
<span class="p_add">+			unsigned long paddr = pmd_pfn(*pmd) &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+			pgprot_t prot = __pgprot((pmd_val(*pmd) ^ paddr));</span>
<span class="p_add">+</span>
<span class="p_add">+			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="p_add">+			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="p_add">+			set_pmd(pmd, __pmd(paddr | pgprot_val(prot)));</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			err = update_pte_range(mm, pmd, addr, next, clear, set);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	} while (pmd++, addr = next, addr != end);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return err;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static int update_pud_range(struct mm_struct *mm, pgd_t *pgd,</span>
<span class="p_add">+					unsigned long addr, unsigned long end,</span>
<span class="p_add">+					pgprot_t clear, pgprot_t set)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	unsigned long next;</span>
<span class="p_add">+	int err = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	if (pud_none(*pud)) {</span>
<span class="p_add">+		err = -EFAULT;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	set_pte(ptep, pte);</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		next = pud_addr_end(addr, end);</span>
<span class="p_add">+		if (pud_sect(*pud) &amp;&amp; ((addr | next) &amp; ~PUD_MASK) == 0) {</span>
<span class="p_add">+			unsigned long paddr = pud_pfn(*pud) &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+			pgprot_t prot = __pgprot(pud_val(*pud) ^ paddr);</span>
<span class="p_add">+</span>
<span class="p_add">+			pgprot_val(prot) &amp;= ~pgprot_val(clear);</span>
<span class="p_add">+			pgprot_val(prot) |= pgprot_val(set);</span>
<span class="p_add">+			set_pud(pud, __pud(paddr | pgprot_val(prot)));</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			err = update_pmd_range(mm, pud, addr, next, clear, set);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	} while (pud++, addr = next, addr != end);</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return err;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int update_page_range(unsigned long addr,</span>
<span class="p_add">+				unsigned long end, pgprot_t clear,</span>
<span class="p_add">+				pgprot_t set)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	unsigned long next;</span>
<span class="p_add">+	int err;</span>
<span class="p_add">+	struct mm_struct *mm = &amp;init_mm;</span>
<span class="p_add">+</span>
<span class="p_add">+	BUG_ON(addr &gt;= end);</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	if (pgd_none(*pgd)) {</span>
<span class="p_add">+		err = -EFAULT;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		next = pgd_addr_end(addr, end);</span>
<span class="p_add">+		err = update_pud_range(mm, pgd, addr, next, clear, set);</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	} while (pgd++, addr = next, addr != end);</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return err;</span>
 }
 
 static int change_memory_common(unsigned long addr, int numpages,
<span class="p_chunk">@@ -43,7 +180,6 @@</span> <span class="p_context"> static int change_memory_common(unsigned long addr, int numpages,</span>
 	unsigned long size = PAGE_SIZE*numpages;
 	unsigned long end = start + size;
 	int ret;
<span class="p_del">-	struct page_change_data data;</span>
 
 	if (!PAGE_ALIGNED(addr)) {
 		start &amp;= PAGE_MASK;
<span class="p_chunk">@@ -51,17 +187,15 @@</span> <span class="p_context"> static int change_memory_common(unsigned long addr, int numpages,</span>
 		WARN_ON_ONCE(1);
 	}
 
<span class="p_del">-	if (start &lt; MODULES_VADDR || start &gt;= MODULES_END)</span>
<span class="p_add">+	if (start &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)start) &amp;&amp;</span>
<span class="p_add">+		(start &lt; MODULES_VADDR || start &gt;= MODULES_END))</span>
 		return -EINVAL;
 
<span class="p_del">-	if (end &lt; MODULES_VADDR || end &gt;= MODULES_END)</span>
<span class="p_add">+	if (end &lt; PAGE_OFFSET &amp;&amp; !is_vmalloc_addr((void *)end) &amp;&amp;</span>
<span class="p_add">+		(end &lt; MODULES_VADDR || end &gt;= MODULES_END))</span>
 		return -EINVAL;
 
<span class="p_del">-	data.set_mask = set_mask;</span>
<span class="p_del">-	data.clear_mask = clear_mask;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = apply_to_page_range(&amp;init_mm, start, size, change_page_range,</span>
<span class="p_del">-					&amp;data);</span>
<span class="p_add">+	ret = update_page_range(addr, end, clear_mask, set_mask);</span>
 
 	flush_tlb_kernel_range(start, end);
 	return ret;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



