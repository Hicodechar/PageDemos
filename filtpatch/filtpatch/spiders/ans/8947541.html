
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v1,13/18] x86: DMA support for memory encryption - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v1,13/18] x86: DMA support for memory encryption</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>April 26, 2016, 10:58 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160426225812.13567.91220.stgit@tlendack-t1.amdoffice.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8947541/mbox/"
   >mbox</a>
|
   <a href="/patch/8947541/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8947541/">/patch/8947541/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id D0C8A9F441
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 26 Apr 2016 22:58:43 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id BD11C20222
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 26 Apr 2016 22:58:42 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 764A320259
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 26 Apr 2016 22:58:41 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753752AbcDZW6b (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 26 Apr 2016 18:58:31 -0400
Received: from mail-bl2on0077.outbound.protection.outlook.com
	([65.55.169.77]:39240
	&quot;EHLO na01-bl2-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1753169AbcDZW6Y (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 26 Apr 2016 18:58:24 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=amdcloud.onmicrosoft.com; s=selector1-amd-com;
	h=From:To:Date:Subject:Message-ID:Content-Type:MIME-Version;
	bh=gHXnD4JzXwyqgiC4NrjV9bikJlYWu7tTtsTimpwa080=;
	b=IuJoyraDjpcBONFRZN7/nORNykWfp98UOsLN7AyXDB77vS1qCze/Kz5wYBOiWnz5veAKJK+dVVrGGGuuUGgmUIvgmvtSx5R6aoMmvvgA5IC8NabDjT9nTTvPm9+rmZYYk91P/W3kX1ujiHKSTSeaCRTjk8s1Af7CTw2GJ2yhJW8=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
	header.d=none; vger.kernel.org;
	dmarc=none action=none header.from=amd.com; 
Received: from tlendack-t1.amdoffice.net (165.204.77.1) by
	DM3PR1201MB1117.namprd12.prod.outlook.com (10.164.198.17) with
	Microsoft SMTP
	Server (TLS) id 15.1.477.8; Tue, 26 Apr 2016 22:58:17 +0000
From: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;
Subject: [RFC PATCH v1 13/18] x86: DMA support for memory encryption
To: &lt;linux-arch@vger.kernel.org&gt;, &lt;linux-efi@vger.kernel.org&gt;,
	&lt;kvm@vger.kernel.org&gt;, &lt;linux-doc@vger.kernel.org&gt;,
	&lt;x86@kernel.org&gt;, &lt;linux-kernel@vger.kernel.org&gt;,
	&lt;kasan-dev@googlegroups.com&gt;, &lt;linux-mm@kvack.org&gt;,
	&lt;iommu@lists.linux-foundation.org&gt;
CC: Radim =?utf-8?b?S3LEjW3DocWZ?= &lt;rkrcmar@redhat.com&gt;,
	Arnd Bergmann &lt;arnd@arndb.de&gt;, Jonathan Corbet &lt;corbet@lwn.net&gt;,
	Matt Fleming &lt;matt@codeblueprint.co.uk&gt;, Joerg Roedel &lt;joro@8bytes.org&gt;,
	&quot;Konrad Rzeszutek Wilk&quot; &lt;konrad.wilk@oracle.com&gt;,
	Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	&quot;Ingo Molnar&quot; &lt;mingo@redhat.com&gt;, Borislav Petkov &lt;bp@alien8.de&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;,
	&quot;Alexander Potapenko&quot; &lt;glider@google.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	&quot;Dmitry Vyukov&quot; &lt;dvyukov@google.com&gt;
Date: Tue, 26 Apr 2016 17:58:12 -0500
Message-ID: &lt;20160426225812.13567.91220.stgit@tlendack-t1.amdoffice.net&gt;
In-Reply-To: &lt;20160426225553.13567.19459.stgit@tlendack-t1.amdoffice.net&gt;
References: &lt;20160426225553.13567.19459.stgit@tlendack-t1.amdoffice.net&gt;
User-Agent: StGit/0.17.1-dirty
MIME-Version: 1.0
Content-Type: text/plain; charset=&quot;utf-8&quot;
Content-Transfer-Encoding: 7bit
X-Originating-IP: [165.204.77.1]
X-ClientProxiedBy: BLUPR05CA0043.namprd05.prod.outlook.com (10.141.20.13) To
	DM3PR1201MB1117.namprd12.prod.outlook.com (10.164.198.17)
X-MS-Office365-Filtering-Correlation-Id: 2b4f3151-2b52-46de-1973-08d36e264273
X-Microsoft-Exchange-Diagnostics: 1; DM3PR1201MB1117;
	2:Dqa1ed390gqiH80u8KrZ+kFLV1mkyZeSQTXflXjJaIsN12XALUD6+SO81NphzV2CUKG9PUsAv6UBWQYsk2h+ltCJJIZcAnjw9/02R0bSzF/b3IqGBOHggA1Segb24WMk2DuH+CT+9lkAfT98ejSt/eQ/URgCVR/86W5EM3/+vJ6v5AFr7NboW+renR+a5Ofc;
	3:d6Z1Y4aN4ME9y938g/fbw64BG5WNmKWMBOruZSHDIfyN+tEawQUeUAgiA/cJOiqbeCaWjPGIZceMrEhQDb+KUwzjo0Kw2aqQ30DC+dVfeDfavNy8eH+YbtqgtgV4AstB
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:DM3PR1201MB1117;
X-Microsoft-Exchange-Diagnostics: 1; DM3PR1201MB1117;
	25:776x0vZi0hbDVBFktQCtQ/3d9LuZ271X7wtqr+Nr7Z5TMAmHUU7Fbg8qjHqbOYiOpo3lyGjguiRZQnwT3vDU3AUjFIp2eWKI/O4mHNfEqnXFoWH6s0tVr52EwCSJX0LaIfTgZcjmYKd/MikEnfZILnxviAIoeS3crKAnVkFszaoHtc9+kY/FpzXdHJWPKkX2lNmOnPSBAfQ5KUfsIhRYMCIGl8i3S7z7V2X3dWLekZX3TA2hLFr63N5UL/3YtW0DdsnCnV7s8Q6BWt6V/rmd7ppZ/dJ2IJa80rcnh8KTb8wI0DRsWuc3YQ+Xg7hS5FB/tOlVaCHnEZ9uKyXqBtSHTYdyXpi3c6lhj2VyFril7wC5Q94LnHlff7CnxTR8s5O5mRS1bsiMu8J0WiDwz7AEoA1XbgVL4lAvnBRGweZTJMwLXMxaU/hkFsP7/XkhdncsWj2+JT8UkRXx2GZN4PSsdRh0duF/MsAXSoafS3KHiCWhUBwU981o3Gme8sbwwV1oudA5IjSoRimqsysr/Co8AgnyM1ucvWSIIUD5Gh1wUjU1zl7SUMWkCj/+hLeSbP8+/fsgkTQttVyKwffpRZl1nW/Tyzndj4jqPL2ZobroUXdT74P4oWxKvYXiDVcS1P1lUSK6sVpJKHzkA/MzYYZm7g==
X-Microsoft-Exchange-Diagnostics: 1; DM3PR1201MB1117;
	20:QGgKtEG2iDSOXylyjoWjTVdNeI4BZ5LXIsRdYaaf506t+0jUXzjMmqQCCxp22ALC1r2dt2yv4x2XMQtB9GUG+42no+B+zbmBqhREO1z8nut8MGCdhOJfl32z3aNU7SLSBgExcWNYI2BUAHVoFOGV5DVbnH87gHBt13OW8BB0wzzePBsqsC9IXUNNNcf8TbqmWEGIkbqq1QJigjCWy/TWbMDFuW+cjj9kiEfISr5EfotX+xPV6EssrFmxWktNj10wpu2BBJiUcCSk6gyXJE5/Ve7RrErwIphD6jC8SApLppkmTz/+NvLjkeZwgB4ua3LOmOTsFLxqatmw55TBjRhSfvcjDanL3F7kyFnATNyiGtzKLKGKRAfJQrVMDTIoPuCeBE4MdWQnpsf4spoyQ0koXBa9R0rK2YrupEH9ZQxbxn9URyIbqUmKb/wPemSJ05pIZYJxbKH//elbsftWGmF8llq+8QIFrk1gWMfVhy+VPsKyww6a+ecDn51w13CDFZTc;
	4:G8OARZwyiK7sbZdCKM+c3OB/6EzmLKMRO4gc+B9Us6Bduhlk+eA7jFfVPWJXBXuk9JXaaQ+YJYLXXU3z+PlhJfqu6b9bUK16C5AUVLy0WIiHE4gq1Hr4pt+F1+7JLmsFh4Z6TozB3RTzyOqa34lfR0FcuKrlxy9RMVaC+En+r4Thu5UYHmOWYoJCXaXLFI1SVgkGsv9s+oBJ8vGcDur/dngmSslVkn263vw/+OLwNpcsluTh7nEAP7O42MlDbvr9yl4MbC63DCAm4w+3dgAWDy5fkTVOi2FzuGq6C07LoygB/7RKAVjZEXBNbEQn0f55MLc401JLf8vti++u1Q1i2lwF9IR9f6fv7y8eNEe9/WsekcYzBo2fYNdjxreUr2Y2h9v03awbhQssBpCAT0me3AFEy/0LgC9DjhNl
	0cgPaIo=
X-Microsoft-Antispam-PRVS: &lt;DM3PR1201MB1117B1C82D74BB66E0072DAEEC630@DM3PR1201MB1117.namprd12.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:;
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(9101521072)(601004)(2401047)(5005006)(8121501046)(10201501046)(3002001)(6055026);
	SRVR:DM3PR1201MB1117; BCL:0; PCL:0; RULEID:;
	SRVR:DM3PR1201MB1117; 
X-Forefront-PRVS: 0924C6A0D5
X-Forefront-Antispam-Report: SFV:NSPM;
	SFS:(10009020)(4630300001)(6009001)(5008740100001)(50986999)(54356999)(42186005)(76176999)(5004730100002)(53416004)(103116003)(97746001)(230700001)(81166005)(9686002)(2950100001)(77096005)(2201001)(92566002)(66066001)(19580405001)(19580395003)(33646002)(229853001)(4001350100001)(86362001)(47776003)(1076002)(50466002)(5001770100001)(4326007)(6116002)(189998001)(2906002)(23676002)(1096002)(586003)(71626007)(217873001)(473944003);
	DIR:OUT; SFP:1101; SCL:1; SRVR:DM3PR1201MB1117;
	H:tlendack-t1.amdoffice.net; FPR:; SPF:None; MLV:sfv; LANG:en;
X-Microsoft-Exchange-Diagnostics: =?utf-8?B?MTtETTNQUjEyMDFNQjExMTc7MjM6Q3FyeWZuWEc1L1d0YUIza3ZWQml2dUxh?=
	=?utf-8?B?dGdHK2M2RWs2N3Q5aHVsS2dKa25xQW95ZHJpTnlBN080enJvbGR0OWcxQXhm?=
	=?utf-8?B?cldTcnMzOStPeVg5allwanUzeEZPUnZBVk81WmdnaUhpM2RJTEN4WGFmYksw?=
	=?utf-8?B?cW4wRDhWOG80dFhvY0xQUUpaem5vcVhTdGRYcEh4cW54SUNCVGZWcDFwZVFi?=
	=?utf-8?B?QXNhZ2poWVgwZ0puVkgraENzajVSQllwc0dxMnVncU1EdkNRN2VjZXJVb0Fs?=
	=?utf-8?B?cFdpT3ZMOXMyUHRpenF5blYxTC82bkc5Yms2SjVaQnVqTmtBYVBRQndEcUZH?=
	=?utf-8?B?VHlrOFhhcTZ1a0JyNWFBMXlhcmhVenE0Zm5CaXZPZ3JaeC9XWEpRMUpXaGF0?=
	=?utf-8?B?S2FZYUw3WVQxcUZMK21kZlQ4YVVzTUIrbjdJeTB4c3ZESmJNM0N5OFBJYUxR?=
	=?utf-8?B?eC9JdXF4YzZLUHpXU2ZxZ25WVklaSjNZdk5Hczd4ZzREYzNaaWxqRDJzdUYv?=
	=?utf-8?B?TEo0cUJqcEZkbHcwNzhnT0EwYkcyNldYTXIwUFNCam4wQ0hGNG01ZFZNWm9Y?=
	=?utf-8?B?d0dMRm5VUGttbVRqVDVPdjc0YTNpbGZaZTNCS0E5TjBJdkpJOEZEMC90eXU3?=
	=?utf-8?B?OVBIVzNmcG9FY0YvYjBaM056c2RjM29UeDMyNDNxMkdCeUl4bnVUYXI1SDNF?=
	=?utf-8?B?Sk1RbUR3alBpV3pVZkVwOGVQQ0pZbDkvMU9xVVBxanpBM2crNUVSa3Q4YzZW?=
	=?utf-8?B?OHlsZHFlT3VTMGFNTjdsNDZUem11R2I1c1N5SmlEc1F5a0plemIrYjVtdXJ4?=
	=?utf-8?B?R0tBK2JvTTRTTXZJMGlNODNIUUdKbUhlV1I4M0M1RGp2VVVKaEFEbkt4MGlo?=
	=?utf-8?B?SUVXRjZmR2ZnYmJxL0RzSnozR3Z1L21aYjNUWG9tQjJQM2dmUWszMDYrWTlB?=
	=?utf-8?B?SFRiSHc5R1V5YVFYL09CbFdFUFFLdi8xRE1takczM3ZSWXJJMHRwQnQzeGlu?=
	=?utf-8?B?K3ZWeW11MjJSWGVSKzNVeWhpUktmRHUxa1VhVUI3dWJLeEN3VmxoTllJS1hu?=
	=?utf-8?B?RmFPdVl6MWk4R1Q0MG1UTkljaExwUUk3cnEvcnVpRzNPZjdFb1h5RjZNQzdB?=
	=?utf-8?B?V3NEbzQrMFFMLzZ0Ri96Y0F3SzZQM2ZLVXN2MkNhRDZTWWkwMmRmN3FhdTlt?=
	=?utf-8?B?aVl4TWZKZE1TMWxKYmplS3JXNjlkUXJPKzh3WHduNTgwUUVwVHFnck9QUWc4?=
	=?utf-8?B?c1hvNko1VEVGaGZ6S0gzanFQTDlrRk5oQWIwNHViUmlqS3RFVzhidUNLeWtP?=
	=?utf-8?B?Szh3TjJjWi8zK2kxMVN4SGh3Zktxd0ZWZU84VFlRQTZCeTNzNUJqcTdVVElz?=
	=?utf-8?B?bWtqYTNkMVlvTTBycFQ5UC9aTnpJYnRVVW9tR1NVZGp1Q3c5UDFDTTJCdjVP?=
	=?utf-8?Q?pgV99lzo=3D?=
X-Microsoft-Exchange-Diagnostics: 1; DM3PR1201MB1117;
	5:OwskswXaY3jigbWSm4uvbKkfHN/eAdk8zYmRKsLsuPZWP0tyMW3TOQpPt7BPMbBwMayRvD56hvuq71jKWRDq3xWswvmoLedj8dFyzvgRb5XyqWOsJFjJlSLdWbc74tQZF9mGnyDNxsdEKYenNnDBnQ==;
	24:HKrMBbdqKi8x7VbkDErHni4wsNZS4TrWgP73KV4u3w8YfA3BAp4sahyO4hQO3IYck3msZp/sC0Zh+jwl+rKXYsOZHx+DEVrTuMLEXE5HZjo=;
	7:JzY1r/d4E6ITiQ8ZSlq2EGlQNL678udVWmeY+VPAvU62BOGa8UgTfjTVLOu0QEQOWA8swVBDMmDN1O/F1R9RkJHuodniB4s6ExvSt0I7qxxOaR1mkk5IHqGxUEbpkw6D2uOwb++JlDYkAYClVQ+RO2d9O/0KrVjA8pZuBfvAeKQ=;
	20:/ibC6HJCKPoBTkLe81v3nuaiwIORDi81NVqQ4JJEvnjL/hkBQiJ+qzLtqmpd1eqMlx8kJkY1rQzUS35t5YTXQm+2TuMGy1Ywn9Rl4rgiueHvPDm7YdScP+1AoIinHuXDfBshCEQTRIsvNO1sVgRBqbNCgzCIk+rdH7o14YnT9sVZq6npZMlMIrHMjOFXwXAAMIWQlU5bT62Qea6CqiDTAUhVFicmRbHQWDgCwUuEsTzuX9y6RFxDeXgAQHHB35E5
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 26 Apr 2016 22:58:17.1710
	(UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM3PR1201MB1117
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.9 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,RCVD_IN_DNSWL_HI,RP_MATCHES_RCVD,UNPARSEABLE_RELAY
	autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - April 26, 2016, 10:58 p.m.</div>
<pre class="content">
Since DMA addresses will effectively look like 48-bit addresses when the
memory encryption mask is set, SWIOTLB is needed if the DMA mask of the
device performing the DMA does not support 48-bits. SWIOTLB will be
initialized to create un-encrypted bounce buffers for use by these devices.
<span class="signed-off-by">
Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
---
 arch/x86/include/asm/dma-mapping.h |    5 ++-
 arch/x86/include/asm/mem_encrypt.h |    5 +++
 arch/x86/kernel/pci-dma.c          |   11 ++++--
 arch/x86/kernel/pci-nommu.c        |    2 +
 arch/x86/kernel/pci-swiotlb.c      |    8 +++--
 arch/x86/mm/mem_encrypt.c          |   21 ++++++++++++
 include/linux/swiotlb.h            |    1 +
 init/main.c                        |    6 +++
 lib/swiotlb.c                      |   64 ++++++++++++++++++++++++++++++++----
 9 files changed, 106 insertions(+), 17 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - April 29, 2016, 3:12 p.m.</div>
<pre class="content">
On 04/29/2016 02:17 AM, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Tue, Apr 26, 2016 at 05:58:12PM -0500, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt; Since DMA addresses will effectively look like 48-bit addresses when the</span>
<span class="quote">&gt;&gt; memory encryption mask is set, SWIOTLB is needed if the DMA mask of the</span>
<span class="quote">&gt;&gt; device performing the DMA does not support 48-bits. SWIOTLB will be</span>
<span class="quote">&gt;&gt; initialized to create un-encrypted bounce buffers for use by these devices.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I presume the sme_me_mask does not use the lower 48 bits?</span>

The sme_me_mask will actually be bit 47. So, when applied, the address
will become a 48-bit address.
<span class="quote">
&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ..snip..</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; index 7d56d1b..594dc65 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; @@ -12,6 +12,8 @@</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  #include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/swiotlb.h&gt;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  #include &lt;asm/mem_encrypt.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;&gt; @@ -168,6 +170,25 @@ void __init sme_early_init(void)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  /* Architecture __weak replacement functions */</span>
<span class="quote">&gt;&gt; +void __init mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	if (!sme_me_mask)</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* Make SWIOTLB use an unencrypted DMA area */</span>
<span class="quote">&gt;&gt; +	swiotlb_clear_encryption();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +unsigned long swiotlb_get_me_mask(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return sme_me_mask;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	sme_set_mem_dec(vaddr, size);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  void __init *efi_me_early_memremap(resource_size_t paddr,</span>
<span class="quote">&gt;&gt;  				   unsigned long size)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; index 017fced..121b9de 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; @@ -30,6 +30,7 @@ int swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose);</span>
<span class="quote">&gt;&gt;  extern unsigned long swiotlb_nr_tbl(void);</span>
<span class="quote">&gt;&gt;  unsigned long swiotlb_size_or_default(void);</span>
<span class="quote">&gt;&gt;  extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);</span>
<span class="quote">&gt;&gt; +extern void __init swiotlb_clear_encryption(void);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Enumeration for sync targets</span>
<span class="quote">&gt;&gt; diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt;&gt; index b3c6e36..1013d1c 100644</span>
<span class="quote">&gt;&gt; --- a/init/main.c</span>
<span class="quote">&gt;&gt; +++ b/init/main.c</span>
<span class="quote">&gt;&gt; @@ -458,6 +458,10 @@ void __init __weak thread_info_cache_init(void)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +void __init __weak mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Set up kernel memory allocators</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt; @@ -597,6 +601,8 @@ asmlinkage __visible void __init start_kernel(void)</span>
<span class="quote">&gt;&gt;  	 */</span>
<span class="quote">&gt;&gt;  	locking_selftest();</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +	mem_encrypt_init();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;&gt;  	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;</span>
<span class="quote">&gt;&gt;  	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What happens if devices use the bounce buffer before mem_encrypt_init()?</span>

The call to mem_encrypt_init is early in the boot process, I may have
overlooked something, but what devices would be performing DMA before
this?

Thanks,
Tom
<span class="quote">
&gt; </span>
<span class="quote">&gt; ..snip..</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - April 29, 2016, 11:49 p.m.</div>
<pre class="content">
On 04/29/2016 11:27 AM, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Fri, Apr 29, 2016 at 10:12:45AM -0500, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt; On 04/29/2016 02:17 AM, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt;&gt;&gt; On Tue, Apr 26, 2016 at 05:58:12PM -0500, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; Since DMA addresses will effectively look like 48-bit addresses when the</span>
<span class="quote">&gt;&gt;&gt;&gt; memory encryption mask is set, SWIOTLB is needed if the DMA mask of the</span>
<span class="quote">&gt;&gt;&gt;&gt; device performing the DMA does not support 48-bits. SWIOTLB will be</span>
<span class="quote">&gt;&gt;&gt;&gt; initialized to create un-encrypted bounce buffers for use by these devices.</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I presume the sme_me_mask does not use the lower 48 bits?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The sme_me_mask will actually be bit 47. So, when applied, the address</span>
<span class="quote">&gt;&gt; will become a 48-bit address.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; ..snip..</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index 7d56d1b..594dc65 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -12,6 +12,8 @@</span>
<span class="quote">&gt;&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;&gt;  #include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; +#include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; +#include &lt;linux/swiotlb.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;&gt;  #include &lt;asm/mem_encrypt.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;  #include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -168,6 +170,25 @@ void __init sme_early_init(void)</span>
<span class="quote">&gt;&gt;&gt;&gt;  }</span>
<span class="quote">&gt;&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;&gt;  /* Architecture __weak replacement functions */</span>
<span class="quote">&gt;&gt;&gt;&gt; +void __init mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt;&gt; +	if (!sme_me_mask)</span>
<span class="quote">&gt;&gt;&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +	/* Make SWIOTLB use an unencrypted DMA area */</span>
<span class="quote">&gt;&gt;&gt;&gt; +	swiotlb_clear_encryption();</span>
<span class="quote">&gt;&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +unsigned long swiotlb_get_me_mask(void)</span>
<span class="quote">&gt;&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt;&gt; +	return sme_me_mask;</span>
<span class="quote">&gt;&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +void swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt;&gt; +	sme_set_mem_dec(vaddr, size);</span>
<span class="quote">&gt;&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt;  void __init *efi_me_early_memremap(resource_size_t paddr,</span>
<span class="quote">&gt;&gt;&gt;&gt;  				   unsigned long size)</span>
<span class="quote">&gt;&gt;&gt;&gt;  {</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt;&gt;&gt; index 017fced..121b9de 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -30,6 +30,7 @@ int swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose);</span>
<span class="quote">&gt;&gt;&gt;&gt;  extern unsigned long swiotlb_nr_tbl(void);</span>
<span class="quote">&gt;&gt;&gt;&gt;  unsigned long swiotlb_size_or_default(void);</span>
<span class="quote">&gt;&gt;&gt;&gt;  extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);</span>
<span class="quote">&gt;&gt;&gt;&gt; +extern void __init swiotlb_clear_encryption(void);</span>
<span class="quote">&gt;&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;&gt;&gt;   * Enumeration for sync targets</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index b3c6e36..1013d1c 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/init/main.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/init/main.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -458,6 +458,10 @@ void __init __weak thread_info_cache_init(void)</span>
<span class="quote">&gt;&gt;&gt;&gt;  }</span>
<span class="quote">&gt;&gt;&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;&gt; +void __init __weak mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;&gt;&gt;   * Set up kernel memory allocators</span>
<span class="quote">&gt;&gt;&gt;&gt;   */</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -597,6 +601,8 @@ asmlinkage __visible void __init start_kernel(void)</span>
<span class="quote">&gt;&gt;&gt;&gt;  	 */</span>
<span class="quote">&gt;&gt;&gt;&gt;  	locking_selftest();</span>
<span class="quote">&gt;&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;&gt; +	mem_encrypt_init();</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;&gt;&gt;&gt;  	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;</span>
<span class="quote">&gt;&gt;&gt;&gt;  	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; What happens if devices use the bounce buffer before mem_encrypt_init()?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The call to mem_encrypt_init is early in the boot process, I may have</span>
<span class="quote">&gt;&gt; overlooked something, but what devices would be performing DMA before</span>
<span class="quote">&gt;&gt; this?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I am not saying that you overlooked. Merely wondering if somebody re-orders these</span>
<span class="quote">&gt; calls what would happen. It maybe also good to have a comment right before</span>
<span class="quote">&gt; mem_encrpyt_init stating what will happen if the device does DMA before the function</span>
<span class="quote">&gt; is called.</span>
<span class="quote">&gt; </span>

Ah, ok. Before mem_encrypt_init is called the bounce buffers will be
marked as encrypted in the page tables. The use of the bounce buffers
will not have the memory encryption bit as part of the DMA address so a
device will DMA into memory in the clear. When the bounce buffer is
copied to the original buffer it will be accessed by a virtual address
that has the memory encryption bit set in the page tables. So the
plaintext data that was DMA&#39;d in will be decrypted resulting in invalid
data in the destination buffer.

I&#39;ll be sure to add a comment before the call.

Thanks,
Tom
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 3a27b93..33a4f6d 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -13,6 +13,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/io.h&gt;
 #include &lt;asm/swiotlb.h&gt;
 #include &lt;linux/dma-contiguous.h&gt;
<span class="p_add">+#include &lt;asm/mem_encrypt.h&gt;</span>
 
 #ifdef CONFIG_ISA
 # define ISA_DMA_BIT_MASK DMA_BIT_MASK(24)
<span class="p_chunk">@@ -70,12 +71,12 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 
 static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
 {
<span class="p_del">-	return paddr;</span>
<span class="p_add">+	return paddr | sme_me_mask;</span>
 }
 
 static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)
 {
<span class="p_del">-	return daddr;</span>
<span class="p_add">+	return daddr &amp; ~sme_me_mask;</span>
 }
 #endif /* CONFIG_X86_DMA_REMAP */
 
<span class="p_header">diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">index 42868f5..d17d8cf 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_chunk">@@ -37,6 +37,11 @@</span> <span class="p_context"> void __init *sme_early_memremap(resource_size_t paddr,</span>
 void __init sme_early_init(void);
 
 /* Architecture __weak replacement functions */
<span class="p_add">+void __init mem_encrypt_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned long swiotlb_get_me_mask(void);</span>
<span class="p_add">+void swiotlb_set_mem_dec(void *vaddr, unsigned long size);</span>
<span class="p_add">+</span>
 void __init *efi_me_early_memremap(resource_size_t paddr,
 				   unsigned long size);
 
<span class="p_header">diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c</span>
<span class="p_header">index 6ba014c..bd1daae 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-dma.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-dma.c</span>
<span class="p_chunk">@@ -92,9 +92,12 @@</span> <span class="p_context"> again:</span>
 	/* CMA can be used only in the context which permits sleeping */
 	if (gfpflags_allow_blocking(flag)) {
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
<span class="p_del">-		if (page &amp;&amp; page_to_phys(page) + size &gt; dma_mask) {</span>
<span class="p_del">-			dma_release_from_contiguous(dev, page, count);</span>
<span class="p_del">-			page = NULL;</span>
<span class="p_add">+		if (page) {</span>
<span class="p_add">+			addr = phys_to_dma(dev, page_to_phys(page));</span>
<span class="p_add">+			if (addr + size &gt; dma_mask) {</span>
<span class="p_add">+				dma_release_from_contiguous(dev, page, count);</span>
<span class="p_add">+				page = NULL;</span>
<span class="p_add">+			}</span>
 		}
 	}
 	/* fallback */
<span class="p_chunk">@@ -103,7 +106,7 @@</span> <span class="p_context"> again:</span>
 	if (!page)
 		return NULL;
 
<span class="p_del">-	addr = page_to_phys(page);</span>
<span class="p_add">+	addr = phys_to_dma(dev, page_to_phys(page));</span>
 	if (addr + size &gt; dma_mask) {
 		__free_pages(page, get_order(size));
 
<span class="p_header">diff --git a/arch/x86/kernel/pci-nommu.c b/arch/x86/kernel/pci-nommu.c</span>
<span class="p_header">index da15918..ca2b820 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-nommu.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-nommu.c</span>
<span class="p_chunk">@@ -30,7 +30,7 @@</span> <span class="p_context"> static dma_addr_t nommu_map_page(struct device *dev, struct page *page,</span>
 				 enum dma_data_direction dir,
 				 struct dma_attrs *attrs)
 {
<span class="p_del">-	dma_addr_t bus = page_to_phys(page) + offset;</span>
<span class="p_add">+	dma_addr_t bus = phys_to_dma(dev, page_to_phys(page)) + offset;</span>
 	WARN_ON(size == 0);
 	if (!check_addr(&quot;map_single&quot;, dev, bus, size))
 		return DMA_ERROR_CODE;
<span class="p_header">diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">index 7c577a1..0ae083d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_chunk">@@ -12,6 +12,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/dma.h&gt;
 #include &lt;asm/xen/swiotlb-xen.h&gt;
 #include &lt;asm/iommu_table.h&gt;
<span class="p_add">+#include &lt;asm/mem_encrypt.h&gt;</span>
<span class="p_add">+</span>
 int swiotlb __read_mostly;
 
 void *x86_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
<span class="p_chunk">@@ -64,13 +66,15 @@</span> <span class="p_context"> static struct dma_map_ops swiotlb_dma_ops = {</span>
  * pci_swiotlb_detect_override - set swiotlb to 1 if necessary
  *
  * This returns non-zero if we are forced to use swiotlb (by the boot
<span class="p_del">- * option).</span>
<span class="p_add">+ * option). If memory encryption is enabled then swiotlb will be set</span>
<span class="p_add">+ * to 1 so that bounce buffers are allocated and used for devices that</span>
<span class="p_add">+ * do not support the addressing range required for the encryption mask.</span>
  */
 int __init pci_swiotlb_detect_override(void)
 {
 	int use_swiotlb = swiotlb | swiotlb_force;
 
<span class="p_del">-	if (swiotlb_force)</span>
<span class="p_add">+	if (swiotlb_force || sme_me_mask)</span>
 		swiotlb = 1;
 
 	return use_swiotlb;
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">index 7d56d1b..594dc65 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_chunk">@@ -12,6 +12,8 @@</span> <span class="p_context"></span>
 
 #include &lt;linux/init.h&gt;
 #include &lt;linux/mm.h&gt;
<span class="p_add">+#include &lt;linux/dma-mapping.h&gt;</span>
<span class="p_add">+#include &lt;linux/swiotlb.h&gt;</span>
 
 #include &lt;asm/mem_encrypt.h&gt;
 #include &lt;asm/cacheflush.h&gt;
<span class="p_chunk">@@ -168,6 +170,25 @@</span> <span class="p_context"> void __init sme_early_init(void)</span>
 }
 
 /* Architecture __weak replacement functions */
<span class="p_add">+void __init mem_encrypt_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!sme_me_mask)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Make SWIOTLB use an unencrypted DMA area */</span>
<span class="p_add">+	swiotlb_clear_encryption();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned long swiotlb_get_me_mask(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return sme_me_mask;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	sme_set_mem_dec(vaddr, size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init *efi_me_early_memremap(resource_size_t paddr,
 				   unsigned long size)
 {
<span class="p_header">diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="p_header">index 017fced..121b9de 100644</span>
<span class="p_header">--- a/include/linux/swiotlb.h</span>
<span class="p_header">+++ b/include/linux/swiotlb.h</span>
<span class="p_chunk">@@ -30,6 +30,7 @@</span> <span class="p_context"> int swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose);</span>
 extern unsigned long swiotlb_nr_tbl(void);
 unsigned long swiotlb_size_or_default(void);
 extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);
<span class="p_add">+extern void __init swiotlb_clear_encryption(void);</span>
 
 /*
  * Enumeration for sync targets
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index b3c6e36..1013d1c 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -458,6 +458,10 @@</span> <span class="p_context"> void __init __weak thread_info_cache_init(void)</span>
 }
 #endif
 
<span class="p_add">+void __init __weak mem_encrypt_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Set up kernel memory allocators
  */
<span class="p_chunk">@@ -597,6 +601,8 @@</span> <span class="p_context"> asmlinkage __visible void __init start_kernel(void)</span>
 	 */
 	locking_selftest();
 
<span class="p_add">+	mem_encrypt_init();</span>
<span class="p_add">+</span>
 #ifdef CONFIG_BLK_DEV_INITRD
 	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;
 	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 76f29ec..339ffdc 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -131,6 +131,26 @@</span> <span class="p_context"> unsigned long swiotlb_size_or_default(void)</span>
 	return size ? size : (IO_TLB_DEFAULT_SIZE);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Support for memory encryption. If memory encryption is supported, then an</span>
<span class="p_add">+ * override to these functions will be provided.</span>
<span class="p_add">+ */</span>
<span class="p_add">+unsigned long __weak swiotlb_get_me_mask(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __weak swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="p_add">+static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="p_add">+				      phys_addr_t address)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return phys_to_dma(hwdev, address) &amp; ~swiotlb_get_me_mask();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Note that this doesn&#39;t work with highmem page */
 static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,
 				      volatile void *address)
<span class="p_chunk">@@ -159,6 +179,30 @@</span> <span class="p_context"> void swiotlb_print_info(void)</span>
 	       bytes &gt;&gt; 20, vstart, vend - 1);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * If memory encryption is active, the DMA address for an encrypted page may</span>
<span class="p_add">+ * be beyond the range of the device. If bounce buffers are required be sure</span>
<span class="p_add">+ * that they are not on an encrypted page. This should be called before the</span>
<span class="p_add">+ * iotlb area is used.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init swiotlb_clear_encryption(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *vaddr;</span>
<span class="p_add">+	unsigned long bytes;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (no_iotlb_memory || !io_tlb_start || late_alloc)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="p_add">+	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="p_add">+	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="p_add">+	memset(vaddr, 0, bytes);</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="p_add">+	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="p_add">+	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)
 {
 	void *v_overflow_buffer;
<span class="p_chunk">@@ -294,6 +338,8 @@</span> <span class="p_context"> swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)</span>
 	io_tlb_start = virt_to_phys(tlb);
 	io_tlb_end = io_tlb_start + bytes;
 
<span class="p_add">+	/* Keep TLB in unencrypted memory if memory encryption is active */</span>
<span class="p_add">+	swiotlb_set_mem_dec(tlb, bytes);</span>
 	memset(tlb, 0, bytes);
 
 	/*
<span class="p_chunk">@@ -304,6 +350,8 @@</span> <span class="p_context"> swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)</span>
 	if (!v_overflow_buffer)
 		goto cleanup2;
 
<span class="p_add">+	/* Keep overflow in unencrypted memory if memory encryption is active */</span>
<span class="p_add">+	swiotlb_set_mem_dec(v_overflow_buffer, io_tlb_overflow);</span>
 	io_tlb_overflow_buffer = virt_to_phys(v_overflow_buffer);
 
 	/*
<span class="p_chunk">@@ -541,7 +589,7 @@</span> <span class="p_context"> static phys_addr_t</span>
 map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 	   enum dma_data_direction dir)
 {
<span class="p_del">-	dma_addr_t start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="p_add">+	dma_addr_t start_dma_addr = swiotlb_phys_to_dma(hwdev, io_tlb_start);</span>
 
 	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);
 }
<span class="p_chunk">@@ -659,7 +707,7 @@</span> <span class="p_context"> swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
 			goto err_warn;
 
 		ret = phys_to_virt(paddr);
<span class="p_del">-		dev_addr = phys_to_dma(hwdev, paddr);</span>
<span class="p_add">+		dev_addr = swiotlb_phys_to_dma(hwdev, paddr);</span>
 
 		/* Confirm address can be DMA&#39;d by device */
 		if (dev_addr + size - 1 &gt; dma_mask) {
<span class="p_chunk">@@ -758,15 +806,15 @@</span> <span class="p_context"> dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
 	map = map_single(dev, phys, size, dir);
 	if (map == SWIOTLB_MAP_ERROR) {
 		swiotlb_full(dev, size, dir, 1);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
<span class="p_del">-	dev_addr = phys_to_dma(dev, map);</span>
<span class="p_add">+	dev_addr = swiotlb_phys_to_dma(dev, map);</span>
 
 	/* Ensure that the address returned is DMA&#39;ble */
 	if (!dma_capable(dev, dev_addr, size)) {
 		swiotlb_tbl_unmap_single(dev, map, size, dir);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
 	return dev_addr;
<span class="p_chunk">@@ -901,7 +949,7 @@</span> <span class="p_context"> swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
 				sg_dma_len(sgl) = 0;
 				return 0;
 			}
<span class="p_del">-			sg-&gt;dma_address = phys_to_dma(hwdev, map);</span>
<span class="p_add">+			sg-&gt;dma_address = swiotlb_phys_to_dma(hwdev, map);</span>
 		} else
 			sg-&gt;dma_address = dev_addr;
 		sg_dma_len(sg) = sg-&gt;length;
<span class="p_chunk">@@ -984,7 +1032,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_sync_sg_for_device);</span>
 int
 swiotlb_dma_mapping_error(struct device *hwdev, dma_addr_t dma_addr)
 {
<span class="p_del">-	return (dma_addr == phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
<span class="p_add">+	return (dma_addr == swiotlb_phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_mapping_error);
 
<span class="p_chunk">@@ -997,6 +1045,6 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_dma_mapping_error);</span>
 int
 swiotlb_dma_supported(struct device *hwdev, u64 mask)
 {
<span class="p_del">-	return phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
<span class="p_add">+	return swiotlb_phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_supported);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



