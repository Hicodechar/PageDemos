
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[08/31] nds32: Cache and TLB routines - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [08/31] nds32: Cache and TLB routines</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 8, 2017, 5:54 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;220aabe68365f970ed6de79ef88f9598f272dcb9.1510118606.git.green.hu@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10047755/mbox/"
   >mbox</a>
|
   <a href="/patch/10047755/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10047755/">/patch/10047755/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	C107860381 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 06:20:42 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id AE63B2A4B1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 06:20:42 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id A30A72A4B8; Wed,  8 Nov 2017 06:20:42 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3853A2A4B1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 06:20:40 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754109AbdKHGUg (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 8 Nov 2017 01:20:36 -0500
Received: from mail-pf0-f195.google.com ([209.85.192.195]:49461 &quot;EHLO
	mail-pf0-f195.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1754045AbdKHGUS (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 8 Nov 2017 01:20:18 -0500
Received: by mail-pf0-f195.google.com with SMTP id i5so1110196pfe.6;
	Tue, 07 Nov 2017 22:20:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:in-reply-to:references;
	bh=8zRYAkDhVrNO3gWAh/dTR0MU7K6NE4gHiKTCCXlX94o=;
	b=jcAVISDcQxZWOvn/0ClJawrbLwLtkSAASyIqqn7vTiLqRbozvJpQqGx6PqGUkvMDAD
	pbAO2Mo2gs/WUNHpGy3KM6Bc7kLBBG5JFcM8o/e2E//N9+e6PmKwIdPKTUBaCSGnA2y2
	B39JnUUHvOprWwwApe6s69Spmp+4oXnJQVr2ZhnRT5Tki4BzzDztxgwCDH3az8w/vmT4
	e2SGeQgbGFWzPqWoqebL+5cR863F/HO3ebxgEmJtq38AKjv1tHISWvf44v66iv+dBcUf
	RuhwI2hCd/KR6OlaL3oXDMdQ1shmuUZh+9cKfiZvoKyAsjx8b0bnME9uEjtezkQ7WKut
	RkEQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:in-reply-to:references;
	bh=8zRYAkDhVrNO3gWAh/dTR0MU7K6NE4gHiKTCCXlX94o=;
	b=dB7rxEIRC96cQk87sXND6N6rPfn800hNnPn/GUXKhX/cGFjiZSdm9u7GGzLD7C79MU
	U+bN6Yuhx8sppXwO66qq8w0+Xi90S7MWgnOxS7bbkIfr5iyejvEsfIDRJkZaLKqkLWvq
	ZBZAen++LVOGce9R+ASLsqgBpsBB1g96LU7oqTPG1SnFqaTph/U2ibKtZ7z0DJvTq3NX
	AmdQZyVbjg0L0Zx9q0MnhqBu+t18KFv2OUXaIDLt/EuD1KIoLABzkRWJDp2bh1gnKgG1
	GBcMQmH6ZYdrSETk7WDlsI2GlI/Hu/ZO11GRD98QhjIoIy6UCDL1XVEOfpjpHtebGrMA
	FjeQ==
X-Gm-Message-State: AJaThX4w0gi3Sy/jJ1OIlsZHBxHybw+AVJhtb8b2PGstdOkrnrD+HHMR
	zUqZG4eqsmodjORSTVIdgOw=
X-Google-Smtp-Source: ABhQp+QT/JvuV0Fey/Jlrwz+9LU0enNRIyrd0ZsnQOHoACfYRqua7G2qcFaSTnnfW8HKcwltYhYa9g==
X-Received: by 10.99.140.22 with SMTP id m22mr1291143pgd.258.1510122016347; 
	Tue, 07 Nov 2017 22:20:16 -0800 (PST)
Received: from app09.andestech.com ([118.163.51.199])
	by smtp.gmail.com with ESMTPSA id
	a4sm6581339pfj.72.2017.11.07.22.20.13
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Tue, 07 Nov 2017 22:20:15 -0800 (PST)
From: Greentime Hu &lt;green.hu@gmail.com&gt;
To: greentime@andestech.com, linux-kernel@vger.kernel.org,
	arnd@arndb.de, linux-arch@vger.kernel.org, tglx@linutronix.de,
	jason@lakedaemon.net, marc.zyngier@arm.com, robh+dt@kernel.org,
	netdev@vger.kernel.org
Cc: green.hu@gmail.com, Vincent Chen &lt;vincentc@andestech.com&gt;
Subject: [PATCH 08/31] nds32: Cache and TLB routines
Date: Wed,  8 Nov 2017 13:54:56 +0800
Message-Id: &lt;220aabe68365f970ed6de79ef88f9598f272dcb9.1510118606.git.green.hu@gmail.com&gt;
X-Mailer: git-send-email 1.7.9.5
In-Reply-To: &lt;cover.1510118606.git.green.hu@gmail.com&gt;
References: &lt;cover.1510118606.git.green.hu@gmail.com&gt;
In-Reply-To: &lt;cover.1510118606.git.green.hu@gmail.com&gt;
References: &lt;cover.1510118606.git.green.hu@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Nov. 8, 2017, 5:54 a.m.</div>
<pre class="content">
<span class="from">From: Greentime Hu &lt;greentime@andestech.com&gt;</span>
<span class="signed-off-by">
Signed-off-by: Vincent Chen &lt;vincentc@andestech.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Greentime Hu &lt;greentime@andestech.com&gt;</span>
---
 arch/nds32/include/asm/cache.h         |   25 ++
 arch/nds32/include/asm/cache_info.h    |   26 ++
 arch/nds32/include/asm/cacheflush.h    |   57 +++
 arch/nds32/include/asm/mmu_context.h   |   81 +++++
 arch/nds32/include/asm/proc-fns.h      |   94 +++++
 arch/nds32/include/asm/tlb.h           |   41 +++
 arch/nds32/include/asm/tlbflush.h      |   60 ++++
 arch/nds32/include/uapi/asm/cachectl.h |   19 +
 arch/nds32/kernel/cacheinfo.c          |   62 ++++
 arch/nds32/mm/cacheflush.c             |  331 +++++++++++++++++
 arch/nds32/mm/proc-n13.c               |  608 ++++++++++++++++++++++++++++++++
 arch/nds32/mm/tlb.c                    |   63 ++++
 12 files changed, 1467 insertions(+)
 create mode 100644 arch/nds32/include/asm/cache.h
 create mode 100644 arch/nds32/include/asm/cache_info.h
 create mode 100644 arch/nds32/include/asm/cacheflush.h
 create mode 100644 arch/nds32/include/asm/mmu_context.h
 create mode 100644 arch/nds32/include/asm/proc-fns.h
 create mode 100644 arch/nds32/include/asm/tlb.h
 create mode 100644 arch/nds32/include/asm/tlbflush.h
 create mode 100644 arch/nds32/include/uapi/asm/cachectl.h
 create mode 100644 arch/nds32/kernel/cacheinfo.c
 create mode 100644 arch/nds32/mm/cacheflush.c
 create mode 100644 arch/nds32/mm/proc-n13.c
 create mode 100644 arch/nds32/mm/tlb.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176">Arnd Bergmann</a> - Nov. 8, 2017, 8:45 a.m.</div>
<pre class="content">
On Wed, Nov 8, 2017 at 6:54 AM, Greentime Hu &lt;green.hu@gmail.com&gt; wrote:
<span class="quote">
&gt; +#ifndef __NDS32_PROCFNS_H__</span>
<span class="quote">&gt; +#define __NDS32_PROCFNS_H__</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define CPU_NAME n13</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef __KERNEL__</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef __STDC__</span>
<span class="quote">&gt; +#define ____cpu_fn(name,fn)       name##fn</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define ____cpu_fn(name,fn)       name/**/fn</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#define __cpu_fn(name,fn)         ____cpu_fn(name,fn)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_proc_init                  __cpu_fn( CPU_NAME, _proc_init)</span>
<span class="quote">&gt; +#define cpu_proc_fin                   __cpu_fn( CPU_NAME, _proc_fin)</span>
<span class="quote">&gt; +#define cpu_do_idle                    __cpu_fn( CPU_NAME, _do_idle)</span>
<span class="quote">&gt; +#define cpu_reset                      __cpu_fn( CPU_NAME, _reset)</span>
<span class="quote">&gt; +#define cpu_switch_mm                  __cpu_fn( CPU_NAME, _switch_mm)</span>

I see you have copied this from ARM. Do you actually need the same complexity,
with the ability to build either optimal code for a particular CPU or
a multi-CPU
version?

Most other architectures seem to have settled for doing just one of the two
models. How many CPU implementations to you expect to support that
differ in all of those functions?

      Arnd
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Nov. 8, 2017, 9:01 a.m.</div>
<pre class="content">
2017-11-08 16:45 GMT+08:00 Arnd Bergmann &lt;arnd@arndb.de&gt;:
<span class="quote">&gt; On Wed, Nov 8, 2017 at 6:54 AM, Greentime Hu &lt;green.hu@gmail.com&gt; wrote:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +#ifndef __NDS32_PROCFNS_H__</span>
<span class="quote">&gt;&gt; +#define __NDS32_PROCFNS_H__</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define CPU_NAME n13</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifdef __KERNEL__</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifdef __STDC__</span>
<span class="quote">&gt;&gt; +#define ____cpu_fn(name,fn)       name##fn</span>
<span class="quote">&gt;&gt; +#else</span>
<span class="quote">&gt;&gt; +#define ____cpu_fn(name,fn)       name/**/fn</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +#define __cpu_fn(name,fn)         ____cpu_fn(name,fn)</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define cpu_proc_init                  __cpu_fn( CPU_NAME, _proc_init)</span>
<span class="quote">&gt;&gt; +#define cpu_proc_fin                   __cpu_fn( CPU_NAME, _proc_fin)</span>
<span class="quote">&gt;&gt; +#define cpu_do_idle                    __cpu_fn( CPU_NAME, _do_idle)</span>
<span class="quote">&gt;&gt; +#define cpu_reset                      __cpu_fn( CPU_NAME, _reset)</span>
<span class="quote">&gt;&gt; +#define cpu_switch_mm                  __cpu_fn( CPU_NAME, _switch_mm)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I see you have copied this from ARM. Do you actually need the same complexity,</span>
<span class="quote">&gt; with the ability to build either optimal code for a particular CPU or</span>
<span class="quote">&gt; a multi-CPU</span>
<span class="quote">&gt; version?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Most other architectures seem to have settled for doing just one of the two</span>
<span class="quote">&gt; models. How many CPU implementations to you expect to support that</span>
<span class="quote">&gt; differ in all of those functions?</span>
<span class="quote">&gt;</span>

I think we can simplify the implementations because we may not have that
many implementations. I will refine it in the next version patch.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/nds32/include/asm/cache.h b/arch/nds32/include/asm/cache.h</span>
new file mode 100644
<span class="p_header">index 0000000..36ec549</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cache.h</span>
<span class="p_chunk">@@ -0,0 +1,25 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_CACHE_H__</span>
<span class="p_add">+#define __NDS32_CACHE_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#define L1_CACHE_BYTES	32</span>
<span class="p_add">+#define L1_CACHE_SHIFT	5</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_DMA_MINALIGN   L1_CACHE_BYTES</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __NDS32_CACHE_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/cache_info.h b/arch/nds32/include/asm/cache_info.h</span>
new file mode 100644
<span class="p_header">index 0000000..a59d73d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cache_info.h</span>
<span class="p_chunk">@@ -0,0 +1,26 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+struct cache_info {</span>
<span class="p_add">+	unsigned char ways;</span>
<span class="p_add">+	unsigned char line_size;</span>
<span class="p_add">+	unsigned short sets;</span>
<span class="p_add">+	unsigned short size;</span>
<span class="p_add">+#if !defined(CONFIG_CPU_CACHE_NONALIASING)</span>
<span class="p_add">+	unsigned short aliasing_num;</span>
<span class="p_add">+	unsigned int aliasing_mask;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+};</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/cacheflush.h b/arch/nds32/include/asm/cacheflush.h</span>
new file mode 100644
<span class="p_header">index 0000000..0c7c9db</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cacheflush.h</span>
<span class="p_chunk">@@ -0,0 +1,57 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_CACHEFLUSH_H__</span>
<span class="p_add">+#define __NDS32_CACHEFLUSH_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define PG_dcache_dirty PG_arch_1</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef CONFIG_CPU_CACHE_NONALIASING</span>
<span class="p_add">+void flush_cache_mm(struct mm_struct *mm);</span>
<span class="p_add">+void flush_cache_dup_mm(struct mm_struct *mm);</span>
<span class="p_add">+void flush_cache_range(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_cache_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, unsigned long pfn);</span>
<span class="p_add">+void flush_cache_kmaps(void);</span>
<span class="p_add">+void flush_cache_vmap(unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_cache_vunmap(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1</span>
<span class="p_add">+void flush_dcache_page(struct page *page);</span>
<span class="p_add">+void copy_to_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+		       unsigned long vaddr, void *dst, void *src, int len);</span>
<span class="p_add">+void copy_from_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+			 unsigned long vaddr, void *dst, void *src, int len);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_HAS_FLUSH_ANON_PAGE</span>
<span class="p_add">+void flush_anon_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		     struct page *page, unsigned long vaddr);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE</span>
<span class="p_add">+void flush_kernel_dcache_page(struct page *page);</span>
<span class="p_add">+void flush_icache_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_icache_page(struct vm_area_struct *vma, struct page *page);</span>
<span class="p_add">+#define flush_dcache_mmap_lock(mapping)   spin_lock_irq(&amp;(mapping)-&gt;tree_lock)</span>
<span class="p_add">+#define flush_dcache_mmap_unlock(mapping) spin_unlock_irq(&amp;(mapping)-&gt;tree_lock)</span>
<span class="p_add">+</span>
<span class="p_add">+#else</span>
<span class="p_add">+#include &lt;asm-generic/cacheflush.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __NDS32_CACHEFLUSH_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/mmu_context.h b/arch/nds32/include/asm/mmu_context.h</span>
new file mode 100644
<span class="p_header">index 0000000..4a59b5d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -0,0 +1,81 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASM_NDS32_MMU_CONTEXT_H</span>
<span class="p_add">+#define __ASM_NDS32_MMU_CONTEXT_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm-generic/mm_hooks.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int</span>
<span class="p_add">+init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mm-&gt;context.id = 0;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define destroy_context(mm)	do { } while(0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define CID_BITS	9</span>
<span class="p_add">+extern spinlock_t cid_lock;</span>
<span class="p_add">+extern unsigned int cpu_last_cid;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __new_context(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cid;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	cid = cpu_last_cid;</span>
<span class="p_add">+	cpu_last_cid += 1 &lt;&lt; TLB_MISC_offCID;</span>
<span class="p_add">+	if (cpu_last_cid == 0)</span>
<span class="p_add">+		cpu_last_cid = 1 &lt;&lt; TLB_MISC_offCID &lt;&lt; CID_BITS;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((cid &amp; TLB_MISC_mskCID) == 0)</span>
<span class="p_add">+		flush_tlb_all();</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	mm-&gt;context.id = cid;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void check_context(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely</span>
<span class="p_add">+	    ((mm-&gt;context.id ^ cpu_last_cid) &gt;&gt; TLB_MISC_offCID &gt;&gt; CID_BITS))</span>
<span class="p_add">+		__new_context(mm);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
<span class="p_add">+			     struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cpu = smp_processor_id();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!cpumask_test_and_set_cpu(cpu, mm_cpumask(next)) || prev != next) {</span>
<span class="p_add">+		check_context(next);</span>
<span class="p_add">+		cpu_switch_mm(next);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define deactivate_mm(tsk,mm)	do { } while (0)</span>
<span class="p_add">+#define activate_mm(prev,next)	switch_mm(prev, next, NULL)</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/proc-fns.h b/arch/nds32/include/asm/proc-fns.h</span>
new file mode 100644
<span class="p_header">index 0000000..4321014</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/proc-fns.h</span>
<span class="p_chunk">@@ -0,0 +1,94 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_PROCFNS_H__</span>
<span class="p_add">+#define __NDS32_PROCFNS_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#define CPU_NAME n13</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef __KERNEL__</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef __STDC__</span>
<span class="p_add">+#define ____cpu_fn(name,fn)       name##fn</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define ____cpu_fn(name,fn)       name/**/fn</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#define __cpu_fn(name,fn)         ____cpu_fn(name,fn)</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_proc_init			__cpu_fn( CPU_NAME, _proc_init)</span>
<span class="p_add">+#define cpu_proc_fin			__cpu_fn( CPU_NAME, _proc_fin)</span>
<span class="p_add">+#define cpu_do_idle			__cpu_fn( CPU_NAME, _do_idle)</span>
<span class="p_add">+#define cpu_reset			__cpu_fn( CPU_NAME, _reset)</span>
<span class="p_add">+#define cpu_switch_mm			__cpu_fn( CPU_NAME, _switch_mm)</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_dcache_inval_all		__cpu_fn( CPU_NAME, _dcache_inval_all)</span>
<span class="p_add">+#define cpu_dcache_wbinval_all		__cpu_fn( CPU_NAME, _dcache_wbinval_all)</span>
<span class="p_add">+#define cpu_dcache_inval_page		__cpu_fn( CPU_NAME, _dcache_inval_page)</span>
<span class="p_add">+#define cpu_dcache_wb_page		__cpu_fn( CPU_NAME, _dcache_wb_page)</span>
<span class="p_add">+#define cpu_dcache_wbinval_page		__cpu_fn( CPU_NAME, _dcache_wbinval_page)</span>
<span class="p_add">+#define cpu_dcache_inval_range		__cpu_fn( CPU_NAME, _dcache_inval_range)</span>
<span class="p_add">+#define cpu_dcache_wb_range		__cpu_fn( CPU_NAME, _dcache_wb_range)</span>
<span class="p_add">+#define cpu_dcache_wbinval_range	__cpu_fn( CPU_NAME, _dcache_wbinval_range)</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_icache_inval_all		__cpu_fn( CPU_NAME, _icache_inval_all)</span>
<span class="p_add">+#define cpu_icache_inval_page		__cpu_fn( CPU_NAME, _icache_inval_page)</span>
<span class="p_add">+#define cpu_icache_inval_range		__cpu_fn( CPU_NAME, _icache_inval_range)</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_cache_wbinval_page		__cpu_fn( CPU_NAME, _cache_wbinval_page)</span>
<span class="p_add">+#define cpu_cache_wbinval_range		__cpu_fn( CPU_NAME, _cache_wbinval_range)</span>
<span class="p_add">+#define cpu_cache_wbinval_range_check	__cpu_fn( CPU_NAME, _cache_wbinval_range_check)</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_dma_wb_range		__cpu_fn( CPU_NAME, _dma_wb_range)</span>
<span class="p_add">+#define cpu_dma_inval_range		__cpu_fn( CPU_NAME, _dma_inval_range)</span>
<span class="p_add">+#define cpu_dma_wbinval_range		__cpu_fn( CPU_NAME, _dma_wbinval_range)</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct mm_struct;</span>
<span class="p_add">+struct vm_area_struct;</span>
<span class="p_add">+extern void cpu_proc_init(void);</span>
<span class="p_add">+extern void cpu_proc_fin(void);</span>
<span class="p_add">+extern void cpu_do_idle(void);</span>
<span class="p_add">+extern void cpu_reset(unsigned long reset);</span>
<span class="p_add">+extern void cpu_switch_mm(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_dcache_inval_all(void);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_all(void);</span>
<span class="p_add">+extern void cpu_dcache_inval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_wb_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dcache_wb_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_icache_inval_all(void);</span>
<span class="p_add">+extern void cpu_icache_inval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_icache_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_cache_wbinval_page(unsigned long page, int flushi);</span>
<span class="p_add">+extern void cpu_cache_wbinval_range(unsigned long start,</span>
<span class="p_add">+				    unsigned long end, int flushi);</span>
<span class="p_add">+extern void cpu_cache_wbinval_range_check(struct vm_area_struct *vma,</span>
<span class="p_add">+					  unsigned long start,</span>
<span class="p_add">+					  unsigned long end, bool flushi,</span>
<span class="p_add">+					  bool wbd);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_dma_wb_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dma_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dma_wbinval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __KERNEL__ */</span>
<span class="p_add">+#endif /* __NDS32_PROCFNS_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/tlb.h b/arch/nds32/include/asm/tlb.h</span>
new file mode 100644
<span class="p_header">index 0000000..c599827</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/tlb.h</span>
<span class="p_chunk">@@ -0,0 +1,41 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASMNDS32_TLB_H</span>
<span class="p_add">+#define __ASMNDS32_TLB_H</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_start_vma(tlb,vma)						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (!tlb-&gt;fullmm)					\</span>
<span class="p_add">+			flush_cache_range(vma, vma-&gt;vm_start, vma-&gt;vm_end); \</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_end_vma(tlb,vma)				\</span>
<span class="p_add">+	do { 						\</span>
<span class="p_add">+		if(!tlb-&gt;fullmm)			\</span>
<span class="p_add">+			flush_tlb_range(vma, vma-&gt;vm_start, vma-&gt;vm_end); \</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define __tlb_remove_tlb_entry(tlb, pte, addr) do { } while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_flush(tlb)	flush_tlb_mm((tlb)-&gt;mm)</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm-generic/tlb.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define __pte_free_tlb(tlb, pte, addr)	pte_free((tlb)-&gt;mm, pte)</span>
<span class="p_add">+#define __pmd_free_tlb(tlb, pmd, addr)	pmd_free((tln)-&gt;mm, pmd)</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/tlbflush.h b/arch/nds32/include/asm/tlbflush.h</span>
new file mode 100644
<span class="p_header">index 0000000..680aeb3</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -0,0 +1,60 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef _ASMNDS32_TLBFLUSH_H</span>
<span class="p_add">+#define _ASMNDS32_TLBFLUSH_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_flua();</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_flua();</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_kernel_range(unsigned long start,</span>
<span class="p_add">+						unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		__nds32__tlbop_inv(start);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_range(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long start, unsigned long end);</span>
<span class="p_add">+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+#define flush_tlb_all		local_flush_tlb_all</span>
<span class="p_add">+#define flush_tlb_mm		local_flush_tlb_mm</span>
<span class="p_add">+#define flush_tlb_range		local_flush_tlb_range</span>
<span class="p_add">+#define flush_tlb_page		local_flush_tlb_page</span>
<span class="p_add">+#define flush_tlb_kernel_range	local_flush_tlb_kernel_range</span>
<span class="p_add">+</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long address, pte_t * pte);</span>
<span class="p_add">+void tlb_migrate_finish(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/uapi/asm/cachectl.h b/arch/nds32/include/uapi/asm/cachectl.h</span>
new file mode 100644
<span class="p_header">index 0000000..a56a37d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/uapi/asm/cachectl.h</span>
<span class="p_chunk">@@ -0,0 +1,19 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This file is subject to the terms and conditions of the GNU General Public</span>
<span class="p_add">+ * License.  See the file &quot;COPYING&quot; in the main directory of this archive</span>
<span class="p_add">+ * for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 1994, 1995, 1996 by Ralf Baechle</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifndef	_ASM_CACHECTL</span>
<span class="p_add">+#define	_ASM_CACHECTL</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Options for cacheflush system call</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define	ICACHE	0		/* flush instruction cache        */</span>
<span class="p_add">+#define	DCACHE	1		/* writeback and flush data cache */</span>
<span class="p_add">+#define	BCACHE	2		/* flush instruction cache + writeback and flush data cache */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ASM_CACHECTL */</span>
<span class="p_header">diff --git a/arch/nds32/kernel/cacheinfo.c b/arch/nds32/kernel/cacheinfo.c</span>
new file mode 100644
<span class="p_header">index 0000000..edc0fda</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/kernel/cacheinfo.c</span>
<span class="p_chunk">@@ -0,0 +1,62 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/bitops.h&gt;</span>
<span class="p_add">+#include &lt;linux/cacheinfo.h&gt;</span>
<span class="p_add">+#include &lt;linux/cpu.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static void ci_leaf_init(struct cacheinfo *this_leaf,</span>
<span class="p_add">+			 enum cache_type type, unsigned int level)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char cache_type = (type &amp; CACHE_TYPE_INST ? ICACHE : DCACHE);</span>
<span class="p_add">+</span>
<span class="p_add">+	this_leaf-&gt;level = level;</span>
<span class="p_add">+	this_leaf-&gt;type = type;</span>
<span class="p_add">+	this_leaf-&gt;coherency_line_size = CACHE_LINE_SIZE(cache_type);</span>
<span class="p_add">+	this_leaf-&gt;number_of_sets = CACHE_SET(cache_type);;</span>
<span class="p_add">+	this_leaf-&gt;ways_of_associativity = CACHE_WAY(cache_type);</span>
<span class="p_add">+	this_leaf-&gt;size = this_leaf-&gt;number_of_sets *</span>
<span class="p_add">+	    this_leaf-&gt;coherency_line_size * this_leaf-&gt;ways_of_associativity;</span>
<span class="p_add">+#if defined(CONFIG_CPU_DCACHE_WRITETHROUGH)</span>
<span class="p_add">+	this_leaf-&gt;attributes = CACHE_WRITE_THROUGH;</span>
<span class="p_add">+#else</span>
<span class="p_add">+	this_leaf-&gt;attributes = CACHE_WRITE_BACK;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int init_cache_level(unsigned int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Only 1 level and I/D cache seperate. */</span>
<span class="p_add">+	this_cpu_ci-&gt;num_levels = 1;</span>
<span class="p_add">+	this_cpu_ci-&gt;num_leaves = 2;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int populate_cache_leaves(unsigned int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int level, idx;</span>
<span class="p_add">+	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);</span>
<span class="p_add">+	struct cacheinfo *this_leaf = this_cpu_ci-&gt;info_list;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (idx = 0, level = 1; level &lt;= this_cpu_ci-&gt;num_levels &amp;&amp;</span>
<span class="p_add">+	     idx &lt; this_cpu_ci-&gt;num_leaves; idx++, level++) {</span>
<span class="p_add">+		ci_leaf_init(this_leaf++, CACHE_TYPE_DATA, level);</span>
<span class="p_add">+		ci_leaf_init(this_leaf++, CACHE_TYPE_INST, level);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/cacheflush.c b/arch/nds32/mm/cacheflush.c</span>
new file mode 100644
<span class="p_header">index 0000000..f5917fb</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/cacheflush.c</span>
<span class="p_chunk">@@ -0,0 +1,331 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/fs.h&gt;</span>
<span class="p_add">+#include &lt;linux/pagemap.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm/shmparam.h&gt;</span>
<span class="p_add">+#include &lt;asm/cache_info.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct cache_info L1_cache_info[2];</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CPU_CACHE_NONALIASING</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		      pte_t * pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long pfn = pte_pfn(*pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pfn_valid(pfn))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm == current-&gt;active_mm) {</span>
<span class="p_add">+</span>
<span class="p_add">+		__nds32__mtsr_dsb(addr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+		__nds32__tlbop_rwr(*pte);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+	}</span>
<span class="p_add">+	page = pfn_to_page(pfn);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((test_and_clear_bit(PG_dcache_dirty, &amp;page-&gt;flags)) ||</span>
<span class="p_add">+	    (vma-&gt;vm_flags &amp; VM_EXEC)) {</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!PageHighMem(page)) {</span>
<span class="p_add">+			cpu_cache_wbinval_page((unsigned long)</span>
<span class="p_add">+					       page_address(page),</span>
<span class="p_add">+					       vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			unsigned long kaddr = (unsigned long)kmap_atomic(page);</span>
<span class="p_add">+			cpu_cache_wbinval_page(kaddr, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+			kunmap_atomic((void *)kaddr);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#else</span>
<span class="p_add">+extern pte_t va_present(struct mm_struct *mm, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long aliasing(unsigned long addr, unsigned long page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return ((addr &amp; PAGE_MASK) ^ page) &amp; (REALSHMLBA - 1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kremap0(unsigned long uaddr, unsigned long pa)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BASE_ADDR0 0xffffc000</span>
<span class="p_add">+	kaddr = BASE_ADDR0 | (uaddr &amp; L1_cache_info[DCACHE].aliasing_mask);</span>
<span class="p_add">+	pte = (pa | PAGE_KERNEL);</span>
<span class="p_add">+	__nds32__mtsr_dsb(kaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwlk(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return kaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kunmap01(unsigned long kaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_unlk(kaddr);</span>
<span class="p_add">+	__nds32__tlbop_inv(kaddr);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kremap1(unsigned long uaddr, unsigned long pa)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BASE_ADDR1 0xffff8000</span>
<span class="p_add">+	kaddr = BASE_ADDR1 | (uaddr &amp; L1_cache_info[DCACHE].aliasing_mask);</span>
<span class="p_add">+	pte = (pa | PAGE_KERNEL);</span>
<span class="p_add">+	__nds32__mtsr_dsb(kaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwlk(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return kaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_dup_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_range(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; 8 * PAGE_SIZE) {</span>
<span class="p_add">+		cpu_dcache_wbinval_all();</span>
<span class="p_add">+		if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+			cpu_icache_inval_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, start))</span>
<span class="p_add">+			cpu_cache_wbinval_page(start, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+	return;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(addr, pfn &lt;&lt; PAGE_SHIFT);</span>
<span class="p_add">+	cpu_cache_wbinval_page(vto, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_vmap(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_vunmap(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_user_highpage(struct page *to, struct page *from,</span>
<span class="p_add">+			unsigned long vaddr, struct vm_area_struct *vma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, vfrom, flags, kto, kfrom, pfrom, pto;</span>
<span class="p_add">+	kto = ((unsigned long)page_address(to) &amp; PAGE_MASK);</span>
<span class="p_add">+	kfrom = ((unsigned long)page_address(from) &amp; PAGE_MASK);</span>
<span class="p_add">+	pto = page_to_phys(to);</span>
<span class="p_add">+	pfrom = page_to_phys(from);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (aliasing(vaddr, (unsigned long)kfrom))</span>
<span class="p_add">+		cpu_dcache_wb_page((unsigned long)kfrom);</span>
<span class="p_add">+	if (aliasing(vaddr, (unsigned long)kto))</span>
<span class="p_add">+		cpu_dcache_inval_page((unsigned long)kto);</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, pto);</span>
<span class="p_add">+	vfrom = kremap1(vaddr, pfrom);</span>
<span class="p_add">+	copy_page((void *)vto, (void *)vfrom);</span>
<span class="p_add">+	kunmap01(vfrom);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(copy_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void clear_user_highpage(struct page *page, unsigned long vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags, kto;</span>
<span class="p_add">+</span>
<span class="p_add">+	kto = ((unsigned long)page_address(page) &amp; PAGE_MASK);</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (aliasing(kto, vaddr) &amp;&amp; kto != 0) {</span>
<span class="p_add">+		cpu_dcache_inval_page(kto);</span>
<span class="p_add">+		cpu_icache_inval_page(kto);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	clear_page((void *)vto);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(clear_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct address_space *mapping;</span>
<span class="p_add">+</span>
<span class="p_add">+	mapping = page_mapping(page);</span>
<span class="p_add">+	if (mapping &amp;&amp; !mapping_mapped(mapping))</span>
<span class="p_add">+		set_bit(PG_dcache_dirty, &amp;page-&gt;flags);</span>
<span class="p_add">+	else {</span>
<span class="p_add">+		int i, pc;</span>
<span class="p_add">+		unsigned long vto, kaddr, flags;</span>
<span class="p_add">+		kaddr = (unsigned long)page_address(page);</span>
<span class="p_add">+		cpu_dcache_wbinval_page(kaddr);</span>
<span class="p_add">+		pc = CACHE_SET(DCACHE) * CACHE_LINE_SIZE(DCACHE) / PAGE_SIZE;</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		for (i = 0; i &lt; pc; i++) {</span>
<span class="p_add">+			vto =</span>
<span class="p_add">+			    kremap0(kaddr + i * PAGE_SIZE, page_to_phys(page));</span>
<span class="p_add">+			cpu_dcache_wbinval_page(vto);</span>
<span class="p_add">+			kunmap01(vto);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_to_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+		       unsigned long vaddr, void *dst, void *src, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, start, end, vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	dst = (void *)(vto | (vaddr &amp; (PAGE_SIZE - 1)));</span>
<span class="p_add">+	memcpy(dst, src, len);</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_EXEC) {</span>
<span class="p_add">+		line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+		start = (unsigned long)dst &amp; ~(line_size - 1);</span>
<span class="p_add">+		end =</span>
<span class="p_add">+		    ((unsigned long)dst + len + line_size - 1) &amp; ~(line_size -</span>
<span class="p_add">+								   1);</span>
<span class="p_add">+		cpu_cache_wbinval_range(start, end, 1);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_from_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+			 unsigned long vaddr, void *dst, void *src, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	src = (void *)(vto | (vaddr &amp; (PAGE_SIZE - 1)));</span>
<span class="p_add">+	memcpy(dst, src, len);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_anon_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		     struct page *page, unsigned long vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	if (!PageAnon(page))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm != current-&gt;active_mm)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+		cpu_icache_inval_page(vaddr &amp; PAGE_MASK);</span>
<span class="p_add">+	cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_kernel_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_cache_wbinval_range(start, end, 1);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_page(struct vm_area_struct *vma, struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_cache_wbinval_page((unsigned long)page_address(page),</span>
<span class="p_add">+			       vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		      pte_t * pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	unsigned long pfn = pte_pfn(*pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pfn_valid(pfn))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm == current-&gt;active_mm) {</span>
<span class="p_add">+		__nds32__mtsr_dsb(addr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+		__nds32__tlbop_rwr(*pte);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	page = pfn_to_page(pfn);</span>
<span class="p_add">+	if (test_and_clear_bit(PG_dcache_dirty, &amp;page-&gt;flags) ||</span>
<span class="p_add">+	    (vma-&gt;vm_flags &amp; VM_EXEC)) {</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/mm/proc-n13.c b/arch/nds32/mm/proc-n13.c</span>
new file mode 100644
<span class="p_header">index 0000000..9956785</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/proc-n13.c</span>
<span class="p_chunk">@@ -0,0 +1,608 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;asm/nds32.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+#include &lt;asm/l2_cache.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/cache_info.h&gt;</span>
<span class="p_add">+extern struct cache_info L1_cache_info[2];</span>
<span class="p_add">+</span>
<span class="p_add">+int va_kernel_present(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *ptep, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pmd_offset(pgd_offset_k(addr), addr);</span>
<span class="p_add">+	if (!pmd_none(*pmd)) {</span>
<span class="p_add">+		ptep = pte_offset_map(pmd, addr);</span>
<span class="p_add">+		pte = *ptep;</span>
<span class="p_add">+		if (pte_present(pte))</span>
<span class="p_add">+			return pte;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t va_present(struct mm_struct * mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *ptep, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	if (!pgd_none(*pgd)) {</span>
<span class="p_add">+		pud = pud_offset(pgd, addr);</span>
<span class="p_add">+		if (!pud_none(*pud)) {</span>
<span class="p_add">+			pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+			if (!pmd_none(*pmd)) {</span>
<span class="p_add">+				ptep = pte_offset_map(pmd, addr);</span>
<span class="p_add">+				pte = *ptep;</span>
<span class="p_add">+				if (pte_present(pte))</span>
<span class="p_add">+					return pte;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int va_readable(struct pt_regs *regs, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (user_mode(regs)) {</span>
<span class="p_add">+		/* user mode */</span>
<span class="p_add">+		pte = va_present(mm, addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_read(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* superuser mode is always readable, so we can only</span>
<span class="p_add">+		 * check it is present or not*/</span>
<span class="p_add">+		return (! !va_kernel_present(addr));</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int va_writable(struct pt_regs *regs, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (user_mode(regs)) {</span>
<span class="p_add">+		/* user mode */</span>
<span class="p_add">+		pte = va_present(mm, addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_write(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* superuser mode */</span>
<span class="p_add">+		pte = va_kernel_present(addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_kernel_write(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * All</span>
<span class="p_add">+ */</span>
<span class="p_add">+void n13_icache_inval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long end, line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+	end =</span>
<span class="p_add">+	    line_size * L1_cache_info[ICACHE].ways * L1_cache_info[ICACHE].sets;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end &gt; 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_inval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__cctl_l1d_invalall();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_wb_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base)</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_alvl();</span>
<span class="p_add">+	else</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+#else</span>
<span class="p_add">+	__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_wbinval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base)</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_alvl();</span>
<span class="p_add">+	else</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+#else</span>
<span class="p_add">+	__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	__nds32__cctl_l1d_invalall();</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Page</span>
<span class="p_add">+ */</span>
<span class="p_add">+void n13_icache_inval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_inval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_wb_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_wbinval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_cache_wbinval_page(unsigned long page, int flushi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	n13_dcache_wbinval_page(page);</span>
<span class="p_add">+	if (flushi)</span>
<span class="p_add">+		n13_icache_inval_page(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Range</span>
<span class="p_add">+ */</span>
<span class="p_add">+void n13_icache_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_wb_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dcache_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_cache_wbinval_range(unsigned long start, unsigned long end, int flushi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, align_start, align_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	align_start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	align_end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+	n13_dcache_wbinval_range(align_start, align_end);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (flushi) {</span>
<span class="p_add">+		line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+		align_start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+		align_end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+		n13_icache_inval_range(align_start, align_end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_cache_wbinval_range_check(struct vm_area_struct *vma,</span>
<span class="p_add">+				   unsigned long start, unsigned long end,</span>
<span class="p_add">+				   bool flushi, bool wbd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, t_start, t_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!flushi &amp;&amp; !wbd)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; (8 * PAGE_SIZE)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			n13_dcache_wbinval_all();</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			n13_icache_inval_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	t_start = (start + PAGE_SIZE) &amp; PAGE_MASK;</span>
<span class="p_add">+	t_end = ((end - 1) &amp; PAGE_MASK);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((start &amp; PAGE_MASK) == t_end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, start)) {</span>
<span class="p_add">+			if (wbd)</span>
<span class="p_add">+				n13_dcache_wbinval_range(start, end);</span>
<span class="p_add">+			if (flushi)</span>
<span class="p_add">+				n13_icache_inval_range(start, end);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va_present(vma-&gt;vm_mm, start)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			n13_dcache_wbinval_range(start, end);</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			n13_icache_inval_range(start, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va_present(vma-&gt;vm_mm, end - 1)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			n13_dcache_wbinval_range(start, end);</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			n13_icache_inval_range(start, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	while (t_start &lt; t_end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, t_start)) {</span>
<span class="p_add">+			if (wbd)</span>
<span class="p_add">+				n13_dcache_wbinval_page(t_start);</span>
<span class="p_add">+			if (flushi)</span>
<span class="p_add">+				n13_icache_inval_page(t_start);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		t_start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * DMA</span>
<span class="p_add">+ */</span>
<span class="p_add">+void n13_dma_wb_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	n13_dcache_wb_range(start, end);</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base) {</span>
<span class="p_add">+		unsigned long p_start = __pa(start);</span>
<span class="p_add">+		unsigned long p_end = __pa(end);</span>
<span class="p_add">+		unsigned long cmd;</span>
<span class="p_add">+		/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+		line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+		p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+		p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+		cmd =</span>
<span class="p_add">+		    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_WB |</span>
<span class="p_add">+		    CCTL_SINGLE_CMD;</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			cmd += line_size;</span>
<span class="p_add">+			p_start += line_size;</span>
<span class="p_add">+		} while (p_end &gt; p_start);</span>
<span class="p_add">+		cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+		L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+void n13_l2dcache_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long p_start;</span>
<span class="p_add">+	unsigned long p_end;</span>
<span class="p_add">+	unsigned long cmd;</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	p_start = __pa(start);</span>
<span class="p_add">+	p_end = __pa(end);</span>
<span class="p_add">+	/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+	line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+	p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+	p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	cmd =</span>
<span class="p_add">+	    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_WBINVAL |</span>
<span class="p_add">+	    CCTL_SINGLE_CMD;</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+		L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+		cmd += line_size;</span>
<span class="p_add">+		p_start += line_size;</span>
<span class="p_add">+	} while (p_end &gt; p_start);</span>
<span class="p_add">+	cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+	L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dma_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long old_start = start;</span>
<span class="p_add">+	unsigned long old_end = end;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (start != old_start) {</span>
<span class="p_add">+		n13_dcache_wbinval_range(start, start + line_size);</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+		if (atl2c_base)</span>
<span class="p_add">+			n13_l2dcache_wbinval_range(start, start + line_size);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (end != old_end) {</span>
<span class="p_add">+		n13_dcache_wbinval_range(end - line_size, end);</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+		if (atl2c_base)</span>
<span class="p_add">+			n13_l2dcache_wbinval_range(end - line_size, end);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	}</span>
<span class="p_add">+	n13_dcache_inval_range(start, end);</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base) {</span>
<span class="p_add">+		unsigned long p_start = __pa(start);</span>
<span class="p_add">+		unsigned long p_end = __pa(end);</span>
<span class="p_add">+		unsigned long cmd;</span>
<span class="p_add">+		/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+		line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+		p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+		p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+		cmd =</span>
<span class="p_add">+		    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_INVAL |</span>
<span class="p_add">+		    CCTL_SINGLE_CMD;</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			cmd += line_size;</span>
<span class="p_add">+			p_start += line_size;</span>
<span class="p_add">+		} while (p_end &gt; p_start);</span>
<span class="p_add">+		cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+		L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_dma_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	n13_dcache_wbinval_range(start, end);</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+	if (atl2c_base) {</span>
<span class="p_add">+		unsigned long p_start = __pa(start);</span>
<span class="p_add">+		unsigned long p_end = __pa(end);</span>
<span class="p_add">+		unsigned long cmd;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+		line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+		p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+		p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+		cmd =</span>
<span class="p_add">+		    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_WBINVAL |</span>
<span class="p_add">+		    CCTL_SINGLE_CMD;</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			cmd += line_size;</span>
<span class="p_add">+			p_start += line_size;</span>
<span class="p_add">+		} while (p_end &gt; p_start);</span>
<span class="p_add">+		cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+		L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_proc_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_proc_fin(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_do_idle(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__standby_no_wake_grant();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_reset(unsigned long reset)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 tmp;</span>
<span class="p_add">+	GIE_DISABLE();</span>
<span class="p_add">+	tmp = __nds32__mfsr(NDS32_SR_CACHE_CTL);</span>
<span class="p_add">+	tmp &amp;= ~(CACHE_CTL_mskIC_EN | CACHE_CTL_mskDC_EN);</span>
<span class="p_add">+	__nds32__mtsr_isb(tmp, NDS32_SR_CACHE_CTL);</span>
<span class="p_add">+	n13_dcache_wbinval_all();</span>
<span class="p_add">+	n13_icache_inval_all();</span>
<span class="p_add">+</span>
<span class="p_add">+	__asm__ __volatile__(&quot;jr.toff %0\n\t&quot;::&quot;r&quot;(reset));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void n13_switch_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long cid;</span>
<span class="p_add">+	cid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	cid = (cid &amp; ~TLB_MISC_mskCID) | mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(cid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	__nds32__mtsr_isb(__pa(mm-&gt;pgd), NDS32_SR_L1_PPTB);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/tlb.c b/arch/nds32/mm/tlb.c</span>
new file mode 100644
<span class="p_header">index 0000000..b397b9f</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/tlb.c</span>
<span class="p_chunk">@@ -0,0 +1,63 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock_types.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;asm/nds32.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned int cpu_last_cid = { TLB_MISC_mskCID + (2 &lt;&lt; TLB_MISC_offCID) };</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_SPINLOCK(cid_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_range(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, ocid, ncid;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; 0x400000) {</span>
<span class="p_add">+		__nds32__tlbop_flua();</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	ocid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	ncid = (ocid &amp; ~TLB_MISC_mskCID) | vma-&gt;vm_mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(ncid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		__nds32__tlbop_inv(start);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__mtsr_dsb(ocid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, ocid, ncid;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	ocid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	ncid = (ocid &amp; ~TLB_MISC_mskCID) | vma-&gt;vm_mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(ncid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	__nds32__tlbop_inv(addr);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	__nds32__mtsr_dsb(ocid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



