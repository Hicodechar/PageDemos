
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v5,4/4] sparc64: Add support for ADI (Application Data Integrity) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v5,4/4] sparc64: Add support for ADI (Application Data Integrity)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 25, 2017, 7:57 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;0b6865aabc010ee3a7ea956a70447abbab53ea70.1485362562.git.khalid.aziz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9537849/mbox/"
   >mbox</a>
|
   <a href="/patch/9537849/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9537849/">/patch/9537849/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	ADA916042C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 25 Jan 2017 19:58:46 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9B0FF27F8F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 25 Jan 2017 19:58:46 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 8DB3127F99; Wed, 25 Jan 2017 19:58:46 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	UNPARSEABLE_RELAY autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2AC6527F8F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 25 Jan 2017 19:58:44 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752226AbdAYT6h (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 25 Jan 2017 14:58:37 -0500
Received: from aserp1040.oracle.com ([141.146.126.69]:17677 &quot;EHLO
	aserp1040.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752056AbdAYT6b (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 25 Jan 2017 14:58:31 -0500
Received: from userv0021.oracle.com (userv0021.oracle.com [156.151.31.71])
	by aserp1040.oracle.com (Sentrion-MTA-4.3.2/Sentrion-MTA-4.3.2) with
	ESMTP id v0PJvrjb026736
	(version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Wed, 25 Jan 2017 19:57:54 GMT
Received: from aserv0121.oracle.com (aserv0121.oracle.com [141.146.126.235])
	by userv0021.oracle.com (8.14.4/8.14.4) with ESMTP id
	v0PJvpaA001314
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=OK);
	Wed, 25 Jan 2017 19:57:52 GMT
Received: from abhmp0008.oracle.com (abhmp0008.oracle.com [141.146.116.14])
	by aserv0121.oracle.com (8.13.8/8.13.8) with ESMTP id
	v0PJvm2m031400; Wed, 25 Jan 2017 19:57:49 GMT
Received: from concerto.us.oracle.com (/10.159.124.207)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Wed, 25 Jan 2017 11:57:47 -0800
From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;
To: davem@davemloft.net, corbet@lwn.net
Cc: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;, viro@zeniv.linux.org.uk,
	nitin.m.gupta@oracle.com, mike.kravetz@oracle.com,
	akpm@linux-foundation.org, mingo@kernel.org,
	kirill.shutemov@linux.intel.com, adam.buchbinder@gmail.com,
	hughd@google.com, minchan@kernel.org, keescook@chromium.org,
	chris.hyser@oracle.com, atish.patra@oracle.com,
	cmetcalf@mellanox.com, atomlin@redhat.com, jslaby@suse.cz,
	joe@perches.com, paul.gortmaker@windriver.com, mhocko@suse.com,
	lstoakes@gmail.com, jack@suse.cz, dave.hansen@linux.intel.com,
	vbabka@suse.cz, dan.j.williams@intel.com, iamjoonsoo.kim@lge.com,
	linux-doc@vger.kernel.org, linux-kernel@vger.kernel.org,
	sparclinux@vger.kernel.org, linux-mm@kvack.org,
	Khalid Aziz &lt;khalid@gonehiking.org&gt;
Subject: [PATCH v5 4/4] sparc64: Add support for ADI (Application Data
	Integrity)
Date: Wed, 25 Jan 2017 12:57:16 -0700
Message-Id: &lt;0b6865aabc010ee3a7ea956a70447abbab53ea70.1485362562.git.khalid.aziz@oracle.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;cover.1485362562.git.khalid.aziz@oracle.com&gt;
References: &lt;cover.1485362562.git.khalid.aziz@oracle.com&gt;
In-Reply-To: &lt;cover.1485362562.git.khalid.aziz@oracle.com&gt;
References: &lt;cover.1485362562.git.khalid.aziz@oracle.com&gt;
X-Source-IP: userv0021.oracle.com [156.151.31.71]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 25, 2017, 7:57 p.m.</div>
<pre class="content">
ADI is a new feature supported on SPARC M7 and newer processors to allow
hardware to catch rogue accesses to memory. ADI is supported for data
fetches only and not instruction fetches. An app can enable ADI on its
data pages, set version tags on them and use versioned addresses to
access the data pages. Upper bits of the address contain the version
tag. On M7 processors, upper four bits (bits 63-60) contain the version
tag. If a rogue app attempts to access ADI enabled data pages, its
access is blocked and processor generates an exception. Please see
Documentation/sparc/adi.txt for further details.

This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable
MCD (Memory Corruption Detection) on selected memory ranges, enable
TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI
version tags on page swap out/in or migration. It also adds handlers for
traps related to MCD. ADI is not enabled by default for any task. A task
must explicitly enable ADI on a memory range and set version tag for ADI
to be effective for the task.

This initial implementation supports saving and restoring one tag per
page. A page must use same version tag across the entire page for the
tag to survive swap and migration. Swap swupport infrastructure in this
patch allows for this capability to be expanded to store/restore more
than one tag per page in future.
<span class="signed-off-by">
Signed-off-by: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Cc: Khalid Aziz &lt;khalid@gonehiking.org&gt;
---
v5:
	- Fixed indentation issues and instrcuctions in assembly code
	- Removed CONFIG_SPARC64 from mdesc.c
	- Changed to maintain state of MCDPER register in thread info
	  flags as opposed to in mm context. MCDPER is a per-thread
	  state and belongs in thread info flag as opposed to mm context
	  which is shared across threads. Added comments to clarify this
	  is a lazily maintained state and must be updated on context
	  switch and copy_process()
	- Updated code to use the new arch_do_swap_page() and
	  arch_unmap_one() functions

v4:
	- Broke patch up into smaller patches

v3:
	- Removed CONFIG_SPARC_ADI
	- Replaced prctl commands with mprotect
	- Added auxiliary vectors for ADI parameters
	- Enabled ADI for swappable pages

v2:
	- Fixed a build error

 Documentation/sparc/adi.txt             | 288 ++++++++++++++++++++++++++++++++
 arch/sparc/include/asm/adi.h            |   6 +
 arch/sparc/include/asm/adi_64.h         |  46 +++++
 arch/sparc/include/asm/elf_64.h         |   8 +
 arch/sparc/include/asm/hugetlb.h        |  13 ++
 arch/sparc/include/asm/mman.h           |  40 ++++-
 arch/sparc/include/asm/mmu_64.h         |   1 +
 arch/sparc/include/asm/mmu_context_64.h |  43 +++++
 arch/sparc/include/asm/pgtable_64.h     |  85 +++++++++-
 arch/sparc/include/asm/thread_info_64.h |   1 +
 arch/sparc/include/asm/uaccess_64.h     | 120 ++++++++++++-
 arch/sparc/include/uapi/asm/auxvec.h    |   8 +
 arch/sparc/include/uapi/asm/mman.h      |   2 +
 arch/sparc/kernel/Makefile              |   1 +
 arch/sparc/kernel/adi_64.c              |  93 +++++++++++
 arch/sparc/kernel/mdesc.c               |   2 +
 arch/sparc/kernel/process_64.c          |  25 +++
 arch/sparc/kernel/traps_64.c            |  88 +++++++++-
 arch/sparc/mm/gup.c                     |  37 ++++
 include/linux/mm.h                      |   2 +
 20 files changed, 897 insertions(+), 12 deletions(-)
 create mode 100644 Documentation/sparc/adi.txt
 create mode 100644 arch/sparc/include/asm/adi.h
 create mode 100644 arch/sparc/include/asm/adi_64.h
 create mode 100644 arch/sparc/kernel/adi_64.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 25, 2017, 10 p.m.</div>
<pre class="content">
On 01/25/2017 12:57 PM, Khalid Aziz wrote:
<span class="quote">&gt; ADI is a new feature supported on SPARC M7 and newer processors to allow</span>
<span class="quote">&gt; hardware to catch rogue accesses to memory. ADI is supported for data</span>
<span class="quote">&gt; fetches only and not instruction fetches. An app can enable ADI on its</span>
<span class="quote">&gt; data pages, set version tags on them and use versioned addresses to</span>
<span class="quote">&gt; access the data pages. Upper bits of the address contain the version</span>
<span class="quote">&gt; tag. On M7 processors, upper four bits (bits 63-60) contain the version</span>
<span class="quote">&gt; tag. If a rogue app attempts to access ADI enabled data pages, its</span>
<span class="quote">&gt; access is blocked and processor generates an exception. Please see</span>
<span class="quote">&gt; Documentation/sparc/adi.txt for further details.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable</span>
<span class="quote">&gt; MCD (Memory Corruption Detection) on selected memory ranges, enable</span>
<span class="quote">&gt; TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI</span>
<span class="quote">&gt; version tags on page swap out/in or migration. It also adds handlers for</span>
<span class="quote">&gt; traps related to MCD. ADI is not enabled by default for any task. A task</span>
<span class="quote">&gt; must explicitly enable ADI on a memory range and set version tag for ADI</span>
<span class="quote">&gt; to be effective for the task.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This initial implementation supports saving and restoring one tag per</span>
<span class="quote">&gt; page. A page must use same version tag across the entire page for the</span>
<span class="quote">&gt; tag to survive swap and migration. Swap swupport infrastructure in this</span>
<span class="quote">&gt; patch allows for this capability to be expanded to store/restore more</span>
<span class="quote">&gt; than one tag per page in future.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
<span class="quote">&gt; Cc: Khalid Aziz &lt;khalid@gonehiking.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; v5:</span>
<span class="quote">&gt; 	- Fixed indentation issues and instrcuctions in assembly code</span>
<span class="quote">&gt; 	- Removed CONFIG_SPARC64 from mdesc.c</span>
<span class="quote">&gt; 	- Changed to maintain state of MCDPER register in thread info</span>
<span class="quote">&gt; 	  flags as opposed to in mm context. MCDPER is a per-thread</span>
<span class="quote">&gt; 	  state and belongs in thread info flag as opposed to mm context</span>
<span class="quote">&gt; 	  which is shared across threads. Added comments to clarify this</span>
<span class="quote">&gt; 	  is a lazily maintained state and must be updated on context</span>
<span class="quote">&gt; 	  switch and copy_process()</span>
<span class="quote">&gt; 	- Updated code to use the new arch_do_swap_page() and</span>
<span class="quote">&gt; 	  arch_unmap_one() functions</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; v4:</span>
<span class="quote">&gt; 	- Broke patch up into smaller patches</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; v3:</span>
<span class="quote">&gt; 	- Removed CONFIG_SPARC_ADI</span>
<span class="quote">&gt; 	- Replaced prctl commands with mprotect</span>
<span class="quote">&gt; 	- Added auxiliary vectors for ADI parameters</span>
<span class="quote">&gt; 	- Enabled ADI for swappable pages</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; v2:</span>
<span class="quote">&gt; 	- Fixed a build error</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   Documentation/sparc/adi.txt             | 288 ++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;   arch/sparc/include/asm/adi.h            |   6 +</span>
<span class="quote">&gt;   arch/sparc/include/asm/adi_64.h         |  46 +++++</span>
<span class="quote">&gt;   arch/sparc/include/asm/elf_64.h         |   8 +</span>
<span class="quote">&gt;   arch/sparc/include/asm/hugetlb.h        |  13 ++</span>
<span class="quote">&gt;   arch/sparc/include/asm/mman.h           |  40 ++++-</span>
<span class="quote">&gt;   arch/sparc/include/asm/mmu_64.h         |   1 +</span>
<span class="quote">&gt;   arch/sparc/include/asm/mmu_context_64.h |  43 +++++</span>
<span class="quote">&gt;   arch/sparc/include/asm/pgtable_64.h     |  85 +++++++++-</span>
<span class="quote">&gt;   arch/sparc/include/asm/thread_info_64.h |   1 +</span>
<span class="quote">&gt;   arch/sparc/include/asm/uaccess_64.h     | 120 ++++++++++++-</span>
<span class="quote">&gt;   arch/sparc/include/uapi/asm/auxvec.h    |   8 +</span>
<span class="quote">&gt;   arch/sparc/include/uapi/asm/mman.h      |   2 +</span>
<span class="quote">&gt;   arch/sparc/kernel/Makefile              |   1 +</span>
<span class="quote">&gt;   arch/sparc/kernel/adi_64.c              |  93 +++++++++++</span>
<span class="quote">&gt;   arch/sparc/kernel/mdesc.c               |   2 +</span>
<span class="quote">&gt;   arch/sparc/kernel/process_64.c          |  25 +++</span>
<span class="quote">&gt;   arch/sparc/kernel/traps_64.c            |  88 +++++++++-</span>
<span class="quote">&gt;   arch/sparc/mm/gup.c                     |  37 ++++</span>
<span class="quote">&gt;   include/linux/mm.h                      |   2 +</span>
<span class="quote">&gt;   20 files changed, 897 insertions(+), 12 deletions(-)</span>
<span class="quote">&gt;   create mode 100644 Documentation/sparc/adi.txt</span>
<span class="quote">&gt;   create mode 100644 arch/sparc/include/asm/adi.h</span>
<span class="quote">&gt;   create mode 100644 arch/sparc/include/asm/adi_64.h</span>
<span class="quote">&gt;   create mode 100644 arch/sparc/kernel/adi_64.c</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/Documentation/sparc/adi.txt b/Documentation/sparc/adi.txt</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..1740f8a</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/Documentation/sparc/adi.txt</span>
<span class="quote">&gt; @@ -0,0 +1,288 @@</span>
<span class="quote">&gt; +Application Data Integrity (ADI)</span>
<span class="quote">&gt; +================================</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +SPARC M7 processor adds the Application Data Integrity (ADI) feature.</span>
<span class="quote">&gt; +ADI allows a task to set version tags on any subset of its address</span>
<span class="quote">&gt; +space. Once ADI is enabled and version tags are set for ranges of</span>
<span class="quote">&gt; +address space of a task, the processor will compare the tag in pointers</span>
<span class="quote">&gt; +to memory in these ranges to the version set by the application</span>
<span class="quote">&gt; +previously. Access to memory is granted only if the tag in given</span>
<span class="quote">&gt; +pointer matches the tag set by the application. In case of mismatch,</span>
<span class="quote">&gt; +processor raises an exception.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +Following steps must be taken by a task to enable ADI fully:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +1. Set the user mode PSTATE.mcde bit. This acts as master switch for</span>
<span class="quote">&gt; +   the task&#39;s entire address space to enable/disable ADI for the task.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +2. Set TTE.mcd bit on any TLB entries that correspond to the range of</span>
<span class="quote">&gt; +   addresses ADI is being enabled on. MMU checks the version tag only</span>
<span class="quote">&gt; +   on the pages that have TTE.mcd bit set.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +3. Set the version tag for virtual addresses using stxa instruction</span>
<span class="quote">&gt; +   and one of the MCD specific ASIs. Each stxa instruction sets the</span>
<span class="quote">&gt; +   given tag for one ADI block size number of bytes. This step must</span>
<span class="quote">&gt; +   be repeated for entire page to set tags for entire page.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +ADI block size for the platform is provided by the hypervisor to the</span>
<span class="quote">&gt; +kernel in machine description tables. Hypervisor also provides the</span>
<span class="quote">&gt; +number of top bits in the virtual address that specify the version tag.</span>
<span class="quote">&gt; +Once version tag has been set for a memory location, the tag is stored</span>
<span class="quote">&gt; +in the physical memory and the same tag must be present in the ADI</span>
<span class="quote">&gt; +version tag bits of the virtual address being presented to the MMU. For</span>
<span class="quote">&gt; +example on SPARC M7 processor, MMU uses bits 63-60 for version tags and</span>
<span class="quote">&gt; +ADI block size is same as cacheline size which is 64 bytes. A task that</span>
<span class="quote">&gt; +sets ADI version to say 10 on a range of memory, must access that memory</span>
<span class="quote">&gt; +using virtual addresses that contain 0xa in bits 63-60.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +ADI is enabled on a set of pages using mprotect() with PROT_ADI flag.</span>
<span class="quote">&gt; +When ADI is enabled on a set of pages by a task for the first time,</span>
<span class="quote">&gt; +kernel sets the PSTATE.mcde bit fot the task. Version tags for memory</span>
<span class="quote">&gt; +addresses are set with an stxa instruction on the addresses using</span>
<span class="quote">&gt; +ASI_MCD_PRIMARY or ASI_MCD_ST_BLKINIT_PRIMARY. ADI block size is</span>
<span class="quote">&gt; +provided by the hypervisor to the kernel.  Kernel returns the value of</span>
<span class="quote">&gt; +ADI block size to userspace using auxiliary vector along with other ADI</span>
<span class="quote">&gt; +info. Following auxiliary vectors are provided by the kernel:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	AT_ADI_BLKSZ	ADI block size. This is the granularity and</span>
<span class="quote">&gt; +			alignment, in bytes, of ADI versioning.</span>
<span class="quote">&gt; +	AT_ADI_NBITS	Number of ADI version bits in the VA</span>
<span class="quote">&gt; +	AT_ADI_UEONADI	ADI version of memory containing uncorrectable</span>
<span class="quote">&gt; +			errors will be set to this value</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +IMPORTANT NOTES:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +- Version tag values of 0x0 and 0xf are reserved.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +- Version tags are set on virtual addresses from userspace even though</span>
<span class="quote">&gt; +  tags are stored in physical memory. Tags are set on a physical page</span>
<span class="quote">&gt; +  after it has been allocated to a task and a pte has been created for</span>
<span class="quote">&gt; +  it.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +- When a task frees a memory page it had set version tags on, the page</span>
<span class="quote">&gt; +  goes back to free page pool. When this page is re-allocated to a task,</span>
<span class="quote">&gt; +  kernel clears the page using block initialization ASI which clears the</span>
<span class="quote">&gt; +  version tags as well for the page. If a page allocated to a task is</span>
<span class="quote">&gt; +  freed and allocated back to the same task, old version tags set by the</span>
<span class="quote">&gt; +  task on that page will no longer be present.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +- Kernel does not set any tags for user pages and it is entirely a</span>
<span class="quote">&gt; +  task&#39;s responsibility to set any version tags. Kernel does ensure the</span>
<span class="quote">&gt; +  version tags are preserved if a page is swapped out to the disk and</span>
<span class="quote">&gt; +  swapped back in. It also preserves that version tags if a page is</span>
<span class="quote">&gt; +  migrated.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +- Initial implementation assumes a single page uses exact same version</span>
<span class="quote">&gt; +  tag for the entire page. Kernel saves the version tag for only the</span>
<span class="quote">&gt; +  first byte when swapping or migrating a page and restores that tag to</span>
<span class="quote">&gt; +  the entire page after swapping in or migrating the page. Future</span>
<span class="quote">&gt; +  implementations may expand kernel&#39;s capability to store/restore more</span>
<span class="quote">&gt; +  than one tag per page.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +- ADI works for any size pages. A userspace task need not be aware of</span>
<span class="quote">&gt; +  page size when using ADI. It can simply select a virtual address</span>
<span class="quote">&gt; +  range, enable ADI on the range using mprotect() and set version tags</span>
<span class="quote">&gt; +  for the entire range. mprotect() ensures range is aligned to page size</span>
<span class="quote">&gt; +  and is a multiple of page size.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +ADI related traps</span>
<span class="quote">&gt; +-----------------</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +With ADI enabled, following new traps may occur:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +Disrupting memory corruption</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	When a store accesses a memory localtion that has TTE.mcd=1,</span>
<span class="quote">&gt; +	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="quote">&gt; +	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="quote">&gt; +	the corresponding cacheline, a memory corruption trap occurs. By</span>
<span class="quote">&gt; +	default, it is a disrupting trap and is sent to the hypervisor</span>
<span class="quote">&gt; +	first. Hypervisor creates a sun4v error report and sends a</span>
<span class="quote">&gt; +	resumable error (TT=0x7e) trap to the kernel. The kernel sends</span>
<span class="quote">&gt; +	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="quote">&gt; +	info:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		siginfo.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +		siginfo.errno = 0;</span>
<span class="quote">&gt; +		siginfo.si_code = SEGV_ADIDERR;</span>
<span class="quote">&gt; +		siginfo.si_addr = addr; /* PC where first mismatch occurred */</span>
<span class="quote">&gt; +		siginfo.si_trapno = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +Precise memory corruption</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	When a store accesses a memory location that has TTE.mcd=1,</span>
<span class="quote">&gt; +	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="quote">&gt; +	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="quote">&gt; +	the corresponding cacheline, a memory corruption trap occurs. If</span>
<span class="quote">&gt; +	MCD precise exception is enabled (MCDPERR=1), a precise</span>
<span class="quote">&gt; +	exception is sent to the kernel with TT=0x1a. The kernel sends</span>
<span class="quote">&gt; +	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="quote">&gt; +	info:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		siginfo.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +		siginfo.errno = 0;</span>
<span class="quote">&gt; +		siginfo.si_code = SEGV_ADIPERR;</span>
<span class="quote">&gt; +		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="quote">&gt; +		siginfo.si_trapno = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	NOTE: ADI tag mismatch on a load always results in precise trap.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +MCD disabled</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	When a task has not enabled ADI and attempts to set ADI version</span>
<span class="quote">&gt; +	on a memory address, processor sends an MCD disabled trap. This</span>
<span class="quote">&gt; +	trap is handled by hypervisor first and the hypervisor vectors this</span>
<span class="quote">&gt; +	trap through to the kernel as Data Access Exception trap with</span>
<span class="quote">&gt; +	fault type set to 0xa (invalid ASI). When this occurs, the kernel</span>
<span class="quote">&gt; +	sends the task SIGSEGV signal with following info:</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		siginfo.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +		siginfo.errno = 0;</span>
<span class="quote">&gt; +		siginfo.si_code = SEGV_ACCADI;</span>
<span class="quote">&gt; +		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="quote">&gt; +		siginfo.si_trapno = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +Sample program to use ADI</span>
<span class="quote">&gt; +-------------------------</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +Following sample program is meant to illustrate how to use the ADI</span>
<span class="quote">&gt; +functionality.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;unistd.h&gt;</span>
<span class="quote">&gt; +#include &lt;stdio.h&gt;</span>
<span class="quote">&gt; +#include &lt;stdlib.h&gt;</span>
<span class="quote">&gt; +#include &lt;elf.h&gt;</span>
<span class="quote">&gt; +#include &lt;sys/ipc.h&gt;</span>
<span class="quote">&gt; +#include &lt;sys/shm.h&gt;</span>
<span class="quote">&gt; +#include &lt;sys/mman.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/asi.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifndef AT_ADI_BLKSZ</span>
<span class="quote">&gt; +#define AT_ADI_BLKSZ	34</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#ifndef AT_ADI_NBITS</span>
<span class="quote">&gt; +#define AT_ADI_NBITS	35</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#ifndef AT_ADI_UEONADI</span>
<span class="quote">&gt; +#define AT_ADI_UEONADI	36</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifndef PROT_ADI</span>
<span class="quote">&gt; +#define PROT_ADI	0x10</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define BUFFER_SIZE     32*1024*1024UL</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +main(int argc, char* argv[], char* envp[])</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +        unsigned long i, mcde, adi_blksz, adi_nbits, adi_ueonadi;</span>
<span class="quote">&gt; +        char *shmaddr, *tmp_addr, *end, *veraddr, *clraddr;</span>
<span class="quote">&gt; +        int shmid, version;</span>
<span class="quote">&gt; +	Elf64_auxv_t *auxv;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	adi_blksz = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	while(*envp++ != NULL);</span>
<span class="quote">&gt; +	for (auxv = (Elf64_auxv_t *)envp; auxv-&gt;a_type != AT_NULL; auxv++) {</span>
<span class="quote">&gt; +		switch (auxv-&gt;a_type) {</span>
<span class="quote">&gt; +		case AT_ADI_BLKSZ:</span>
<span class="quote">&gt; +			adi_blksz = auxv-&gt;a_un.a_val;</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		case AT_ADI_NBITS:</span>
<span class="quote">&gt; +			adi_nbits = auxv-&gt;a_un.a_val;</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		case AT_ADI_UEONADI:</span>
<span class="quote">&gt; +			adi_ueonadi = auxv-&gt;a_un.a_val;</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	if (adi_blksz == 0) {</span>
<span class="quote">&gt; +		fprintf(stderr, &quot;Oops! ADI is not supported\n&quot;);</span>
<span class="quote">&gt; +		exit(1);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	printf(&quot;ADI capabilities:\n&quot;);</span>
<span class="quote">&gt; +	printf(&quot;\tBlock size = %ld\n&quot;, adi_blksz);</span>
<span class="quote">&gt; +	printf(&quot;\tNumber of bits = %ld\n&quot;, adi_nbits);</span>
<span class="quote">&gt; +	printf(&quot;\tUE on ADI error = %ld\n&quot;, adi_ueonadi);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        if ((shmid = shmget(2, BUFFER_SIZE,</span>
<span class="quote">&gt; +                                IPC_CREAT | SHM_R | SHM_W)) &lt; 0) {</span>
<span class="quote">&gt; +                perror(&quot;shmget failed&quot;);</span>
<span class="quote">&gt; +                exit(1);</span>
<span class="quote">&gt; +        }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        shmaddr = shmat(shmid, NULL, 0);</span>
<span class="quote">&gt; +        if (shmaddr == (char *)-1) {</span>
<span class="quote">&gt; +                perror(&quot;shm attach failed&quot;);</span>
<span class="quote">&gt; +                shmctl(shmid, IPC_RMID, NULL);</span>
<span class="quote">&gt; +                exit(1);</span>
<span class="quote">&gt; +        }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE|PROT_ADI)) {</span>
<span class="quote">&gt; +		perror(&quot;mprotect failed&quot;);</span>
<span class="quote">&gt; +		goto err_out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        /* Set the ADI version tag on the shm segment</span>
<span class="quote">&gt; +         */</span>
<span class="quote">&gt; +        version = 10;</span>
<span class="quote">&gt; +        tmp_addr = shmaddr;</span>
<span class="quote">&gt; +        end = shmaddr + BUFFER_SIZE;</span>
<span class="quote">&gt; +        while (tmp_addr &lt; end) {</span>
<span class="quote">&gt; +                asm volatile(</span>
<span class="quote">&gt; +                        &quot;stxa %1, [%0]0x90\n\t&quot;</span>
<span class="quote">&gt; +                        :</span>
<span class="quote">&gt; +                        : &quot;r&quot; (tmp_addr), &quot;r&quot; (version));</span>
<span class="quote">&gt; +                tmp_addr += adi_blksz;</span>
<span class="quote">&gt; +        }</span>
<span class="quote">&gt; +	asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        /* Create a versioned address from the normal address by placing</span>
<span class="quote">&gt; +	 * version tag in the upper adi_nbits bits</span>
<span class="quote">&gt; +         */</span>
<span class="quote">&gt; +        tmp_addr = (void *) ((unsigned long)shmaddr &lt;&lt; adi_nbits);</span>
<span class="quote">&gt; +        tmp_addr = (void *) ((unsigned long)tmp_addr &gt;&gt; adi_nbits);</span>
<span class="quote">&gt; +        veraddr = (void *) (((unsigned long)version &lt;&lt; (64-adi_nbits))</span>
<span class="quote">&gt; +                        | (unsigned long)tmp_addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        printf(&quot;Starting the writes:\n&quot;);</span>
<span class="quote">&gt; +        for (i = 0; i &lt; BUFFER_SIZE; i++) {</span>
<span class="quote">&gt; +                veraddr[i] = (char)(i);</span>
<span class="quote">&gt; +                if (!(i % (1024 * 1024)))</span>
<span class="quote">&gt; +                        printf(&quot;.&quot;);</span>
<span class="quote">&gt; +        }</span>
<span class="quote">&gt; +        printf(&quot;\n&quot;);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        printf(&quot;Verifying data...&quot;);</span>
<span class="quote">&gt; +	fflush(stdout);</span>
<span class="quote">&gt; +        for (i = 0; i &lt; BUFFER_SIZE; i++)</span>
<span class="quote">&gt; +                if (veraddr[i] != (char)i)</span>
<span class="quote">&gt; +                        printf(&quot;\nIndex %lu mismatched\n&quot;, i);</span>
<span class="quote">&gt; +        printf(&quot;Done.\n&quot;);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        /* Disable ADI and clean up</span>
<span class="quote">&gt; +         */</span>
<span class="quote">&gt; +	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE)) {</span>
<span class="quote">&gt; +		perror(&quot;mprotect failed&quot;);</span>
<span class="quote">&gt; +		goto err_out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="quote">&gt; +                perror(&quot;Detach failure&quot;);</span>
<span class="quote">&gt; +        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +        exit(0);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +err_out:</span>
<span class="quote">&gt; +        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="quote">&gt; +                perror(&quot;Detach failure&quot;);</span>
<span class="quote">&gt; +        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="quote">&gt; +        exit(1);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/adi.h b/arch/sparc/include/asm/adi.h</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..acad0d0</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/adi.h</span>
<span class="quote">&gt; @@ -0,0 +1,6 @@</span>
<span class="quote">&gt; +#ifndef ___ASM_SPARC_ADI_H</span>
<span class="quote">&gt; +#define ___ASM_SPARC_ADI_H</span>
<span class="quote">&gt; +#if defined(__sparc__) &amp;&amp; defined(__arch64__)</span>
<span class="quote">&gt; +#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/adi_64.h b/arch/sparc/include/asm/adi_64.h</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..24fe52f</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/adi_64.h</span>
<span class="quote">&gt; @@ -0,0 +1,46 @@</span>
<span class="quote">&gt; +/* adi_64.h: ADI related data structures</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * Copyright (C) 2016 Khalid Aziz (khalid.aziz@oracle.com)</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#ifndef __ASM_SPARC64_ADI_H</span>
<span class="quote">&gt; +#define __ASM_SPARC64_ADI_H</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifndef __ASSEMBLY__</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct adi_caps {</span>
<span class="quote">&gt; +	__u64 blksz;</span>
<span class="quote">&gt; +	__u64 nbits;</span>
<span class="quote">&gt; +	__u64 ue_on_adi;</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct adi_config {</span>
<span class="quote">&gt; +	bool enabled;</span>
<span class="quote">&gt; +	struct adi_caps caps;</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern struct adi_config adi_state;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern void mdesc_adi_init(void);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool adi_capable(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return adi_state.enabled;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline unsigned long adi_blksize(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return adi_state.caps.blksz;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline unsigned long adi_nbits(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return adi_state.caps.nbits;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#endif	/* __ASSEMBLY__ */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#endif	/* !(__ASM_SPARC64_ADI_H) */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/elf_64.h b/arch/sparc/include/asm/elf_64.h</span>
<span class="quote">&gt; index 3f2d403..cf00fbc 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/elf_64.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/elf_64.h</span>
<span class="quote">&gt; @@ -210,4 +210,12 @@ do {	if ((ex).e_ident[EI_CLASS] == ELFCLASS32)	\</span>
<span class="quote">&gt;   			(current-&gt;personality &amp; (~PER_MASK)));	\</span>
<span class="quote">&gt;   } while (0)</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#define ARCH_DLINFO						\</span>
<span class="quote">&gt; +do {								\</span>
<span class="quote">&gt; +	extern struct adi_config adi_state;			\</span>
<span class="quote">&gt; +	NEW_AUX_ENT(AT_ADI_BLKSZ, adi_state.caps.blksz);	\</span>
<span class="quote">&gt; +	NEW_AUX_ENT(AT_ADI_NBITS, adi_state.caps.nbits);	\</span>
<span class="quote">&gt; +	NEW_AUX_ENT(AT_ADI_UEONADI, adi_state.caps.ue_on_adi);	\</span>
<span class="quote">&gt; +} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   #endif /* !(__ASM_SPARC64_ELF_H) */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/hugetlb.h b/arch/sparc/include/asm/hugetlb.h</span>
<span class="quote">&gt; index dcbf985..ac2fe18 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/hugetlb.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/hugetlb.h</span>
<span class="quote">&gt; @@ -77,5 +77,18 @@ static inline void arch_clear_hugepage_flags(struct page *page)</span>
<span class="quote">&gt;   void hugetlb_free_pgd_range(struct mmu_gather *tlb, unsigned long addr,</span>
<span class="quote">&gt;   			    unsigned long end, unsigned long floor,</span>
<span class="quote">&gt;   			    unsigned long ceiling);</span>
<span class="quote">&gt; +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt; +static inline pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt; +			 struct page *page, int writeable)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/* If this vma has ADI enabled on it, turn on TTE.mcd</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (vma-&gt;vm_flags &amp; VM_SPARC_ADI)</span>
<span class="quote">&gt; +		return pte_mkmcd(entry);</span>
<span class="quote">&gt; +	else</span>
<span class="quote">&gt; +		return pte_mknotmcd(entry);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #endif /* _ASM_SPARC64_HUGETLB_H */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/mman.h b/arch/sparc/include/asm/mman.h</span>
<span class="quote">&gt; index 59bb593..95d3abc 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/mman.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/mman.h</span>
<span class="quote">&gt; @@ -6,5 +6,43 @@</span>
<span class="quote">&gt;   #ifndef __ASSEMBLY__</span>
<span class="quote">&gt;   #define arch_mmap_check(addr,len,flags)	sparc_mmap_check(addr,len)</span>
<span class="quote">&gt;   int sparc_mmap_check(unsigned long addr, unsigned long len);</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt; +#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define arch_calc_vm_prot_bits(prot, pkey) sparc_calc_vm_prot_bits(prot)</span>
<span class="quote">&gt; +static inline unsigned long sparc_calc_vm_prot_bits(unsigned long prot)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (prot &amp; PROT_ADI) {</span>
<span class="quote">&gt; +		struct pt_regs *regs;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (!current-&gt;mm-&gt;context.adi) {</span>
<span class="quote">&gt; +			regs = task_pt_regs(current);</span>
<span class="quote">&gt; +			regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="quote">&gt; +			current-&gt;mm-&gt;context.adi = true;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		return VM_SPARC_ADI;</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define arch_vm_get_page_prot(vm_flags) sparc_vm_get_page_prot(vm_flags)</span>
<span class="quote">&gt; +static inline pgprot_t sparc_vm_get_page_prot(unsigned long vm_flags)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return (vm_flags &amp; VM_SPARC_ADI) ? __pgprot(_PAGE_MCD_4V) : __pgprot(0);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define arch_validate_prot(prot) sparc_validate_prot(prot)</span>
<span class="quote">&gt; +static inline int sparc_validate_prot(unsigned long prot)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM | PROT_ADI))</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	if ((prot &amp; PROT_ADI) &amp;&amp; !adi_capable())</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	return 1;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#endif /* CONFIG_SPARC64 */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;   #endif /* __SPARC_MMAN_H__ */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="quote">&gt; index f7de0db..e1d30ac 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="quote">&gt; @@ -96,6 +96,7 @@ typedef struct {</span>
<span class="quote">&gt;   	unsigned long		thp_pte_count;</span>
<span class="quote">&gt;   	struct tsb_config	tsb_block[MM_NUM_TSBS];</span>
<span class="quote">&gt;   	struct hv_tsb_descr	tsb_descr[MM_NUM_TSBS];</span>
<span class="quote">&gt; +	bool			adi;</span>
<span class="quote">&gt;   } mm_context_t;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #endif /* !__ASSEMBLY__ */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="quote">&gt; index b84be67..3b78c4f 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="quote">&gt; @@ -7,6 +7,7 @@</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #include &lt;linux/spinlock.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/spitfire.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm-generic/mm_hooks.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)</span>
<span class="quote">&gt; @@ -127,6 +128,7 @@ static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
<span class="quote">&gt;   		__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),</span>
<span class="quote">&gt;   			       SECONDARY_CONTEXT);</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -151,6 +153,47 @@ static inline void activate_mm(struct mm_struct *active_mm, struct mm_struct *mm</span>
<span class="quote">&gt;   	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#define  __HAVE_ARCH_START_CONTEXT_SWITCH</span>
<span class="quote">&gt; +static inline void arch_start_context_switch(struct task_struct *prev)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/* Save the current state of MCDPER register for the process we are</span>
<span class="quote">&gt; +	 * switching from</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (adi_capable()) {</span>
<span class="quote">&gt; +		register unsigned long tmp_mcdper;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		__asm__ __volatile__(</span>
<span class="quote">&gt; +			&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="quote">&gt; +			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="quote">&gt; +			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="quote">&gt; +			:</span>
<span class="quote">&gt; +			: &quot;g1&quot;);</span>
<span class="quote">&gt; +		if (tmp_mcdper)</span>
<span class="quote">&gt; +			set_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt; +		else</span>
<span class="quote">&gt; +			clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define finish_arch_post_lock_switch	finish_arch_post_lock_switch</span>
<span class="quote">&gt; +static inline void finish_arch_post_lock_switch(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/* Restore the state of MCDPER register for the new process</span>
<span class="quote">&gt; +	 * just switched to.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (adi_capable()) {</span>
<span class="quote">&gt; +		register unsigned long tmp_mcdper;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		tmp_mcdper = test_thread_flag(TIF_MCDPER);</span>
<span class="quote">&gt; +		__asm__ __volatile__(</span>
<span class="quote">&gt; +			&quot;mov %0, %%g1\n\t&quot;</span>
<span class="quote">&gt; +			&quot;.word 0x9d800001\n\t&quot;	/* wr %g0, %g1, %mcdper&quot; */</span>
<span class="quote">&gt; +			:</span>
<span class="quote">&gt; +			: &quot;ir&quot; (tmp_mcdper)</span>
<span class="quote">&gt; +			: &quot;g1&quot;);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   #endif /* !(__ASSEMBLY__) */</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #endif /* !(__SPARC64_MMU_CONTEXT_H) */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/pgtable_64.h b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="quote">&gt; index f4e4834..8b74985 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/pgtable_64.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="quote">&gt; @@ -17,6 +17,7 @@</span>
<span class="quote">&gt;   #include &lt;asm/types.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/spitfire.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/asi.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/page.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/processor.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -564,6 +565,18 @@ static inline pte_t pte_mkspecial(pte_t pte)</span>
<span class="quote">&gt;   	return pte;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +static inline pte_t pte_mkmcd(pte_t pte)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pte_val(pte) |= _PAGE_MCD_4V;</span>
<span class="quote">&gt; +	return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline pte_t pte_mknotmcd(pte_t pte)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pte_val(pte) &amp;= ~_PAGE_MCD_4V;</span>
<span class="quote">&gt; +	return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   static inline unsigned long pte_young(pte_t pte)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	unsigned long mask;</span>
<span class="quote">&gt; @@ -964,9 +977,14 @@ void pgtable_trans_huge_deposit(struct mm_struct *mm, pmd_t *pmdp,</span>
<span class="quote">&gt;   pgtable_t pgtable_trans_huge_withdraw(struct mm_struct *mm, pmd_t *pmdp);</span>
<span class="quote">&gt;   #endif</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -/* Encode and de-code a swap entry */</span>
<span class="quote">&gt; +/* Encode and de-code a swap entry. Upper bits of offset are used to</span>
<span class="quote">&gt; + * store the ADI version tag for pages that have ADI enabled and tags set</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt;   #define __swp_type(entry)	(((entry).val &gt;&gt; PAGE_SHIFT) &amp; 0xffUL)</span>
<span class="quote">&gt; -#define __swp_offset(entry)	((entry).val &gt;&gt; (PAGE_SHIFT + 8UL))</span>
<span class="quote">&gt; +#define __swp_offset(entry)		\</span>
<span class="quote">&gt; +	((((entry).val &lt;&lt; adi_nbits()) &gt;&gt; adi_nbits()) &gt;&gt; (PAGE_SHIFT + 8UL))</span>
<span class="quote">&gt; +#define __swp_aditag(entry)		\</span>
<span class="quote">&gt; +	((entry).val &gt;&gt; (sizeof(unsigned long)-adi_nbits()))</span>
<span class="quote">&gt;   #define __swp_entry(type, offset)	\</span>
<span class="quote">&gt;   	( (swp_entry_t) \</span>
<span class="quote">&gt;   	  { \</span>
<span class="quote">&gt; @@ -989,6 +1007,69 @@ int page_in_phys_avail(unsigned long paddr);</span>
<span class="quote">&gt;   int remap_pfn_range(struct vm_area_struct *, unsigned long, unsigned long,</span>
<span class="quote">&gt;   		    unsigned long, pgprot_t);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#define __HAVE_ARCH_DO_SWAP_PAGE</span>
<span class="quote">&gt; +static inline void arch_do_swap_page(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt; +				     pte_t pte, pte_t oldpte)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (pte_val(pte) &amp; _PAGE_MCD_4V) {</span>
<span class="quote">&gt; +		swp_entry_t tmp;</span>
<span class="quote">&gt; +		pgoff_t swap_off;</span>
<span class="quote">&gt; +		unsigned long swap_type, version;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* Check if the swapped out page has an ADI version</span>
<span class="quote">&gt; +		 * saved in the swap offset. If yes, restore</span>
<span class="quote">&gt; +		 * version tag to the newly allocated page</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		tmp = __pte_to_swp_entry(oldpte);</span>
<span class="quote">&gt; +		swap_off = __swp_offset(tmp);</span>
<span class="quote">&gt; +		swap_type = __swp_type(tmp);</span>
<span class="quote">&gt; +		version = __swp_aditag(tmp);</span>
<span class="quote">&gt; +		if (version) {</span>
<span class="quote">&gt; +			unsigned long i, paddr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			paddr = pte_val(pte) &amp; _PAGE_PADDR_4V;</span>
<span class="quote">&gt; +			for (i = paddr; i &lt; (paddr+PAGE_SIZE);</span>
<span class="quote">&gt; +					i += adi_blksize())</span>
<span class="quote">&gt; +				asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="quote">&gt; +					:</span>
<span class="quote">&gt; +					: &quot;r&quot; (version), &quot;r&quot; (i),</span>
<span class="quote">&gt; +					  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define __HAVE_ARCH_UNMAP_ONE</span>
<span class="quote">&gt; +static inline void arch_unmap_one(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt; +				  pte_t pte, pte_t oldpte)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (pte_val(oldpte) &amp; _PAGE_MCD_4V) {</span>
<span class="quote">&gt; +		unsigned long version, paddr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		paddr = pte_val(oldpte) &amp; _PAGE_PADDR_4V;</span>
<span class="quote">&gt; +		asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="quote">&gt; +			     : &quot;=r&quot; (version)</span>
<span class="quote">&gt; +			     : &quot;r&quot; (paddr), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="quote">&gt; +		if (version) {</span>
<span class="quote">&gt; +			swp_entry_t tmp;</span>
<span class="quote">&gt; +			pgoff_t swap_off;</span>
<span class="quote">&gt; +			unsigned long swap_type, shift_size;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			/* Save ADI version tag in the top bits</span>
<span class="quote">&gt; +			 * of swap offset</span>
<span class="quote">&gt; +			 */</span>
<span class="quote">&gt; +			tmp = __pte_to_swp_entry(pte);</span>
<span class="quote">&gt; +			swap_off = __swp_offset(tmp);</span>
<span class="quote">&gt; +			swap_type = __swp_type(tmp);</span>
<span class="quote">&gt; +			shift_size = PAGE_SHIFT + 8UL + adi_nbits();</span>
<span class="quote">&gt; +			swap_off = (swap_off &lt;&lt; shift_size)&gt;&gt;shift_size;</span>
<span class="quote">&gt; +			swap_off = (version &lt;&lt; (sizeof(unsigned long) -</span>
<span class="quote">&gt; +					        shift_size)) | swap_off;</span>
<span class="quote">&gt; +			tmp = __swp_entry(swap_type, swap_off);</span>
<span class="quote">&gt; +			pte = __swp_entry_to_pte(tmp);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   static inline int io_remap_pfn_range(struct vm_area_struct *vma,</span>
<span class="quote">&gt;   				     unsigned long from, unsigned long pfn,</span>
<span class="quote">&gt;   				     unsigned long size, pgprot_t prot)</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/thread_info_64.h b/arch/sparc/include/asm/thread_info_64.h</span>
<span class="quote">&gt; index 3d7b925..b08fd39 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/thread_info_64.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/thread_info_64.h</span>
<span class="quote">&gt; @@ -191,6 +191,7 @@ register struct thread_info *current_thread_info_reg asm(&quot;g6&quot;);</span>
<span class="quote">&gt;    *       an immediate value in instructions such as andcc.</span>
<span class="quote">&gt;    */</span>
<span class="quote">&gt;   /* flag bit 12 is available */</span>
<span class="quote">&gt; +#define TIF_MCDPER		12	/* Precise MCD exception */</span>
<span class="quote">&gt;   #define TIF_MEMDIE		13	/* is terminating due to OOM killer */</span>
<span class="quote">&gt;   #define TIF_POLLING_NRFLAG	14</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; diff --git a/arch/sparc/include/asm/uaccess_64.h b/arch/sparc/include/asm/uaccess_64.h</span>
<span class="quote">&gt; index 5373136..6bfe818 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/asm/uaccess_64.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/asm/uaccess_64.h</span>
<span class="quote">&gt; @@ -10,8 +10,10 @@</span>
<span class="quote">&gt;   #include &lt;linux/compiler.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/string.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/thread_info.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/sched.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/asi.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/spitfire.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm-generic/uaccess-unaligned.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/extable_64.h&gt;</span>
<span class="quote">&gt;   #endif</span>
<span class="quote">&gt; @@ -72,6 +74,31 @@ static inline bool __chk_range_not_ok(unsigned long addr, unsigned long size, un</span>
<span class="quote">&gt;   	__chk_range_not_ok((unsigned long __force)(addr), size, limit); \</span>
<span class="quote">&gt;   })</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +static inline void enable_adi(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * If userspace is using ADI, it could potentially pass a pointer</span>
<span class="quote">&gt; +	 * with version tag embedded in it. To maintain the ADI security,</span>
<span class="quote">&gt; +	 * we must enable PSTATE.mcde. Userspace would have already set</span>
<span class="quote">&gt; +	 * TTE.mcd in an earlier call to kernel and set the version tag</span>
<span class="quote">&gt; +	 * for the address being dereferenced. Setting PSTATE.mcde would</span>
<span class="quote">&gt; +	 * ensure any access to userspace data through a system call</span>
<span class="quote">&gt; +	 * honors ADI and does not allow a rogue app to bypass ADI by</span>
<span class="quote">&gt; +	 * using system calls. Also to ensure the right exception,</span>
<span class="quote">&gt; +	 * precise or disrupting, is delivered to the userspace, update</span>
<span class="quote">&gt; +	 * PMCDPER to match MCDPER</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	__asm__ __volatile__(</span>
<span class="quote">&gt; +		&quot;rdpr %%pstate, %%g1\n\t&quot;</span>
<span class="quote">&gt; +		&quot;or %%g1, %0, %%g1\n\t&quot;</span>
<span class="quote">&gt; +		&quot;wrpr %%g1, %%g0, %%pstate\n\t&quot;</span>
<span class="quote">&gt; +		&quot;.word 0x83438000\n\t&quot;	/* rd %mcdper, %g1 */</span>
<span class="quote">&gt; +		&quot;.word 0xaf900001\n\t&quot;	/* wrpr  %g0, %g1, %pmcdper */</span>
<span class="quote">&gt; +		:</span>
<span class="quote">&gt; +		: &quot;i&quot; (PSTATE_MCDE)</span>
<span class="quote">&gt; +		: &quot;g1&quot;);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   static inline int __access_ok(const void __user * addr, unsigned long size)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	return 1;</span>
<span class="quote">&gt; @@ -112,7 +139,9 @@ struct __large_struct { unsigned long buf[100]; };</span>
<span class="quote">&gt;   #define __m(x) ((struct __large_struct *)(x))</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #define __put_user_nocheck(data, addr, size) ({			\</span>
<span class="quote">&gt; -	register int __pu_ret;					\</span>
<span class="quote">&gt; +	register int __pu_ret, __adi_status;				\</span>
<span class="quote">&gt; +	if ((__adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))	\</span>
<span class="quote">&gt; +		enable_adi();					\</span>
<span class="quote">&gt;   	switch (size) {						\</span>
<span class="quote">&gt;   	case 1: __put_user_asm(data, b, addr, __pu_ret); break;	\</span>
<span class="quote">&gt;   	case 2: __put_user_asm(data, h, addr, __pu_ret); break;	\</span>
<span class="quote">&gt; @@ -120,6 +149,9 @@ struct __large_struct { unsigned long buf[100]; };</span>
<span class="quote">&gt;   	case 8: __put_user_asm(data, x, addr, __pu_ret); break;	\</span>
<span class="quote">&gt;   	default: __pu_ret = __put_user_bad(); break;		\</span>
<span class="quote">&gt;   	}							\</span>
<span class="quote">&gt; +	if (__adi_status)					\</span>
<span class="quote">&gt; +		/* wrpr  %g0, %pmcdper */			\</span>
<span class="quote">&gt; +		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);	\</span>
<span class="quote">&gt;   	__pu_ret;						\</span>
<span class="quote">&gt;   })</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -146,8 +178,10 @@ __asm__ __volatile__(							\</span>
<span class="quote">&gt;   int __put_user_bad(void);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #define __get_user_nocheck(data, addr, size, type) ({			     \</span>
<span class="quote">&gt; -	register int __gu_ret;						     \</span>
<span class="quote">&gt; +	register int __gu_ret, __adi_status;				     \</span>
<span class="quote">&gt;   	register unsigned long __gu_val;				     \</span>
<span class="quote">&gt; +	if ((__adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))	     \</span>
<span class="quote">&gt; +		enable_adi();						     \</span>
<span class="quote">&gt;   	switch (size) {							     \</span>
<span class="quote">&gt;   		case 1: __get_user_asm(__gu_val, ub, addr, __gu_ret); break; \</span>
<span class="quote">&gt;   		case 2: __get_user_asm(__gu_val, uh, addr, __gu_ret); break; \</span>
<span class="quote">&gt; @@ -159,6 +193,9 @@ int __put_user_bad(void);</span>
<span class="quote">&gt;   			break;						     \</span>
<span class="quote">&gt;   	} 								     \</span>
<span class="quote">&gt;   	data = (__force type) __gu_val;					     \</span>
<span class="quote">&gt; +	if (__adi_status)						     \</span>
<span class="quote">&gt; +		/* wrpr  %g0, %pmcdper */				     \</span>
<span class="quote">&gt; +		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);		     \</span>
<span class="quote">&gt;   	 __gu_ret;							     \</span>
<span class="quote">&gt;   })</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -185,15 +222,53 @@ __asm__ __volatile__(							\</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   int __get_user_bad(void);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +/* When kernel access userspace memory, it must honor ADI setting</span>
<span class="quote">&gt; + * to ensure ADI protection continues across system calls. Kernel</span>
<span class="quote">&gt; + * must set PSTATE.mcde bit. It must also update PMCDPER register</span>
<span class="quote">&gt; + * to reflect MCDPER register so the kind of exception generated</span>
<span class="quote">&gt; + * in case of ADI version tag mismatch, is what the userspace is</span>
<span class="quote">&gt; + * expecting. PMCDPER exists only on the processors that support</span>
<span class="quote">&gt; + * ADI and must be accessed conditionally to avoid illegal</span>
<span class="quote">&gt; + * instruction trap.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#define user_access_begin()						\</span>
<span class="quote">&gt; +	do {								\</span>
<span class="quote">&gt; +		if (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)		\</span>
<span class="quote">&gt; +			enable_adi();					\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define user_access_end()						\</span>
<span class="quote">&gt; +	do {								\</span>
<span class="quote">&gt; +		if (adi_capable())					\</span>
<span class="quote">&gt; +			/* wrpr  %g0, %pmcdper */			\</span>
<span class="quote">&gt; +			__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);	\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define unsafe_get_user(x, ptr, err)		\</span>
<span class="quote">&gt; +		do { if (unlikely(__get_user(x, ptr))) goto err; } while (0)</span>
<span class="quote">&gt; +#define unsafe_put_user(x, ptr, err)		\</span>
<span class="quote">&gt; +		do { if (unlikely(__put_user(x, ptr))) goto err; } while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   unsigned long __must_check ___copy_from_user(void *to,</span>
<span class="quote">&gt;   					     const void __user *from,</span>
<span class="quote">&gt;   					     unsigned long size);</span>
<span class="quote">&gt;   static inline unsigned long __must_check</span>
<span class="quote">&gt;   copy_from_user(void *to, const void __user *from, unsigned long size)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; +	unsigned long ret, adi_status;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	check_object_size(to, size, false);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	return ___copy_from_user(to, from, size);</span>
<span class="quote">&gt; +	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="quote">&gt; +		enable_adi();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	ret = ___copy_from_user(to, from, size);</span>
<span class="quote">&gt; +	if (adi_status)</span>
<span class="quote">&gt; +		/* wrpr  %g0, %pmcdper */</span>
<span class="quote">&gt; +		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   #define __copy_from_user copy_from_user</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -203,9 +278,18 @@ unsigned long __must_check ___copy_to_user(void __user *to,</span>
<span class="quote">&gt;   static inline unsigned long __must_check</span>
<span class="quote">&gt;   copy_to_user(void __user *to, const void *from, unsigned long size)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; +	unsigned long ret, adi_status;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	check_object_size(from, size, true);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	return ___copy_to_user(to, from, size);</span>
<span class="quote">&gt; +	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="quote">&gt; +		enable_adi();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	ret = ___copy_to_user(to, from, size);</span>
<span class="quote">&gt; +	if (adi_status)</span>
<span class="quote">&gt; +		/* wrpr  %g0, %pmcdper */</span>
<span class="quote">&gt; +		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   #define __copy_to_user copy_to_user</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -215,13 +299,37 @@ unsigned long __must_check ___copy_in_user(void __user *to,</span>
<span class="quote">&gt;   static inline unsigned long __must_check</span>
<span class="quote">&gt;   copy_in_user(void __user *to, void __user *from, unsigned long size)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	return ___copy_in_user(to, from, size);</span>
<span class="quote">&gt; +	unsigned long ret, adi_status;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="quote">&gt; +		enable_adi();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	ret = ___copy_in_user(to, from, size);</span>
<span class="quote">&gt; +	if (adi_status)</span>
<span class="quote">&gt; +		/* wrpr  %g0, %pmcdper */</span>
<span class="quote">&gt; +		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   #define __copy_in_user copy_in_user</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   unsigned long __must_check __clear_user(void __user *, unsigned long);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -#define clear_user __clear_user</span>
<span class="quote">&gt; +static inline unsigned long __must_check</span>
<span class="quote">&gt; +___clear_user(void __user *uaddr, unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long ret, adi_status;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="quote">&gt; +		enable_adi();</span>
<span class="quote">&gt; +	ret = __clear_user(uaddr, size);</span>
<span class="quote">&gt; +	if (adi_status)</span>
<span class="quote">&gt; +		/* wrpr  %g0, %pmcdper */</span>
<span class="quote">&gt; +		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define clear_user ___clear_user</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   __must_check long strlen_user(const char __user *str);</span>
<span class="quote">&gt;   __must_check long strnlen_user(const char __user *str, long n);</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/uapi/asm/auxvec.h b/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="quote">&gt; index ad6f360..6fe1249 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="quote">&gt; @@ -1,4 +1,12 @@</span>
<span class="quote">&gt;   #ifndef __ASMSPARC_AUXVEC_H</span>
<span class="quote">&gt;   #define __ASMSPARC_AUXVEC_H</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt; +#define AT_ADI_BLKSZ	34</span>
<span class="quote">&gt; +#define AT_ADI_NBITS	35</span>
<span class="quote">&gt; +#define AT_ADI_UEONADI	36</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define AT_VECTOR_SIZE_ARCH	3</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   #endif /* !(__ASMSPARC_AUXVEC_H) */</span>
<span class="quote">&gt; diff --git a/arch/sparc/include/uapi/asm/mman.h b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="quote">&gt; index 9765896..a72c033 100644</span>
<span class="quote">&gt; --- a/arch/sparc/include/uapi/asm/mman.h</span>
<span class="quote">&gt; +++ b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="quote">&gt; @@ -5,6 +5,8 @@</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   /* SunOS&#39;ified... */</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#define PROT_ADI	0x10		/* ADI enabled */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   #define MAP_RENAME      MAP_ANONYMOUS   /* In SunOS terminology */</span>
<span class="quote">&gt;   #define MAP_NORESERVE   0x40            /* don&#39;t reserve swap pages */</span>
<span class="quote">&gt;   #define MAP_INHERIT     0x80            /* SunOS doesn&#39;t do this, but... */</span>
<span class="quote">&gt; diff --git a/arch/sparc/kernel/Makefile b/arch/sparc/kernel/Makefile</span>
<span class="quote">&gt; index fa3c02d..c9c4e76 100644</span>
<span class="quote">&gt; --- a/arch/sparc/kernel/Makefile</span>
<span class="quote">&gt; +++ b/arch/sparc/kernel/Makefile</span>
<span class="quote">&gt; @@ -67,6 +67,7 @@ obj-$(CONFIG_SPARC64)   += visemul.o</span>
<span class="quote">&gt;   obj-$(CONFIG_SPARC64)   += hvapi.o</span>
<span class="quote">&gt;   obj-$(CONFIG_SPARC64)   += sstate.o</span>
<span class="quote">&gt;   obj-$(CONFIG_SPARC64)   += mdesc.o</span>
<span class="quote">&gt; +obj-$(CONFIG_SPARC64)   += adi_64.o</span>
<span class="quote">&gt;   obj-$(CONFIG_SPARC64)	+= pcr.o</span>
<span class="quote">&gt;   obj-$(CONFIG_SPARC64)	+= nmi.o</span>
<span class="quote">&gt;   obj-$(CONFIG_SPARC64_SMP) += cpumap.o</span>
<span class="quote">&gt; diff --git a/arch/sparc/kernel/adi_64.c b/arch/sparc/kernel/adi_64.c</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..aba1960</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/sparc/kernel/adi_64.c</span>
<span class="quote">&gt; @@ -0,0 +1,93 @@</span>
<span class="quote">&gt; +/* adi_64.c: support for ADI (Application Data Integrity) feature on</span>
<span class="quote">&gt; + * sparc m7 and newer processors. This feature is also known as</span>
<span class="quote">&gt; + * SSM (Silicon Secured Memory).</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * Copyright (C) 2016 Khalid Aziz (khalid.aziz@oracle.com)</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#include &lt;linux/init.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mdesc.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct adi_config adi_state;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* mdesc_adi_init() : Parse machine description provided by the</span>
<span class="quote">&gt; + *	hypervisor to detect ADI capabilities</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * Hypervisor reports ADI capabilities of platform in &quot;hwcap-list&quot; property</span>
<span class="quote">&gt; + * for &quot;cpu&quot; node. If the platform supports ADI, &quot;hwcap-list&quot; property</span>
<span class="quote">&gt; + * contains the keyword &quot;adp&quot;. If the platform supports ADI, &quot;platform&quot;</span>
<span class="quote">&gt; + * node will contain &quot;adp-blksz&quot;, &quot;adp-nbits&quot; and &quot;ue-on-adp&quot; properties</span>
<span class="quote">&gt; + * to describe the ADI capabilities.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +void __init mdesc_adi_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct mdesc_handle *hp = mdesc_grab();</span>
<span class="quote">&gt; +	const char *prop;</span>
<span class="quote">&gt; +	u64 pn, *val;</span>
<span class="quote">&gt; +	int len;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!hp)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pn = mdesc_node_by_name(hp, MDESC_NODE_NULL, &quot;cpu&quot;);</span>
<span class="quote">&gt; +	if (pn == MDESC_NODE_NULL)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	prop = mdesc_get_property(hp, pn, &quot;hwcap-list&quot;, &amp;len);</span>
<span class="quote">&gt; +	if (!prop)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Look for &quot;adp&quot; keyword in hwcap-list which would indicate</span>
<span class="quote">&gt; +	 * ADI support</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	adi_state.enabled = false;</span>
<span class="quote">&gt; +	while (len) {</span>
<span class="quote">&gt; +		int plen;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (!strcmp(prop, &quot;adp&quot;)) {</span>
<span class="quote">&gt; +			adi_state.enabled = true;</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		plen = strlen(prop) + 1;</span>
<span class="quote">&gt; +		prop += plen;</span>
<span class="quote">&gt; +		len -= plen;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!adi_state.enabled)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Find the ADI properties in &quot;platform&quot; node. If all ADI</span>
<span class="quote">&gt; +	 * properties are not found, ADI support is incomplete and</span>
<span class="quote">&gt; +	 * do not enable ADI in the kernel.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	pn = mdesc_node_by_name(hp, MDESC_NODE_NULL, &quot;platform&quot;);</span>
<span class="quote">&gt; +	if (pn == MDESC_NODE_NULL)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	val = (u64 *) mdesc_get_property(hp, pn, &quot;adp-blksz&quot;, &amp;len);</span>
<span class="quote">&gt; +	if (!val)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +	adi_state.caps.blksz = *val;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	val = (u64 *) mdesc_get_property(hp, pn, &quot;adp-nbits&quot;, &amp;len);</span>
<span class="quote">&gt; +	if (!val)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +	adi_state.caps.nbits = *val;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	val = (u64 *) mdesc_get_property(hp, pn, &quot;ue-on-adp&quot;, &amp;len);</span>
<span class="quote">&gt; +	if (!val)</span>
<span class="quote">&gt; +		goto adi_not_found;</span>
<span class="quote">&gt; +	adi_state.caps.ue_on_adi = *val;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mdesc_release(hp);</span>
<span class="quote">&gt; +	return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +adi_not_found:</span>
<span class="quote">&gt; +	adi_state.enabled = false;</span>
<span class="quote">&gt; +	if (hp)</span>
<span class="quote">&gt; +		mdesc_release(hp);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/arch/sparc/kernel/mdesc.c b/arch/sparc/kernel/mdesc.c</span>
<span class="quote">&gt; index 8a6982d..0703a60 100644</span>
<span class="quote">&gt; --- a/arch/sparc/kernel/mdesc.c</span>
<span class="quote">&gt; +++ b/arch/sparc/kernel/mdesc.c</span>
<span class="quote">&gt; @@ -20,6 +20,7 @@</span>
<span class="quote">&gt;   #include &lt;asm/uaccess.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/oplib.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/smp.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   /* Unlike the OBP device tree, the machine description is a full-on</span>
<span class="quote">&gt;    * DAG.  An arbitrary number of ARCs are possible from one</span>
<span class="quote">&gt; @@ -1104,5 +1105,6 @@ void __init sun4v_mdesc_init(void)</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	cur_mdesc = hp;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +	mdesc_adi_init();</span>
<span class="quote">&gt;   	report_platform_properties();</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt; diff --git a/arch/sparc/kernel/process_64.c b/arch/sparc/kernel/process_64.c</span>
<span class="quote">&gt; index 47ff558..0baa283 100644</span>
<span class="quote">&gt; --- a/arch/sparc/kernel/process_64.c</span>
<span class="quote">&gt; +++ b/arch/sparc/kernel/process_64.c</span>
<span class="quote">&gt; @@ -680,6 +680,31 @@ int copy_thread(unsigned long clone_flags, unsigned long sp,</span>
<span class="quote">&gt;   	return 0;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +/* TIF_MCDPER in thread info flags for current task is updated lazily upon</span>
<span class="quote">&gt; + * a context switch. Update the this flag in current task&#39;s thread flags</span>
<span class="quote">&gt; + * before dup so the dup&#39;d task will inherit the current TIF_MCDPER flag.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (adi_capable()) {</span>
<span class="quote">&gt; +		register unsigned long tmp_mcdper;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		__asm__ __volatile__(</span>
<span class="quote">&gt; +			&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="quote">&gt; +			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="quote">&gt; +			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="quote">&gt; +			:</span>
<span class="quote">&gt; +			: &quot;g1&quot;);</span>
<span class="quote">&gt; +		if (tmp_mcdper)</span>
<span class="quote">&gt; +			set_thread_flag(TIF_MCDPER);</span>
<span class="quote">&gt; +		else</span>
<span class="quote">&gt; +			clear_thread_flag(TIF_MCDPER);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	*dst = *src;</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   typedef struct {</span>
<span class="quote">&gt;   	union {</span>
<span class="quote">&gt;   		unsigned int	pr_regs[32];</span>
<span class="quote">&gt; diff --git a/arch/sparc/kernel/traps_64.c b/arch/sparc/kernel/traps_64.c</span>
<span class="quote">&gt; index 500c9c6..576937c 100644</span>
<span class="quote">&gt; --- a/arch/sparc/kernel/traps_64.c</span>
<span class="quote">&gt; +++ b/arch/sparc/kernel/traps_64.c</span>
<span class="quote">&gt; @@ -44,6 +44,7 @@</span>
<span class="quote">&gt;   #include &lt;asm/memctrl.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/setup.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #include &quot;entry.h&quot;</span>
<span class="quote">&gt;   #include &quot;kernel.h&quot;</span>
<span class="quote">&gt; @@ -351,12 +352,31 @@ void sun4v_data_access_exception(struct pt_regs *regs, unsigned long addr, unsig</span>
<span class="quote">&gt;   		regs-&gt;tpc &amp;= 0xffffffff;</span>
<span class="quote">&gt;   		regs-&gt;tnpc &amp;= 0xffffffff;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt; -	info.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* MCD (Memory Corruption Detection) disabled trap (TT=0x19) in HV</span>
<span class="quote">&gt; +	 * is vectored thorugh data access exception trap with fault type</span>
<span class="quote">&gt; +	 * set to HV_FAULT_TYPE_MCD_DIS. Check for MCD disabled trap</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt;   	info.si_errno = 0;</span>
<span class="quote">&gt; -	info.si_code = SEGV_MAPERR;</span>
<span class="quote">&gt;   	info.si_addr = (void __user *) addr;</span>
<span class="quote">&gt;   	info.si_trapno = 0;</span>
<span class="quote">&gt; -	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="quote">&gt; +	switch (type) {</span>
<span class="quote">&gt; +	case HV_FAULT_TYPE_INV_ASI:</span>
<span class="quote">&gt; +		info.si_signo = SIGILL;</span>
<span class="quote">&gt; +		info.si_code = ILL_ILLADR;</span>
<span class="quote">&gt; +		force_sig_info(SIGILL, &amp;info, current);</span>
<span class="quote">&gt; +		break;</span>
<span class="quote">&gt; +	case HV_FAULT_TYPE_MCD_DIS:</span>
<span class="quote">&gt; +		info.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +		info.si_code = SEGV_ACCADI;</span>
<span class="quote">&gt; +		force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="quote">&gt; +		break;</span>
<span class="quote">&gt; +	default:</span>
<span class="quote">&gt; +		info.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +		info.si_code = SEGV_MAPERR;</span>
<span class="quote">&gt; +		force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="quote">&gt; +		break;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   void sun4v_data_access_exception_tl1(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)</span>
<span class="quote">&gt; @@ -1801,6 +1821,7 @@ struct sun4v_error_entry {</span>
<span class="quote">&gt;   #define SUN4V_ERR_ATTRS_ASI		0x00000080</span>
<span class="quote">&gt;   #define SUN4V_ERR_ATTRS_PRIV_REG	0x00000100</span>
<span class="quote">&gt;   #define SUN4V_ERR_ATTRS_SPSTATE_MSK	0x00000600</span>
<span class="quote">&gt; +#define SUN4V_ERR_ATTRS_MCD		0x00000800</span>
<span class="quote">&gt;   #define SUN4V_ERR_ATTRS_SPSTATE_SHFT	9</span>
<span class="quote">&gt;   #define SUN4V_ERR_ATTRS_MODE_MSK	0x03000000</span>
<span class="quote">&gt;   #define SUN4V_ERR_ATTRS_MODE_SHFT	24</span>
<span class="quote">&gt; @@ -1998,6 +2019,54 @@ static void sun4v_log_error(struct pt_regs *regs, struct sun4v_error_entry *ent,</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +/* Handle memory corruption detected error which is vectored in</span>
<span class="quote">&gt; + * through resumable error trap.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +void do_mcd_err(struct pt_regs *regs, struct sun4v_error_entry ent)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	siginfo_t info;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (notify_die(DIE_TRAP, &quot;MCD error&quot;, regs,</span>
<span class="quote">&gt; +		       0, 0x34, SIGSEGV) == NOTIFY_STOP)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (regs-&gt;tstate &amp; TSTATE_PRIV) {</span>
<span class="quote">&gt; +		/* MCD exception could happen because the task was running</span>
<span class="quote">&gt; +		 * a system call with MCD enabled and passed a non-versioned</span>
<span class="quote">&gt; +		 * pointer or pointer with bad version tag to  the system</span>
<span class="quote">&gt; +		 * call. In such cases, hypervisor places the address of</span>
<span class="quote">&gt; +		 * offending instruction in the resumable error report. This</span>
<span class="quote">&gt; +		 * is a deferred error, so the read/write that caused the trap</span>
<span class="quote">&gt; +		 * was potentially retired long time back and we may have</span>
<span class="quote">&gt; +		 * no choice but to send SIGSEGV to the process.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		const struct exception_table_entry *entry;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		entry = search_exception_tables(regs-&gt;tpc);</span>
<span class="quote">&gt; +		if (entry) {</span>
<span class="quote">&gt; +			/* Looks like a bad syscall parameter */</span>
<span class="quote">&gt; +#ifdef DEBUG_EXCEPTIONS</span>
<span class="quote">&gt; +			pr_emerg(&quot;Exception: PC&lt;%016lx&gt; faddr&lt;UNKNOWN&gt;\n&quot;,</span>
<span class="quote">&gt; +				 regs-&gt;tpc);</span>
<span class="quote">&gt; +			pr_emerg(&quot;EX_TABLE: insn&lt;%016lx&gt; fixup&lt;%016lx&gt;\n&quot;,</span>
<span class="quote">&gt; +				 ent.err_raddr, entry-&gt;fixup);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +			regs-&gt;tpc = entry-&gt;fixup;</span>
<span class="quote">&gt; +			regs-&gt;tnpc = regs-&gt;tpc + 4;</span>
<span class="quote">&gt; +			return;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Send SIGSEGV to the userspace process with the right code</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	info.si_signo = SIGSEGV;</span>
<span class="quote">&gt; +	info.si_errno = 0;</span>
<span class="quote">&gt; +	info.si_code = SEGV_ADIDERR;</span>
<span class="quote">&gt; +	info.si_addr = (void __user *)ent.err_raddr;</span>
<span class="quote">&gt; +	info.si_trapno = 0;</span>
<span class="quote">&gt; +	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   /* We run with %pil set to PIL_NORMAL_MAX and PSTATE_IE enabled in %pstate.</span>
<span class="quote">&gt;    * Log the event and clear the first word of the entry.</span>
<span class="quote">&gt;    */</span>
<span class="quote">&gt; @@ -2035,6 +2104,14 @@ void sun4v_resum_error(struct pt_regs *regs, unsigned long offset)</span>
<span class="quote">&gt;   		goto out;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +	/* If this is a memory corruption detected error, call the</span>
<span class="quote">&gt; +	 * handler</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (local_copy.err_attrs &amp; SUN4V_ERR_ATTRS_MCD) {</span>
<span class="quote">&gt; +		do_mcd_err(regs, local_copy);</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	sun4v_log_error(regs, &amp;local_copy, cpu,</span>
<span class="quote">&gt;   			KERN_ERR &quot;RESUMABLE ERROR&quot;,</span>
<span class="quote">&gt;   			&amp;sun4v_resum_oflow_cnt);</span>
<span class="quote">&gt; @@ -2543,6 +2620,11 @@ void sun4v_mem_corrupt_detect_precise(struct pt_regs *regs, unsigned long addr,</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	siginfo_t info;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +	if (!adi_capable()) {</span>
<span class="quote">&gt; +		bad_trap(regs, 0x1a);</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	if (notify_die(DIE_TRAP, &quot;memory corruption precise exception&quot;, regs,</span>
<span class="quote">&gt;   		       0, 0x8, SIGSEGV) == NOTIFY_STOP)</span>
<span class="quote">&gt;   		return;</span>
<span class="quote">&gt; diff --git a/arch/sparc/mm/gup.c b/arch/sparc/mm/gup.c</span>
<span class="quote">&gt; index cd0e32b..579f7ae 100644</span>
<span class="quote">&gt; --- a/arch/sparc/mm/gup.c</span>
<span class="quote">&gt; +++ b/arch/sparc/mm/gup.c</span>
<span class="quote">&gt; @@ -11,6 +11,7 @@</span>
<span class="quote">&gt;   #include &lt;linux/pagemap.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/rwsem.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/adi.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   /*</span>
<span class="quote">&gt;    * The performance critical leaf functions are made noinline otherwise gcc</span>
<span class="quote">&gt; @@ -157,6 +158,24 @@ int __get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
<span class="quote">&gt;   	pgd_t *pgdp;</span>
<span class="quote">&gt;   	int nr = 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt; +	if (adi_capable()) {</span>
<span class="quote">&gt; +		long addr = start;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* If userspace has passed a versioned address, kernel</span>
<span class="quote">&gt; +		 * will not find it in the VMAs since it does not store</span>
<span class="quote">&gt; +		 * the version tags in the list of VMAs. Storing version</span>
<span class="quote">&gt; +		 * tags in list of VMAs is impractical since they can be</span>
<span class="quote">&gt; +		 * changed any time from userspace without dropping into</span>
<span class="quote">&gt; +		 * kernel. Any address search in VMAs will be done with</span>
<span class="quote">&gt; +		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="quote">&gt; +		 * are dropped here by sign extending the last bit before</span>
<span class="quote">&gt; +		 * ADI bits. IOMMU does not implement version tags.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>


So you are depending on the sign extension to clear the ADI bits... but 
this only happens if there is a zero in that &quot;last bit before ADI bits&quot;. 
If the last bit is a 1, then the ADI bits will be set instead of 
cleared.  That seems like an unintended consequence given the comment. I 
am aware of the value of adi_nbits() and of the number of valid bits in 
a virtual address on the M7 processor, but wouldn&#39;t using &#39;unsigned 
long&#39; for everything here guarantee the ADI bits get cleared regardless 
of the state of the last non-adi bit?
<span class="quote">

&gt; +		start = addr;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;   	start &amp;= PAGE_MASK;</span>
<span class="quote">&gt;   	addr = start;</span>
<span class="quote">&gt;   	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; @@ -187,6 +206,24 @@ int get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
<span class="quote">&gt;   	pgd_t *pgdp;</span>
<span class="quote">&gt;   	int nr = 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt; +	if (adi_capable()) {</span>
<span class="quote">&gt; +		long addr = start;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* If userspace has passed a versioned address, kernel</span>
<span class="quote">&gt; +		 * will not find it in the VMAs since it does not store</span>
<span class="quote">&gt; +		 * the version tags in the list of VMAs. Storing version</span>
<span class="quote">&gt; +		 * tags in list of VMAs is impractical since they can be</span>
<span class="quote">&gt; +		 * changed any time from userspace without dropping into</span>
<span class="quote">&gt; +		 * kernel. Any address search in VMAs will be done with</span>
<span class="quote">&gt; +		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="quote">&gt; +		 * are dropped here by sign extending the last bit before</span>
<span class="quote">&gt; +		 * ADI bits. IOMMU does not implements version tags,</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>

Same comment here, and the various other places that employ this same 
code construct.


Rob
<span class="quote">



&gt; +		start = addr;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;   	start &amp;= PAGE_MASK;</span>
<span class="quote">&gt;   	addr = start;</span>
<span class="quote">&gt;   	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;</span>
<span class="quote">&gt; diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="quote">&gt; index a92c8d7..5c894a5 100644</span>
<span class="quote">&gt; --- a/include/linux/mm.h</span>
<span class="quote">&gt; +++ b/include/linux/mm.h</span>
<span class="quote">&gt; @@ -225,6 +225,8 @@ extern unsigned int kobjsize(const void *objp);</span>
<span class="quote">&gt;   # define VM_GROWSUP	VM_ARCH_1</span>
<span class="quote">&gt;   #elif defined(CONFIG_IA64)</span>
<span class="quote">&gt;   # define VM_GROWSUP	VM_ARCH_1</span>
<span class="quote">&gt; +#elif defined(CONFIG_SPARC64)</span>
<span class="quote">&gt; +# define VM_SPARC_ADI	VM_ARCH_1	/* Uses ADI tag for access control */</span>
<span class="quote">&gt;   #elif !defined(CONFIG_MMU)</span>
<span class="quote">&gt;   # define VM_MAPPED_COPY	VM_ARCH_1	/* T if mapped copy of data (nommu mmap) */</span>
<span class="quote">&gt;   #endif</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=129">David Miller</a> - Jan. 25, 2017, 10:13 p.m.</div>
<pre class="content">
<span class="from">From: Rob Gardner &lt;rob.gardner@oracle.com&gt;</span>
Date: Wed, 25 Jan 2017 15:00:42 -0700
<span class="quote">
&gt; Same comment here, and the various other places that employ this same</span>
<span class="quote">&gt; code construct.</span>

Please do not quote an entire huge patch just to comment on a small
part of it.

Quote only the minimum necessary context in order to provide your feedback.

Thank you.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 25, 2017, 10:20 p.m.</div>
<pre class="content">
On 01/25/2017 03:00 PM, Rob Gardner wrote:
<span class="quote">&gt; On 01/25/2017 12:57 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; @@ -157,6 +158,24 @@ int __get_user_pages_fast(unsigned long start,</span>
<span class="quote">&gt;&gt; int nr_pages, int write,</span>
<span class="quote">&gt;&gt;       pgd_t *pgdp;</span>
<span class="quote">&gt;&gt;       int nr = 0;</span>
<span class="quote">&gt;&gt;   +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt;&gt; +    if (adi_capable()) {</span>
<span class="quote">&gt;&gt; +        long addr = start;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +        /* If userspace has passed a versioned address, kernel</span>
<span class="quote">&gt;&gt; +         * will not find it in the VMAs since it does not store</span>
<span class="quote">&gt;&gt; +         * the version tags in the list of VMAs. Storing version</span>
<span class="quote">&gt;&gt; +         * tags in list of VMAs is impractical since they can be</span>
<span class="quote">&gt;&gt; +         * changed any time from userspace without dropping into</span>
<span class="quote">&gt;&gt; +         * kernel. Any address search in VMAs will be done with</span>
<span class="quote">&gt;&gt; +         * non-versioned addresses. Ensure the ADI version bits</span>
<span class="quote">&gt;&gt; +         * are dropped here by sign extending the last bit before</span>
<span class="quote">&gt;&gt; +         * ADI bits. IOMMU does not implement version tags.</span>
<span class="quote">&gt;&gt; +         */</span>
<span class="quote">&gt;&gt; +        addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So you are depending on the sign extension to clear the ADI bits... but</span>
<span class="quote">&gt; this only happens if there is a zero in that &quot;last bit before ADI bits&quot;.</span>
<span class="quote">&gt; If the last bit is a 1, then the ADI bits will be set instead of</span>
<span class="quote">&gt; cleared.  That seems like an unintended consequence given the comment. I</span>
<span class="quote">&gt; am aware of the value of adi_nbits() and of the number of valid bits in</span>
<span class="quote">&gt; a virtual address on the M7 processor, but wouldn&#39;t using &#39;unsigned</span>
<span class="quote">&gt; long&#39; for everything here guarantee the ADI bits get cleared regardless</span>
<span class="quote">&gt; of the state of the last non-adi bit?</span>

Sign extension is the right thing to do. MMU considers values of 0 and 
15 for bits 63-60 to be untagged addresses and expects bit 59 to be 
sign-extended for untagged virtual addresses. The code I added is 
explicitly meant to sign-extend, not zero out the top 4 bits.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=157521">Rob Gardner</a> - Jan. 25, 2017, 10:50 p.m.</div>
<pre class="content">
On 01/25/2017 03:20 PM, Khalid Aziz wrote:
<span class="quote">&gt; On 01/25/2017 03:00 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt; On 01/25/2017 12:57 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; @@ -157,6 +158,24 @@ int __get_user_pages_fast(unsigned long start,</span>
<span class="quote">&gt;&gt;&gt; int nr_pages, int write,</span>
<span class="quote">&gt;&gt;&gt;       pgd_t *pgdp;</span>
<span class="quote">&gt;&gt;&gt;       int nr = 0;</span>
<span class="quote">&gt;&gt;&gt;   +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt;&gt;&gt; +    if (adi_capable()) {</span>
<span class="quote">&gt;&gt;&gt; +        long addr = start;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +        /* If userspace has passed a versioned address, kernel</span>
<span class="quote">&gt;&gt;&gt; +         * will not find it in the VMAs since it does not store</span>
<span class="quote">&gt;&gt;&gt; +         * the version tags in the list of VMAs. Storing version</span>
<span class="quote">&gt;&gt;&gt; +         * tags in list of VMAs is impractical since they can be</span>
<span class="quote">&gt;&gt;&gt; +         * changed any time from userspace without dropping into</span>
<span class="quote">&gt;&gt;&gt; +         * kernel. Any address search in VMAs will be done with</span>
<span class="quote">&gt;&gt;&gt; +         * non-versioned addresses. Ensure the ADI version bits</span>
<span class="quote">&gt;&gt;&gt; +         * are dropped here by sign extending the last bit before</span>
<span class="quote">&gt;&gt;&gt; +         * ADI bits. IOMMU does not implement version tags.</span>
<span class="quote">&gt;&gt;&gt; +         */</span>
<span class="quote">&gt;&gt;&gt; +        addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; So you are depending on the sign extension to clear the ADI bits... but</span>
<span class="quote">&gt;&gt; this only happens if there is a zero in that &quot;last bit before ADI bits&quot;.</span>
<span class="quote">&gt;&gt; If the last bit is a 1, then the ADI bits will be set instead of</span>
<span class="quote">&gt;&gt; cleared.  That seems like an unintended consequence given the comment. I</span>
<span class="quote">&gt;&gt; am aware of the value of adi_nbits() and of the number of valid bits in</span>
<span class="quote">&gt;&gt; a virtual address on the M7 processor, but wouldn&#39;t using &#39;unsigned</span>
<span class="quote">&gt;&gt; long&#39; for everything here guarantee the ADI bits get cleared regardless</span>
<span class="quote">&gt;&gt; of the state of the last non-adi bit?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Sign extension is the right thing to do. MMU considers values of 0 and </span>
<span class="quote">&gt; 15 for bits 63-60 to be untagged addresses and expects bit 59 to be </span>
<span class="quote">&gt; sign-extended for untagged virtual addresses. The code I added is </span>
<span class="quote">&gt; explicitly meant to sign-extend, not zero out the top 4 bits.</span>

OK, that wasn&#39;t perfectly clear from the comment, which said &quot;version 
bits are dropped&quot;.

So sign extending will produce an address that the MMU can use, but will 
it produce an address that will allow a successful search in the page 
tables? ie, was this same sign extending done when first handing out 
that virtual address to the user?

Rob
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 25, 2017, 10:57 p.m.</div>
<pre class="content">
On 01/25/2017 03:50 PM, Rob Gardner wrote:
<span class="quote">&gt; On 01/25/2017 03:20 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; On 01/25/2017 03:00 PM, Rob Gardner wrote:</span>
<span class="quote">&gt;&gt;&gt; On 01/25/2017 12:57 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -157,6 +158,24 @@ int __get_user_pages_fast(unsigned long start,</span>
<span class="quote">&gt;&gt;&gt;&gt; int nr_pages, int write,</span>
<span class="quote">&gt;&gt;&gt;&gt;       pgd_t *pgdp;</span>
<span class="quote">&gt;&gt;&gt;&gt;       int nr = 0;</span>
<span class="quote">&gt;&gt;&gt;&gt;   +#ifdef CONFIG_SPARC64</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (adi_capable()) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +        long addr = start;</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +        /* If userspace has passed a versioned address, kernel</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * will not find it in the VMAs since it does not store</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * the version tags in the list of VMAs. Storing version</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * tags in list of VMAs is impractical since they can be</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * changed any time from userspace without dropping into</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * kernel. Any address search in VMAs will be done with</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * non-versioned addresses. Ensure the ADI version bits</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * are dropped here by sign extending the last bit before</span>
<span class="quote">&gt;&gt;&gt;&gt; +         * ADI bits. IOMMU does not implement version tags.</span>
<span class="quote">&gt;&gt;&gt;&gt; +         */</span>
<span class="quote">&gt;&gt;&gt;&gt; +        addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; So you are depending on the sign extension to clear the ADI bits... but</span>
<span class="quote">&gt;&gt;&gt; this only happens if there is a zero in that &quot;last bit before ADI bits&quot;.</span>
<span class="quote">&gt;&gt;&gt; If the last bit is a 1, then the ADI bits will be set instead of</span>
<span class="quote">&gt;&gt;&gt; cleared.  That seems like an unintended consequence given the comment. I</span>
<span class="quote">&gt;&gt;&gt; am aware of the value of adi_nbits() and of the number of valid bits in</span>
<span class="quote">&gt;&gt;&gt; a virtual address on the M7 processor, but wouldn&#39;t using &#39;unsigned</span>
<span class="quote">&gt;&gt;&gt; long&#39; for everything here guarantee the ADI bits get cleared regardless</span>
<span class="quote">&gt;&gt;&gt; of the state of the last non-adi bit?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Sign extension is the right thing to do. MMU considers values of 0 and</span>
<span class="quote">&gt;&gt; 15 for bits 63-60 to be untagged addresses and expects bit 59 to be</span>
<span class="quote">&gt;&gt; sign-extended for untagged virtual addresses. The code I added is</span>
<span class="quote">&gt;&gt; explicitly meant to sign-extend, not zero out the top 4 bits.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; OK, that wasn&#39;t perfectly clear from the comment, which said &quot;version</span>
<span class="quote">&gt; bits are dropped&quot;.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So sign extending will produce an address that the MMU can use, but will</span>
<span class="quote">&gt; it produce an address that will allow a successful search in the page</span>
<span class="quote">&gt; tables? ie, was this same sign extending done when first handing out</span>
<span class="quote">&gt; that virtual address to the user?</span>
<span class="quote">&gt;</span>

Yes to both your questions. When virtual addresses are handed out, the 
last implemented virtual address bit is sign-extended. Sign-extending 
when dropping version bits preserves that original sign-extension. This 
is why MMU considers tag values of 0 as well as 15 to be invalid because 
they both represent sign-extension of the last implemented virtual address.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=129">David Miller</a> - Jan. 30, 2017, 10:15 p.m.</div>
<pre class="content">
<span class="from">From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Date: Wed, 25 Jan 2017 12:57:16 -0700
<span class="quote">
&gt; +static inline void enable_adi(void)</span>
<span class="quote">&gt; +{</span>
 ...
<span class="quote">&gt; +	__asm__ __volatile__(</span>
<span class="quote">&gt; +		&quot;rdpr %%pstate, %%g1\n\t&quot;</span>
<span class="quote">&gt; +		&quot;or %%g1, %0, %%g1\n\t&quot;</span>
<span class="quote">&gt; +		&quot;wrpr %%g1, %%g0, %%pstate\n\t&quot;</span>
<span class="quote">&gt; +		&quot;.word 0x83438000\n\t&quot;	/* rd %mcdper, %g1 */</span>
<span class="quote">&gt; +		&quot;.word 0xaf900001\n\t&quot;	/* wrpr  %g0, %g1, %pmcdper */</span>
<span class="quote">&gt; +		:</span>
<span class="quote">&gt; +		: &quot;i&quot; (PSTATE_MCDE)</span>
<span class="quote">&gt; +		: &quot;g1&quot;);</span>
<span class="quote">&gt; +}</span>

This is _crazy_ expensive.

This is 4 privileged register operations, every single one incurs a full
pipline flush and virtual cpu thread yield.

And we do this around _every_ single userspace access from the kernel
when the thread has ADI enabled.

I think if the kernel manages the ADI metadata properly, you can get rid
of all of this.

On etrap, you change ESTATE_PSTATE{1,2} to have the MCDE bit enabled.
Then the kernel always runs with ADI enabled.

Furthermore, since the %mcdper register should be set to whatever the
current task has asked for, you should be able to avoid touching it
as well assuming that traps do not change %mcdper&#39;s value.

Then you don&#39;t need to do anything special during userspace accesses
which seems to be the way this was designed to be used.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Jan. 31, 2017, 11:38 p.m.</div>
<pre class="content">
On 01/30/2017 03:15 PM, David Miller wrote:
<span class="quote">&gt; From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
<span class="quote">&gt; Date: Wed, 25 Jan 2017 12:57:16 -0700</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +static inline void enable_adi(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;  ...</span>
<span class="quote">&gt;&gt; +	__asm__ __volatile__(</span>
<span class="quote">&gt;&gt; +		&quot;rdpr %%pstate, %%g1\n\t&quot;</span>
<span class="quote">&gt;&gt; +		&quot;or %%g1, %0, %%g1\n\t&quot;</span>
<span class="quote">&gt;&gt; +		&quot;wrpr %%g1, %%g0, %%pstate\n\t&quot;</span>
<span class="quote">&gt;&gt; +		&quot;.word 0x83438000\n\t&quot;	/* rd %mcdper, %g1 */</span>
<span class="quote">&gt;&gt; +		&quot;.word 0xaf900001\n\t&quot;	/* wrpr  %g0, %g1, %pmcdper */</span>
<span class="quote">&gt;&gt; +		:</span>
<span class="quote">&gt;&gt; +		: &quot;i&quot; (PSTATE_MCDE)</span>
<span class="quote">&gt;&gt; +		: &quot;g1&quot;);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This is _crazy_ expensive.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This is 4 privileged register operations, every single one incurs a full</span>
<span class="quote">&gt; pipline flush and virtual cpu thread yield.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; And we do this around _every_ single userspace access from the kernel</span>
<span class="quote">&gt; when the thread has ADI enabled.</span>

Hi Dave,

Thanks for the feedback. This is very helpful. I checked and it indeed 
can cost 50+ cycles even on M7 processor for PSTATE accesses.
<span class="quote">
&gt;</span>
<span class="quote">&gt; I think if the kernel manages the ADI metadata properly, you can get rid</span>
<span class="quote">&gt; of all of this.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On etrap, you change ESTATE_PSTATE{1,2} to have the MCDE bit enabled.</span>
<span class="quote">&gt; Then the kernel always runs with ADI enabled.</span>

Running the kernel with PSTATE.mcde=1 can possibly be problematic as we 
had discussed earlier in this thread where keeping PSTATE.mcde enabled 
might mean kernel having to keep track of which pages still have tags 
set on them or flush tags on every page on free. I will go through the 
code again to see if it PSTATE.mcde can be turned on in kernel all the 
time, which might be the case if we can ensure kernel accesses pages 
with TTE.mcd cleared.
<span class="quote">
&gt;</span>
<span class="quote">&gt; Furthermore, since the %mcdper register should be set to whatever the</span>
<span class="quote">&gt; current task has asked for, you should be able to avoid touching it</span>
<span class="quote">&gt; as well assuming that traps do not change %mcdper&#39;s value.</span>

When running in privileged mode, it is the value of %pmcdper that 
matter, not %mcdper, hence I added code to sync %pmcdper with %mcdper 
when entering privileged mode. Nevertheless, one of the HW designers has 
suggested I might be able to get away without having to futz with 
%pmcdper by using membar before exiting privileged mode which might 
still get me the same effect I am looking for without the cost.

--
Khalid
<span class="quote">
&gt;</span>
<span class="quote">&gt; Then you don&#39;t need to do anything special during userspace accesses</span>
<span class="quote">&gt; which seems to be the way this was designed to be used.</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe from this list: send the line &quot;unsubscribe sparclinux&quot; in</span>
<span class="quote">&gt; the body of a message to majordomo@vger.kernel.org</span>
<span class="quote">&gt; More majordomo info at  http://vger.kernel.org/majordomo-info.html</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=129">David Miller</a> - Feb. 1, 2017, 5:18 p.m.</div>
<pre class="content">
<span class="from">From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Date: Tue, 31 Jan 2017 16:38:49 -0700
<span class="quote">
&gt; Thanks for the feedback. This is very helpful. I checked and it indeed</span>
<span class="quote">&gt; can cost 50+ cycles even on M7 processor for PSTATE accesses.</span>

Consider how many bytes can be copied in 50+ cycles :-)
<span class="quote">
&gt;&gt; On etrap, you change ESTATE_PSTATE{1,2} to have the MCDE bit enabled.</span>
<span class="quote">&gt;&gt; Then the kernel always runs with ADI enabled.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Running the kernel with PSTATE.mcde=1 can possibly be problematic as</span>
<span class="quote">&gt; we had discussed earlier in this thread where keeping PSTATE.mcde</span>
<span class="quote">&gt; enabled might mean kernel having to keep track of which pages still</span>
<span class="quote">&gt; have tags set on them or flush tags on every page on free. I will go</span>
<span class="quote">&gt; through the code again to see if it PSTATE.mcde can be turned on in</span>
<span class="quote">&gt; kernel all the time, which might be the case if we can ensure kernel</span>
<span class="quote">&gt; accesses pages with TTE.mcd cleared.</span>

If we can clear the tags properly on page release when the page was
used for ADI, it can work.

One way would be to track the state in the page struct somehow, and
in arch_alloc_page() clear the tags if necessary.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/sparc/adi.txt b/Documentation/sparc/adi.txt</span>
new file mode 100644
<span class="p_header">index 0000000..1740f8a</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/Documentation/sparc/adi.txt</span>
<span class="p_chunk">@@ -0,0 +1,288 @@</span> <span class="p_context"></span>
<span class="p_add">+Application Data Integrity (ADI)</span>
<span class="p_add">+================================</span>
<span class="p_add">+</span>
<span class="p_add">+SPARC M7 processor adds the Application Data Integrity (ADI) feature.</span>
<span class="p_add">+ADI allows a task to set version tags on any subset of its address</span>
<span class="p_add">+space. Once ADI is enabled and version tags are set for ranges of</span>
<span class="p_add">+address space of a task, the processor will compare the tag in pointers</span>
<span class="p_add">+to memory in these ranges to the version set by the application</span>
<span class="p_add">+previously. Access to memory is granted only if the tag in given</span>
<span class="p_add">+pointer matches the tag set by the application. In case of mismatch,</span>
<span class="p_add">+processor raises an exception.</span>
<span class="p_add">+</span>
<span class="p_add">+Following steps must be taken by a task to enable ADI fully:</span>
<span class="p_add">+</span>
<span class="p_add">+1. Set the user mode PSTATE.mcde bit. This acts as master switch for</span>
<span class="p_add">+   the task&#39;s entire address space to enable/disable ADI for the task.</span>
<span class="p_add">+</span>
<span class="p_add">+2. Set TTE.mcd bit on any TLB entries that correspond to the range of</span>
<span class="p_add">+   addresses ADI is being enabled on. MMU checks the version tag only</span>
<span class="p_add">+   on the pages that have TTE.mcd bit set.</span>
<span class="p_add">+</span>
<span class="p_add">+3. Set the version tag for virtual addresses using stxa instruction</span>
<span class="p_add">+   and one of the MCD specific ASIs. Each stxa instruction sets the</span>
<span class="p_add">+   given tag for one ADI block size number of bytes. This step must</span>
<span class="p_add">+   be repeated for entire page to set tags for entire page.</span>
<span class="p_add">+</span>
<span class="p_add">+ADI block size for the platform is provided by the hypervisor to the</span>
<span class="p_add">+kernel in machine description tables. Hypervisor also provides the</span>
<span class="p_add">+number of top bits in the virtual address that specify the version tag.</span>
<span class="p_add">+Once version tag has been set for a memory location, the tag is stored</span>
<span class="p_add">+in the physical memory and the same tag must be present in the ADI</span>
<span class="p_add">+version tag bits of the virtual address being presented to the MMU. For</span>
<span class="p_add">+example on SPARC M7 processor, MMU uses bits 63-60 for version tags and</span>
<span class="p_add">+ADI block size is same as cacheline size which is 64 bytes. A task that</span>
<span class="p_add">+sets ADI version to say 10 on a range of memory, must access that memory</span>
<span class="p_add">+using virtual addresses that contain 0xa in bits 63-60.</span>
<span class="p_add">+</span>
<span class="p_add">+ADI is enabled on a set of pages using mprotect() with PROT_ADI flag.</span>
<span class="p_add">+When ADI is enabled on a set of pages by a task for the first time,</span>
<span class="p_add">+kernel sets the PSTATE.mcde bit fot the task. Version tags for memory</span>
<span class="p_add">+addresses are set with an stxa instruction on the addresses using</span>
<span class="p_add">+ASI_MCD_PRIMARY or ASI_MCD_ST_BLKINIT_PRIMARY. ADI block size is</span>
<span class="p_add">+provided by the hypervisor to the kernel.  Kernel returns the value of</span>
<span class="p_add">+ADI block size to userspace using auxiliary vector along with other ADI</span>
<span class="p_add">+info. Following auxiliary vectors are provided by the kernel:</span>
<span class="p_add">+</span>
<span class="p_add">+	AT_ADI_BLKSZ	ADI block size. This is the granularity and</span>
<span class="p_add">+			alignment, in bytes, of ADI versioning.</span>
<span class="p_add">+	AT_ADI_NBITS	Number of ADI version bits in the VA</span>
<span class="p_add">+	AT_ADI_UEONADI	ADI version of memory containing uncorrectable</span>
<span class="p_add">+			errors will be set to this value</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+IMPORTANT NOTES:</span>
<span class="p_add">+</span>
<span class="p_add">+- Version tag values of 0x0 and 0xf are reserved.</span>
<span class="p_add">+</span>
<span class="p_add">+- Version tags are set on virtual addresses from userspace even though</span>
<span class="p_add">+  tags are stored in physical memory. Tags are set on a physical page</span>
<span class="p_add">+  after it has been allocated to a task and a pte has been created for</span>
<span class="p_add">+  it.</span>
<span class="p_add">+</span>
<span class="p_add">+- When a task frees a memory page it had set version tags on, the page</span>
<span class="p_add">+  goes back to free page pool. When this page is re-allocated to a task,</span>
<span class="p_add">+  kernel clears the page using block initialization ASI which clears the</span>
<span class="p_add">+  version tags as well for the page. If a page allocated to a task is</span>
<span class="p_add">+  freed and allocated back to the same task, old version tags set by the</span>
<span class="p_add">+  task on that page will no longer be present.</span>
<span class="p_add">+</span>
<span class="p_add">+- Kernel does not set any tags for user pages and it is entirely a</span>
<span class="p_add">+  task&#39;s responsibility to set any version tags. Kernel does ensure the</span>
<span class="p_add">+  version tags are preserved if a page is swapped out to the disk and</span>
<span class="p_add">+  swapped back in. It also preserves that version tags if a page is</span>
<span class="p_add">+  migrated.</span>
<span class="p_add">+</span>
<span class="p_add">+- Initial implementation assumes a single page uses exact same version</span>
<span class="p_add">+  tag for the entire page. Kernel saves the version tag for only the</span>
<span class="p_add">+  first byte when swapping or migrating a page and restores that tag to</span>
<span class="p_add">+  the entire page after swapping in or migrating the page. Future</span>
<span class="p_add">+  implementations may expand kernel&#39;s capability to store/restore more</span>
<span class="p_add">+  than one tag per page.</span>
<span class="p_add">+</span>
<span class="p_add">+- ADI works for any size pages. A userspace task need not be aware of</span>
<span class="p_add">+  page size when using ADI. It can simply select a virtual address</span>
<span class="p_add">+  range, enable ADI on the range using mprotect() and set version tags</span>
<span class="p_add">+  for the entire range. mprotect() ensures range is aligned to page size</span>
<span class="p_add">+  and is a multiple of page size.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+ADI related traps</span>
<span class="p_add">+-----------------</span>
<span class="p_add">+</span>
<span class="p_add">+With ADI enabled, following new traps may occur:</span>
<span class="p_add">+</span>
<span class="p_add">+Disrupting memory corruption</span>
<span class="p_add">+</span>
<span class="p_add">+	When a store accesses a memory localtion that has TTE.mcd=1,</span>
<span class="p_add">+	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="p_add">+	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="p_add">+	the corresponding cacheline, a memory corruption trap occurs. By</span>
<span class="p_add">+	default, it is a disrupting trap and is sent to the hypervisor</span>
<span class="p_add">+	first. Hypervisor creates a sun4v error report and sends a</span>
<span class="p_add">+	resumable error (TT=0x7e) trap to the kernel. The kernel sends</span>
<span class="p_add">+	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="p_add">+	info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ADIDERR;</span>
<span class="p_add">+		siginfo.si_addr = addr; /* PC where first mismatch occurred */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+Precise memory corruption</span>
<span class="p_add">+</span>
<span class="p_add">+	When a store accesses a memory location that has TTE.mcd=1,</span>
<span class="p_add">+	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="p_add">+	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="p_add">+	the corresponding cacheline, a memory corruption trap occurs. If</span>
<span class="p_add">+	MCD precise exception is enabled (MCDPERR=1), a precise</span>
<span class="p_add">+	exception is sent to the kernel with TT=0x1a. The kernel sends</span>
<span class="p_add">+	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="p_add">+	info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ADIPERR;</span>
<span class="p_add">+		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	NOTE: ADI tag mismatch on a load always results in precise trap.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+MCD disabled</span>
<span class="p_add">+</span>
<span class="p_add">+	When a task has not enabled ADI and attempts to set ADI version</span>
<span class="p_add">+	on a memory address, processor sends an MCD disabled trap. This</span>
<span class="p_add">+	trap is handled by hypervisor first and the hypervisor vectors this</span>
<span class="p_add">+	trap through to the kernel as Data Access Exception trap with</span>
<span class="p_add">+	fault type set to 0xa (invalid ASI). When this occurs, the kernel</span>
<span class="p_add">+	sends the task SIGSEGV signal with following info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ACCADI;</span>
<span class="p_add">+		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+Sample program to use ADI</span>
<span class="p_add">+-------------------------</span>
<span class="p_add">+</span>
<span class="p_add">+Following sample program is meant to illustrate how to use the ADI</span>
<span class="p_add">+functionality.</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;unistd.h&gt;</span>
<span class="p_add">+#include &lt;stdio.h&gt;</span>
<span class="p_add">+#include &lt;stdlib.h&gt;</span>
<span class="p_add">+#include &lt;elf.h&gt;</span>
<span class="p_add">+#include &lt;sys/ipc.h&gt;</span>
<span class="p_add">+#include &lt;sys/shm.h&gt;</span>
<span class="p_add">+#include &lt;sys/mman.h&gt;</span>
<span class="p_add">+#include &lt;asm/asi.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef AT_ADI_BLKSZ</span>
<span class="p_add">+#define AT_ADI_BLKSZ	34</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifndef AT_ADI_NBITS</span>
<span class="p_add">+#define AT_ADI_NBITS	35</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifndef AT_ADI_UEONADI</span>
<span class="p_add">+#define AT_ADI_UEONADI	36</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef PROT_ADI</span>
<span class="p_add">+#define PROT_ADI	0x10</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define BUFFER_SIZE     32*1024*1024UL</span>
<span class="p_add">+</span>
<span class="p_add">+main(int argc, char* argv[], char* envp[])</span>
<span class="p_add">+{</span>
<span class="p_add">+        unsigned long i, mcde, adi_blksz, adi_nbits, adi_ueonadi;</span>
<span class="p_add">+        char *shmaddr, *tmp_addr, *end, *veraddr, *clraddr;</span>
<span class="p_add">+        int shmid, version;</span>
<span class="p_add">+	Elf64_auxv_t *auxv;</span>
<span class="p_add">+</span>
<span class="p_add">+	adi_blksz = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	while(*envp++ != NULL);</span>
<span class="p_add">+	for (auxv = (Elf64_auxv_t *)envp; auxv-&gt;a_type != AT_NULL; auxv++) {</span>
<span class="p_add">+		switch (auxv-&gt;a_type) {</span>
<span class="p_add">+		case AT_ADI_BLKSZ:</span>
<span class="p_add">+			adi_blksz = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case AT_ADI_NBITS:</span>
<span class="p_add">+			adi_nbits = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case AT_ADI_UEONADI:</span>
<span class="p_add">+			adi_ueonadi = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (adi_blksz == 0) {</span>
<span class="p_add">+		fprintf(stderr, &quot;Oops! ADI is not supported\n&quot;);</span>
<span class="p_add">+		exit(1);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	printf(&quot;ADI capabilities:\n&quot;);</span>
<span class="p_add">+	printf(&quot;\tBlock size = %ld\n&quot;, adi_blksz);</span>
<span class="p_add">+	printf(&quot;\tNumber of bits = %ld\n&quot;, adi_nbits);</span>
<span class="p_add">+	printf(&quot;\tUE on ADI error = %ld\n&quot;, adi_ueonadi);</span>
<span class="p_add">+</span>
<span class="p_add">+        if ((shmid = shmget(2, BUFFER_SIZE,</span>
<span class="p_add">+                                IPC_CREAT | SHM_R | SHM_W)) &lt; 0) {</span>
<span class="p_add">+                perror(&quot;shmget failed&quot;);</span>
<span class="p_add">+                exit(1);</span>
<span class="p_add">+        }</span>
<span class="p_add">+</span>
<span class="p_add">+        shmaddr = shmat(shmid, NULL, 0);</span>
<span class="p_add">+        if (shmaddr == (char *)-1) {</span>
<span class="p_add">+                perror(&quot;shm attach failed&quot;);</span>
<span class="p_add">+                shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+                exit(1);</span>
<span class="p_add">+        }</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE|PROT_ADI)) {</span>
<span class="p_add">+		perror(&quot;mprotect failed&quot;);</span>
<span class="p_add">+		goto err_out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Set the ADI version tag on the shm segment</span>
<span class="p_add">+         */</span>
<span class="p_add">+        version = 10;</span>
<span class="p_add">+        tmp_addr = shmaddr;</span>
<span class="p_add">+        end = shmaddr + BUFFER_SIZE;</span>
<span class="p_add">+        while (tmp_addr &lt; end) {</span>
<span class="p_add">+                asm volatile(</span>
<span class="p_add">+                        &quot;stxa %1, [%0]0x90\n\t&quot;</span>
<span class="p_add">+                        :</span>
<span class="p_add">+                        : &quot;r&quot; (tmp_addr), &quot;r&quot; (version));</span>
<span class="p_add">+                tmp_addr += adi_blksz;</span>
<span class="p_add">+        }</span>
<span class="p_add">+	asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Create a versioned address from the normal address by placing</span>
<span class="p_add">+	 * version tag in the upper adi_nbits bits</span>
<span class="p_add">+         */</span>
<span class="p_add">+        tmp_addr = (void *) ((unsigned long)shmaddr &lt;&lt; adi_nbits);</span>
<span class="p_add">+        tmp_addr = (void *) ((unsigned long)tmp_addr &gt;&gt; adi_nbits);</span>
<span class="p_add">+        veraddr = (void *) (((unsigned long)version &lt;&lt; (64-adi_nbits))</span>
<span class="p_add">+                        | (unsigned long)tmp_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+        printf(&quot;Starting the writes:\n&quot;);</span>
<span class="p_add">+        for (i = 0; i &lt; BUFFER_SIZE; i++) {</span>
<span class="p_add">+                veraddr[i] = (char)(i);</span>
<span class="p_add">+                if (!(i % (1024 * 1024)))</span>
<span class="p_add">+                        printf(&quot;.&quot;);</span>
<span class="p_add">+        }</span>
<span class="p_add">+        printf(&quot;\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        printf(&quot;Verifying data...&quot;);</span>
<span class="p_add">+	fflush(stdout);</span>
<span class="p_add">+        for (i = 0; i &lt; BUFFER_SIZE; i++)</span>
<span class="p_add">+                if (veraddr[i] != (char)i)</span>
<span class="p_add">+                        printf(&quot;\nIndex %lu mismatched\n&quot;, i);</span>
<span class="p_add">+        printf(&quot;Done.\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Disable ADI and clean up</span>
<span class="p_add">+         */</span>
<span class="p_add">+	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE)) {</span>
<span class="p_add">+		perror(&quot;mprotect failed&quot;);</span>
<span class="p_add">+		goto err_out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="p_add">+                perror(&quot;Detach failure&quot;);</span>
<span class="p_add">+        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+        exit(0);</span>
<span class="p_add">+</span>
<span class="p_add">+err_out:</span>
<span class="p_add">+        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="p_add">+                perror(&quot;Detach failure&quot;);</span>
<span class="p_add">+        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+        exit(1);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/adi.h b/arch/sparc/include/asm/adi.h</span>
new file mode 100644
<span class="p_header">index 0000000..acad0d0</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/include/asm/adi.h</span>
<span class="p_chunk">@@ -0,0 +1,6 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef ___ASM_SPARC_ADI_H</span>
<span class="p_add">+#define ___ASM_SPARC_ADI_H</span>
<span class="p_add">+#if defined(__sparc__) &amp;&amp; defined(__arch64__)</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/adi_64.h b/arch/sparc/include/asm/adi_64.h</span>
new file mode 100644
<span class="p_header">index 0000000..24fe52f</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/include/asm/adi_64.h</span>
<span class="p_chunk">@@ -0,0 +1,46 @@</span> <span class="p_context"></span>
<span class="p_add">+/* adi_64.h: ADI related data structures</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2016 Khalid Aziz (khalid.aziz@oracle.com)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifndef __ASM_SPARC64_ADI_H</span>
<span class="p_add">+#define __ASM_SPARC64_ADI_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASSEMBLY__</span>
<span class="p_add">+</span>
<span class="p_add">+struct adi_caps {</span>
<span class="p_add">+	__u64 blksz;</span>
<span class="p_add">+	__u64 nbits;</span>
<span class="p_add">+	__u64 ue_on_adi;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct adi_config {</span>
<span class="p_add">+	bool enabled;</span>
<span class="p_add">+	struct adi_caps caps;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct adi_config adi_state;</span>
<span class="p_add">+</span>
<span class="p_add">+extern void mdesc_adi_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool adi_capable(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return adi_state.enabled;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long adi_blksize(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return adi_state.caps.blksz;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long adi_nbits(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return adi_state.caps.nbits;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#endif	/* __ASSEMBLY__ */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif	/* !(__ASM_SPARC64_ADI_H) */</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/elf_64.h b/arch/sparc/include/asm/elf_64.h</span>
<span class="p_header">index 3f2d403..cf00fbc 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/elf_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/elf_64.h</span>
<span class="p_chunk">@@ -210,4 +210,12 @@</span> <span class="p_context"> do {	if ((ex).e_ident[EI_CLASS] == ELFCLASS32)	\</span>
 			(current-&gt;personality &amp; (~PER_MASK)));	\
 } while (0)
 
<span class="p_add">+#define ARCH_DLINFO						\</span>
<span class="p_add">+do {								\</span>
<span class="p_add">+	extern struct adi_config adi_state;			\</span>
<span class="p_add">+	NEW_AUX_ENT(AT_ADI_BLKSZ, adi_state.caps.blksz);	\</span>
<span class="p_add">+	NEW_AUX_ENT(AT_ADI_NBITS, adi_state.caps.nbits);	\</span>
<span class="p_add">+	NEW_AUX_ENT(AT_ADI_UEONADI, adi_state.caps.ue_on_adi);	\</span>
<span class="p_add">+} while (0)</span>
<span class="p_add">+</span>
 #endif /* !(__ASM_SPARC64_ELF_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/hugetlb.h b/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_header">index dcbf985..ac2fe18 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -77,5 +77,18 @@</span> <span class="p_context"> static inline void arch_clear_hugepage_flags(struct page *page)</span>
 void hugetlb_free_pgd_range(struct mmu_gather *tlb, unsigned long addr,
 			    unsigned long end, unsigned long floor,
 			    unsigned long ceiling);
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+static inline pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+			 struct page *page, int writeable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* If this vma has ADI enabled on it, turn on TTE.mcd</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SPARC_ADI)</span>
<span class="p_add">+		return pte_mkmcd(entry);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return pte_mknotmcd(entry);</span>
<span class="p_add">+}</span>
<span class="p_add">+#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="p_add">+#endif</span>
 
 #endif /* _ASM_SPARC64_HUGETLB_H */
<span class="p_header">diff --git a/arch/sparc/include/asm/mman.h b/arch/sparc/include/asm/mman.h</span>
<span class="p_header">index 59bb593..95d3abc 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mman.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mman.h</span>
<span class="p_chunk">@@ -6,5 +6,43 @@</span> <span class="p_context"></span>
 #ifndef __ASSEMBLY__
 #define arch_mmap_check(addr,len,flags)	sparc_mmap_check(addr,len)
 int sparc_mmap_check(unsigned long addr, unsigned long len);
<span class="p_del">-#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_calc_vm_prot_bits(prot, pkey) sparc_calc_vm_prot_bits(prot)</span>
<span class="p_add">+static inline unsigned long sparc_calc_vm_prot_bits(unsigned long prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (prot &amp; PROT_ADI) {</span>
<span class="p_add">+		struct pt_regs *regs;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!current-&gt;mm-&gt;context.adi) {</span>
<span class="p_add">+			regs = task_pt_regs(current);</span>
<span class="p_add">+			regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="p_add">+			current-&gt;mm-&gt;context.adi = true;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return VM_SPARC_ADI;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_vm_get_page_prot(vm_flags) sparc_vm_get_page_prot(vm_flags)</span>
<span class="p_add">+static inline pgprot_t sparc_vm_get_page_prot(unsigned long vm_flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (vm_flags &amp; VM_SPARC_ADI) ? __pgprot(_PAGE_MCD_4V) : __pgprot(0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_validate_prot(prot) sparc_validate_prot(prot)</span>
<span class="p_add">+static inline int sparc_validate_prot(unsigned long prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM | PROT_ADI))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if ((prot &amp; PROT_ADI) &amp;&amp; !adi_capable())</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	return 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif /* CONFIG_SPARC64 */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __ASSEMBLY__ */</span>
 #endif /* __SPARC_MMAN_H__ */
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">index f7de0db..e1d30ac 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_chunk">@@ -96,6 +96,7 @@</span> <span class="p_context"> typedef struct {</span>
 	unsigned long		thp_pte_count;
 	struct tsb_config	tsb_block[MM_NUM_TSBS];
 	struct hv_tsb_descr	tsb_descr[MM_NUM_TSBS];
<span class="p_add">+	bool			adi;</span>
 } mm_context_t;
 
 #endif /* !__ASSEMBLY__ */
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index b84be67..3b78c4f 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -7,6 +7,7 @@</span> <span class="p_context"></span>
 
 #include &lt;linux/spinlock.h&gt;
 #include &lt;asm/spitfire.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 #include &lt;asm-generic/mm_hooks.h&gt;
 
 static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
<span class="p_chunk">@@ -127,6 +128,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 		__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),
 			       SECONDARY_CONTEXT);
 	}
<span class="p_add">+</span>
 	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);
 }
 
<span class="p_chunk">@@ -151,6 +153,47 @@</span> <span class="p_context"> static inline void activate_mm(struct mm_struct *active_mm, struct mm_struct *mm</span>
 	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);
 }
 
<span class="p_add">+#define  __HAVE_ARCH_START_CONTEXT_SWITCH</span>
<span class="p_add">+static inline void arch_start_context_switch(struct task_struct *prev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Save the current state of MCDPER register for the process we are</span>
<span class="p_add">+	 * switching from</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="p_add">+			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+		if (tmp_mcdper)</span>
<span class="p_add">+			set_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define finish_arch_post_lock_switch	finish_arch_post_lock_switch</span>
<span class="p_add">+static inline void finish_arch_post_lock_switch(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Restore the state of MCDPER register for the new process</span>
<span class="p_add">+	 * just switched to.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		tmp_mcdper = test_thread_flag(TIF_MCDPER);</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;mov %0, %%g1\n\t&quot;</span>
<span class="p_add">+			&quot;.word 0x9d800001\n\t&quot;	/* wr %g0, %g1, %mcdper&quot; */</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;ir&quot; (tmp_mcdper)</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* !(__ASSEMBLY__) */
 
 #endif /* !(__SPARC64_MMU_CONTEXT_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/pgtable_64.h b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_header">index f4e4834..8b74985 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_chunk">@@ -17,6 +17,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/types.h&gt;
 #include &lt;asm/spitfire.h&gt;
 #include &lt;asm/asi.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 #include &lt;asm/page.h&gt;
 #include &lt;asm/processor.h&gt;
 
<span class="p_chunk">@@ -564,6 +565,18 @@</span> <span class="p_context"> static inline pte_t pte_mkspecial(pte_t pte)</span>
 	return pte;
 }
 
<span class="p_add">+static inline pte_t pte_mkmcd(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_val(pte) |= _PAGE_MCD_4V;</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pte_t pte_mknotmcd(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_val(pte) &amp;= ~_PAGE_MCD_4V;</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline unsigned long pte_young(pte_t pte)
 {
 	unsigned long mask;
<span class="p_chunk">@@ -964,9 +977,14 @@</span> <span class="p_context"> void pgtable_trans_huge_deposit(struct mm_struct *mm, pmd_t *pmdp,</span>
 pgtable_t pgtable_trans_huge_withdraw(struct mm_struct *mm, pmd_t *pmdp);
 #endif
 
<span class="p_del">-/* Encode and de-code a swap entry */</span>
<span class="p_add">+/* Encode and de-code a swap entry. Upper bits of offset are used to</span>
<span class="p_add">+ * store the ADI version tag for pages that have ADI enabled and tags set</span>
<span class="p_add">+ */</span>
 #define __swp_type(entry)	(((entry).val &gt;&gt; PAGE_SHIFT) &amp; 0xffUL)
<span class="p_del">-#define __swp_offset(entry)	((entry).val &gt;&gt; (PAGE_SHIFT + 8UL))</span>
<span class="p_add">+#define __swp_offset(entry)		\</span>
<span class="p_add">+	((((entry).val &lt;&lt; adi_nbits()) &gt;&gt; adi_nbits()) &gt;&gt; (PAGE_SHIFT + 8UL))</span>
<span class="p_add">+#define __swp_aditag(entry)		\</span>
<span class="p_add">+	((entry).val &gt;&gt; (sizeof(unsigned long)-adi_nbits()))</span>
 #define __swp_entry(type, offset)	\
 	( (swp_entry_t) \
 	  { \
<span class="p_chunk">@@ -989,6 +1007,69 @@</span> <span class="p_context"> int page_in_phys_avail(unsigned long paddr);</span>
 int remap_pfn_range(struct vm_area_struct *, unsigned long, unsigned long,
 		    unsigned long, pgprot_t);
 
<span class="p_add">+#define __HAVE_ARCH_DO_SWAP_PAGE</span>
<span class="p_add">+static inline void arch_do_swap_page(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+				     pte_t pte, pte_t oldpte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (pte_val(pte) &amp; _PAGE_MCD_4V) {</span>
<span class="p_add">+		swp_entry_t tmp;</span>
<span class="p_add">+		pgoff_t swap_off;</span>
<span class="p_add">+		unsigned long swap_type, version;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Check if the swapped out page has an ADI version</span>
<span class="p_add">+		 * saved in the swap offset. If yes, restore</span>
<span class="p_add">+		 * version tag to the newly allocated page</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		tmp = __pte_to_swp_entry(oldpte);</span>
<span class="p_add">+		swap_off = __swp_offset(tmp);</span>
<span class="p_add">+		swap_type = __swp_type(tmp);</span>
<span class="p_add">+		version = __swp_aditag(tmp);</span>
<span class="p_add">+		if (version) {</span>
<span class="p_add">+			unsigned long i, paddr;</span>
<span class="p_add">+</span>
<span class="p_add">+			paddr = pte_val(pte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+			for (i = paddr; i &lt; (paddr+PAGE_SIZE);</span>
<span class="p_add">+					i += adi_blksize())</span>
<span class="p_add">+				asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="p_add">+					:</span>
<span class="p_add">+					: &quot;r&quot; (version), &quot;r&quot; (i),</span>
<span class="p_add">+					  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define __HAVE_ARCH_UNMAP_ONE</span>
<span class="p_add">+static inline void arch_unmap_one(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+				  pte_t pte, pte_t oldpte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (pte_val(oldpte) &amp; _PAGE_MCD_4V) {</span>
<span class="p_add">+		unsigned long version, paddr;</span>
<span class="p_add">+</span>
<span class="p_add">+		paddr = pte_val(oldpte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+		asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+			     : &quot;=r&quot; (version)</span>
<span class="p_add">+			     : &quot;r&quot; (paddr), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+		if (version) {</span>
<span class="p_add">+			swp_entry_t tmp;</span>
<span class="p_add">+			pgoff_t swap_off;</span>
<span class="p_add">+			unsigned long swap_type, shift_size;</span>
<span class="p_add">+</span>
<span class="p_add">+			/* Save ADI version tag in the top bits</span>
<span class="p_add">+			 * of swap offset</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			tmp = __pte_to_swp_entry(pte);</span>
<span class="p_add">+			swap_off = __swp_offset(tmp);</span>
<span class="p_add">+			swap_type = __swp_type(tmp);</span>
<span class="p_add">+			shift_size = PAGE_SHIFT + 8UL + adi_nbits();</span>
<span class="p_add">+			swap_off = (swap_off &lt;&lt; shift_size)&gt;&gt;shift_size;</span>
<span class="p_add">+			swap_off = (version &lt;&lt; (sizeof(unsigned long) -</span>
<span class="p_add">+					        shift_size)) | swap_off;</span>
<span class="p_add">+			tmp = __swp_entry(swap_type, swap_off);</span>
<span class="p_add">+			pte = __swp_entry_to_pte(tmp);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int io_remap_pfn_range(struct vm_area_struct *vma,
 				     unsigned long from, unsigned long pfn,
 				     unsigned long size, pgprot_t prot)
<span class="p_header">diff --git a/arch/sparc/include/asm/thread_info_64.h b/arch/sparc/include/asm/thread_info_64.h</span>
<span class="p_header">index 3d7b925..b08fd39 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/thread_info_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/thread_info_64.h</span>
<span class="p_chunk">@@ -191,6 +191,7 @@</span> <span class="p_context"> register struct thread_info *current_thread_info_reg asm(&quot;g6&quot;);</span>
  *       an immediate value in instructions such as andcc.
  */
 /* flag bit 12 is available */
<span class="p_add">+#define TIF_MCDPER		12	/* Precise MCD exception */</span>
 #define TIF_MEMDIE		13	/* is terminating due to OOM killer */
 #define TIF_POLLING_NRFLAG	14
 
<span class="p_header">diff --git a/arch/sparc/include/asm/uaccess_64.h b/arch/sparc/include/asm/uaccess_64.h</span>
<span class="p_header">index 5373136..6bfe818 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/uaccess_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/uaccess_64.h</span>
<span class="p_chunk">@@ -10,8 +10,10 @@</span> <span class="p_context"></span>
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/string.h&gt;
 #include &lt;linux/thread_info.h&gt;
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
 #include &lt;asm/asi.h&gt;
 #include &lt;asm/spitfire.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 #include &lt;asm-generic/uaccess-unaligned.h&gt;
 #include &lt;asm/extable_64.h&gt;
 #endif
<span class="p_chunk">@@ -72,6 +74,31 @@</span> <span class="p_context"> static inline bool __chk_range_not_ok(unsigned long addr, unsigned long size, un</span>
 	__chk_range_not_ok((unsigned long __force)(addr), size, limit); \
 })
 
<span class="p_add">+static inline void enable_adi(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If userspace is using ADI, it could potentially pass a pointer</span>
<span class="p_add">+	 * with version tag embedded in it. To maintain the ADI security,</span>
<span class="p_add">+	 * we must enable PSTATE.mcde. Userspace would have already set</span>
<span class="p_add">+	 * TTE.mcd in an earlier call to kernel and set the version tag</span>
<span class="p_add">+	 * for the address being dereferenced. Setting PSTATE.mcde would</span>
<span class="p_add">+	 * ensure any access to userspace data through a system call</span>
<span class="p_add">+	 * honors ADI and does not allow a rogue app to bypass ADI by</span>
<span class="p_add">+	 * using system calls. Also to ensure the right exception,</span>
<span class="p_add">+	 * precise or disrupting, is delivered to the userspace, update</span>
<span class="p_add">+	 * PMCDPER to match MCDPER</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__asm__ __volatile__(</span>
<span class="p_add">+		&quot;rdpr %%pstate, %%g1\n\t&quot;</span>
<span class="p_add">+		&quot;or %%g1, %0, %%g1\n\t&quot;</span>
<span class="p_add">+		&quot;wrpr %%g1, %%g0, %%pstate\n\t&quot;</span>
<span class="p_add">+		&quot;.word 0x83438000\n\t&quot;	/* rd %mcdper, %g1 */</span>
<span class="p_add">+		&quot;.word 0xaf900001\n\t&quot;	/* wrpr  %g0, %g1, %pmcdper */</span>
<span class="p_add">+		:</span>
<span class="p_add">+		: &quot;i&quot; (PSTATE_MCDE)</span>
<span class="p_add">+		: &quot;g1&quot;);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int __access_ok(const void __user * addr, unsigned long size)
 {
 	return 1;
<span class="p_chunk">@@ -112,7 +139,9 @@</span> <span class="p_context"> struct __large_struct { unsigned long buf[100]; };</span>
 #define __m(x) ((struct __large_struct *)(x))
 
 #define __put_user_nocheck(data, addr, size) ({			\
<span class="p_del">-	register int __pu_ret;					\</span>
<span class="p_add">+	register int __pu_ret, __adi_status;				\</span>
<span class="p_add">+	if ((__adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))	\</span>
<span class="p_add">+		enable_adi();					\</span>
 	switch (size) {						\
 	case 1: __put_user_asm(data, b, addr, __pu_ret); break;	\
 	case 2: __put_user_asm(data, h, addr, __pu_ret); break;	\
<span class="p_chunk">@@ -120,6 +149,9 @@</span> <span class="p_context"> struct __large_struct { unsigned long buf[100]; };</span>
 	case 8: __put_user_asm(data, x, addr, __pu_ret); break;	\
 	default: __pu_ret = __put_user_bad(); break;		\
 	}							\
<span class="p_add">+	if (__adi_status)					\</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */			\</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);	\</span>
 	__pu_ret;						\
 })
 
<span class="p_chunk">@@ -146,8 +178,10 @@</span> <span class="p_context"> __asm__ __volatile__(							\</span>
 int __put_user_bad(void);
 
 #define __get_user_nocheck(data, addr, size, type) ({			     \
<span class="p_del">-	register int __gu_ret;						     \</span>
<span class="p_add">+	register int __gu_ret, __adi_status;				     \</span>
 	register unsigned long __gu_val;				     \
<span class="p_add">+	if ((__adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))	     \</span>
<span class="p_add">+		enable_adi();						     \</span>
 	switch (size) {							     \
 		case 1: __get_user_asm(__gu_val, ub, addr, __gu_ret); break; \
 		case 2: __get_user_asm(__gu_val, uh, addr, __gu_ret); break; \
<span class="p_chunk">@@ -159,6 +193,9 @@</span> <span class="p_context"> int __put_user_bad(void);</span>
 			break;						     \
 	} 								     \
 	data = (__force type) __gu_val;					     \
<span class="p_add">+	if (__adi_status)						     \</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */				     \</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);		     \</span>
 	 __gu_ret;							     \
 })
 
<span class="p_chunk">@@ -185,15 +222,53 @@</span> <span class="p_context"> __asm__ __volatile__(							\</span>
 
 int __get_user_bad(void);
 
<span class="p_add">+/* When kernel access userspace memory, it must honor ADI setting</span>
<span class="p_add">+ * to ensure ADI protection continues across system calls. Kernel</span>
<span class="p_add">+ * must set PSTATE.mcde bit. It must also update PMCDPER register</span>
<span class="p_add">+ * to reflect MCDPER register so the kind of exception generated</span>
<span class="p_add">+ * in case of ADI version tag mismatch, is what the userspace is</span>
<span class="p_add">+ * expecting. PMCDPER exists only on the processors that support</span>
<span class="p_add">+ * ADI and must be accessed conditionally to avoid illegal</span>
<span class="p_add">+ * instruction trap.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define user_access_begin()						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)		\</span>
<span class="p_add">+			enable_adi();					\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define user_access_end()						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (adi_capable())					\</span>
<span class="p_add">+			/* wrpr  %g0, %pmcdper */			\</span>
<span class="p_add">+			__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);	\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define unsafe_get_user(x, ptr, err)		\</span>
<span class="p_add">+		do { if (unlikely(__get_user(x, ptr))) goto err; } while (0)</span>
<span class="p_add">+#define unsafe_put_user(x, ptr, err)		\</span>
<span class="p_add">+		do { if (unlikely(__put_user(x, ptr))) goto err; } while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 unsigned long __must_check ___copy_from_user(void *to,
 					     const void __user *from,
 					     unsigned long size);
 static inline unsigned long __must_check
 copy_from_user(void *to, const void __user *from, unsigned long size)
 {
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
 	check_object_size(to, size, false);
 
<span class="p_del">-	return ___copy_from_user(to, from, size);</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ___copy_from_user(to, from, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
 #define __copy_from_user copy_from_user
 
<span class="p_chunk">@@ -203,9 +278,18 @@</span> <span class="p_context"> unsigned long __must_check ___copy_to_user(void __user *to,</span>
 static inline unsigned long __must_check
 copy_to_user(void __user *to, const void *from, unsigned long size)
 {
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
 	check_object_size(from, size, true);
 
<span class="p_del">-	return ___copy_to_user(to, from, size);</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ___copy_to_user(to, from, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+	return ret;</span>
 }
 #define __copy_to_user copy_to_user
 
<span class="p_chunk">@@ -215,13 +299,37 @@</span> <span class="p_context"> unsigned long __must_check ___copy_in_user(void __user *to,</span>
 static inline unsigned long __must_check
 copy_in_user(void __user *to, void __user *from, unsigned long size)
 {
<span class="p_del">-	return ___copy_in_user(to, from, size);</span>
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ___copy_in_user(to, from, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
 #define __copy_in_user copy_in_user
 
 unsigned long __must_check __clear_user(void __user *, unsigned long);
 
<span class="p_del">-#define clear_user __clear_user</span>
<span class="p_add">+static inline unsigned long __must_check</span>
<span class="p_add">+___clear_user(void __user *uaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long ret, adi_status;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((adi_status = (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi)))</span>
<span class="p_add">+		enable_adi();</span>
<span class="p_add">+	ret = __clear_user(uaddr, size);</span>
<span class="p_add">+	if (adi_status)</span>
<span class="p_add">+		/* wrpr  %g0, %pmcdper */</span>
<span class="p_add">+		__asm__ __volatile__(&quot;.word 0xaf900000&quot;::);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define clear_user ___clear_user</span>
 
 __must_check long strlen_user(const char __user *str);
 __must_check long strnlen_user(const char __user *str, long n);
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/auxvec.h b/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="p_header">index ad6f360..6fe1249 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/auxvec.h</span>
<span class="p_chunk">@@ -1,4 +1,12 @@</span> <span class="p_context"></span>
 #ifndef __ASMSPARC_AUXVEC_H
 #define __ASMSPARC_AUXVEC_H
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+#define AT_ADI_BLKSZ	34</span>
<span class="p_add">+#define AT_ADI_NBITS	35</span>
<span class="p_add">+#define AT_ADI_UEONADI	36</span>
<span class="p_add">+</span>
<span class="p_add">+#define AT_VECTOR_SIZE_ARCH	3</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif /* !(__ASMSPARC_AUXVEC_H) */
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/mman.h b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_header">index 9765896..a72c033 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_chunk">@@ -5,6 +5,8 @@</span> <span class="p_context"></span>
 
 /* SunOS&#39;ified... */
 
<span class="p_add">+#define PROT_ADI	0x10		/* ADI enabled */</span>
<span class="p_add">+</span>
 #define MAP_RENAME      MAP_ANONYMOUS   /* In SunOS terminology */
 #define MAP_NORESERVE   0x40            /* don&#39;t reserve swap pages */
 #define MAP_INHERIT     0x80            /* SunOS doesn&#39;t do this, but... */
<span class="p_header">diff --git a/arch/sparc/kernel/Makefile b/arch/sparc/kernel/Makefile</span>
<span class="p_header">index fa3c02d..c9c4e76 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/Makefile</span>
<span class="p_header">+++ b/arch/sparc/kernel/Makefile</span>
<span class="p_chunk">@@ -67,6 +67,7 @@</span> <span class="p_context"> obj-$(CONFIG_SPARC64)   += visemul.o</span>
 obj-$(CONFIG_SPARC64)   += hvapi.o
 obj-$(CONFIG_SPARC64)   += sstate.o
 obj-$(CONFIG_SPARC64)   += mdesc.o
<span class="p_add">+obj-$(CONFIG_SPARC64)   += adi_64.o</span>
 obj-$(CONFIG_SPARC64)	+= pcr.o
 obj-$(CONFIG_SPARC64)	+= nmi.o
 obj-$(CONFIG_SPARC64_SMP) += cpumap.o
<span class="p_header">diff --git a/arch/sparc/kernel/adi_64.c b/arch/sparc/kernel/adi_64.c</span>
new file mode 100644
<span class="p_header">index 0000000..aba1960</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/kernel/adi_64.c</span>
<span class="p_chunk">@@ -0,0 +1,93 @@</span> <span class="p_context"></span>
<span class="p_add">+/* adi_64.c: support for ADI (Application Data Integrity) feature on</span>
<span class="p_add">+ * sparc m7 and newer processors. This feature is also known as</span>
<span class="p_add">+ * SSM (Silicon Secured Memory).</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2016 Khalid Aziz (khalid.aziz@oracle.com)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This work is licensed under the terms of the GNU GPL, version 2.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &lt;linux/init.h&gt;</span>
<span class="p_add">+#include &lt;asm/mdesc.h&gt;</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct adi_config adi_state;</span>
<span class="p_add">+</span>
<span class="p_add">+/* mdesc_adi_init() : Parse machine description provided by the</span>
<span class="p_add">+ *	hypervisor to detect ADI capabilities</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Hypervisor reports ADI capabilities of platform in &quot;hwcap-list&quot; property</span>
<span class="p_add">+ * for &quot;cpu&quot; node. If the platform supports ADI, &quot;hwcap-list&quot; property</span>
<span class="p_add">+ * contains the keyword &quot;adp&quot;. If the platform supports ADI, &quot;platform&quot;</span>
<span class="p_add">+ * node will contain &quot;adp-blksz&quot;, &quot;adp-nbits&quot; and &quot;ue-on-adp&quot; properties</span>
<span class="p_add">+ * to describe the ADI capabilities.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init mdesc_adi_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mdesc_handle *hp = mdesc_grab();</span>
<span class="p_add">+	const char *prop;</span>
<span class="p_add">+	u64 pn, *val;</span>
<span class="p_add">+	int len;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!hp)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	pn = mdesc_node_by_name(hp, MDESC_NODE_NULL, &quot;cpu&quot;);</span>
<span class="p_add">+	if (pn == MDESC_NODE_NULL)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	prop = mdesc_get_property(hp, pn, &quot;hwcap-list&quot;, &amp;len);</span>
<span class="p_add">+	if (!prop)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Look for &quot;adp&quot; keyword in hwcap-list which would indicate</span>
<span class="p_add">+	 * ADI support</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	adi_state.enabled = false;</span>
<span class="p_add">+	while (len) {</span>
<span class="p_add">+		int plen;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!strcmp(prop, &quot;adp&quot;)) {</span>
<span class="p_add">+			adi_state.enabled = true;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		plen = strlen(prop) + 1;</span>
<span class="p_add">+		prop += plen;</span>
<span class="p_add">+		len -= plen;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!adi_state.enabled)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Find the ADI properties in &quot;platform&quot; node. If all ADI</span>
<span class="p_add">+	 * properties are not found, ADI support is incomplete and</span>
<span class="p_add">+	 * do not enable ADI in the kernel.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pn = mdesc_node_by_name(hp, MDESC_NODE_NULL, &quot;platform&quot;);</span>
<span class="p_add">+	if (pn == MDESC_NODE_NULL)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = (u64 *) mdesc_get_property(hp, pn, &quot;adp-blksz&quot;, &amp;len);</span>
<span class="p_add">+	if (!val)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+	adi_state.caps.blksz = *val;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = (u64 *) mdesc_get_property(hp, pn, &quot;adp-nbits&quot;, &amp;len);</span>
<span class="p_add">+	if (!val)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+	adi_state.caps.nbits = *val;</span>
<span class="p_add">+</span>
<span class="p_add">+	val = (u64 *) mdesc_get_property(hp, pn, &quot;ue-on-adp&quot;, &amp;len);</span>
<span class="p_add">+	if (!val)</span>
<span class="p_add">+		goto adi_not_found;</span>
<span class="p_add">+	adi_state.caps.ue_on_adi = *val;</span>
<span class="p_add">+</span>
<span class="p_add">+	mdesc_release(hp);</span>
<span class="p_add">+	return;</span>
<span class="p_add">+</span>
<span class="p_add">+adi_not_found:</span>
<span class="p_add">+	adi_state.enabled = false;</span>
<span class="p_add">+	if (hp)</span>
<span class="p_add">+		mdesc_release(hp);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/sparc/kernel/mdesc.c b/arch/sparc/kernel/mdesc.c</span>
<span class="p_header">index 8a6982d..0703a60 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/mdesc.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/mdesc.c</span>
<span class="p_chunk">@@ -20,6 +20,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/uaccess.h&gt;
 #include &lt;asm/oplib.h&gt;
 #include &lt;asm/smp.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 
 /* Unlike the OBP device tree, the machine description is a full-on
  * DAG.  An arbitrary number of ARCs are possible from one
<span class="p_chunk">@@ -1104,5 +1105,6 @@</span> <span class="p_context"> void __init sun4v_mdesc_init(void)</span>
 
 	cur_mdesc = hp;
 
<span class="p_add">+	mdesc_adi_init();</span>
 	report_platform_properties();
 }
<span class="p_header">diff --git a/arch/sparc/kernel/process_64.c b/arch/sparc/kernel/process_64.c</span>
<span class="p_header">index 47ff558..0baa283 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/process_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/process_64.c</span>
<span class="p_chunk">@@ -680,6 +680,31 @@</span> <span class="p_context"> int copy_thread(unsigned long clone_flags, unsigned long sp,</span>
 	return 0;
 }
 
<span class="p_add">+/* TIF_MCDPER in thread info flags for current task is updated lazily upon</span>
<span class="p_add">+ * a context switch. Update the this flag in current task&#39;s thread flags</span>
<span class="p_add">+ * before dup so the dup&#39;d task will inherit the current TIF_MCDPER flag.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="p_add">+			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+		if (tmp_mcdper)</span>
<span class="p_add">+			set_thread_flag(TIF_MCDPER);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			clear_thread_flag(TIF_MCDPER);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	*dst = *src;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 typedef struct {
 	union {
 		unsigned int	pr_regs[32];
<span class="p_header">diff --git a/arch/sparc/kernel/traps_64.c b/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">index 500c9c6..576937c 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/traps_64.c</span>
<span class="p_chunk">@@ -44,6 +44,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/memctrl.h&gt;
 #include &lt;asm/cacheflush.h&gt;
 #include &lt;asm/setup.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 
 #include &quot;entry.h&quot;
 #include &quot;kernel.h&quot;
<span class="p_chunk">@@ -351,12 +352,31 @@</span> <span class="p_context"> void sun4v_data_access_exception(struct pt_regs *regs, unsigned long addr, unsig</span>
 		regs-&gt;tpc &amp;= 0xffffffff;
 		regs-&gt;tnpc &amp;= 0xffffffff;
 	}
<span class="p_del">-	info.si_signo = SIGSEGV;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* MCD (Memory Corruption Detection) disabled trap (TT=0x19) in HV</span>
<span class="p_add">+	 * is vectored thorugh data access exception trap with fault type</span>
<span class="p_add">+	 * set to HV_FAULT_TYPE_MCD_DIS. Check for MCD disabled trap</span>
<span class="p_add">+	 */</span>
 	info.si_errno = 0;
<span class="p_del">-	info.si_code = SEGV_MAPERR;</span>
 	info.si_addr = (void __user *) addr;
 	info.si_trapno = 0;
<span class="p_del">-	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+	switch (type) {</span>
<span class="p_add">+	case HV_FAULT_TYPE_INV_ASI:</span>
<span class="p_add">+		info.si_signo = SIGILL;</span>
<span class="p_add">+		info.si_code = ILL_ILLADR;</span>
<span class="p_add">+		force_sig_info(SIGILL, &amp;info, current);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case HV_FAULT_TYPE_MCD_DIS:</span>
<span class="p_add">+		info.si_signo = SIGSEGV;</span>
<span class="p_add">+		info.si_code = SEGV_ACCADI;</span>
<span class="p_add">+		force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		info.si_signo = SIGSEGV;</span>
<span class="p_add">+		info.si_code = SEGV_MAPERR;</span>
<span class="p_add">+		force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
 }
 
 void sun4v_data_access_exception_tl1(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)
<span class="p_chunk">@@ -1801,6 +1821,7 @@</span> <span class="p_context"> struct sun4v_error_entry {</span>
 #define SUN4V_ERR_ATTRS_ASI		0x00000080
 #define SUN4V_ERR_ATTRS_PRIV_REG	0x00000100
 #define SUN4V_ERR_ATTRS_SPSTATE_MSK	0x00000600
<span class="p_add">+#define SUN4V_ERR_ATTRS_MCD		0x00000800</span>
 #define SUN4V_ERR_ATTRS_SPSTATE_SHFT	9
 #define SUN4V_ERR_ATTRS_MODE_MSK	0x03000000
 #define SUN4V_ERR_ATTRS_MODE_SHFT	24
<span class="p_chunk">@@ -1998,6 +2019,54 @@</span> <span class="p_context"> static void sun4v_log_error(struct pt_regs *regs, struct sun4v_error_entry *ent,</span>
 	}
 }
 
<span class="p_add">+/* Handle memory corruption detected error which is vectored in</span>
<span class="p_add">+ * through resumable error trap.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void do_mcd_err(struct pt_regs *regs, struct sun4v_error_entry ent)</span>
<span class="p_add">+{</span>
<span class="p_add">+	siginfo_t info;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (notify_die(DIE_TRAP, &quot;MCD error&quot;, regs,</span>
<span class="p_add">+		       0, 0x34, SIGSEGV) == NOTIFY_STOP)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (regs-&gt;tstate &amp; TSTATE_PRIV) {</span>
<span class="p_add">+		/* MCD exception could happen because the task was running</span>
<span class="p_add">+		 * a system call with MCD enabled and passed a non-versioned</span>
<span class="p_add">+		 * pointer or pointer with bad version tag to  the system</span>
<span class="p_add">+		 * call. In such cases, hypervisor places the address of</span>
<span class="p_add">+		 * offending instruction in the resumable error report. This</span>
<span class="p_add">+		 * is a deferred error, so the read/write that caused the trap</span>
<span class="p_add">+		 * was potentially retired long time back and we may have</span>
<span class="p_add">+		 * no choice but to send SIGSEGV to the process.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		const struct exception_table_entry *entry;</span>
<span class="p_add">+</span>
<span class="p_add">+		entry = search_exception_tables(regs-&gt;tpc);</span>
<span class="p_add">+		if (entry) {</span>
<span class="p_add">+			/* Looks like a bad syscall parameter */</span>
<span class="p_add">+#ifdef DEBUG_EXCEPTIONS</span>
<span class="p_add">+			pr_emerg(&quot;Exception: PC&lt;%016lx&gt; faddr&lt;UNKNOWN&gt;\n&quot;,</span>
<span class="p_add">+				 regs-&gt;tpc);</span>
<span class="p_add">+			pr_emerg(&quot;EX_TABLE: insn&lt;%016lx&gt; fixup&lt;%016lx&gt;\n&quot;,</span>
<span class="p_add">+				 ent.err_raddr, entry-&gt;fixup);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+			regs-&gt;tpc = entry-&gt;fixup;</span>
<span class="p_add">+			regs-&gt;tnpc = regs-&gt;tpc + 4;</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Send SIGSEGV to the userspace process with the right code</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	info.si_signo = SIGSEGV;</span>
<span class="p_add">+	info.si_errno = 0;</span>
<span class="p_add">+	info.si_code = SEGV_ADIDERR;</span>
<span class="p_add">+	info.si_addr = (void __user *)ent.err_raddr;</span>
<span class="p_add">+	info.si_trapno = 0;</span>
<span class="p_add">+	force_sig_info(SIGSEGV, &amp;info, current);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* We run with %pil set to PIL_NORMAL_MAX and PSTATE_IE enabled in %pstate.
  * Log the event and clear the first word of the entry.
  */
<span class="p_chunk">@@ -2035,6 +2104,14 @@</span> <span class="p_context"> void sun4v_resum_error(struct pt_regs *regs, unsigned long offset)</span>
 		goto out;
 	}
 
<span class="p_add">+	/* If this is a memory corruption detected error, call the</span>
<span class="p_add">+	 * handler</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (local_copy.err_attrs &amp; SUN4V_ERR_ATTRS_MCD) {</span>
<span class="p_add">+		do_mcd_err(regs, local_copy);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	sun4v_log_error(regs, &amp;local_copy, cpu,
 			KERN_ERR &quot;RESUMABLE ERROR&quot;,
 			&amp;sun4v_resum_oflow_cnt);
<span class="p_chunk">@@ -2543,6 +2620,11 @@</span> <span class="p_context"> void sun4v_mem_corrupt_detect_precise(struct pt_regs *regs, unsigned long addr,</span>
 {
 	siginfo_t info;
 
<span class="p_add">+	if (!adi_capable()) {</span>
<span class="p_add">+		bad_trap(regs, 0x1a);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (notify_die(DIE_TRAP, &quot;memory corruption precise exception&quot;, regs,
 		       0, 0x8, SIGSEGV) == NOTIFY_STOP)
 		return;
<span class="p_header">diff --git a/arch/sparc/mm/gup.c b/arch/sparc/mm/gup.c</span>
<span class="p_header">index cd0e32b..579f7ae 100644</span>
<span class="p_header">--- a/arch/sparc/mm/gup.c</span>
<span class="p_header">+++ b/arch/sparc/mm/gup.c</span>
<span class="p_chunk">@@ -11,6 +11,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/pagemap.h&gt;
 #include &lt;linux/rwsem.h&gt;
 #include &lt;asm/pgtable.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 
 /*
  * The performance critical leaf functions are made noinline otherwise gcc
<span class="p_chunk">@@ -157,6 +158,24 @@</span> <span class="p_context"> int __get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
 	pgd_t *pgdp;
 	int nr = 0;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		long addr = start;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If userspace has passed a versioned address, kernel</span>
<span class="p_add">+		 * will not find it in the VMAs since it does not store</span>
<span class="p_add">+		 * the version tags in the list of VMAs. Storing version</span>
<span class="p_add">+		 * tags in list of VMAs is impractical since they can be</span>
<span class="p_add">+		 * changed any time from userspace without dropping into</span>
<span class="p_add">+		 * kernel. Any address search in VMAs will be done with</span>
<span class="p_add">+		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="p_add">+		 * are dropped here by sign extending the last bit before</span>
<span class="p_add">+		 * ADI bits. IOMMU does not implement version tags.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="p_add">+		start = addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
 	start &amp;= PAGE_MASK;
 	addr = start;
 	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;
<span class="p_chunk">@@ -187,6 +206,24 @@</span> <span class="p_context"> int get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
 	pgd_t *pgdp;
 	int nr = 0;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		long addr = start;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If userspace has passed a versioned address, kernel</span>
<span class="p_add">+		 * will not find it in the VMAs since it does not store</span>
<span class="p_add">+		 * the version tags in the list of VMAs. Storing version</span>
<span class="p_add">+		 * tags in list of VMAs is impractical since they can be</span>
<span class="p_add">+		 * changed any time from userspace without dropping into</span>
<span class="p_add">+		 * kernel. Any address search in VMAs will be done with</span>
<span class="p_add">+		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="p_add">+		 * are dropped here by sign extending the last bit before</span>
<span class="p_add">+		 * ADI bits. IOMMU does not implements version tags,</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="p_add">+		start = addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
 	start &amp;= PAGE_MASK;
 	addr = start;
 	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index a92c8d7..5c894a5 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -225,6 +225,8 @@</span> <span class="p_context"> extern unsigned int kobjsize(const void *objp);</span>
 # define VM_GROWSUP	VM_ARCH_1
 #elif defined(CONFIG_IA64)
 # define VM_GROWSUP	VM_ARCH_1
<span class="p_add">+#elif defined(CONFIG_SPARC64)</span>
<span class="p_add">+# define VM_SPARC_ADI	VM_ARCH_1	/* Uses ADI tag for access control */</span>
 #elif !defined(CONFIG_MMU)
 # define VM_MAPPED_COPY	VM_ARCH_1	/* T if mapped copy of data (nommu mmap) */
 #endif

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



