
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v4] arm64: Add support for PTE contiguous bit. - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v4] arm64: Add support for PTE contiguous bit.</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=142331">David Woods</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 11, 2015, 9:02 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1449867744-8130-1-git-send-email-dwoods@ezchip.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7832791/mbox/"
   >mbox</a>
|
   <a href="/patch/7832791/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7832791/">/patch/7832791/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id DA2F4BEEE1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Dec 2015 21:02:43 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 81E672047D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Dec 2015 21:02:42 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 3B97220527
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Dec 2015 21:02:40 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754226AbbLKVCh (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 11 Dec 2015 16:02:37 -0500
Received: from mail-am1on0074.outbound.protection.outlook.com
	([157.56.112.74]:56288
	&quot;EHLO emea01-am1-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1753845AbbLKVCf (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 11 Dec 2015 16:02:35 -0500
Received: from AMSPR02CA0044.eurprd02.prod.outlook.com (10.242.225.172) by
	DB3PR02MB123.eurprd02.prod.outlook.com (10.141.3.21) with Microsoft
	SMTP Server (TLS) id 15.1.337.19; Fri, 11 Dec 2015 21:02:31 +0000
Received: from DB3FFO11FD051.protection.gbl (2a01:111:f400:7e04::102) by
	AMSPR02CA0044.outlook.office365.com (2a01:111:e400:8028::44) with
	Microsoft SMTP Server (TLS) id 15.1.355.16 via Frontend Transport;
	Fri, 11 Dec 2015 21:02:31 +0000
Authentication-Results: spf=fail (sender IP is 12.216.194.146)
	smtp.mailfrom=ezchip.com; ezchip.com; dkim=none (message not signed)
	header.d=none; ezchip.com;
	dmarc=none action=none header.from=ezchip.com; 
Received-SPF: Fail (protection.outlook.com: domain of ezchip.com does not
	designate 12.216.194.146 as permitted sender)
	receiver=protection.outlook.com; client-ip=12.216.194.146;
	helo=ld-2.internal.tilera.com;
Received: from ld-2.internal.tilera.com (12.216.194.146) by
	DB3FFO11FD051.mail.protection.outlook.com (10.47.217.82) with
	Microsoft SMTP Server (TLS) id 15.1.346.13 via Frontend Transport;
	Fri, 11 Dec 2015 21:02:30 +0000
Received: (from dwoods@localhost)
	by ld-2.internal.tilera.com (8.14.4/8.14.4/Submit) id tBBL2TBk008181; 
	Fri, 11 Dec 2015 16:02:29 -0500
From: David Woods &lt;dwoods@ezchip.com&gt;
To: &lt;dwoods@ezchip.com&gt;
CC: &lt;catalin.marinas@arm.com&gt;, &lt;will.deacon@arm.com&gt;,
	&lt;steve.capper@linaro.org&gt;, &lt;jeremy.linton@arm.com&gt;,
	&lt;linux-arm-kernel@lists.infradead.org&gt;,
	&lt;linux-kernel@vger.kernel.org&gt;, &lt;linux-mm@kvack.org&gt;,
	&lt;cmetcalf@ezchip.com&gt;
Subject: [PATCH v4] arm64: Add support for PTE contiguous bit.
Date: Fri, 11 Dec 2015 16:02:24 -0500
Message-ID: &lt;1449867744-8130-1-git-send-email-dwoods@ezchip.com&gt;
X-Mailer: git-send-email 2.1.2
X-EOPAttributedMessage: 0
X-Microsoft-Exchange-Diagnostics: 1; DB3FFO11FD051;
	1:3VZilyB2L/kFI9Xo3JF6vV3iEcD3zjd9hv3oFG93qvDwWldlRGJNcGqgFXGUjSut/bPZJfQf4UXt8+TQX1U8YA2mS5iqXStSDihXSIo/ZMDA3Nn8N8UDm2mUvUUu7s0rS171Tk8uJZ3n0XOBvC3CeZzPV4H6ErZwG/sYOMGsAi5G7N+Zg/20VEO2S+33B9ri482qcdISSbh6tvU8DQG5uZ+7tzdu1Hl/CxAAYPIv1K653ZnUQCEI/BiodGwivt8apBP5WkAD5pQeqicg4MnD8JYq5aaf8dbhv1vPYiZhIbSGj1JcYUtVzGAA9uqRY5uBYHYoDJL+52JVEscp6/T8tJA6NEcO3RG/4w0X84JRx5FPvCSYBo5P4rM3FjM9UQAyDxFKNglBGBo3IHgwikqjNA==
X-Forefront-Antispam-Report: CIP:12.216.194.146; CTRY:US; IPV:NLI; EFV:NLI;
	SFV:NSPM;
	SFS:(10009020)(6009001)(2980300002)(1109001)(1110001)(339900001)(189002)(199003)(105606002)(19580405001)(1096002)(87936001)(50226001)(2351001)(47776003)(19580395003)(48376002)(85426001)(106466001)(229853001)(50986999)(575784001)(107886002)(11100500001)(586003)(1220700001)(5001970100001)(104016004)(86362001)(110136002)(7049001)(50466002)(5008740100001)(6806005)(5003940100001)(4001450100002)(6200100001)(33646002)(92566002)(189998001)(4001430100002)(36756003)(42186005)(1880700001);
	DIR:OUT; SFP:1101; SCL:1; SRVR:DB3PR02MB123;
	H:ld-2.internal.tilera.com; FPR:; SPF:Fail;
	PTR:wb-fw1.tilera.com; MX:1; A:1; LANG:en; 
MIME-Version: 1.0
Content-Type: text/plain
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB123;
	2:NP8Ee34tkzYt66jIpitHmjnr8e3nkY0qf7gVvRclrosFXVwzMBOSp9nBl8+nw8nk34BXNgICeV8t5FCovYz+VJ6fJe45kRByIyLQR8V5jUL+SrPFd3WGisYhWjUqVntgl6op67XVqpYsBSUSaW/BgQ==;
	3:81P633roddcHj9OXkuw5zmzqTGjlxWHF6zQaOcnyX50e+0C55L4U2ddqcWkO+zLBkoQDm66DmhV2UqOmTB61fzKT3L6m294QcK6Nsg/kagIwpcK8FHqZqzXAnDgweboctGt4pYKdlwddIP2NM4+Ygk9ddpmiRMGDP/UD7XzFDR/BguLPywdqqMes0/KkJC/jwh8P+yJoofVDHlJpkSnf1ep20aMc0BmrJZHWyTiRyJw=;
	25:CSLRmfdkND3BSYket9iFAgQlFm1+td05f7Vs3QQjUkzkmbjx0ZuPDywjc9tma+xrhxT9GOf6LbzXZnVwOjhTRy1uvgj46GcAbvYX5orfSAo30QxhKIXm5369BlnbcLPEKvfGvDnTxtN8fOsC9iXKKXYa9jzb77GLYqKKkLzVSTaj1lMT2XyBtzirSw+GRmJ0/lEGI1IxPT3LJJP8U80m8MKqK1yzHzUdTKhHBuevfREyL+Ww1JeoEgbe0gVAJacM;
	20:Xvo1+S4NcYWyphbLQP1+pYRFisrNBbtbtYELlemLr/8ORS3u794RuL1c1YE3f72RWCPtyOVKVmkrzisMnmCyr9N7C7JuetpytDJOfr7n2vPVhBmDKQ6SFq9jxuSvDUFVo7+kcQtk2JViAUe5vGQ0Bq+NdSd0TpwLPTu3kzqg0J0=
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:DB3PR02MB123;
X-Microsoft-Antispam-PRVS: &lt;DB3PR02MB123E6A795653EEAA5E996FBBCEA0@DB3PR02MB123.eurprd02.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:(121898900299872);
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(601004)(2401047)(5005006)(520078)(8121501046)(3002001)(10201501046);
	SRVR:DB3PR02MB123; BCL:0; PCL:0; RULEID:; SRVR:DB3PR02MB123; 
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB123;
	4:hbUXA0dgtgEw3Tum3c8v0qIpG11zvOwzw3J8XRgWRDlbQBAeHruEG3Db/z2nvHRcc72qXoxypGsESXhdZgyBeDvWcaVblDovhlXJP0IP/im/EH76/UFpbGP3+z7ekLK7VXbR+EQ5IzJw75mBRY7Xg+95/QZLHT4zcd/zPDatHC5yl/eFCt+EMGoXLoGH9P7/HBjRmbHmkrEmJTj5OBsuDP2Ucw7flIRmYIqKoR53MxrW20VAF4Xy5WG784IFdfk5K/m6bwodMk2D1CpGUMItgEh4rsXuKHVjebTm11vLt+xG9Cz+241H9cIloou+q6lcAo/jI+dY0M8NWwCM92UTOWJXl97ez5Pf9q8kk1x71HTOmW5cMsMz/vDtG17FVjQaUCMh3Ed/J3JUHXzNMz0r9nqBrkYHpL5S9HKWfKVDgQY=
X-Forefront-PRVS: 0787459938
X-Microsoft-Exchange-Diagnostics: =?us-ascii?Q?1; DB3PR02MB123;
	23:JwOuNm2uBy9UuP/KqL1iB0mfPsIpSOORSl8fHXVumm?=
	=?us-ascii?Q?4t/brMuJk2oWwPonckyftB8/xT2wGkYokkeVFm+UCClAPdLkC4DODitnVlFz?=
	=?us-ascii?Q?PzZgku4o14IoEZkioG1htD4S7uO3mZV1or1ssldhf2tLfwxckfG9iM73n1KO?=
	=?us-ascii?Q?8lcylN36IQIgkisHHdPNErUBiHt6bWXzbF+IrhuQPlgKtVEghUg6bghgH7JJ?=
	=?us-ascii?Q?yZ405y0qDKS3/GYj1sLy/yrahavwUrT4ChfRz8+yCGYT1x9AEVsX5r1gyoLq?=
	=?us-ascii?Q?gAzzKVjGIQ2sTppMcbIoGaBdoBQZb+xPx86C4QM/23x467looGPY6pkVtSi7?=
	=?us-ascii?Q?tGNDa9Ump03sJs0GZSnoXhUjO3SO30rypZ88wwwfy6cqkHUk+BRfmmOW0NqJ?=
	=?us-ascii?Q?6Pp/N+NEtN9+Uipt38EZl6Q88YZxLu1pQ1xDX49YmLhMlrAxkLew8cyVkPTb?=
	=?us-ascii?Q?9YWTdROfyMdEEARmlN/AS3pP3Qd9sp8Ia02F+4bd0KHp0P9K0Ne4XJE3Zu4x?=
	=?us-ascii?Q?szczeY4VAOa8jujowJTFq3ASrNha7Vd/Zkmm4WOp0eVE+OYYhWxw5mZuTaBa?=
	=?us-ascii?Q?HZJwaILevuHtpqgJDpwlGWd8dR7Yp0l7bW3p7H4eE5aftVzhXbU9gzxoqLYy?=
	=?us-ascii?Q?3TX0aT46ApbrhcOMr3vXU7wdhD+Qn2u0zYcHBDnyQkEzwNmTxrE8vgT8WMjA?=
	=?us-ascii?Q?6BWNGtfpU4W7/3ZimzAd6kQ5ZKpSIg6I8nP6b1ZXclAu4k/jTqdvXMpSjnC7?=
	=?us-ascii?Q?uSF9IuXjRekAsSsTKqZOIn9grlP0HuuS6Q3eOp8w5Y3y1RI58EoPGrbLygPc?=
	=?us-ascii?Q?hVGQ2koxIwHOViNjBW/98tx6JkItERmOVsn+dexLCWT39tdzUvq8JItRTfVZ?=
	=?us-ascii?Q?0NtXuyA7ASPNLRe/q+IPUCSa06M7YqDTfBM8V1Uu6gvJj8Knwvz3y0jqOP53?=
	=?us-ascii?Q?yr9jOIqNwAizExTbeagd0pNPM3nBfa1ej8xkC3znYLiuLZalhfM0ftYjrQBE?=
	=?us-ascii?Q?wPj/GNhHooRRXaAetCiapBA8znx2ibhzGU30wXIYDspg2+e5cSHD9xDA2/2V?=
	=?us-ascii?Q?9NoFD5iNHBYmcPSA1a/T2Z3ZnHcGniM0l7uQRDqUv8bFh9s/JV90BIRlfzRe?=
	=?us-ascii?Q?UbSpSOQ6yJNZSg8i9ukzW++jXaJi8f5XSmag+BS0HmGW1LawMbBA=3D=3D?=
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB123;
	5:KKjsijcIr9J8T00fFABL2T/k7775aZlTjzSgHH+58I9LewdlahGo0y86VYJc2pVzc9/uA8DKvP2cA5uZHNswmL2FXRrK/H2qVh1frLkr9BkOakB6MynB3AF/seLRzGzW/V+qvddW43ZDrPfPpc7BgA==;
	24:GUWNcNNrEedoM4CjH3Lcv5CpG0NWP5dLN4Y64IT/Rk1sserQlKs25IxD683bz2g7+n4JZ8vBNkJViMHg/0CAo7Pq3Em3fy2eqh+34gNi/Iw=
SpamDiagnosticOutput: 1:23
SpamDiagnosticMetadata: NSPM
X-OriginatorOrg: ezchip.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 11 Dec 2015 21:02:30.5780
	(UTC)
X-MS-Exchange-CrossTenant-Id: 0fc16e0a-3cd3-4092-8b2f-0a42cff122c3
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=0fc16e0a-3cd3-4092-8b2f-0a42cff122c3;
	Ip=[12.216.194.146]; Helo=[ld-2.internal.tilera.com]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DB3PR02MB123
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Dec. 11, 2015, 9:02 p.m.</div>
<pre class="content">
The arm64 MMU supports a Contiguous bit which is a hint that the TTE
is one of a set of contiguous entries which can be cached in a single
TLB entry.  Supporting this bit adds new intermediate huge page sizes.

The set of huge page sizes available depends on the base page size.
Without using contiguous pages the huge page sizes are as follows.

 4KB:   2MB  1GB
64KB: 512MB

With a 4KB granule, the contiguous bit groups together sets of 16 pages
and with a 64KB granule it groups sets of 32 pages.  This enables two new
huge page sizes in each case, so that the full set of available sizes
is as follows.

 4KB:  64KB   2MB  32MB  1GB
64KB:   2MB 512MB  16GB

If a 16KB granule is used then the contiguous bit groups 128 pages
at the PTE level and 32 pages at the PMD level.

If the base page size is set to 64KB then 2MB pages are enabled by
default.  It is possible in the future to make 2MB the default huge
page size for both 4KB and 64KB granules.
<span class="signed-off-by">
Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="reviewed-by">Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
---

This version of the patch addresses all the comments I&#39;ve received 
to date and is passing the libhugetlbfs tests.  Catalin, assuming 
there are no further comments, can this be considered for the arm64 
next tree?

 arch/arm64/Kconfig                     |   3 -
 arch/arm64/include/asm/hugetlb.h       |  44 ++----
 arch/arm64/include/asm/pgtable-hwdef.h |  18 ++-
 arch/arm64/include/asm/pgtable.h       |  10 +-
 arch/arm64/mm/hugetlbpage.c            | 267 ++++++++++++++++++++++++++++++++-
 include/linux/hugetlb.h                |   2 -
 6 files changed, 306 insertions(+), 38 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64911">Steve Capper</a> - Dec. 16, 2015, 12:50 p.m.</div>
<pre class="content">
On 11 December 2015 at 21:02, David Woods &lt;dwoods@ezchip.com&gt; wrote:
<span class="quote">&gt; The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt; is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt; TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt; Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  4KB:   2MB  1GB</span>
<span class="quote">&gt; 64KB: 512MB</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; With a 4KB granule, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt; and with a 64KB granule it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt; huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt; is as follows.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt; 64KB:   2MB 512MB  16GB</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If a 16KB granule is used then the contiguous bit groups 128 pages</span>
<span class="quote">&gt; at the PTE level and 32 pages at the PMD level.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt; default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt; page size for both 4KB and 64KB granules.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="quote">&gt; Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This version of the patch addresses all the comments I&#39;ve received</span>
<span class="quote">&gt; to date and is passing the libhugetlbfs tests.  Catalin, assuming</span>
<span class="quote">&gt; there are no further comments, can this be considered for the arm64</span>
<span class="quote">&gt; next tree?</span>

Hi David,
Thanks for this revised series.

I have a few comments below. Most arose when I enabled STRICT_MM_TYPECHECKS.

I have tested this on my arm64 system with PAGE_SIZE==64KB, and it ran well.

Cheers,
--
Steve
<span class="quote">
&gt;</span>
<span class="quote">&gt;  arch/arm64/Kconfig                     |   3 -</span>
<span class="quote">&gt;  arch/arm64/include/asm/hugetlb.h       |  44 ++----</span>
<span class="quote">&gt;  arch/arm64/include/asm/pgtable-hwdef.h |  18 ++-</span>
<span class="quote">&gt;  arch/arm64/include/asm/pgtable.h       |  10 +-</span>
<span class="quote">&gt;  arch/arm64/mm/hugetlbpage.c            | 267 ++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;  include/linux/hugetlb.h                |   2 -</span>
<span class="quote">&gt;  6 files changed, 306 insertions(+), 38 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt; index 4876459..ffa3c54 100644</span>
<span class="quote">&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt; @@ -530,9 +530,6 @@ config HW_PERF_EVENTS</span>
<span class="quote">&gt;  config SYS_SUPPORTS_HUGETLBFS</span>
<span class="quote">&gt;         def_bool y</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="quote">&gt; -       def_bool y</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  config ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;         def_bool y if ARM64_4K_PAGES || (ARM64_16K_PAGES &amp;&amp; !ARM64_VA_BITS_36)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt; index bb4052e..bbc1e35 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt; @@ -26,36 +26,7 @@ static inline pte_t huge_ptep_get(pte_t *ptep)</span>
<span class="quote">&gt;         return *ptep;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt; -                                  pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       set_pte_at(mm, addr, ptep, pte);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="quote">&gt; -                                        unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       ptep_clear_flush(vma, addr, ptep);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="quote">&gt; -                                          unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       ptep_set_wrprotect(mm, addr, ptep);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt; -                                           unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="quote">&gt; -                                            unsigned long addr, pte_t *ptep,</span>
<span class="quote">&gt; -                                            pte_t pte, int dirty)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,</span>
<span class="quote">&gt;                                           unsigned long addr, unsigned long end,</span>
<span class="quote">&gt; @@ -97,4 +68,19 @@ static inline void arch_clear_hugepage_flags(struct page *page)</span>
<span class="quote">&gt;         clear_bit(PG_dcache_clean, &amp;page-&gt;flags);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                               struct page *page, int writable);</span>
<span class="quote">&gt; +#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="quote">&gt; +extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt; +                           pte_t *ptep, pte_t pte);</span>
<span class="quote">&gt; +extern int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                                     unsigned long addr, pte_t *ptep,</span>
<span class="quote">&gt; +                                     pte_t pte, int dirty);</span>
<span class="quote">&gt; +extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt; +                                    unsigned long addr, pte_t *ptep);</span>
<span class="quote">&gt; +extern void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="quote">&gt; +                                   unsigned long addr, pte_t *ptep);</span>
<span class="quote">&gt; +extern void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                                 unsigned long addr, pte_t *ptep);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #endif /* __ASM_HUGETLB_H */</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt; index d6739e8..5c25b83 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt; @@ -90,7 +90,23 @@</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Contiguous page definitions.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -#define CONT_PTES              (_AC(1, UL) &lt;&lt; CONT_SHIFT)</span>
<span class="quote">&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt; +#define CONT_PTE_SHIFT         5</span>
<span class="quote">&gt; +#define CONT_PMD_SHIFT         5</span>
<span class="quote">&gt; +#elif defined(CONFIG_ARM64_16K_PAGES)</span>
<span class="quote">&gt; +#define CONT_PTE_SHIFT         7</span>
<span class="quote">&gt; +#define CONT_PMD_SHIFT         5</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define CONT_PTE_SHIFT         4</span>
<span class="quote">&gt; +#define CONT_PMD_SHIFT         4</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define CONT_PTES              (1 &lt;&lt; CONT_PTE_SHIFT)</span>
<span class="quote">&gt; +#define CONT_PTE_SIZE          (CONT_PTES * PAGE_SIZE)</span>
<span class="quote">&gt; +#define CONT_PTE_MASK          (~(CONT_PTE_SIZE - 1))</span>
<span class="quote">&gt; +#define CONT_PMDS              (1 &lt;&lt; CONT_PMD_SHIFT)</span>
<span class="quote">&gt; +#define CONT_PMD_SIZE          (CONT_PMDS * PMD_SIZE)</span>
<span class="quote">&gt; +#define CONT_PMD_MASK          (~(CONT_PMD_SIZE - 1))</span>
<span class="quote">&gt;  /* the the numerical offset of the PTE within a range of CONT_PTES */</span>
<span class="quote">&gt;  #define CONT_RANGE_OFFSET(addr) (((addr)&gt;&gt;PAGE_SHIFT)&amp;(CONT_PTES-1))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; index 450b355..35a318c 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; @@ -227,7 +227,8 @@ static inline pte_t pte_mkspecial(pte_t pte)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static inline pte_t pte_mkcont(pte_t pte)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -       return set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt; +       pte = set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt; +       return set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static inline pte_t pte_mknoncont(pte_t pte)</span>
<span class="quote">&gt; @@ -235,6 +236,11 @@ static inline pte_t pte_mknoncont(pte_t pte)</span>
<span class="quote">&gt;         return clear_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +static inline pmd_t pmd_mkcont(pmd_t pmd)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       return __pmd(pmd_val(pmd) | PMD_SECT_CONT);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         *ptep = pte;</span>
<span class="quote">&gt; @@ -304,7 +310,7 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Hugetlb definitions.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -#define HUGE_MAX_HSTATE                2</span>
<span class="quote">&gt; +#define HUGE_MAX_HSTATE                4</span>
<span class="quote">&gt;  #define HPAGE_SHIFT            PMD_SHIFT</span>
<span class="quote">&gt;  #define HPAGE_SIZE             (_AC(1, UL) &lt;&lt; HPAGE_SHIFT)</span>
<span class="quote">&gt;  #define HPAGE_MASK             (~(HPAGE_SIZE - 1))</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; index 383b03f..39a5e67 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -41,17 +41,282 @@ int pud_huge(pud_t pud)</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +static int find_num_contig(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt; +                          pte_t *ptep, pte_t pte, size_t *pgsize)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pgd_t *pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +       pud_t *pud;</span>
<span class="quote">&gt; +       pmd_t *pmd;</span>
<span class="quote">&gt; +</span>

nit: We should probably set *pgsize = PAGE_SIZE here that way it&#39;s
defined on early return.
(Not a problem now, but may help if this code needs to be tweaked in future).
<span class="quote">
&gt; +       if (!pte_cont(pte))</span>
<span class="quote">&gt; +               return 1;</span>
<span class="quote">&gt; +       if (!pgd_present(*pgd)) {</span>
<span class="quote">&gt; +               VM_BUG_ON(!pgd_present(*pgd));</span>
<span class="quote">&gt; +               return 1;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +       if (!pud_present(*pud)) {</span>
<span class="quote">&gt; +               VM_BUG_ON(!pud_present(*pud));</span>
<span class="quote">&gt; +               return 1;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +       if (!pmd_present(*pmd)) {</span>
<span class="quote">&gt; +               VM_BUG_ON(!pmd_present(*pmd));</span>
<span class="quote">&gt; +               return 1;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       if ((pte_t *)pmd == ptep) {</span>
<span class="quote">&gt; +               *pgsize = PMD_SIZE;</span>
<span class="quote">&gt; +               return CONT_PMDS;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       *pgsize = PAGE_SIZE;</span>
<span class="quote">&gt; +       return CONT_PTES;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt; +                           pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       size_t pgsize;</span>
<span class="quote">&gt; +       int i;</span>
<span class="quote">&gt; +       int ncontig = find_num_contig(mm, addr, ptep, pte, &amp;pgsize);</span>
<span class="quote">&gt; +       unsigned long pfn;</span>
<span class="quote">&gt; +       pgprot_t hugeprot;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (ncontig == 1) {</span>
<span class="quote">&gt; +               set_pte_at(mm, addr, ptep, pte);</span>
<span class="quote">&gt; +               return;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pfn = pte_pfn(pte);</span>
<span class="quote">&gt; +       hugeprot = __pgprot(pte_val(pfn_pte(pfn, 0)) ^ pte_val(pte));</span>

For pfn_pte, we need the following to satisfy the strict mm checks:
pfn_pte(pfn, __pgprot(0))
<span class="quote">

&gt; +       for (i = 0; i &lt; ncontig; i++) {</span>
<span class="quote">&gt; +               pr_debug(&quot;%s: set pte %p to 0x%llx\n&quot;, __func__, ptep,</span>
<span class="quote">&gt; +                        pfn_pte(pfn, hugeprot));</span>

We need to wrap the last argument with pte_val(.);
<span class="quote">
&gt; +               set_pte_at(mm, addr, ptep, pfn_pte(pfn, hugeprot));</span>
<span class="quote">&gt; +               ptep++;</span>
<span class="quote">&gt; +               pfn += pgsize &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +               addr += pgsize;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="quote">&gt; +                     unsigned long addr, unsigned long sz)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt; +       pud_t *pud;</span>
<span class="quote">&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pr_debug(&quot;%s: addr:0x%lx sz:0x%lx\n&quot;, __func__, addr, sz);</span>
<span class="quote">&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +       pud = pud_alloc(mm, pgd, addr);</span>
<span class="quote">&gt; +       if (!pud)</span>
<span class="quote">&gt; +               return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (sz == PUD_SIZE) {</span>
<span class="quote">&gt; +               pte = (pte_t *)pud;</span>
<span class="quote">&gt; +       } else if (sz == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="quote">&gt; +               pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +               WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt; +               pte = pte_alloc_map(mm, NULL, pmd, addr);</span>

We get away with this on arm64 because we don&#39;t have high memory.

If one were to port this to 32-bit ARM, then this would break as it
would leave a mapping open.
(i.e. there&#39;s no corresponding pte_unmap(.) to line up with the
pte_offset_map from pte_alloc_map).

Maybe worth a quick comment for potential porters that they need to
either disable CONFIG_HIGHPTE or rework the page table page allocation
for contiguous ptes (tricky as one may already have non-contiguous
ptes present).
<span class="quote">
&gt; +       } else if (sz == PMD_SIZE) {</span>
<span class="quote">&gt; +               if (IS_ENABLED(CONFIG_ARCH_WANT_HUGE_PMD_SHARE) &amp;&amp;</span>
<span class="quote">&gt; +                   pud_none(*pud))</span>
<span class="quote">&gt; +                       pte = huge_pmd_share(mm, addr, pud);</span>
<span class="quote">&gt; +               else</span>
<span class="quote">&gt; +                       pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; +       } else if (sz == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="quote">&gt; +               pmd_t *pmd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +               pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; +               WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt; +               return (pte_t *)pmd;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pr_debug(&quot;%s: addr:0x%lx sz:0x%lx ret pte=%p/0x%llx\n&quot;, __func__, addr,</span>
<span class="quote">&gt; +              sz, pte, pte_val(*pte));</span>
<span class="quote">&gt; +       return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt; +       pud_t *pud;</span>
<span class="quote">&gt; +       pmd_t *pmd = NULL;</span>
<span class="quote">&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +       pr_debug(&quot;%s: addr:0x%lx pgd:%p\n&quot;, __func__, addr, pgd);</span>
<span class="quote">&gt; +       if (!pgd_present(*pgd))</span>
<span class="quote">&gt; +               return NULL;</span>
<span class="quote">&gt; +       pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +       if (!pud_present(*pud))</span>
<span class="quote">&gt; +               return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (pud_huge(*pud))</span>
<span class="quote">&gt; +               return (pte_t *)pud;</span>
<span class="quote">&gt; +       pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +       if (!pmd_present(*pmd))</span>
<span class="quote">&gt; +               return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (pte_cont(pmd_pte(*pmd))) {</span>
<span class="quote">&gt; +               pmd = pmd_offset(</span>
<span class="quote">&gt; +                       pud, (addr &amp; CONT_PMD_MASK));</span>
<span class="quote">&gt; +               return (pte_t *)pmd;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       if (pmd_huge(*pmd))</span>
<span class="quote">&gt; +               return (pte_t *)pmd;</span>
<span class="quote">&gt; +       pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; +       if (pte_present(*pte) &amp;&amp; pte_cont(*pte)) {</span>
<span class="quote">&gt; +               pte = pte_offset_kernel(</span>
<span class="quote">&gt; +                       pmd, (addr &amp; CONT_PTE_MASK));</span>

Probably best return pte here.
<span class="quote">

&gt; +       }</span>
<span class="quote">&gt; +       return pte;</span>

and NULL here to signify an error (as we get to the point where we
know that addr isn&#39;t referring to a huge page).
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                        struct page *page, int writable)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (pagesize == CONT_PTE_SIZE) {</span>
<span class="quote">&gt; +               entry = pte_mkcont(entry);</span>
<span class="quote">&gt; +       } else if (pagesize == CONT_PMD_SIZE) {</span>
<span class="quote">&gt; +               entry = pmd_pte(pmd_mkcont(pte_pmd(entry)));</span>
<span class="quote">&gt; +       } else if (pagesize != PUD_SIZE &amp;&amp; pagesize != PMD_SIZE) {</span>
<span class="quote">&gt; +               pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="quote">&gt; +                       __func__, pagesize);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       return entry;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt; +                             unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pte_t pte;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (pte_cont(*ptep)) {</span>
<span class="quote">&gt; +               int ncontig, i;</span>
<span class="quote">&gt; +               size_t pgsize;</span>
<span class="quote">&gt; +               pte_t *cpte;</span>
<span class="quote">&gt; +               bool is_dirty = false;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +               cpte = huge_pte_offset(mm, addr);</span>
<span class="quote">&gt; +               ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="quote">&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>

The call to pte_val is spurious.
<span class="quote">
&gt; +               /* save the 1st pte to return */</span>
<span class="quote">&gt; +               pte = ptep_get_and_clear(mm, addr, cpte);</span>
<span class="quote">&gt; +               for (i = 1; i &lt; ncontig; ++i) {</span>
<span class="quote">&gt; +                       /*</span>
<span class="quote">&gt; +                        * If HW_AFDBM is enabled, then the HW could</span>
<span class="quote">&gt; +                        * turn on the dirty bit for any of the page</span>
<span class="quote">&gt; +                        * in the set, so check them all.</span>
<span class="quote">&gt; +                        */</span>
<span class="quote">&gt; +                       ++cpte;</span>
<span class="quote">&gt; +                       if (pte_dirty(ptep_get_and_clear(mm, addr, cpte)))</span>
<span class="quote">&gt; +                               is_dirty = true;</span>

Okay, ptep_get_and_clear uses the exclusive monitor to guard against
updates from AFDBM. The above looks good to me.
<span class="quote">
&gt; +               }</span>
<span class="quote">&gt; +               if (is_dirty)</span>
<span class="quote">&gt; +                       return pte_mkdirty(pte);</span>
<span class="quote">&gt; +               else</span>
<span class="quote">&gt; +                       return pte;</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                              unsigned long addr, pte_t *ptep,</span>
<span class="quote">&gt; +                              pte_t pte, int dirty)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pte_t *cpte;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (pte_cont(pte)) {</span>
<span class="quote">&gt; +               int ncontig, i, changed = 0;</span>
<span class="quote">&gt; +               size_t pgsize = 0;</span>
<span class="quote">&gt; +               unsigned long pfn = pte_pfn(pte);</span>
<span class="quote">&gt; +               /* Select all bits except the pfn */</span>
<span class="quote">&gt; +               pgprot_t hugeprot =</span>
<span class="quote">&gt; +                       __pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>

pfn_pte needs the second argument wrapping with __pgprot(.)
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +               cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="quote">&gt; +               pfn = pte_pfn(*cpte);</span>
<span class="quote">&gt; +               ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="quote">&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>

The call to pte_val(.) is spurious.
<span class="quote">
&gt; +               for (i = 0; i &lt; ncontig; ++i, ++cpte) {</span>
<span class="quote">&gt; +                       changed = ptep_set_access_flags(vma, addr, cpte,</span>
<span class="quote">&gt; +                                                       pfn_pte(pfn,</span>
<span class="quote">&gt; +                                                               hugeprot),</span>
<span class="quote">&gt; +                                                       dirty);</span>

ptep_set_access_flags calls through to set_pte_at which will warn if
we are in a scenario where we can lose dirty information. So this code
looks okay for AFDBM to me.
<span class="quote">
&gt; +                       pfn += pgsize &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +               }</span>
<span class="quote">&gt; +               return changed;</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="quote">&gt; +                            unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       if (pte_cont(*ptep)) {</span>
<span class="quote">&gt; +               int ncontig, i;</span>
<span class="quote">&gt; +               pte_t *cpte;</span>
<span class="quote">&gt; +               size_t pgsize = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +               cpte = huge_pte_offset(mm, addr);</span>
<span class="quote">&gt; +               ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="quote">&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>

The call to pte_val is spurious(.).
<span class="quote">
&gt; +               for (i = 0; i &lt; ncontig; ++i, ++cpte)</span>
<span class="quote">&gt; +                       ptep_set_wrprotect(mm, addr, cpte);</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               ptep_set_wrprotect(mm, addr, ptep);</span>
<span class="quote">&gt; +       }</span>

ptep_set_wrprotect uses the exclusive monitor, thus is protected from
AFDBM. This looks good to me.
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                          unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       if (pte_cont(*ptep)) {</span>
<span class="quote">&gt; +               int ncontig, i;</span>
<span class="quote">&gt; +               pte_t *cpte;</span>
<span class="quote">&gt; +               size_t pgsize = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +               cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="quote">&gt; +               ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="quote">&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>

Call to pte_val is spurious.
<span class="quote">
&gt; +               for (i = 0; i &lt; ncontig; ++i, ++cpte)</span>
<span class="quote">&gt; +                       ptep_clear_flush(vma, addr, cpte);</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               ptep_clear_flush(vma, addr, ptep);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static __init int setup_hugepagesz(char *opt)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         unsigned long ps = memparse(opt, &amp;opt);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         if (ps == PMD_SIZE) {</span>
<span class="quote">&gt;                 hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt;         } else if (ps == PUD_SIZE) {</span>
<span class="quote">&gt;                 hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt; +       } else if (ps == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="quote">&gt; +               hugetlb_add_hstate(CONT_PTE_SHIFT);</span>
<span class="quote">&gt; +       } else if (ps == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="quote">&gt; +               hugetlb_add_hstate((PMD_SHIFT + CONT_PMD_SHIFT) - PAGE_SHIFT);</span>
<span class="quote">&gt;         } else {</span>
<span class="quote">&gt; -               pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="quote">&gt; +               pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
<span class="quote">&gt;                 return 0;</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;         return 1;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt; +static __init int add_default_hugepagesz(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       if (size_to_hstate(CONT_PTES * PAGE_SIZE) == NULL)</span>
<span class="quote">&gt; +               hugetlb_add_hstate(CONT_PMD_SHIFT);</span>
<span class="quote">&gt; +       return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +arch_initcall(add_default_hugepagesz);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="quote">&gt; index 685c262..b0eb064 100644</span>
<span class="quote">&gt; --- a/include/linux/hugetlb.h</span>
<span class="quote">&gt; +++ b/include/linux/hugetlb.h</span>
<span class="quote">&gt; @@ -96,9 +96,7 @@ u32 hugetlb_fault_mutex_hash(struct hstate *h, struct mm_struct *mm,</span>
<span class="quote">&gt;                                 struct address_space *mapping,</span>
<span class="quote">&gt;                                 pgoff_t idx, unsigned long address);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;  pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud);</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  extern int hugepages_treat_as_movable;</span>
<span class="quote">&gt;  extern int sysctl_hugetlb_shm_group;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; 2.1.2</span>
<span class="quote">&gt;</span>
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Dec. 17, 2015, 7:33 p.m.</div>
<pre class="content">
On 12/16/2015 07:50 AM, Steve Capper wrote:
<span class="quote">&gt; On 11 December 2015 at 21:02, David Woods &lt;dwoods@ezchip.com&gt; wrote:</span>
<span class="quote">&gt;&gt; The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt;&gt; is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt;&gt; TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt;&gt; Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   4KB:   2MB  1GB</span>
<span class="quote">&gt;&gt; 64KB: 512MB</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; With a 4KB granule, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt;&gt; and with a 64KB granule it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt;&gt; huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt;&gt; is as follows.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt;&gt; 64KB:   2MB 512MB  16GB</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; If a 16KB granule is used then the contiguous bit groups 128 pages</span>
<span class="quote">&gt;&gt; at the PTE level and 32 pages at the PMD level.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt;&gt; default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt;&gt; page size for both 4KB and 64KB granules.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="quote">&gt;&gt; Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This version of the patch addresses all the comments I&#39;ve received</span>
<span class="quote">&gt;&gt; to date and is passing the libhugetlbfs tests.  Catalin, assuming</span>
<span class="quote">&gt;&gt; there are no further comments, can this be considered for the arm64</span>
<span class="quote">&gt;&gt; next tree?</span>
<span class="quote">&gt; Hi David,</span>
<span class="quote">&gt; Thanks for this revised series.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I have a few comments below. Most arose when I enabled STRICT_MM_TYPECHECKS.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I have tested this on my arm64 system with PAGE_SIZE==64KB, and it ran well.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Cheers,</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; Steve</span>

Thanks Steve, I took all your suggestions and have posted v5 of this patch.

-Dave
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt;   arch/arm64/Kconfig                     |   3 -</span>
<span class="quote">&gt;&gt;   arch/arm64/include/asm/hugetlb.h       |  44 ++----</span>
<span class="quote">&gt;&gt;   arch/arm64/include/asm/pgtable-hwdef.h |  18 ++-</span>
<span class="quote">&gt;&gt;   arch/arm64/include/asm/pgtable.h       |  10 +-</span>
<span class="quote">&gt;&gt;   arch/arm64/mm/hugetlbpage.c            | 267 ++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;&gt;   include/linux/hugetlb.h                |   2 -</span>
<span class="quote">&gt;&gt;   6 files changed, 306 insertions(+), 38 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; index 4876459..ffa3c54 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; @@ -530,9 +530,6 @@ config HW_PERF_EVENTS</span>
<span class="quote">&gt;&gt;   config SYS_SUPPORTS_HUGETLBFS</span>
<span class="quote">&gt;&gt;          def_bool y</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="quote">&gt;&gt; -       def_bool y</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt;   config ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;&gt;          def_bool y if ARM64_4K_PAGES || (ARM64_16K_PAGES &amp;&amp; !ARM64_VA_BITS_36)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt;&gt; index bb4052e..bbc1e35 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt;&gt; @@ -26,36 +26,7 @@ static inline pte_t huge_ptep_get(pte_t *ptep)</span>
<span class="quote">&gt;&gt;          return *ptep;</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; -                                  pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;&gt; -{</span>
<span class="quote">&gt;&gt; -       set_pte_at(mm, addr, ptep, pte);</span>
<span class="quote">&gt;&gt; -}</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; -                                        unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; -{</span>
<span class="quote">&gt;&gt; -       ptep_clear_flush(vma, addr, ptep);</span>
<span class="quote">&gt;&gt; -}</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; -                                          unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; -{</span>
<span class="quote">&gt;&gt; -       ptep_set_wrprotect(mm, addr, ptep);</span>
<span class="quote">&gt;&gt; -}</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; -                                           unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; -{</span>
<span class="quote">&gt;&gt; -       return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="quote">&gt;&gt; -}</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; -                                            unsigned long addr, pte_t *ptep,</span>
<span class="quote">&gt;&gt; -                                            pte_t pte, int dirty)</span>
<span class="quote">&gt;&gt; -{</span>
<span class="quote">&gt;&gt; -       return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="quote">&gt;&gt; -}</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,</span>
<span class="quote">&gt;&gt;                                            unsigned long addr, unsigned long end,</span>
<span class="quote">&gt;&gt; @@ -97,4 +68,19 @@ static inline void arch_clear_hugepage_flags(struct page *page)</span>
<span class="quote">&gt;&gt;          clear_bit(PG_dcache_clean, &amp;page-&gt;flags);</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                               struct page *page, int writable);</span>
<span class="quote">&gt;&gt; +#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="quote">&gt;&gt; +extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; +                           pte_t *ptep, pte_t pte);</span>
<span class="quote">&gt;&gt; +extern int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                                     unsigned long addr, pte_t *ptep,</span>
<span class="quote">&gt;&gt; +                                     pte_t pte, int dirty);</span>
<span class="quote">&gt;&gt; +extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +                                    unsigned long addr, pte_t *ptep);</span>
<span class="quote">&gt;&gt; +extern void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +                                   unsigned long addr, pte_t *ptep);</span>
<span class="quote">&gt;&gt; +extern void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                                 unsigned long addr, pte_t *ptep);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   #endif /* __ASM_HUGETLB_H */</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; index d6739e8..5c25b83 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; @@ -90,7 +90,23 @@</span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;    * Contiguous page definitions.</span>
<span class="quote">&gt;&gt;    */</span>
<span class="quote">&gt;&gt; -#define CONT_PTES              (_AC(1, UL) &lt;&lt; CONT_SHIFT)</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt; +#define CONT_PTE_SHIFT         5</span>
<span class="quote">&gt;&gt; +#define CONT_PMD_SHIFT         5</span>
<span class="quote">&gt;&gt; +#elif defined(CONFIG_ARM64_16K_PAGES)</span>
<span class="quote">&gt;&gt; +#define CONT_PTE_SHIFT         7</span>
<span class="quote">&gt;&gt; +#define CONT_PMD_SHIFT         5</span>
<span class="quote">&gt;&gt; +#else</span>
<span class="quote">&gt;&gt; +#define CONT_PTE_SHIFT         4</span>
<span class="quote">&gt;&gt; +#define CONT_PMD_SHIFT         4</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define CONT_PTES              (1 &lt;&lt; CONT_PTE_SHIFT)</span>
<span class="quote">&gt;&gt; +#define CONT_PTE_SIZE          (CONT_PTES * PAGE_SIZE)</span>
<span class="quote">&gt;&gt; +#define CONT_PTE_MASK          (~(CONT_PTE_SIZE - 1))</span>
<span class="quote">&gt;&gt; +#define CONT_PMDS              (1 &lt;&lt; CONT_PMD_SHIFT)</span>
<span class="quote">&gt;&gt; +#define CONT_PMD_SIZE          (CONT_PMDS * PMD_SIZE)</span>
<span class="quote">&gt;&gt; +#define CONT_PMD_MASK          (~(CONT_PMD_SIZE - 1))</span>
<span class="quote">&gt;&gt;   /* the the numerical offset of the PTE within a range of CONT_PTES */</span>
<span class="quote">&gt;&gt;   #define CONT_RANGE_OFFSET(addr) (((addr)&gt;&gt;PAGE_SHIFT)&amp;(CONT_PTES-1))</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; index 450b355..35a318c 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; @@ -227,7 +227,8 @@ static inline pte_t pte_mkspecial(pte_t pte)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   static inline pte_t pte_mkcont(pte_t pte)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt; -       return set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt;&gt; +       pte = set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt;&gt; +       return set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   static inline pte_t pte_mknoncont(pte_t pte)</span>
<span class="quote">&gt;&gt; @@ -235,6 +236,11 @@ static inline pte_t pte_mknoncont(pte_t pte)</span>
<span class="quote">&gt;&gt;          return clear_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static inline pmd_t pmd_mkcont(pmd_t pmd)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       return __pmd(pmd_val(pmd) | PMD_SECT_CONT);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;          *ptep = pte;</span>
<span class="quote">&gt;&gt; @@ -304,7 +310,7 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;    * Hugetlb definitions.</span>
<span class="quote">&gt;&gt;    */</span>
<span class="quote">&gt;&gt; -#define HUGE_MAX_HSTATE                2</span>
<span class="quote">&gt;&gt; +#define HUGE_MAX_HSTATE                4</span>
<span class="quote">&gt;&gt;   #define HPAGE_SHIFT            PMD_SHIFT</span>
<span class="quote">&gt;&gt;   #define HPAGE_SIZE             (_AC(1, UL) &lt;&lt; HPAGE_SHIFT)</span>
<span class="quote">&gt;&gt;   #define HPAGE_MASK             (~(HPAGE_SIZE - 1))</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; index 383b03f..39a5e67 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; @@ -41,17 +41,282 @@ int pud_huge(pud_t pud)</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static int find_num_contig(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; +                          pte_t *ptep, pte_t pte, size_t *pgsize)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pgd_t *pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +       pud_t *pud;</span>
<span class="quote">&gt;&gt; +       pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt; nit: We should probably set *pgsize = PAGE_SIZE here that way it&#39;s</span>
<span class="quote">&gt; defined on early return.</span>
<span class="quote">&gt; (Not a problem now, but may help if this code needs to be tweaked in future).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +       if (!pte_cont(pte))</span>
<span class="quote">&gt;&gt; +               return 1;</span>
<span class="quote">&gt;&gt; +       if (!pgd_present(*pgd)) {</span>
<span class="quote">&gt;&gt; +               VM_BUG_ON(!pgd_present(*pgd));</span>
<span class="quote">&gt;&gt; +               return 1;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt;&gt; +       if (!pud_present(*pud)) {</span>
<span class="quote">&gt;&gt; +               VM_BUG_ON(!pud_present(*pud));</span>
<span class="quote">&gt;&gt; +               return 1;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt; +       if (!pmd_present(*pmd)) {</span>
<span class="quote">&gt;&gt; +               VM_BUG_ON(!pmd_present(*pmd));</span>
<span class="quote">&gt;&gt; +               return 1;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       if ((pte_t *)pmd == ptep) {</span>
<span class="quote">&gt;&gt; +               *pgsize = PMD_SIZE;</span>
<span class="quote">&gt;&gt; +               return CONT_PMDS;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       *pgsize = PAGE_SIZE;</span>
<span class="quote">&gt;&gt; +       return CONT_PTES;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; +                           pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       size_t pgsize;</span>
<span class="quote">&gt;&gt; +       int i;</span>
<span class="quote">&gt;&gt; +       int ncontig = find_num_contig(mm, addr, ptep, pte, &amp;pgsize);</span>
<span class="quote">&gt;&gt; +       unsigned long pfn;</span>
<span class="quote">&gt;&gt; +       pgprot_t hugeprot;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (ncontig == 1) {</span>
<span class="quote">&gt;&gt; +               set_pte_at(mm, addr, ptep, pte);</span>
<span class="quote">&gt;&gt; +               return;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pfn = pte_pfn(pte);</span>
<span class="quote">&gt;&gt; +       hugeprot = __pgprot(pte_val(pfn_pte(pfn, 0)) ^ pte_val(pte));</span>
<span class="quote">&gt; For pfn_pte, we need the following to satisfy the strict mm checks:</span>
<span class="quote">&gt; pfn_pte(pfn, __pgprot(0))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +       for (i = 0; i &lt; ncontig; i++) {</span>
<span class="quote">&gt;&gt; +               pr_debug(&quot;%s: set pte %p to 0x%llx\n&quot;, __func__, ptep,</span>
<span class="quote">&gt;&gt; +                        pfn_pte(pfn, hugeprot));</span>
<span class="quote">&gt; We need to wrap the last argument with pte_val(.);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +               set_pte_at(mm, addr, ptep, pfn_pte(pfn, hugeprot));</span>
<span class="quote">&gt;&gt; +               ptep++;</span>
<span class="quote">&gt;&gt; +               pfn += pgsize &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; +               addr += pgsize;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +                     unsigned long addr, unsigned long sz)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt;&gt; +       pud_t *pud;</span>
<span class="quote">&gt;&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pr_debug(&quot;%s: addr:0x%lx sz:0x%lx\n&quot;, __func__, addr, sz);</span>
<span class="quote">&gt;&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +       pud = pud_alloc(mm, pgd, addr);</span>
<span class="quote">&gt;&gt; +       if (!pud)</span>
<span class="quote">&gt;&gt; +               return NULL;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (sz == PUD_SIZE) {</span>
<span class="quote">&gt;&gt; +               pte = (pte_t *)pud;</span>
<span class="quote">&gt;&gt; +       } else if (sz == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="quote">&gt;&gt; +               pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +               WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt;&gt; +               pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="quote">&gt; We get away with this on arm64 because we don&#39;t have high memory.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If one were to port this to 32-bit ARM, then this would break as it</span>
<span class="quote">&gt; would leave a mapping open.</span>
<span class="quote">&gt; (i.e. there&#39;s no corresponding pte_unmap(.) to line up with the</span>
<span class="quote">&gt; pte_offset_map from pte_alloc_map).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Maybe worth a quick comment for potential porters that they need to</span>
<span class="quote">&gt; either disable CONFIG_HIGHPTE or rework the page table page allocation</span>
<span class="quote">&gt; for contiguous ptes (tricky as one may already have non-contiguous</span>
<span class="quote">&gt; ptes present).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +       } else if (sz == PMD_SIZE) {</span>
<span class="quote">&gt;&gt; +               if (IS_ENABLED(CONFIG_ARCH_WANT_HUGE_PMD_SHARE) &amp;&amp;</span>
<span class="quote">&gt;&gt; +                   pud_none(*pud))</span>
<span class="quote">&gt;&gt; +                       pte = huge_pmd_share(mm, addr, pud);</span>
<span class="quote">&gt;&gt; +               else</span>
<span class="quote">&gt;&gt; +                       pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; +       } else if (sz == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="quote">&gt;&gt; +               pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +               pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; +               WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt;&gt; +               return (pte_t *)pmd;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pr_debug(&quot;%s: addr:0x%lx sz:0x%lx ret pte=%p/0x%llx\n&quot;, __func__, addr,</span>
<span class="quote">&gt;&gt; +              sz, pte, pte_val(*pte));</span>
<span class="quote">&gt;&gt; +       return pte;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt;&gt; +       pud_t *pud;</span>
<span class="quote">&gt;&gt; +       pmd_t *pmd = NULL;</span>
<span class="quote">&gt;&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +       pr_debug(&quot;%s: addr:0x%lx pgd:%p\n&quot;, __func__, addr, pgd);</span>
<span class="quote">&gt;&gt; +       if (!pgd_present(*pgd))</span>
<span class="quote">&gt;&gt; +               return NULL;</span>
<span class="quote">&gt;&gt; +       pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt;&gt; +       if (!pud_present(*pud))</span>
<span class="quote">&gt;&gt; +               return NULL;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (pud_huge(*pud))</span>
<span class="quote">&gt;&gt; +               return (pte_t *)pud;</span>
<span class="quote">&gt;&gt; +       pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt; +       if (!pmd_present(*pmd))</span>
<span class="quote">&gt;&gt; +               return NULL;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (pte_cont(pmd_pte(*pmd))) {</span>
<span class="quote">&gt;&gt; +               pmd = pmd_offset(</span>
<span class="quote">&gt;&gt; +                       pud, (addr &amp; CONT_PMD_MASK));</span>
<span class="quote">&gt;&gt; +               return (pte_t *)pmd;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       if (pmd_huge(*pmd))</span>
<span class="quote">&gt;&gt; +               return (pte_t *)pmd;</span>
<span class="quote">&gt;&gt; +       pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt;&gt; +       if (pte_present(*pte) &amp;&amp; pte_cont(*pte)) {</span>
<span class="quote">&gt;&gt; +               pte = pte_offset_kernel(</span>
<span class="quote">&gt;&gt; +                       pmd, (addr &amp; CONT_PTE_MASK));</span>
<span class="quote">&gt; Probably best return pte here.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       return pte;</span>
<span class="quote">&gt; and NULL here to signify an error (as we get to the point where we</span>
<span class="quote">&gt; know that addr isn&#39;t referring to a huge page).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                        struct page *page, int writable)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (pagesize == CONT_PTE_SIZE) {</span>
<span class="quote">&gt;&gt; +               entry = pte_mkcont(entry);</span>
<span class="quote">&gt;&gt; +       } else if (pagesize == CONT_PMD_SIZE) {</span>
<span class="quote">&gt;&gt; +               entry = pmd_pte(pmd_mkcont(pte_pmd(entry)));</span>
<span class="quote">&gt;&gt; +       } else if (pagesize != PUD_SIZE &amp;&amp; pagesize != PMD_SIZE) {</span>
<span class="quote">&gt;&gt; +               pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="quote">&gt;&gt; +                       __func__, pagesize);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       return entry;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +                             unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pte_t pte;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (pte_cont(*ptep)) {</span>
<span class="quote">&gt;&gt; +               int ncontig, i;</span>
<span class="quote">&gt;&gt; +               size_t pgsize;</span>
<span class="quote">&gt;&gt; +               pte_t *cpte;</span>
<span class="quote">&gt;&gt; +               bool is_dirty = false;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +               cpte = huge_pte_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +               ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="quote">&gt;&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>
<span class="quote">&gt; The call to pte_val is spurious.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +               /* save the 1st pte to return */</span>
<span class="quote">&gt;&gt; +               pte = ptep_get_and_clear(mm, addr, cpte);</span>
<span class="quote">&gt;&gt; +               for (i = 1; i &lt; ncontig; ++i) {</span>
<span class="quote">&gt;&gt; +                       /*</span>
<span class="quote">&gt;&gt; +                        * If HW_AFDBM is enabled, then the HW could</span>
<span class="quote">&gt;&gt; +                        * turn on the dirty bit for any of the page</span>
<span class="quote">&gt;&gt; +                        * in the set, so check them all.</span>
<span class="quote">&gt;&gt; +                        */</span>
<span class="quote">&gt;&gt; +                       ++cpte;</span>
<span class="quote">&gt;&gt; +                       if (pte_dirty(ptep_get_and_clear(mm, addr, cpte)))</span>
<span class="quote">&gt;&gt; +                               is_dirty = true;</span>
<span class="quote">&gt; Okay, ptep_get_and_clear uses the exclusive monitor to guard against</span>
<span class="quote">&gt; updates from AFDBM. The above looks good to me.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +               }</span>
<span class="quote">&gt;&gt; +               if (is_dirty)</span>
<span class="quote">&gt;&gt; +                       return pte_mkdirty(pte);</span>
<span class="quote">&gt;&gt; +               else</span>
<span class="quote">&gt;&gt; +                       return pte;</span>
<span class="quote">&gt;&gt; +       } else {</span>
<span class="quote">&gt;&gt; +               return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                              unsigned long addr, pte_t *ptep,</span>
<span class="quote">&gt;&gt; +                              pte_t pte, int dirty)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pte_t *cpte;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (pte_cont(pte)) {</span>
<span class="quote">&gt;&gt; +               int ncontig, i, changed = 0;</span>
<span class="quote">&gt;&gt; +               size_t pgsize = 0;</span>
<span class="quote">&gt;&gt; +               unsigned long pfn = pte_pfn(pte);</span>
<span class="quote">&gt;&gt; +               /* Select all bits except the pfn */</span>
<span class="quote">&gt;&gt; +               pgprot_t hugeprot =</span>
<span class="quote">&gt;&gt; +                       __pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>
<span class="quote">&gt; pfn_pte needs the second argument wrapping with __pgprot(.)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +               cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="quote">&gt;&gt; +               pfn = pte_pfn(*cpte);</span>
<span class="quote">&gt;&gt; +               ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="quote">&gt;&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>
<span class="quote">&gt; The call to pte_val(.) is spurious.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +               for (i = 0; i &lt; ncontig; ++i, ++cpte) {</span>
<span class="quote">&gt;&gt; +                       changed = ptep_set_access_flags(vma, addr, cpte,</span>
<span class="quote">&gt;&gt; +                                                       pfn_pte(pfn,</span>
<span class="quote">&gt;&gt; +                                                               hugeprot),</span>
<span class="quote">&gt;&gt; +                                                       dirty);</span>
<span class="quote">&gt; ptep_set_access_flags calls through to set_pte_at which will warn if</span>
<span class="quote">&gt; we are in a scenario where we can lose dirty information. So this code</span>
<span class="quote">&gt; looks okay for AFDBM to me.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +                       pfn += pgsize &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; +               }</span>
<span class="quote">&gt;&gt; +               return changed;</span>
<span class="quote">&gt;&gt; +       } else {</span>
<span class="quote">&gt;&gt; +               return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +                            unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       if (pte_cont(*ptep)) {</span>
<span class="quote">&gt;&gt; +               int ncontig, i;</span>
<span class="quote">&gt;&gt; +               pte_t *cpte;</span>
<span class="quote">&gt;&gt; +               size_t pgsize = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +               cpte = huge_pte_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +               ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="quote">&gt;&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>
<span class="quote">&gt; The call to pte_val is spurious(.).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +               for (i = 0; i &lt; ncontig; ++i, ++cpte)</span>
<span class="quote">&gt;&gt; +                       ptep_set_wrprotect(mm, addr, cpte);</span>
<span class="quote">&gt;&gt; +       } else {</span>
<span class="quote">&gt;&gt; +               ptep_set_wrprotect(mm, addr, ptep);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt; ptep_set_wrprotect uses the exclusive monitor, thus is protected from</span>
<span class="quote">&gt; AFDBM. This looks good to me.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                          unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       if (pte_cont(*ptep)) {</span>
<span class="quote">&gt;&gt; +               int ncontig, i;</span>
<span class="quote">&gt;&gt; +               pte_t *cpte;</span>
<span class="quote">&gt;&gt; +               size_t pgsize = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +               cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="quote">&gt;&gt; +               ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="quote">&gt;&gt; +                                         pte_val(*cpte), &amp;pgsize);</span>
<span class="quote">&gt; Call to pte_val is spurious.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +               for (i = 0; i &lt; ncontig; ++i, ++cpte)</span>
<span class="quote">&gt;&gt; +                       ptep_clear_flush(vma, addr, cpte);</span>
<span class="quote">&gt;&gt; +       } else {</span>
<span class="quote">&gt;&gt; +               ptep_clear_flush(vma, addr, ptep);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   static __init int setup_hugepagesz(char *opt)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;          unsigned long ps = memparse(opt, &amp;opt);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;          if (ps == PMD_SIZE) {</span>
<span class="quote">&gt;&gt;                  hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt;&gt;          } else if (ps == PUD_SIZE) {</span>
<span class="quote">&gt;&gt;                  hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; +       } else if (ps == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="quote">&gt;&gt; +               hugetlb_add_hstate(CONT_PTE_SHIFT);</span>
<span class="quote">&gt;&gt; +       } else if (ps == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="quote">&gt;&gt; +               hugetlb_add_hstate((PMD_SHIFT + CONT_PMD_SHIFT) - PAGE_SHIFT);</span>
<span class="quote">&gt;&gt;          } else {</span>
<span class="quote">&gt;&gt; -               pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="quote">&gt;&gt; +               pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
<span class="quote">&gt;&gt;                  return 0;</span>
<span class="quote">&gt;&gt;          }</span>
<span class="quote">&gt;&gt;          return 1;</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt; +static __init int add_default_hugepagesz(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       if (size_to_hstate(CONT_PTES * PAGE_SIZE) == NULL)</span>
<span class="quote">&gt;&gt; +               hugetlb_add_hstate(CONT_PMD_SHIFT);</span>
<span class="quote">&gt;&gt; +       return 0;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +arch_initcall(add_default_hugepagesz);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="quote">&gt;&gt; index 685c262..b0eb064 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/hugetlb.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/hugetlb.h</span>
<span class="quote">&gt;&gt; @@ -96,9 +96,7 @@ u32 hugetlb_fault_mutex_hash(struct hstate *h, struct mm_struct *mm,</span>
<span class="quote">&gt;&gt;                                  struct address_space *mapping,</span>
<span class="quote">&gt;&gt;                                  pgoff_t idx, unsigned long address);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;&gt;   pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud);</span>
<span class="quote">&gt;&gt; -#endif</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   extern int hugepages_treat_as_movable;</span>
<span class="quote">&gt;&gt;   extern int sysctl_hugetlb_shm_group;</span>
<span class="quote">&gt;&gt; --</span>
<span class="quote">&gt;&gt; 2.1.2</span>
<span class="quote">&gt;&gt;</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 4876459..ffa3c54 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -530,9 +530,6 @@</span> <span class="p_context"> config HW_PERF_EVENTS</span>
 config SYS_SUPPORTS_HUGETLBFS
 	def_bool y
 
<span class="p_del">-config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="p_del">-	def_bool y</span>
<span class="p_del">-</span>
 config ARCH_WANT_HUGE_PMD_SHARE
 	def_bool y if ARM64_4K_PAGES || (ARM64_16K_PAGES &amp;&amp; !ARM64_VA_BITS_36)
 
<span class="p_header">diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_header">index bb4052e..bbc1e35 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -26,36 +26,7 @@</span> <span class="p_context"> static inline pte_t huge_ptep_get(pte_t *ptep)</span>
 	return *ptep;
 }
 
<span class="p_del">-static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-				   pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pte_at(mm, addr, ptep, pte);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="p_del">-					 unsigned long addr, pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	ptep_clear_flush(vma, addr, ptep);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="p_del">-					   unsigned long addr, pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	ptep_set_wrprotect(mm, addr, ptep);</span>
<span class="p_del">-}</span>
 
<span class="p_del">-static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="p_del">-					    unsigned long addr, pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="p_del">-					     unsigned long addr, pte_t *ptep,</span>
<span class="p_del">-					     pte_t pte, int dirty)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="p_del">-}</span>
 
 static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,
 					  unsigned long addr, unsigned long end,
<span class="p_chunk">@@ -97,4 +68,19 @@</span> <span class="p_context"> static inline void arch_clear_hugepage_flags(struct page *page)</span>
 	clear_bit(PG_dcache_clean, &amp;page-&gt;flags);
 }
 
<span class="p_add">+extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+				struct page *page, int writable);</span>
<span class="p_add">+#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="p_add">+extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			    pte_t *ptep, pte_t pte);</span>
<span class="p_add">+extern int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="p_add">+				      unsigned long addr, pte_t *ptep,</span>
<span class="p_add">+				      pte_t pte, int dirty);</span>
<span class="p_add">+extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="p_add">+				     unsigned long addr, pte_t *ptep);</span>
<span class="p_add">+extern void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="p_add">+				    unsigned long addr, pte_t *ptep);</span>
<span class="p_add">+extern void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="p_add">+				  unsigned long addr, pte_t *ptep);</span>
<span class="p_add">+</span>
 #endif /* __ASM_HUGETLB_H */
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_header">index d6739e8..5c25b83 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_chunk">@@ -90,7 +90,23 @@</span> <span class="p_context"></span>
 /*
  * Contiguous page definitions.
  */
<span class="p_del">-#define CONT_PTES		(_AC(1, UL) &lt;&lt; CONT_SHIFT)</span>
<span class="p_add">+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+#define CONT_PTE_SHIFT		5</span>
<span class="p_add">+#define CONT_PMD_SHIFT		5</span>
<span class="p_add">+#elif defined(CONFIG_ARM64_16K_PAGES)</span>
<span class="p_add">+#define CONT_PTE_SHIFT		7</span>
<span class="p_add">+#define CONT_PMD_SHIFT		5</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define CONT_PTE_SHIFT		4</span>
<span class="p_add">+#define CONT_PMD_SHIFT		4</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define CONT_PTES		(1 &lt;&lt; CONT_PTE_SHIFT)</span>
<span class="p_add">+#define CONT_PTE_SIZE		(CONT_PTES * PAGE_SIZE)</span>
<span class="p_add">+#define CONT_PTE_MASK		(~(CONT_PTE_SIZE - 1))</span>
<span class="p_add">+#define CONT_PMDS		(1 &lt;&lt; CONT_PMD_SHIFT)</span>
<span class="p_add">+#define CONT_PMD_SIZE		(CONT_PMDS * PMD_SIZE)</span>
<span class="p_add">+#define CONT_PMD_MASK		(~(CONT_PMD_SIZE - 1))</span>
 /* the the numerical offset of the PTE within a range of CONT_PTES */
 #define CONT_RANGE_OFFSET(addr) (((addr)&gt;&gt;PAGE_SHIFT)&amp;(CONT_PTES-1))
 
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index 450b355..35a318c 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -227,7 +227,8 @@</span> <span class="p_context"> static inline pte_t pte_mkspecial(pte_t pte)</span>
 
 static inline pte_t pte_mkcont(pte_t pte)
 {
<span class="p_del">-	return set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="p_add">+	pte = set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="p_add">+	return set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
 }
 
 static inline pte_t pte_mknoncont(pte_t pte)
<span class="p_chunk">@@ -235,6 +236,11 @@</span> <span class="p_context"> static inline pte_t pte_mknoncont(pte_t pte)</span>
 	return clear_pte_bit(pte, __pgprot(PTE_CONT));
 }
 
<span class="p_add">+static inline pmd_t pmd_mkcont(pmd_t pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return __pmd(pmd_val(pmd) | PMD_SECT_CONT);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline void set_pte(pte_t *ptep, pte_t pte)
 {
 	*ptep = pte;
<span class="p_chunk">@@ -304,7 +310,7 @@</span> <span class="p_context"> static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
 /*
  * Hugetlb definitions.
  */
<span class="p_del">-#define HUGE_MAX_HSTATE		2</span>
<span class="p_add">+#define HUGE_MAX_HSTATE		4</span>
 #define HPAGE_SHIFT		PMD_SHIFT
 #define HPAGE_SIZE		(_AC(1, UL) &lt;&lt; HPAGE_SHIFT)
 #define HPAGE_MASK		(~(HPAGE_SIZE - 1))
<span class="p_header">diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">index 383b03f..39a5e67 100644</span>
<span class="p_header">--- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -41,17 +41,282 @@</span> <span class="p_context"> int pud_huge(pud_t pud)</span>
 #endif
 }
 
<span class="p_add">+static int find_num_contig(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			   pte_t *ptep, pte_t pte, size_t *pgsize)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pte_cont(pte))</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	if (!pgd_present(*pgd)) {</span>
<span class="p_add">+		VM_BUG_ON(!pgd_present(*pgd));</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	if (!pud_present(*pud)) {</span>
<span class="p_add">+		VM_BUG_ON(!pud_present(*pud));</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	if (!pmd_present(*pmd)) {</span>
<span class="p_add">+		VM_BUG_ON(!pmd_present(*pmd));</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if ((pte_t *)pmd == ptep) {</span>
<span class="p_add">+		*pgsize = PMD_SIZE;</span>
<span class="p_add">+		return CONT_PMDS;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	*pgsize = PAGE_SIZE;</span>
<span class="p_add">+	return CONT_PTES;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			    pte_t *ptep, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t pgsize;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	int ncontig = find_num_contig(mm, addr, ptep, pte, &amp;pgsize);</span>
<span class="p_add">+	unsigned long pfn;</span>
<span class="p_add">+	pgprot_t hugeprot;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ncontig == 1) {</span>
<span class="p_add">+		set_pte_at(mm, addr, ptep, pte);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pfn = pte_pfn(pte);</span>
<span class="p_add">+	hugeprot = __pgprot(pte_val(pfn_pte(pfn, 0)) ^ pte_val(pte));</span>
<span class="p_add">+	for (i = 0; i &lt; ncontig; i++) {</span>
<span class="p_add">+		pr_debug(&quot;%s: set pte %p to 0x%llx\n&quot;, __func__, ptep,</span>
<span class="p_add">+			 pfn_pte(pfn, hugeprot));</span>
<span class="p_add">+		set_pte_at(mm, addr, ptep, pfn_pte(pfn, hugeprot));</span>
<span class="p_add">+		ptep++;</span>
<span class="p_add">+		pfn += pgsize &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+		addr += pgsize;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="p_add">+		      unsigned long addr, unsigned long sz)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pte_t *pte = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;%s: addr:0x%lx sz:0x%lx\n&quot;, __func__, addr, sz);</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pud = pud_alloc(mm, pgd, addr);</span>
<span class="p_add">+	if (!pud)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sz == PUD_SIZE) {</span>
<span class="p_add">+		pte = (pte_t *)pud;</span>
<span class="p_add">+	} else if (sz == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="p_add">+		pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+</span>
<span class="p_add">+		WARN_ON(addr &amp; (sz - 1));</span>
<span class="p_add">+		pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="p_add">+	} else if (sz == PMD_SIZE) {</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_ARCH_WANT_HUGE_PMD_SHARE) &amp;&amp;</span>
<span class="p_add">+		    pud_none(*pud))</span>
<span class="p_add">+			pte = huge_pmd_share(mm, addr, pud);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+	} else if (sz == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="p_add">+		pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+		pmd = pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+		WARN_ON(addr &amp; (sz - 1));</span>
<span class="p_add">+		return (pte_t *)pmd;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;%s: addr:0x%lx sz:0x%lx ret pte=%p/0x%llx\n&quot;, __func__, addr,</span>
<span class="p_add">+	       sz, pte, pte_val(*pte));</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd = NULL;</span>
<span class="p_add">+	pte_t *pte = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pr_debug(&quot;%s: addr:0x%lx pgd:%p\n&quot;, __func__, addr, pgd);</span>
<span class="p_add">+	if (!pgd_present(*pgd))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	if (!pud_present(*pud))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pud_huge(*pud))</span>
<span class="p_add">+		return (pte_t *)pud;</span>
<span class="p_add">+	pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	if (!pmd_present(*pmd))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pte_cont(pmd_pte(*pmd))) {</span>
<span class="p_add">+		pmd = pmd_offset(</span>
<span class="p_add">+			pud, (addr &amp; CONT_PMD_MASK));</span>
<span class="p_add">+		return (pte_t *)pmd;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (pmd_huge(*pmd))</span>
<span class="p_add">+		return (pte_t *)pmd;</span>
<span class="p_add">+	pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+	if (pte_present(*pte) &amp;&amp; pte_cont(*pte)) {</span>
<span class="p_add">+		pte = pte_offset_kernel(</span>
<span class="p_add">+			pmd, (addr &amp; CONT_PTE_MASK));</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+			 struct page *page, int writable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pagesize == CONT_PTE_SIZE) {</span>
<span class="p_add">+		entry = pte_mkcont(entry);</span>
<span class="p_add">+	} else if (pagesize == CONT_PMD_SIZE) {</span>
<span class="p_add">+		entry = pmd_pte(pmd_mkcont(pte_pmd(entry)));</span>
<span class="p_add">+	} else if (pagesize != PUD_SIZE &amp;&amp; pagesize != PMD_SIZE) {</span>
<span class="p_add">+		pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="p_add">+			__func__, pagesize);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return entry;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="p_add">+			      unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pte_cont(*ptep)) {</span>
<span class="p_add">+		int ncontig, i;</span>
<span class="p_add">+		size_t pgsize;</span>
<span class="p_add">+		pte_t *cpte;</span>
<span class="p_add">+		bool is_dirty = false;</span>
<span class="p_add">+</span>
<span class="p_add">+		cpte = huge_pte_offset(mm, addr);</span>
<span class="p_add">+		ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="p_add">+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="p_add">+		/* save the 1st pte to return */</span>
<span class="p_add">+		pte = ptep_get_and_clear(mm, addr, cpte);</span>
<span class="p_add">+		for (i = 1; i &lt; ncontig; ++i) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * If HW_AFDBM is enabled, then the HW could</span>
<span class="p_add">+			 * turn on the dirty bit for any of the page</span>
<span class="p_add">+			 * in the set, so check them all.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			++cpte;</span>
<span class="p_add">+			if (pte_dirty(ptep_get_and_clear(mm, addr, cpte)))</span>
<span class="p_add">+				is_dirty = true;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (is_dirty)</span>
<span class="p_add">+			return pte_mkdirty(pte);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			return pte;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="p_add">+			       unsigned long addr, pte_t *ptep,</span>
<span class="p_add">+			       pte_t pte, int dirty)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t *cpte;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pte_cont(pte)) {</span>
<span class="p_add">+		int ncontig, i, changed = 0;</span>
<span class="p_add">+		size_t pgsize = 0;</span>
<span class="p_add">+		unsigned long pfn = pte_pfn(pte);</span>
<span class="p_add">+		/* Select all bits except the pfn */</span>
<span class="p_add">+		pgprot_t hugeprot =</span>
<span class="p_add">+			__pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>
<span class="p_add">+</span>
<span class="p_add">+		cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="p_add">+		pfn = pte_pfn(*cpte);</span>
<span class="p_add">+		ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="p_add">+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="p_add">+		for (i = 0; i &lt; ncontig; ++i, ++cpte) {</span>
<span class="p_add">+			changed = ptep_set_access_flags(vma, addr, cpte,</span>
<span class="p_add">+							pfn_pte(pfn,</span>
<span class="p_add">+								hugeprot),</span>
<span class="p_add">+							dirty);</span>
<span class="p_add">+			pfn += pgsize &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return changed;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
<span class="p_add">+			     unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (pte_cont(*ptep)) {</span>
<span class="p_add">+		int ncontig, i;</span>
<span class="p_add">+		pte_t *cpte;</span>
<span class="p_add">+		size_t pgsize = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		cpte = huge_pte_offset(mm, addr);</span>
<span class="p_add">+		ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="p_add">+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="p_add">+		for (i = 0; i &lt; ncontig; ++i, ++cpte)</span>
<span class="p_add">+			ptep_set_wrprotect(mm, addr, cpte);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		ptep_set_wrprotect(mm, addr, ptep);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void huge_ptep_clear_flush(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (pte_cont(*ptep)) {</span>
<span class="p_add">+		int ncontig, i;</span>
<span class="p_add">+		pte_t *cpte;</span>
<span class="p_add">+		size_t pgsize = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="p_add">+		ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="p_add">+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="p_add">+		for (i = 0; i &lt; ncontig; ++i, ++cpte)</span>
<span class="p_add">+			ptep_clear_flush(vma, addr, cpte);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		ptep_clear_flush(vma, addr, ptep);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static __init int setup_hugepagesz(char *opt)
 {
 	unsigned long ps = memparse(opt, &amp;opt);
<span class="p_add">+</span>
 	if (ps == PMD_SIZE) {
 		hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);
 	} else if (ps == PUD_SIZE) {
 		hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);
<span class="p_add">+	} else if (ps == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="p_add">+		hugetlb_add_hstate(CONT_PTE_SHIFT);</span>
<span class="p_add">+	} else if (ps == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="p_add">+		hugetlb_add_hstate((PMD_SHIFT + CONT_PMD_SHIFT) - PAGE_SHIFT);</span>
 	} else {
<span class="p_del">-		pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="p_add">+		pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
 		return 0;
 	}
 	return 1;
 }
 __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+static __init int add_default_hugepagesz(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (size_to_hstate(CONT_PTES * PAGE_SIZE) == NULL)</span>
<span class="p_add">+		hugetlb_add_hstate(CONT_PMD_SHIFT);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+arch_initcall(add_default_hugepagesz);</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index 685c262..b0eb064 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -96,9 +96,7 @@</span> <span class="p_context"> u32 hugetlb_fault_mutex_hash(struct hstate *h, struct mm_struct *mm,</span>
 				struct address_space *mapping,
 				pgoff_t idx, unsigned long address);
 
<span class="p_del">-#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
 pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud);
<span class="p_del">-#endif</span>
 
 extern int hugepages_treat_as_movable;
 extern int sysctl_hugetlb_shm_group;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



