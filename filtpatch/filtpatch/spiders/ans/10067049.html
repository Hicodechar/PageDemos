
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3/4] RISC-V: Flush I$ when making a dirty page executable - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3/4] RISC-V: Flush I$ when making a dirty page executable</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=177321">Palmer Dabbelt</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 20, 2017, 6:57 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171120185745.30795-4-palmer@sifive.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10067049/mbox/"
   >mbox</a>
|
   <a href="/patch/10067049/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10067049/">/patch/10067049/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2C873603FA for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 20 Nov 2017 18:58:14 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1E5B7291C8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 20 Nov 2017 18:58:14 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1343B292B1; Mon, 20 Nov 2017 18:58:14 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3044F291C8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 20 Nov 2017 18:58:13 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752392AbdKTS6H (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 20 Nov 2017 13:58:07 -0500
Received: from mail-pg0-f65.google.com ([74.125.83.65]:40326 &quot;EHLO
	mail-pg0-f65.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751637AbdKTS6C (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 20 Nov 2017 13:58:02 -0500
Received: by mail-pg0-f65.google.com with SMTP id u3so8088421pgn.7
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 20 Nov 2017 10:58:01 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:subject:date:message-id:in-reply-to:references
	:cc:from:to;
	bh=TMAswLx9Qme55noJCxvHSqLAqGvYZwl8ltI0QxN7OiU=;
	b=LIZA8RcHhbErw083lCvPiMNSqqPmZiv9GNX2pYtGj4IJVpLWcuIEH94HV/yRTegsrn
	I84ijJgW2QkgvQ5dJuK18W8/tNxU9aBK/SE1cq2UlzuloaXFojZzlbhNK2AWSs4DGyAJ
	5xUkWa2ycX0ofmiM0GKNmdtwZMdcZAiYgm0fWcTsawSNOyAQSCqcWE8/p8M/C2UaTgFl
	VxcNjvBuF1MNhj2koOGq684KZziXzFLSazCiTBDBNL8AfLp+OApq0z2I1ZzQIxpypCPr
	t1LCsHb10uUHQPRQ+4H8Qw1MjxYmJaMX/lfx8iH4tPo7QCt3rQ4benKLsjaLf1jEtnZr
	/0Ww==
X-Gm-Message-State: AJaThX7bXjLmL1s1ZmPIvpmUdLD420pHxvfBSvpKjbt2S3B4RuIcOVza
	Y7Lekox67gWF3ADiX2YIO1xeug==
X-Google-Smtp-Source: AGs4zMYph7G3ZL9CdRC2MKF7gxzF+VKb39H26co5yuFaS/4Ivw9w25w7BWQSFuCGMOjcXXNnFw5ATA==
X-Received: by 10.101.75.78 with SMTP id k14mr14262316pgt.272.1511204281106; 
	Mon, 20 Nov 2017 10:58:01 -0800 (PST)
Received: from localhost ([12.206.222.5]) by smtp.gmail.com with ESMTPSA id
	g127sm16394311pgc.29.2017.11.20.10.58.00
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Mon, 20 Nov 2017 10:58:00 -0800 (PST)
Subject: [PATCH 3/4] RISC-V: Flush I$ when making a dirty page executable
Date: Mon, 20 Nov 2017 10:57:44 -0800
Message-Id: &lt;20171120185745.30795-4-palmer@sifive.com&gt;
X-Mailer: git-send-email 2.13.6
In-Reply-To: &lt;20171120185745.30795-1-palmer@sifive.com&gt;
References: &lt;20171120185745.30795-1-palmer@sifive.com&gt;
Cc: patches@groups.riscv.org, Andrew Waterman &lt;andrew@sifive.com&gt;,
	Palmer Dabbelt &lt;palmer@sifive.com&gt;
From: Palmer Dabbelt &lt;palmer@sifive.com&gt;
To: linux-kernel@vger.kernel.org
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=177321">Palmer Dabbelt</a> - Nov. 20, 2017, 6:57 p.m.</div>
<pre class="content">
<span class="from">From: Andrew Waterman &lt;andrew@sifive.com&gt;</span>

The RISC-V ISA allows for instruction caches that are not coherent WRT
stores, even on a single hart.  As a result, we need to explicitly flush
the instruction cache whenever marking a dirty page as executable in
order to preserve the correct system behavior.

Local instruction caches aren&#39;t that scary (our implementations actually
flush the cache, but RISC-V is defined to allow higher-performance
implementations to exist), but RISC-V defines no way to perform an
instruction cache shootdown.  When explicitly asked to do so we can
shoot down remote instruction caches via an IPI, but this is a bit on
the slow side.

Instead of requiring an IPI to all harts whenever marking a page as
executable, we simply flush the currently running harts.  In order to
maintain correct behavior, we additionally mark every other hart as
needing a deferred instruction cache which will be taken before anything
runs on it.
<span class="signed-off-by">
Signed-off-by: Andrew Waterman &lt;andrew@sifive.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Palmer Dabbelt &lt;palmer@sifive.com&gt;</span>
---
 arch/riscv/include/asm/cacheflush.h  | 24 ++++++++++++---
 arch/riscv/include/asm/mmu.h         |  4 +++
 arch/riscv/include/asm/mmu_context.h | 44 +++++++++++++++++++++++++++
 arch/riscv/include/asm/pgtable.h     | 58 ++++++++++++++++++++----------------
 arch/riscv/include/asm/tlbflush.h    |  2 ++
 arch/riscv/kernel/smp.c              | 48 +++++++++++++++++++++++++++++
 arch/riscv/mm/Makefile               |  2 ++
 arch/riscv/mm/cacheflush.c           | 23 ++++++++++++++
 8 files changed, 175 insertions(+), 30 deletions(-)
 create mode 100644 arch/riscv/mm/cacheflush.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=21121">David Laight</a> - Nov. 21, 2017, 4:57 p.m.</div>
<pre class="content">
<span class="from">From: Palmer Dabbelt</span>
<span class="quote">&gt; Sent: 20 November 2017 18:58</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The RISC-V ISA allows for instruction caches that are not coherent WRT</span>
<span class="quote">&gt; stores, even on a single hart.  As a result, we need to explicitly flush</span>
<span class="quote">&gt; the instruction cache whenever marking a dirty page as executable in</span>
<span class="quote">&gt; order to preserve the correct system behavior.</span>

Isn&#39;t the I-flush only needed if there has been an unmap since the
previous I-flush?
Since code is rarely unmapped (exec and driver unload come to mind)
the I-flush won&#39;t be needed very often.

	David
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=177321">Palmer Dabbelt</a> - Nov. 22, 2017, 5:38 p.m.</div>
<pre class="content">
On Tue, 21 Nov 2017 08:57:07 PST (-0800), David.Laight@ACULAB.COM wrote:
<span class="quote">&gt; From: Palmer Dabbelt</span>
<span class="quote">&gt;&gt; Sent: 20 November 2017 18:58</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The RISC-V ISA allows for instruction caches that are not coherent WRT</span>
<span class="quote">&gt;&gt; stores, even on a single hart.  As a result, we need to explicitly flush</span>
<span class="quote">&gt;&gt; the instruction cache whenever marking a dirty page as executable in</span>
<span class="quote">&gt;&gt; order to preserve the correct system behavior.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Isn&#39;t the I-flush only needed if there has been an unmap since the</span>
<span class="quote">&gt; previous I-flush?</span>
<span class="quote">&gt; Since code is rarely unmapped (exec and driver unload come to mind)</span>
<span class="quote">&gt; the I-flush won&#39;t be needed very often.</span>

There&#39;s nothing in the RISC-V ISA that prevents the instruction cache from 
caching read-only (or even unmapped!) pages.  Instructions fetched this manner 
could never commit, but they could fill up the icache with garbage.  I believe 
that means we need to flush on dirty-&gt;execute, but if I&#39;m wrong I&#39;m happy to 
change it.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=177497">Andrew Waterman</a> - Nov. 22, 2017, 7:03 p.m.</div>
<pre class="content">
On Wed, Nov 22, 2017 at 9:38 AM, Palmer Dabbelt &lt;palmer@sifive.com&gt; wrote:
<span class="quote">&gt; On Tue, 21 Nov 2017 08:57:07 PST (-0800), David.Laight@ACULAB.COM wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; From: Palmer Dabbelt</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Sent: 20 November 2017 18:58</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; The RISC-V ISA allows for instruction caches that are not coherent WRT</span>
<span class="quote">&gt;&gt;&gt; stores, even on a single hart.  As a result, we need to explicitly flush</span>
<span class="quote">&gt;&gt;&gt; the instruction cache whenever marking a dirty page as executable in</span>
<span class="quote">&gt;&gt;&gt; order to preserve the correct system behavior.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Isn&#39;t the I-flush only needed if there has been an unmap since the</span>
<span class="quote">&gt;&gt; previous I-flush?</span>
<span class="quote">&gt;&gt; Since code is rarely unmapped (exec and driver unload come to mind)</span>
<span class="quote">&gt;&gt; the I-flush won&#39;t be needed very often.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; There&#39;s nothing in the RISC-V ISA that prevents the instruction cache from</span>
<span class="quote">&gt; caching read-only (or even unmapped!) pages.  Instructions fetched this</span>
<span class="quote">&gt; manner could never commit, but they could fill up the icache with garbage.</span>
<span class="quote">&gt; I believe that means we need to flush on dirty-&gt;execute, but if I&#39;m wrong</span>
<span class="quote">&gt; I&#39;m happy to change it.</span>

Palmer is right about the ISA semantics; a FENCE.I needs to be
executed before executing any code that has been (physically)
modified, because any physical address could reside stale in the I$,
regardless of past virtual-memory permissions.

The approach we took to handle this (executing FENCE.I when a
phsyically dirty page becomes executable) is also used by the arm64
port.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=565">Olof Johansson</a> - Nov. 30, 2017, 8:32 p.m.</div>
<pre class="content">
Hi,

On Mon, Nov 20, 2017 at 10:57 AM, Palmer Dabbelt &lt;palmer@sifive.com&gt; wrote:
<span class="quote">&gt; From: Andrew Waterman &lt;andrew@sifive.com&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The RISC-V ISA allows for instruction caches that are not coherent WRT</span>
<span class="quote">&gt; stores, even on a single hart.  As a result, we need to explicitly flush</span>
<span class="quote">&gt; the instruction cache whenever marking a dirty page as executable in</span>
<span class="quote">&gt; order to preserve the correct system behavior.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Local instruction caches aren&#39;t that scary (our implementations actually</span>
<span class="quote">&gt; flush the cache, but RISC-V is defined to allow higher-performance</span>
<span class="quote">&gt; implementations to exist), but RISC-V defines no way to perform an</span>
<span class="quote">&gt; instruction cache shootdown.  When explicitly asked to do so we can</span>
<span class="quote">&gt; shoot down remote instruction caches via an IPI, but this is a bit on</span>
<span class="quote">&gt; the slow side.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Instead of requiring an IPI to all harts whenever marking a page as</span>
<span class="quote">&gt; executable, we simply flush the currently running harts.  In order to</span>
<span class="quote">&gt; maintain correct behavior, we additionally mark every other hart as</span>
<span class="quote">&gt; needing a deferred instruction cache which will be taken before anything</span>
<span class="quote">&gt; runs on it.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Andrew Waterman &lt;andrew@sifive.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Palmer Dabbelt &lt;palmer@sifive.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/riscv/include/asm/cacheflush.h  | 24 ++++++++++++---</span>
<span class="quote">&gt;  arch/riscv/include/asm/mmu.h         |  4 +++</span>
<span class="quote">&gt;  arch/riscv/include/asm/mmu_context.h | 44 +++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/riscv/include/asm/pgtable.h     | 58 ++++++++++++++++++++----------------</span>
<span class="quote">&gt;  arch/riscv/include/asm/tlbflush.h    |  2 ++</span>
<span class="quote">&gt;  arch/riscv/kernel/smp.c              | 48 +++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/riscv/mm/Makefile               |  2 ++</span>
<span class="quote">&gt;  arch/riscv/mm/cacheflush.c           | 23 ++++++++++++++</span>
<span class="quote">&gt;  8 files changed, 175 insertions(+), 30 deletions(-)</span>
<span class="quote">&gt;  create mode 100644 arch/riscv/mm/cacheflush.c</span>

[...]
<span class="quote">
&gt; diff --git a/arch/riscv/mm/Makefile b/arch/riscv/mm/Makefile</span>
<span class="quote">&gt; index 81f7d9ce6d88..786b5fdec0fd 100644</span>
<span class="quote">&gt; --- a/arch/riscv/mm/Makefile</span>
<span class="quote">&gt; +++ b/arch/riscv/mm/Makefile</span>
<span class="quote">&gt; @@ -2,3 +2,5 @@ obj-y += init.o</span>
<span class="quote">&gt;  obj-y += fault.o</span>
<span class="quote">&gt;  obj-y += extable.o</span>
<span class="quote">&gt;  obj-y += ioremap.o</span>
<span class="quote">&gt; +obj-y += dma.o</span>
<span class="quote">&gt; +obj-y += cacheflush.o</span>

Looks like dma.c didn&#39;t make it into this patch (and didn&#39;t already
exist), so builds fail with:

 make[3]: *** No rule to make target &#39;arch/riscv/mm/dma.o&#39;, needed by
&#39;arch/riscv/mm/built-in.o&#39;.


-Olof
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=177321">Palmer Dabbelt</a> - Nov. 30, 2017, 10:50 p.m.</div>
<pre class="content">
On Thu, 30 Nov 2017 12:32:04 PST (-0800), Olof Johansson wrote:
<span class="quote">&gt; Hi,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On Mon, Nov 20, 2017 at 10:57 AM, Palmer Dabbelt &lt;palmer@sifive.com&gt; wrote:</span>
<span class="quote">&gt;&gt; From: Andrew Waterman &lt;andrew@sifive.com&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The RISC-V ISA allows for instruction caches that are not coherent WRT</span>
<span class="quote">&gt;&gt; stores, even on a single hart.  As a result, we need to explicitly flush</span>
<span class="quote">&gt;&gt; the instruction cache whenever marking a dirty page as executable in</span>
<span class="quote">&gt;&gt; order to preserve the correct system behavior.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Local instruction caches aren&#39;t that scary (our implementations actually</span>
<span class="quote">&gt;&gt; flush the cache, but RISC-V is defined to allow higher-performance</span>
<span class="quote">&gt;&gt; implementations to exist), but RISC-V defines no way to perform an</span>
<span class="quote">&gt;&gt; instruction cache shootdown.  When explicitly asked to do so we can</span>
<span class="quote">&gt;&gt; shoot down remote instruction caches via an IPI, but this is a bit on</span>
<span class="quote">&gt;&gt; the slow side.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Instead of requiring an IPI to all harts whenever marking a page as</span>
<span class="quote">&gt;&gt; executable, we simply flush the currently running harts.  In order to</span>
<span class="quote">&gt;&gt; maintain correct behavior, we additionally mark every other hart as</span>
<span class="quote">&gt;&gt; needing a deferred instruction cache which will be taken before anything</span>
<span class="quote">&gt;&gt; runs on it.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Andrew Waterman &lt;andrew@sifive.com&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Palmer Dabbelt &lt;palmer@sifive.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  arch/riscv/include/asm/cacheflush.h  | 24 ++++++++++++---</span>
<span class="quote">&gt;&gt;  arch/riscv/include/asm/mmu.h         |  4 +++</span>
<span class="quote">&gt;&gt;  arch/riscv/include/asm/mmu_context.h | 44 +++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  arch/riscv/include/asm/pgtable.h     | 58 ++++++++++++++++++++----------------</span>
<span class="quote">&gt;&gt;  arch/riscv/include/asm/tlbflush.h    |  2 ++</span>
<span class="quote">&gt;&gt;  arch/riscv/kernel/smp.c              | 48 +++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  arch/riscv/mm/Makefile               |  2 ++</span>
<span class="quote">&gt;&gt;  arch/riscv/mm/cacheflush.c           | 23 ++++++++++++++</span>
<span class="quote">&gt;&gt;  8 files changed, 175 insertions(+), 30 deletions(-)</span>
<span class="quote">&gt;&gt;  create mode 100644 arch/riscv/mm/cacheflush.c</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/riscv/mm/Makefile b/arch/riscv/mm/Makefile</span>
<span class="quote">&gt;&gt; index 81f7d9ce6d88..786b5fdec0fd 100644</span>
<span class="quote">&gt;&gt; --- a/arch/riscv/mm/Makefile</span>
<span class="quote">&gt;&gt; +++ b/arch/riscv/mm/Makefile</span>
<span class="quote">&gt;&gt; @@ -2,3 +2,5 @@ obj-y += init.o</span>
<span class="quote">&gt;&gt;  obj-y += fault.o</span>
<span class="quote">&gt;&gt;  obj-y += extable.o</span>
<span class="quote">&gt;&gt;  obj-y += ioremap.o</span>
<span class="quote">&gt;&gt; +obj-y += dma.o</span>
<span class="quote">&gt;&gt; +obj-y += cacheflush.o</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Looks like dma.c didn&#39;t make it into this patch (and didn&#39;t already</span>
<span class="quote">&gt; exist), so builds fail with:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  make[3]: *** No rule to make target &#39;arch/riscv/mm/dma.o&#39;, needed by</span>
<span class="quote">&gt; &#39;arch/riscv/mm/built-in.o&#39;.</span>

Ah, thanks for catching that.  I&#39;ll fix up the patch.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/riscv/include/asm/cacheflush.h b/arch/riscv/include/asm/cacheflush.h</span>
<span class="p_header">index 0595585013b0..5c9ed39ee2a2 100644</span>
<span class="p_header">--- a/arch/riscv/include/asm/cacheflush.h</span>
<span class="p_header">+++ b/arch/riscv/include/asm/cacheflush.h</span>
<span class="p_chunk">@@ -18,21 +18,37 @@</span> <span class="p_context"></span>
 
 #undef flush_icache_range
 #undef flush_icache_user_range
<span class="p_add">+#undef flush_dcache_page</span>
 
 static inline void local_flush_icache_all(void)
 {
 	asm volatile (&quot;fence.i&quot; ::: &quot;memory&quot;);
 }
 
<span class="p_add">+#define PG_dcache_clean PG_arch_1</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void flush_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (test_bit(PG_dcache_clean, &amp;page-&gt;flags))</span>
<span class="p_add">+		clear_bit(PG_dcache_clean, &amp;page-&gt;flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * RISC-V doesn&#39;t have an instruction to flush parts of the instruction cache,</span>
<span class="p_add">+ * so instead we just flush the whole thing.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define flush_icache_range(start, end) flush_icache_all()</span>
<span class="p_add">+#define flush_icache_user_range(vma, pg, addr, len) flush_icache_all()</span>
<span class="p_add">+</span>
 #ifndef CONFIG_SMP
 
<span class="p_del">-#define flush_icache_range(start, end) local_flush_icache_all()</span>
<span class="p_del">-#define flush_icache_user_range(vma, pg, addr, len) local_flush_icache_all()</span>
<span class="p_add">+#define flush_icache_all() local_flush_icache_all()</span>
<span class="p_add">+#define flush_icache_mm(mm, local) flush_icache_all()</span>
 
 #else /* CONFIG_SMP */
 
<span class="p_del">-#define flush_icache_range(start, end) sbi_remote_fence_i(0)</span>
<span class="p_del">-#define flush_icache_user_range(vma, pg, addr, len) sbi_remote_fence_i(0)</span>
<span class="p_add">+#define flush_icache_all() sbi_remote_fence_i(0)</span>
<span class="p_add">+void flush_icache_mm(struct mm_struct *mm, bool local);</span>
 
 #endif /* CONFIG_SMP */
 
<span class="p_header">diff --git a/arch/riscv/include/asm/mmu.h b/arch/riscv/include/asm/mmu.h</span>
<span class="p_header">index 66805cba9a27..5df2dccdba12 100644</span>
<span class="p_header">--- a/arch/riscv/include/asm/mmu.h</span>
<span class="p_header">+++ b/arch/riscv/include/asm/mmu.h</span>
<span class="p_chunk">@@ -19,6 +19,10 @@</span> <span class="p_context"></span>
 
 typedef struct {
 	void *vdso;
<span class="p_add">+#ifdef CONFIG_SMP</span>
<span class="p_add">+	/* A local icache flush is needed before user execution can resume. */</span>
<span class="p_add">+	cpumask_t icache_stale_mask;</span>
<span class="p_add">+#endif</span>
 } mm_context_t;
 
 #endif /* __ASSEMBLY__ */
<span class="p_header">diff --git a/arch/riscv/include/asm/mmu_context.h b/arch/riscv/include/asm/mmu_context.h</span>
<span class="p_header">index de1fc1631fc4..b15b169e3d22 100644</span>
<span class="p_header">--- a/arch/riscv/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/riscv/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -1,5 +1,6 @@</span> <span class="p_context"></span>
 /*
  * Copyright (C) 2012 Regents of the University of California
<span class="p_add">+ * Copyright (C) 2017 SiFive</span>
  *
  *   This program is free software; you can redistribute it and/or
  *   modify it under the terms of the GNU General Public License
<span class="p_chunk">@@ -19,6 +20,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/sched.h&gt;
 #include &lt;asm/tlbflush.h&gt;
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
 
 static inline void enter_lazy_tlb(struct mm_struct *mm,
 	struct task_struct *task)
<span class="p_chunk">@@ -46,12 +48,54 @@</span> <span class="p_context"> static inline void set_pgdir(pgd_t *pgd)</span>
 	csr_write(sptbr, virt_to_pfn(pgd) | SPTBR_MODE);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * When necessary, performs a deferred icache flush for the given MM context,</span>
<span class="p_add">+ * on the local CPU.  RISC-V has no direct mechanism for instruction cache</span>
<span class="p_add">+ * shoot downs, so instead we send an IPI that informs the remote harts they</span>
<span class="p_add">+ * need to flush their local instruction caches.  To avoid pathologically slow</span>
<span class="p_add">+ * behavior in a common case (a bunch of single-hart processes on a many-hart</span>
<span class="p_add">+ * machine, ie &#39;make -j&#39;) we avoid the IPIs for harts that are not currently</span>
<span class="p_add">+ * executing a MM context and instead schedule a deferred local instruction</span>
<span class="p_add">+ * cache flush to be performed before execution resumes on each hart.  This</span>
<span class="p_add">+ * actually performs that local instruction cache flush, which implicitly only</span>
<span class="p_add">+ * refers to the current hart.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void flush_icache_deferred(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifdef CONFIG_SMP</span>
<span class="p_add">+	unsigned int cpu = smp_processor_id();</span>
<span class="p_add">+	cpumask_t *mask = &amp;mm-&gt;context.icache_stale_mask;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_test_cpu(cpu, mask)) {</span>
<span class="p_add">+		cpumask_clear_cpu(cpu, mask);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Ensure the remote hart&#39;s writes are visible to this hart.</span>
<span class="p_add">+		 * This pairs with a barrier in flush_icache_mm.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		smp_mb();</span>
<span class="p_add">+		local_flush_icache_all();</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline void switch_mm(struct mm_struct *prev,
 	struct mm_struct *next, struct task_struct *task)
 {
 	if (likely(prev != next)) {
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Mark the current MM context as inactive, and the next as</span>
<span class="p_add">+		 * active.  This is at least used by the icache flushing</span>
<span class="p_add">+		 * routines in order to determine who should</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		unsigned int cpu = smp_processor_id();</span>
<span class="p_add">+</span>
<span class="p_add">+		cpumask_clear_cpu(cpu, mm_cpumask(prev));</span>
<span class="p_add">+		cpumask_set_cpu(cpu, mm_cpumask(next));</span>
<span class="p_add">+</span>
 		set_pgdir(next-&gt;pgd);
 		local_flush_tlb_all();
<span class="p_add">+</span>
<span class="p_add">+		flush_icache_deferred(next);</span>
 	}
 }
 
<span class="p_header">diff --git a/arch/riscv/include/asm/pgtable.h b/arch/riscv/include/asm/pgtable.h</span>
<span class="p_header">index 3399257780b2..2cbd92ed1629 100644</span>
<span class="p_header">--- a/arch/riscv/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/riscv/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -178,28 +178,6 @@</span> <span class="p_context"> static inline pte_t *pte_offset_kernel(pmd_t *pmd, unsigned long addr)</span>
 #define pte_offset_map(dir, addr)	pte_offset_kernel((dir), (addr))
 #define pte_unmap(pte)			((void)(pte))
 
<span class="p_del">-/*</span>
<span class="p_del">- * Certain architectures need to do special things when PTEs within</span>
<span class="p_del">- * a page table are directly modified.  Thus, the following hook is</span>
<span class="p_del">- * made available.</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void set_pte(pte_t *ptep, pte_t pteval)</span>
<span class="p_del">-{</span>
<span class="p_del">-	*ptep = pteval;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pte_at(struct mm_struct *mm,</span>
<span class="p_del">-	unsigned long addr, pte_t *ptep, pte_t pteval)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pte(ptep, pteval);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pte_clear(struct mm_struct *mm,</span>
<span class="p_del">-	unsigned long addr, pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pte_at(mm, addr, ptep, __pte(0));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline int pte_present(pte_t pte)
 {
 	return (pte_val(pte) &amp; _PAGE_PRESENT);
<span class="p_chunk">@@ -210,21 +188,22 @@</span> <span class="p_context"> static inline int pte_none(pte_t pte)</span>
 	return (pte_val(pte) == 0);
 }
 
<span class="p_del">-/* static inline int pte_read(pte_t pte) */</span>
<span class="p_del">-</span>
 static inline int pte_write(pte_t pte)
 {
 	return pte_val(pte) &amp; _PAGE_WRITE;
 }
 
<span class="p_add">+static inline int pte_exec(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return pte_val(pte) &amp; _PAGE_EXEC;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int pte_huge(pte_t pte)
 {
 	return pte_present(pte)
 		&amp;&amp; (pte_val(pte) &amp; (_PAGE_READ | _PAGE_WRITE | _PAGE_EXEC));
 }
 
<span class="p_del">-/* static inline int pte_exec(pte_t pte) */</span>
<span class="p_del">-</span>
 static inline int pte_dirty(pte_t pte)
 {
 	return pte_val(pte) &amp; _PAGE_DIRTY;
<span class="p_chunk">@@ -311,6 +290,33 @@</span> <span class="p_context"> static inline int pte_same(pte_t pte_a, pte_t pte_b)</span>
 	return pte_val(pte_a) == pte_val(pte_b);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Certain architectures need to do special things when PTEs within</span>
<span class="p_add">+ * a page table are directly modified.  Thus, the following hook is</span>
<span class="p_add">+ * made available.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void set_pte(pte_t *ptep, pte_t pteval)</span>
<span class="p_add">+{</span>
<span class="p_add">+	*ptep = pteval;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_pte(pte_t pte);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pte_at(struct mm_struct *mm,</span>
<span class="p_add">+	unsigned long addr, pte_t *ptep, pte_t pteval)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (pte_present(pteval) &amp;&amp; pte_exec(pteval))</span>
<span class="p_add">+		flush_icache_pte(pteval);</span>
<span class="p_add">+</span>
<span class="p_add">+	set_pte(ptep, pteval);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pte_clear(struct mm_struct *mm,</span>
<span class="p_add">+	unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_pte_at(mm, addr, ptep, __pte(0));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #define __HAVE_ARCH_PTEP_SET_ACCESS_FLAGS
 static inline int ptep_set_access_flags(struct vm_area_struct *vma,
 					unsigned long address, pte_t *ptep,
<span class="p_header">diff --git a/arch/riscv/include/asm/tlbflush.h b/arch/riscv/include/asm/tlbflush.h</span>
<span class="p_header">index 5ee4ae370b5e..77edf2826c1f 100644</span>
<span class="p_header">--- a/arch/riscv/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/riscv/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -17,6 +17,8 @@</span> <span class="p_context"></span>
 
 #ifdef CONFIG_MMU
 
<span class="p_add">+#include &lt;linux/mm_types.h&gt;</span>
<span class="p_add">+</span>
 /* Flush entire local TLB */
 static inline void local_flush_tlb_all(void)
 {
<span class="p_header">diff --git a/arch/riscv/kernel/smp.c b/arch/riscv/kernel/smp.c</span>
<span class="p_header">index b4a71ec5906f..1b27ade437b4 100644</span>
<span class="p_header">--- a/arch/riscv/kernel/smp.c</span>
<span class="p_header">+++ b/arch/riscv/kernel/smp.c</span>
<span class="p_chunk">@@ -108,3 +108,51 @@</span> <span class="p_context"> void smp_send_reschedule(int cpu)</span>
 {
 	send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);
 }
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Performs an icache flush for the given MM context.  RISC-V has no direct</span>
<span class="p_add">+ * mechanism for instruction cache shoot downs, so instead we send an IPI that</span>
<span class="p_add">+ * informs the remote harts they need to flush their local instruction caches.</span>
<span class="p_add">+ * To avoid pathologically slow behavior in a common case (a bunch of</span>
<span class="p_add">+ * single-hart processes on a many-hart machine, ie &#39;make -j&#39;) we avoid the</span>
<span class="p_add">+ * IPIs for harts that are not currently executing a MM context and instead</span>
<span class="p_add">+ * schedule a deferred local instruction cache flush to be performed before</span>
<span class="p_add">+ * execution resumes on each hart.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void flush_icache_mm(struct mm_struct *mm, bool local)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cpu;</span>
<span class="p_add">+	cpumask_t others, *mask;</span>
<span class="p_add">+</span>
<span class="p_add">+	preempt_disable();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Mark every hart&#39;s icache as needing a flush for this MM. */</span>
<span class="p_add">+	mask = &amp;mm-&gt;context.icache_stale_mask;</span>
<span class="p_add">+	cpumask_setall(mask);</span>
<span class="p_add">+	/* Flush this hart&#39;s I$ now, and mark it as flushed. */</span>
<span class="p_add">+	cpu = smp_processor_id();</span>
<span class="p_add">+	cpumask_clear_cpu(cpu, mask);</span>
<span class="p_add">+	local_flush_icache_all();</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Flush the I$ of other harts concurrently executing, and mark them as</span>
<span class="p_add">+	 * flushed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	cpumask_andnot(&amp;others, mm_cpumask(mm), cpumask_of(cpu));</span>
<span class="p_add">+	local |= cpumask_empty(&amp;others);</span>
<span class="p_add">+	if (mm != current-&gt;active_mm || !local)</span>
<span class="p_add">+		sbi_remote_fence_i(others.bits);</span>
<span class="p_add">+	else {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * It&#39;s assumed that at least one strongly ordered operation is</span>
<span class="p_add">+		 * performed on this hart between setting a hart&#39;s cpumask bit</span>
<span class="p_add">+		 * and scheduling this MM context on that hart.  Sending an SBI</span>
<span class="p_add">+		 * remote message will do this, but in the case where no</span>
<span class="p_add">+		 * messages are sent we still need to order this hart&#39;s writes</span>
<span class="p_add">+		 * with flush_icache_deferred().</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		smp_mb();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	preempt_enable();</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/riscv/mm/Makefile b/arch/riscv/mm/Makefile</span>
<span class="p_header">index 81f7d9ce6d88..786b5fdec0fd 100644</span>
<span class="p_header">--- a/arch/riscv/mm/Makefile</span>
<span class="p_header">+++ b/arch/riscv/mm/Makefile</span>
<span class="p_chunk">@@ -2,3 +2,5 @@</span> <span class="p_context"> obj-y += init.o</span>
 obj-y += fault.o
 obj-y += extable.o
 obj-y += ioremap.o
<span class="p_add">+obj-y += dma.o</span>
<span class="p_add">+obj-y += cacheflush.o</span>
<span class="p_header">diff --git a/arch/riscv/mm/cacheflush.c b/arch/riscv/mm/cacheflush.c</span>
new file mode 100644
<span class="p_header">index 000000000000..498c0a0814fe</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/riscv/mm/cacheflush.c</span>
<span class="p_chunk">@@ -0,0 +1,23 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2017 SiFive</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *   This program is free software; you can redistribute it and/or</span>
<span class="p_add">+ *   modify it under the terms of the GNU General Public License</span>
<span class="p_add">+ *   as published by the Free Software Foundation, version 2.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *   This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ *   GNU General Public License for more details.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/pgtable.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_pte(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page = pte_page(pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!test_and_set_bit(PG_dcache_clean, &amp;page-&gt;flags))</span>
<span class="p_add">+		flush_icache_all();</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



