
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.9.42 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.9.42</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 11, 2017, 4:08 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170811160822.GB29073@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9896267/mbox/"
   >mbox</a>
|
   <a href="/patch/9896267/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9896267/">/patch/9896267/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	97A16602DA for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Aug 2017 16:08:41 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7553628BD2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Aug 2017 16:08:41 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 6951B28BD5; Fri, 11 Aug 2017 16:08:41 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1672428BD2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Aug 2017 16:08:36 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753441AbdHKQId (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 11 Aug 2017 12:08:33 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:49732 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753240AbdHKQIY (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 11 Aug 2017 12:08:24 -0400
Received: from localhost (unknown [104.132.0.100])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id B1656B66;
	Fri, 11 Aug 2017 16:08:22 +0000 (UTC)
Date: Fri, 11 Aug 2017 09:08:22 -0700
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.9.42
Message-ID: &lt;20170811160822.GB29073@kroah.com&gt;
References: &lt;20170811160817.GA29073@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170811160817.GA29073@kroah.com&gt;
User-Agent: Mutt/1.8.3 (2017-05-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Aug. 11, 2017, 4:08 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 82eb3d1ee801..34d4d9f8a4b2 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 9
<span class="p_del">-SUBLEVEL = 41</span>
<span class="p_add">+SUBLEVEL = 42</span>
 EXTRAVERSION =
 NAME = Roaring Lionus
 
<span class="p_header">diff --git a/arch/arm/boot/dts/Makefile b/arch/arm/boot/dts/Makefile</span>
<span class="p_header">index 7037201c5e3a..f3baa896ce84 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/Makefile</span>
<span class="p_header">+++ b/arch/arm/boot/dts/Makefile</span>
<span class="p_chunk">@@ -820,6 +820,7 @@</span> <span class="p_context"> dtb-$(CONFIG_MACH_SUN8I) += \</span>
 	sun8i-a83t-allwinner-h8homlet-v2.dtb \
 	sun8i-a83t-cubietruck-plus.dtb \
 	sun8i-h3-bananapi-m2-plus.dtb \
<span class="p_add">+	sun8i-h3-nanopi-m1.dtb	\</span>
 	sun8i-h3-nanopi-neo.dtb \
 	sun8i-h3-orangepi-2.dtb \
 	sun8i-h3-orangepi-lite.dtb \
<span class="p_header">diff --git a/arch/arm/boot/dts/armada-388-gp.dts b/arch/arm/boot/dts/armada-388-gp.dts</span>
<span class="p_header">index 895fa6cfa15a..563901e0ec07 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/armada-388-gp.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/armada-388-gp.dts</span>
<span class="p_chunk">@@ -75,7 +75,7 @@</span> <span class="p_context"></span>
 					pinctrl-names = &quot;default&quot;;
 					pinctrl-0 = &lt;&amp;pca0_pins&gt;;
 					interrupt-parent = &lt;&amp;gpio0&gt;;
<span class="p_del">-					interrupts = &lt;18 IRQ_TYPE_EDGE_FALLING&gt;;</span>
<span class="p_add">+					interrupts = &lt;18 IRQ_TYPE_LEVEL_LOW&gt;;</span>
 					gpio-controller;
 					#gpio-cells = &lt;2&gt;;
 					interrupt-controller;
<span class="p_chunk">@@ -87,7 +87,7 @@</span> <span class="p_context"></span>
 					compatible = &quot;nxp,pca9555&quot;;
 					pinctrl-names = &quot;default&quot;;
 					interrupt-parent = &lt;&amp;gpio0&gt;;
<span class="p_del">-					interrupts = &lt;18 IRQ_TYPE_EDGE_FALLING&gt;;</span>
<span class="p_add">+					interrupts = &lt;18 IRQ_TYPE_LEVEL_LOW&gt;;</span>
 					gpio-controller;
 					#gpio-cells = &lt;2&gt;;
 					interrupt-controller;
<span class="p_header">diff --git a/arch/arm/boot/dts/sun7i-a20-olinuxino-lime2-emmc.dts b/arch/arm/boot/dts/sun7i-a20-olinuxino-lime2-emmc.dts</span>
<span class="p_header">index 5ea4915f6d75..10d307408f23 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/sun7i-a20-olinuxino-lime2-emmc.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/sun7i-a20-olinuxino-lime2-emmc.dts</span>
<span class="p_chunk">@@ -56,7 +56,7 @@</span> <span class="p_context"></span>
 };
 
 &amp;pio {
<span class="p_del">-	mmc2_pins_nrst: mmc2@0 {</span>
<span class="p_add">+	mmc2_pins_nrst: mmc2-rst-pin {</span>
 		allwinner,pins = &quot;PC16&quot;;
 		allwinner,function = &quot;gpio_out&quot;;
 		allwinner,drive = &lt;SUN4I_PINCTRL_10_MA&gt;;
<span class="p_header">diff --git a/arch/arm/boot/dts/tango4-vantage-1172.dts b/arch/arm/boot/dts/tango4-vantage-1172.dts</span>
<span class="p_header">index 4cab64cb581e..e3a51e3538b7 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/tango4-vantage-1172.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/tango4-vantage-1172.dts</span>
<span class="p_chunk">@@ -21,7 +21,7 @@</span> <span class="p_context"></span>
 };
 
 &amp;eth0 {
<span class="p_del">-	phy-connection-type = &quot;rgmii&quot;;</span>
<span class="p_add">+	phy-connection-type = &quot;rgmii-id&quot;;</span>
 	phy-handle = &lt;&amp;eth0_phy&gt;;
 	#address-cells = &lt;1&gt;;
 	#size-cells = &lt;0&gt;;
<span class="p_header">diff --git a/arch/arm/include/asm/ftrace.h b/arch/arm/include/asm/ftrace.h</span>
<span class="p_header">index bfe2a2f5a644..22b73112b75f 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/ftrace.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/ftrace.h</span>
<span class="p_chunk">@@ -54,6 +54,24 @@</span> <span class="p_context"> static inline void *return_address(unsigned int level)</span>
 
 #define ftrace_return_address(n) return_address(n)
 
<span class="p_add">+#define ARCH_HAS_SYSCALL_MATCH_SYM_NAME</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool arch_syscall_match_sym_name(const char *sym,</span>
<span class="p_add">+					       const char *name)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!strcmp(sym, &quot;sys_mmap2&quot;))</span>
<span class="p_add">+		sym = &quot;sys_mmap_pgoff&quot;;</span>
<span class="p_add">+	else if (!strcmp(sym, &quot;sys_statfs64_wrapper&quot;))</span>
<span class="p_add">+		sym = &quot;sys_statfs64&quot;;</span>
<span class="p_add">+	else if (!strcmp(sym, &quot;sys_fstatfs64_wrapper&quot;))</span>
<span class="p_add">+		sym = &quot;sys_fstatfs64&quot;;</span>
<span class="p_add">+	else if (!strcmp(sym, &quot;sys_arm_fadvise64_64&quot;))</span>
<span class="p_add">+		sym = &quot;sys_fadvise64_64&quot;;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Ignore case since sym may start with &quot;SyS&quot; instead of &quot;sys&quot; */</span>
<span class="p_add">+	return !strcasecmp(sym, name);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* ifndef __ASSEMBLY__ */
 
 #endif /* _ASM_ARM_FTRACE */
<span class="p_header">diff --git a/arch/parisc/kernel/cache.c b/arch/parisc/kernel/cache.c</span>
<span class="p_header">index c721ea2fdbd8..df757c9675e6 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/cache.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/cache.c</span>
<span class="p_chunk">@@ -604,13 +604,12 @@</span> <span class="p_context"> void flush_cache_range(struct vm_area_struct *vma,</span>
 	if (parisc_requires_coherency())
 		flush_tlb_range(vma, start, end);
 
<span class="p_del">-	if ((end - start) &gt;= parisc_cache_flush_threshold) {</span>
<span class="p_add">+	if ((end - start) &gt;= parisc_cache_flush_threshold</span>
<span class="p_add">+	    || vma-&gt;vm_mm-&gt;context != mfsp(3)) {</span>
 		flush_cache_all();
 		return;
 	}
 
<span class="p_del">-	BUG_ON(vma-&gt;vm_mm-&gt;context != mfsp(3));</span>
<span class="p_del">-</span>
 	flush_user_dcache_range_asm(start, end);
 	if (vma-&gt;vm_flags &amp; VM_EXEC)
 		flush_user_icache_range_asm(start, end);
<span class="p_header">diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c</span>
<span class="p_header">index 3c05c311e35e..028a22bfa90c 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/irq.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/irq.c</span>
<span class="p_chunk">@@ -146,6 +146,19 @@</span> <span class="p_context"> notrace unsigned int __check_irq_replay(void)</span>
 
 	/* Clear bit 0 which we wouldn&#39;t clear otherwise */
 	local_paca-&gt;irq_happened &amp;= ~PACA_IRQ_HARD_DIS;
<span class="p_add">+	if (happened &amp; PACA_IRQ_HARD_DIS) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We may have missed a decrementer interrupt if hard disabled.</span>
<span class="p_add">+		 * Check the decrementer register in case we had a rollover</span>
<span class="p_add">+		 * while hard disabled.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!(happened &amp; PACA_IRQ_DEC)) {</span>
<span class="p_add">+			if (decrementer_check_overflow()) {</span>
<span class="p_add">+				local_paca-&gt;irq_happened |= PACA_IRQ_DEC;</span>
<span class="p_add">+				happened |= PACA_IRQ_DEC;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * Force the delivery of pending soft-disabled interrupts on PS3.
<span class="p_chunk">@@ -171,7 +184,7 @@</span> <span class="p_context"> notrace unsigned int __check_irq_replay(void)</span>
 	 * in case we also had a rollover while hard disabled
 	 */
 	local_paca-&gt;irq_happened &amp;= ~PACA_IRQ_DEC;
<span class="p_del">-	if ((happened &amp; PACA_IRQ_DEC) || decrementer_check_overflow())</span>
<span class="p_add">+	if (happened &amp; PACA_IRQ_DEC)</span>
 		return 0x900;
 
 	/* Finally check if an external interrupt happened */
<span class="p_header">diff --git a/arch/powerpc/kernel/ptrace.c b/arch/powerpc/kernel/ptrace.c</span>
<span class="p_header">index 5c8f12fe9721..dcbb9144c16d 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/ptrace.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/ptrace.c</span>
<span class="p_chunk">@@ -127,12 +127,19 @@</span> <span class="p_context"> static void flush_tmregs_to_thread(struct task_struct *tsk)</span>
 	 * If task is not current, it will have been flushed already to
 	 * it&#39;s thread_struct during __switch_to().
 	 *
<span class="p_del">-	 * A reclaim flushes ALL the state.</span>
<span class="p_add">+	 * A reclaim flushes ALL the state or if not in TM save TM SPRs</span>
<span class="p_add">+	 * in the appropriate thread structures from live.</span>
 	 */
 
<span class="p_del">-	if (tsk == current &amp;&amp; MSR_TM_SUSPENDED(mfmsr()))</span>
<span class="p_del">-		tm_reclaim_current(TM_CAUSE_SIGNAL);</span>
<span class="p_add">+	if (tsk != current)</span>
<span class="p_add">+		return;</span>
 
<span class="p_add">+	if (MSR_TM_SUSPENDED(mfmsr())) {</span>
<span class="p_add">+		tm_reclaim_current(TM_CAUSE_SIGNAL);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		tm_enable();</span>
<span class="p_add">+		tm_save_sprs(&amp;(tsk-&gt;thread));</span>
<span class="p_add">+	}</span>
 }
 #else
 static inline void flush_tmregs_to_thread(struct task_struct *tsk) { }
<span class="p_header">diff --git a/arch/sparc/include/asm/trap_block.h b/arch/sparc/include/asm/trap_block.h</span>
<span class="p_header">index ec9c04de3664..ff05992dae7a 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/trap_block.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/trap_block.h</span>
<span class="p_chunk">@@ -54,6 +54,7 @@</span> <span class="p_context"> extern struct trap_per_cpu trap_block[NR_CPUS];</span>
 void init_cur_cpu_trap(struct thread_info *);
 void setup_tba(void);
 extern int ncpus_probed;
<span class="p_add">+extern u64 cpu_mondo_counter[NR_CPUS];</span>
 
 unsigned long real_hard_smp_processor_id(void);
 
<span class="p_header">diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">index d5807d24b98f..2deb89ef1d5f 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/smp_64.c</span>
<span class="p_chunk">@@ -621,22 +621,48 @@</span> <span class="p_context"> static void cheetah_xcall_deliver(struct trap_per_cpu *tb, int cnt)</span>
 	}
 }
 
<span class="p_del">-/* Multi-cpu list version.  */</span>
<span class="p_add">+#define	CPU_MONDO_COUNTER(cpuid)	(cpu_mondo_counter[cpuid])</span>
<span class="p_add">+#define	MONDO_USEC_WAIT_MIN		2</span>
<span class="p_add">+#define	MONDO_USEC_WAIT_MAX		100</span>
<span class="p_add">+#define	MONDO_RETRY_LIMIT		500000</span>
<span class="p_add">+</span>
<span class="p_add">+/* Multi-cpu list version.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Deliver xcalls to &#39;cnt&#39; number of cpus in &#39;cpu_list&#39;.</span>
<span class="p_add">+ * Sometimes not all cpus receive the mondo, requiring us to re-send</span>
<span class="p_add">+ * the mondo until all cpus have received, or cpus are truly stuck</span>
<span class="p_add">+ * unable to receive mondo, and we timeout.</span>
<span class="p_add">+ * Occasionally a target cpu strand is borrowed briefly by hypervisor to</span>
<span class="p_add">+ * perform guest service, such as PCIe error handling. Consider the</span>
<span class="p_add">+ * service time, 1 second overall wait is reasonable for 1 cpu.</span>
<span class="p_add">+ * Here two in-between mondo check wait time are defined: 2 usec for</span>
<span class="p_add">+ * single cpu quick turn around and up to 100usec for large cpu count.</span>
<span class="p_add">+ * Deliver mondo to large number of cpus could take longer, we adjusts</span>
<span class="p_add">+ * the retry count as long as target cpus are making forward progress.</span>
<span class="p_add">+ */</span>
 static void hypervisor_xcall_deliver(struct trap_per_cpu *tb, int cnt)
 {
<span class="p_del">-	int retries, this_cpu, prev_sent, i, saw_cpu_error;</span>
<span class="p_add">+	int this_cpu, tot_cpus, prev_sent, i, rem;</span>
<span class="p_add">+	int usec_wait, retries, tot_retries;</span>
<span class="p_add">+	u16 first_cpu = 0xffff;</span>
<span class="p_add">+	unsigned long xc_rcvd = 0;</span>
 	unsigned long status;
<span class="p_add">+	int ecpuerror_id = 0;</span>
<span class="p_add">+	int enocpu_id = 0;</span>
 	u16 *cpu_list;
<span class="p_add">+	u16 cpu;</span>
 
 	this_cpu = smp_processor_id();
<span class="p_del">-</span>
 	cpu_list = __va(tb-&gt;cpu_list_pa);
<span class="p_del">-</span>
<span class="p_del">-	saw_cpu_error = 0;</span>
<span class="p_del">-	retries = 0;</span>
<span class="p_add">+	usec_wait = cnt * MONDO_USEC_WAIT_MIN;</span>
<span class="p_add">+	if (usec_wait &gt; MONDO_USEC_WAIT_MAX)</span>
<span class="p_add">+		usec_wait = MONDO_USEC_WAIT_MAX;</span>
<span class="p_add">+	retries = tot_retries = 0;</span>
<span class="p_add">+	tot_cpus = cnt;</span>
 	prev_sent = 0;
<span class="p_add">+</span>
 	do {
<span class="p_del">-		int forward_progress, n_sent;</span>
<span class="p_add">+		int n_sent, mondo_delivered, target_cpu_busy;</span>
 
 		status = sun4v_cpu_mondo_send(cnt,
 					      tb-&gt;cpu_list_pa,
<span class="p_chunk">@@ -644,94 +670,113 @@</span> <span class="p_context"> static void hypervisor_xcall_deliver(struct trap_per_cpu *tb, int cnt)</span>
 
 		/* HV_EOK means all cpus received the xcall, we&#39;re done.  */
 		if (likely(status == HV_EOK))
<span class="p_del">-			break;</span>
<span class="p_add">+			goto xcall_done;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If not these non-fatal errors, panic */</span>
<span class="p_add">+		if (unlikely((status != HV_EWOULDBLOCK) &amp;&amp;</span>
<span class="p_add">+			(status != HV_ECPUERROR) &amp;&amp;</span>
<span class="p_add">+			(status != HV_ENOCPU)))</span>
<span class="p_add">+			goto fatal_errors;</span>
 
 		/* First, see if we made any forward progress.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Go through the cpu_list, count the target cpus that have</span>
<span class="p_add">+		 * received our mondo (n_sent), and those that did not (rem).</span>
<span class="p_add">+		 * Re-pack cpu_list with the cpus remain to be retried in the</span>
<span class="p_add">+		 * front - this simplifies tracking the truly stalled cpus.</span>
 		 *
 		 * The hypervisor indicates successful sends by setting
 		 * cpu list entries to the value 0xffff.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * EWOULDBLOCK means some target cpus did not receive the</span>
<span class="p_add">+		 * mondo and retry usually helps.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * ECPUERROR means at least one target cpu is in error state,</span>
<span class="p_add">+		 * it&#39;s usually safe to skip the faulty cpu and retry.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * ENOCPU means one of the target cpu doesn&#39;t belong to the</span>
<span class="p_add">+		 * domain, perhaps offlined which is unexpected, but not</span>
<span class="p_add">+		 * fatal and it&#39;s okay to skip the offlined cpu.</span>
 		 */
<span class="p_add">+		rem = 0;</span>
 		n_sent = 0;
 		for (i = 0; i &lt; cnt; i++) {
<span class="p_del">-			if (likely(cpu_list[i] == 0xffff))</span>
<span class="p_add">+			cpu = cpu_list[i];</span>
<span class="p_add">+			if (likely(cpu == 0xffff)) {</span>
 				n_sent++;
<span class="p_add">+			} else if ((status == HV_ECPUERROR) &amp;&amp;</span>
<span class="p_add">+				(sun4v_cpu_state(cpu) == HV_CPU_STATE_ERROR)) {</span>
<span class="p_add">+				ecpuerror_id = cpu + 1;</span>
<span class="p_add">+			} else if (status == HV_ENOCPU &amp;&amp; !cpu_online(cpu)) {</span>
<span class="p_add">+				enocpu_id = cpu + 1;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				cpu_list[rem++] = cpu;</span>
<span class="p_add">+			}</span>
 		}
 
<span class="p_del">-		forward_progress = 0;</span>
<span class="p_del">-		if (n_sent &gt; prev_sent)</span>
<span class="p_del">-			forward_progress = 1;</span>
<span class="p_add">+		/* No cpu remained, we&#39;re done. */</span>
<span class="p_add">+		if (rem == 0)</span>
<span class="p_add">+			break;</span>
 
<span class="p_del">-		prev_sent = n_sent;</span>
<span class="p_add">+		/* Otherwise, update the cpu count for retry. */</span>
<span class="p_add">+		cnt = rem;</span>
 
<span class="p_del">-		/* If we get a HV_ECPUERROR, then one or more of the cpus</span>
<span class="p_del">-		 * in the list are in error state.  Use the cpu_state()</span>
<span class="p_del">-		 * hypervisor call to find out which cpus are in error state.</span>
<span class="p_add">+		/* Record the overall number of mondos received by the</span>
<span class="p_add">+		 * first of the remaining cpus.</span>
 		 */
<span class="p_del">-		if (unlikely(status == HV_ECPUERROR)) {</span>
<span class="p_del">-			for (i = 0; i &lt; cnt; i++) {</span>
<span class="p_del">-				long err;</span>
<span class="p_del">-				u16 cpu;</span>
<span class="p_add">+		if (first_cpu != cpu_list[0]) {</span>
<span class="p_add">+			first_cpu = cpu_list[0];</span>
<span class="p_add">+			xc_rcvd = CPU_MONDO_COUNTER(first_cpu);</span>
<span class="p_add">+		}</span>
 
<span class="p_del">-				cpu = cpu_list[i];</span>
<span class="p_del">-				if (cpu == 0xffff)</span>
<span class="p_del">-					continue;</span>
<span class="p_add">+		/* Was any mondo delivered successfully? */</span>
<span class="p_add">+		mondo_delivered = (n_sent &gt; prev_sent);</span>
<span class="p_add">+		prev_sent = n_sent;</span>
 
<span class="p_del">-				err = sun4v_cpu_state(cpu);</span>
<span class="p_del">-				if (err == HV_CPU_STATE_ERROR) {</span>
<span class="p_del">-					saw_cpu_error = (cpu + 1);</span>
<span class="p_del">-					cpu_list[i] = 0xffff;</span>
<span class="p_del">-				}</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else if (unlikely(status != HV_EWOULDBLOCK))</span>
<span class="p_del">-			goto fatal_mondo_error;</span>
<span class="p_add">+		/* or, was any target cpu busy processing other mondos? */</span>
<span class="p_add">+		target_cpu_busy = (xc_rcvd &lt; CPU_MONDO_COUNTER(first_cpu));</span>
<span class="p_add">+		xc_rcvd = CPU_MONDO_COUNTER(first_cpu);</span>
 
<span class="p_del">-		/* Don&#39;t bother rewriting the CPU list, just leave the</span>
<span class="p_del">-		 * 0xffff and non-0xffff entries in there and the</span>
<span class="p_del">-		 * hypervisor will do the right thing.</span>
<span class="p_del">-		 *</span>
<span class="p_del">-		 * Only advance timeout state if we didn&#39;t make any</span>
<span class="p_del">-		 * forward progress.</span>
<span class="p_add">+		/* Retry count is for no progress. If we&#39;re making progress,</span>
<span class="p_add">+		 * reset the retry count.</span>
 		 */
<span class="p_del">-		if (unlikely(!forward_progress)) {</span>
<span class="p_del">-			if (unlikely(++retries &gt; 10000))</span>
<span class="p_del">-				goto fatal_mondo_timeout;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* Delay a little bit to let other cpus catch up</span>
<span class="p_del">-			 * on their cpu mondo queue work.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			udelay(2 * cnt);</span>
<span class="p_add">+		if (likely(mondo_delivered || target_cpu_busy)) {</span>
<span class="p_add">+			tot_retries += retries;</span>
<span class="p_add">+			retries = 0;</span>
<span class="p_add">+		} else if (unlikely(retries &gt; MONDO_RETRY_LIMIT)) {</span>
<span class="p_add">+			goto fatal_mondo_timeout;</span>
 		}
<span class="p_del">-	} while (1);</span>
 
<span class="p_del">-	if (unlikely(saw_cpu_error))</span>
<span class="p_del">-		goto fatal_mondo_cpu_error;</span>
<span class="p_add">+		/* Delay a little bit to let other cpus catch up on</span>
<span class="p_add">+		 * their cpu mondo queue work.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!mondo_delivered)</span>
<span class="p_add">+			udelay(usec_wait);</span>
 
<span class="p_del">-	return;</span>
<span class="p_add">+		retries++;</span>
<span class="p_add">+	} while (1);</span>
 
<span class="p_del">-fatal_mondo_cpu_error:</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: SUN4V mondo cpu error, some target cpus &quot;</span>
<span class="p_del">-	       &quot;(including %d) were in error state\n&quot;,</span>
<span class="p_del">-	       this_cpu, saw_cpu_error - 1);</span>
<span class="p_add">+xcall_done:</span>
<span class="p_add">+	if (unlikely(ecpuerror_id &gt; 0)) {</span>
<span class="p_add">+		pr_crit(&quot;CPU[%d]: SUN4V mondo cpu error, target cpu(%d) was in error state\n&quot;,</span>
<span class="p_add">+		       this_cpu, ecpuerror_id - 1);</span>
<span class="p_add">+	} else if (unlikely(enocpu_id &gt; 0)) {</span>
<span class="p_add">+		pr_crit(&quot;CPU[%d]: SUN4V mondo cpu error, target cpu(%d) does not belong to the domain\n&quot;,</span>
<span class="p_add">+		       this_cpu, enocpu_id - 1);</span>
<span class="p_add">+	}</span>
 	return;
 
<span class="p_add">+fatal_errors:</span>
<span class="p_add">+	/* fatal errors include bad alignment, etc */</span>
<span class="p_add">+	pr_crit(&quot;CPU[%d]: Args were cnt(%d) cpulist_pa(%lx) mondo_block_pa(%lx)\n&quot;,</span>
<span class="p_add">+	       this_cpu, tot_cpus, tb-&gt;cpu_list_pa, tb-&gt;cpu_mondo_block_pa);</span>
<span class="p_add">+	panic(&quot;Unexpected SUN4V mondo error %lu\n&quot;, status);</span>
<span class="p_add">+</span>
 fatal_mondo_timeout:
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: SUN4V mondo timeout, no forward &quot;</span>
<span class="p_del">-	       &quot; progress after %d retries.\n&quot;,</span>
<span class="p_del">-	       this_cpu, retries);</span>
<span class="p_del">-	goto dump_cpu_list_and_out;</span>
<span class="p_del">-</span>
<span class="p_del">-fatal_mondo_error:</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: Unexpected SUN4V mondo error %lu\n&quot;,</span>
<span class="p_del">-	       this_cpu, status);</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: Args were cnt(%d) cpulist_pa(%lx) &quot;</span>
<span class="p_del">-	       &quot;mondo_block_pa(%lx)\n&quot;,</span>
<span class="p_del">-	       this_cpu, cnt, tb-&gt;cpu_list_pa, tb-&gt;cpu_mondo_block_pa);</span>
<span class="p_del">-</span>
<span class="p_del">-dump_cpu_list_and_out:</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: CPU list [ &quot;, this_cpu);</span>
<span class="p_del">-	for (i = 0; i &lt; cnt; i++)</span>
<span class="p_del">-		printk(&quot;%u &quot;, cpu_list[i]);</span>
<span class="p_del">-	printk(&quot;]\n&quot;);</span>
<span class="p_add">+	/* some cpus being non-responsive to the cpu mondo */</span>
<span class="p_add">+	pr_crit(&quot;CPU[%d]: SUN4V mondo timeout, cpu(%d) made no forward progress after %d retries. Total target cpus(%d).\n&quot;,</span>
<span class="p_add">+	       this_cpu, first_cpu, (tot_retries + retries), tot_cpus);</span>
<span class="p_add">+	panic(&quot;SUN4V mondo timeout panic\n&quot;);</span>
 }
 
 static void (*xcall_deliver_impl)(struct trap_per_cpu *, int);
<span class="p_header">diff --git a/arch/sparc/kernel/sun4v_ivec.S b/arch/sparc/kernel/sun4v_ivec.S</span>
<span class="p_header">index 559bc5e9c199..34631995859a 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/sun4v_ivec.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/sun4v_ivec.S</span>
<span class="p_chunk">@@ -26,6 +26,21 @@</span> <span class="p_context"> sun4v_cpu_mondo:</span>
 	ldxa	[%g0] ASI_SCRATCHPAD, %g4
 	sub	%g4, TRAP_PER_CPU_FAULT_INFO, %g4
 
<span class="p_add">+	/* Get smp_processor_id() into %g3 */</span>
<span class="p_add">+	sethi	%hi(trap_block), %g5</span>
<span class="p_add">+	or	%g5, %lo(trap_block), %g5</span>
<span class="p_add">+	sub	%g4, %g5, %g3</span>
<span class="p_add">+	srlx	%g3, TRAP_BLOCK_SZ_SHIFT, %g3</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Increment cpu_mondo_counter[smp_processor_id()] */</span>
<span class="p_add">+	sethi	%hi(cpu_mondo_counter), %g5</span>
<span class="p_add">+	or	%g5, %lo(cpu_mondo_counter), %g5</span>
<span class="p_add">+	sllx	%g3, 3, %g3</span>
<span class="p_add">+	add	%g5, %g3, %g5</span>
<span class="p_add">+	ldx	[%g5], %g3</span>
<span class="p_add">+	add	%g3, 1, %g3</span>
<span class="p_add">+	stx	%g3, [%g5]</span>
<span class="p_add">+</span>
 	/* Get CPU mondo queue base phys address into %g7.  */
 	ldx	[%g4 + TRAP_PER_CPU_CPU_MONDO_PA], %g7
 
<span class="p_header">diff --git a/arch/sparc/kernel/traps_64.c b/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">index d44fb806bbd7..32dafb920908 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/traps_64.c</span>
<span class="p_chunk">@@ -2732,6 +2732,7 @@</span> <span class="p_context"> void do_getpsr(struct pt_regs *regs)</span>
 	}
 }
 
<span class="p_add">+u64 cpu_mondo_counter[NR_CPUS] = {0};</span>
 struct trap_per_cpu trap_block[NR_CPUS];
 EXPORT_SYMBOL(trap_block);
 
<span class="p_header">diff --git a/arch/sparc/lib/U3memcpy.S b/arch/sparc/lib/U3memcpy.S</span>
<span class="p_header">index 54f98706b03b..5a8cb37f0a3b 100644</span>
<span class="p_header">--- a/arch/sparc/lib/U3memcpy.S</span>
<span class="p_header">+++ b/arch/sparc/lib/U3memcpy.S</span>
<span class="p_chunk">@@ -145,13 +145,13 @@</span> <span class="p_context"> ENDPROC(U3_retl_o2_plus_GS_plus_0x08)</span>
 ENTRY(U3_retl_o2_and_7_plus_GS)
 	and	%o2, 7, %o2
 	retl
<span class="p_del">-	 add	%o2, GLOBAL_SPARE, %o2</span>
<span class="p_add">+	 add	%o2, GLOBAL_SPARE, %o0</span>
 ENDPROC(U3_retl_o2_and_7_plus_GS)
 ENTRY(U3_retl_o2_and_7_plus_GS_plus_8)
 	add	GLOBAL_SPARE, 8, GLOBAL_SPARE
 	and	%o2, 7, %o2
 	retl
<span class="p_del">-	 add	%o2, GLOBAL_SPARE, %o2</span>
<span class="p_add">+	 add	%o2, GLOBAL_SPARE, %o0</span>
 ENDPROC(U3_retl_o2_and_7_plus_GS_plus_8)
 #endif
 
<span class="p_header">diff --git a/arch/x86/boot/string.c b/arch/x86/boot/string.c</span>
<span class="p_header">index cc3bd583dce1..9e240fcba784 100644</span>
<span class="p_header">--- a/arch/x86/boot/string.c</span>
<span class="p_header">+++ b/arch/x86/boot/string.c</span>
<span class="p_chunk">@@ -14,6 +14,7 @@</span> <span class="p_context"></span>
 
 #include &lt;linux/types.h&gt;
 #include &quot;ctype.h&quot;
<span class="p_add">+#include &quot;string.h&quot;</span>
 
 int memcmp(const void *s1, const void *s2, size_t len)
 {
<span class="p_header">diff --git a/arch/x86/boot/string.h b/arch/x86/boot/string.h</span>
<span class="p_header">index 725e820602b1..113588ddb43f 100644</span>
<span class="p_header">--- a/arch/x86/boot/string.h</span>
<span class="p_header">+++ b/arch/x86/boot/string.h</span>
<span class="p_chunk">@@ -18,4 +18,13 @@</span> <span class="p_context"> int memcmp(const void *s1, const void *s2, size_t len);</span>
 #define memset(d,c,l) __builtin_memset(d,c,l)
 #define memcmp	__builtin_memcmp
 
<span class="p_add">+extern int strcmp(const char *str1, const char *str2);</span>
<span class="p_add">+extern int strncmp(const char *cs, const char *ct, size_t count);</span>
<span class="p_add">+extern size_t strlen(const char *s);</span>
<span class="p_add">+extern char *strstr(const char *s1, const char *s2);</span>
<span class="p_add">+extern size_t strnlen(const char *s, size_t maxlen);</span>
<span class="p_add">+extern unsigned int atou(const char *s);</span>
<span class="p_add">+extern unsigned long long simple_strtoull(const char *cp, char **endp,</span>
<span class="p_add">+					  unsigned int base);</span>
<span class="p_add">+</span>
 #endif /* BOOT_STRING_H */
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 9cf697ceedbf..55ffd9dc2258 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -152,6 +152,8 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 		if (hlist_unhashed(&amp;n.link))
 			break;
 
<span class="p_add">+		rcu_irq_exit();</span>
<span class="p_add">+</span>
 		if (!n.halted) {
 			local_irq_enable();
 			schedule();
<span class="p_chunk">@@ -160,11 +162,11 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 			/*
 			 * We cannot reschedule. So halt.
 			 */
<span class="p_del">-			rcu_irq_exit();</span>
 			native_safe_halt();
 			local_irq_disable();
<span class="p_del">-			rcu_irq_enter();</span>
 		}
<span class="p_add">+</span>
<span class="p_add">+		rcu_irq_enter();</span>
 	}
 	if (!n.halted)
 		finish_swait(&amp;n.wq, &amp;wait);
<span class="p_header">diff --git a/drivers/ata/libata-scsi.c b/drivers/ata/libata-scsi.c</span>
<span class="p_header">index 8e575fbdf31d..e3e10e8f6f6a 100644</span>
<span class="p_header">--- a/drivers/ata/libata-scsi.c</span>
<span class="p_header">+++ b/drivers/ata/libata-scsi.c</span>
<span class="p_chunk">@@ -2971,10 +2971,12 @@</span> <span class="p_context"> static unsigned int atapi_xlat(struct ata_queued_cmd *qc)</span>
 static struct ata_device *ata_find_dev(struct ata_port *ap, int devno)
 {
 	if (!sata_pmp_attached(ap)) {
<span class="p_del">-		if (likely(devno &lt; ata_link_max_devices(&amp;ap-&gt;link)))</span>
<span class="p_add">+		if (likely(devno &gt;= 0 &amp;&amp;</span>
<span class="p_add">+			   devno &lt; ata_link_max_devices(&amp;ap-&gt;link)))</span>
 			return &amp;ap-&gt;link.device[devno];
 	} else {
<span class="p_del">-		if (likely(devno &lt; ap-&gt;nr_pmp_links))</span>
<span class="p_add">+		if (likely(devno &gt;= 0 &amp;&amp;</span>
<span class="p_add">+			   devno &lt; ap-&gt;nr_pmp_links))</span>
 			return &amp;ap-&gt;pmp_link[devno].device[0];
 	}
 
<span class="p_header">diff --git a/drivers/base/property.c b/drivers/base/property.c</span>
<span class="p_header">index 43a36d68c3fd..06f66687fe0b 100644</span>
<span class="p_header">--- a/drivers/base/property.c</span>
<span class="p_header">+++ b/drivers/base/property.c</span>
<span class="p_chunk">@@ -182,11 +182,12 @@</span> <span class="p_context"> static int pset_prop_read_string(struct property_set *pset,</span>
 	return 0;
 }
 
<span class="p_del">-static inline struct fwnode_handle *dev_fwnode(struct device *dev)</span>
<span class="p_add">+struct fwnode_handle *dev_fwnode(struct device *dev)</span>
 {
 	return IS_ENABLED(CONFIG_OF) &amp;&amp; dev-&gt;of_node ?
 		&amp;dev-&gt;of_node-&gt;fwnode : dev-&gt;fwnode;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(dev_fwnode);</span>
 
 /**
  * device_property_present - check if a property of a device is present
<span class="p_header">diff --git a/drivers/block/nbd.c b/drivers/block/nbd.c</span>
<span class="p_header">index c9441f9d4585..98b767d3171e 100644</span>
<span class="p_header">--- a/drivers/block/nbd.c</span>
<span class="p_header">+++ b/drivers/block/nbd.c</span>
<span class="p_chunk">@@ -929,6 +929,7 @@</span> <span class="p_context"> static int __init nbd_init(void)</span>
 		return -ENOMEM;
 
 	for (i = 0; i &lt; nbds_max; i++) {
<span class="p_add">+		struct request_queue *q;</span>
 		struct gendisk *disk = alloc_disk(1 &lt;&lt; part_shift);
 		if (!disk)
 			goto out;
<span class="p_chunk">@@ -954,12 +955,13 @@</span> <span class="p_context"> static int __init nbd_init(void)</span>
 		 * every gendisk to have its very own request_queue struct.
 		 * These structs are big so we dynamically allocate them.
 		 */
<span class="p_del">-		disk-&gt;queue = blk_mq_init_queue(&amp;nbd_dev[i].tag_set);</span>
<span class="p_del">-		if (!disk-&gt;queue) {</span>
<span class="p_add">+		q = blk_mq_init_queue(&amp;nbd_dev[i].tag_set);</span>
<span class="p_add">+		if (IS_ERR(q)) {</span>
 			blk_mq_free_tag_set(&amp;nbd_dev[i].tag_set);
 			put_disk(disk);
 			goto out;
 		}
<span class="p_add">+		disk-&gt;queue = q;</span>
 
 		/*
 		 * Tell the block layer that we are not a rotational device
<span class="p_header">diff --git a/drivers/block/virtio_blk.c b/drivers/block/virtio_blk.c</span>
<span class="p_header">index 3c3b8f601469..10332c24f961 100644</span>
<span class="p_header">--- a/drivers/block/virtio_blk.c</span>
<span class="p_header">+++ b/drivers/block/virtio_blk.c</span>
<span class="p_chunk">@@ -630,11 +630,12 @@</span> <span class="p_context"> static int virtblk_probe(struct virtio_device *vdev)</span>
 	if (err)
 		goto out_put_disk;
 
<span class="p_del">-	q = vblk-&gt;disk-&gt;queue = blk_mq_init_queue(&amp;vblk-&gt;tag_set);</span>
<span class="p_add">+	q = blk_mq_init_queue(&amp;vblk-&gt;tag_set);</span>
 	if (IS_ERR(q)) {
 		err = -ENOMEM;
 		goto out_free_tags;
 	}
<span class="p_add">+	vblk-&gt;disk-&gt;queue = q;</span>
 
 	q-&gt;queuedata = vblk;
 
<span class="p_header">diff --git a/drivers/clk/samsung/clk-exynos5420.c b/drivers/clk/samsung/clk-exynos5420.c</span>
<span class="p_header">index 8c8b495cbf0d..cdc092a1d9ef 100644</span>
<span class="p_header">--- a/drivers/clk/samsung/clk-exynos5420.c</span>
<span class="p_header">+++ b/drivers/clk/samsung/clk-exynos5420.c</span>
<span class="p_chunk">@@ -586,7 +586,7 @@</span> <span class="p_context"> static const struct samsung_gate_clock exynos5800_gate_clks[] __initconst = {</span>
 	GATE(CLK_ACLK550_CAM, &quot;aclk550_cam&quot;, &quot;mout_user_aclk550_cam&quot;,
 				GATE_BUS_TOP, 24, 0, 0),
 	GATE(CLK_ACLK432_SCALER, &quot;aclk432_scaler&quot;, &quot;mout_user_aclk432_scaler&quot;,
<span class="p_del">-				GATE_BUS_TOP, 27, 0, 0),</span>
<span class="p_add">+				GATE_BUS_TOP, 27, CLK_IS_CRITICAL, 0),</span>
 };
 
 static const struct samsung_mux_clock exynos5420_mux_clks[] __initconst = {
<span class="p_chunk">@@ -956,20 +956,20 @@</span> <span class="p_context"> static const struct samsung_gate_clock exynos5x_gate_clks[] __initconst = {</span>
 	GATE(CLK_SMMU_G2D, &quot;smmu_g2d&quot;, &quot;aclk333_g2d&quot;, GATE_IP_G2D, 7, 0, 0),
 
 	GATE(0, &quot;aclk200_fsys&quot;, &quot;mout_user_aclk200_fsys&quot;,
<span class="p_del">-			GATE_BUS_FSYS0, 9, CLK_IGNORE_UNUSED, 0),</span>
<span class="p_add">+			GATE_BUS_FSYS0, 9, CLK_IS_CRITICAL, 0),</span>
 	GATE(0, &quot;aclk200_fsys2&quot;, &quot;mout_user_aclk200_fsys2&quot;,
 			GATE_BUS_FSYS0, 10, CLK_IGNORE_UNUSED, 0),
 
 	GATE(0, &quot;aclk333_g2d&quot;, &quot;mout_user_aclk333_g2d&quot;,
 			GATE_BUS_TOP, 0, CLK_IGNORE_UNUSED, 0),
 	GATE(0, &quot;aclk266_g2d&quot;, &quot;mout_user_aclk266_g2d&quot;,
<span class="p_del">-			GATE_BUS_TOP, 1, CLK_IGNORE_UNUSED, 0),</span>
<span class="p_add">+			GATE_BUS_TOP, 1, CLK_IS_CRITICAL, 0),</span>
 	GATE(0, &quot;aclk300_jpeg&quot;, &quot;mout_user_aclk300_jpeg&quot;,
 			GATE_BUS_TOP, 4, CLK_IGNORE_UNUSED, 0),
 	GATE(0, &quot;aclk333_432_isp0&quot;, &quot;mout_user_aclk333_432_isp0&quot;,
 			GATE_BUS_TOP, 5, 0, 0),
 	GATE(0, &quot;aclk300_gscl&quot;, &quot;mout_user_aclk300_gscl&quot;,
<span class="p_del">-			GATE_BUS_TOP, 6, CLK_IGNORE_UNUSED, 0),</span>
<span class="p_add">+			GATE_BUS_TOP, 6, CLK_IS_CRITICAL, 0),</span>
 	GATE(0, &quot;aclk333_432_gscl&quot;, &quot;mout_user_aclk333_432_gscl&quot;,
 			GATE_BUS_TOP, 7, CLK_IGNORE_UNUSED, 0),
 	GATE(0, &quot;aclk333_432_isp&quot;, &quot;mout_user_aclk333_432_isp&quot;,
<span class="p_chunk">@@ -983,20 +983,20 @@</span> <span class="p_context"> static const struct samsung_gate_clock exynos5x_gate_clks[] __initconst = {</span>
 	GATE(0, &quot;aclk166&quot;, &quot;mout_user_aclk166&quot;,
 			GATE_BUS_TOP, 14, CLK_IGNORE_UNUSED, 0),
 	GATE(CLK_ACLK333, &quot;aclk333&quot;, &quot;mout_user_aclk333&quot;,
<span class="p_del">-			GATE_BUS_TOP, 15, CLK_IGNORE_UNUSED, 0),</span>
<span class="p_add">+			GATE_BUS_TOP, 15, CLK_IS_CRITICAL, 0),</span>
 	GATE(0, &quot;aclk400_isp&quot;, &quot;mout_user_aclk400_isp&quot;,
 			GATE_BUS_TOP, 16, 0, 0),
 	GATE(0, &quot;aclk400_mscl&quot;, &quot;mout_user_aclk400_mscl&quot;,
 			GATE_BUS_TOP, 17, 0, 0),
 	GATE(0, &quot;aclk200_disp1&quot;, &quot;mout_user_aclk200_disp1&quot;,
<span class="p_del">-			GATE_BUS_TOP, 18, 0, 0),</span>
<span class="p_add">+			GATE_BUS_TOP, 18, CLK_IS_CRITICAL, 0),</span>
 	GATE(CLK_SCLK_MPHY_IXTAL24, &quot;sclk_mphy_ixtal24&quot;, &quot;mphy_refclk_ixtal24&quot;,
 			GATE_BUS_TOP, 28, 0, 0),
 	GATE(CLK_SCLK_HSIC_12M, &quot;sclk_hsic_12m&quot;, &quot;ff_hsic_12m&quot;,
 			GATE_BUS_TOP, 29, 0, 0),
 
 	GATE(0, &quot;aclk300_disp1&quot;, &quot;mout_user_aclk300_disp1&quot;,
<span class="p_del">-			SRC_MASK_TOP2, 24, 0, 0),</span>
<span class="p_add">+			SRC_MASK_TOP2, 24, CLK_IS_CRITICAL, 0),</span>
 
 	GATE(CLK_MAU_EPLL, &quot;mau_epll&quot;, &quot;mout_mau_epll_clk&quot;,
 			SRC_MASK_TOP7, 20, 0, 0),
<span class="p_header">diff --git a/drivers/gpio/gpiolib.c b/drivers/gpio/gpiolib.c</span>
<span class="p_header">index f2bb5122d2c2..063d176baa24 100644</span>
<span class="p_header">--- a/drivers/gpio/gpiolib.c</span>
<span class="p_header">+++ b/drivers/gpio/gpiolib.c</span>
<span class="p_chunk">@@ -703,24 +703,23 @@</span> <span class="p_context"> static irqreturn_t lineevent_irq_thread(int irq, void *p)</span>
 {
 	struct lineevent_state *le = p;
 	struct gpioevent_data ge;
<span class="p_del">-	int ret;</span>
<span class="p_add">+	int ret, level;</span>
 
 	ge.timestamp = ktime_get_real_ns();
<span class="p_add">+	level = gpiod_get_value_cansleep(le-&gt;desc);</span>
 
 	if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_RISING_EDGE
 	    &amp;&amp; le-&gt;eflags &amp; GPIOEVENT_REQUEST_FALLING_EDGE) {
<span class="p_del">-		int level = gpiod_get_value_cansleep(le-&gt;desc);</span>
<span class="p_del">-</span>
 		if (level)
 			/* Emit low-to-high event */
 			ge.id = GPIOEVENT_EVENT_RISING_EDGE;
 		else
 			/* Emit high-to-low event */
 			ge.id = GPIOEVENT_EVENT_FALLING_EDGE;
<span class="p_del">-	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_RISING_EDGE) {</span>
<span class="p_add">+	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_RISING_EDGE &amp;&amp; level) {</span>
 		/* Emit low-to-high event */
 		ge.id = GPIOEVENT_EVENT_RISING_EDGE;
<span class="p_del">-	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_FALLING_EDGE) {</span>
<span class="p_add">+	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_FALLING_EDGE &amp;&amp; !level) {</span>
 		/* Emit high-to-low event */
 		ge.id = GPIOEVENT_EVENT_FALLING_EDGE;
 	} else {
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/si.c b/drivers/gpu/drm/amd/amdgpu/si.c</span>
<span class="p_header">index dc9511c5ecb8..327bdf13e8bc 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/si.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/si.c</span>
<span class="p_chunk">@@ -1301,6 +1301,7 @@</span> <span class="p_context"> static void si_init_golden_registers(struct amdgpu_device *adev)</span>
 		amdgpu_program_register_sequence(adev,
 						 pitcairn_mgcg_cgcg_init,
 						 (const u32)ARRAY_SIZE(pitcairn_mgcg_cgcg_init));
<span class="p_add">+		break;</span>
 	case CHIP_VERDE:
 		amdgpu_program_register_sequence(adev,
 						 verde_golden_registers,
<span class="p_chunk">@@ -1325,6 +1326,7 @@</span> <span class="p_context"> static void si_init_golden_registers(struct amdgpu_device *adev)</span>
 		amdgpu_program_register_sequence(adev,
 						 oland_mgcg_cgcg_init,
 						 (const u32)ARRAY_SIZE(oland_mgcg_cgcg_init));
<span class="p_add">+		break;</span>
 	case CHIP_HAINAN:
 		amdgpu_program_register_sequence(adev,
 						 hainan_golden_registers,
<span class="p_header">diff --git a/drivers/gpu/drm/virtio/virtgpu_fb.c b/drivers/gpu/drm/virtio/virtgpu_fb.c</span>
<span class="p_header">index 2242a80866a9..dc2976c2bed3 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/virtio/virtgpu_fb.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/virtio/virtgpu_fb.c</span>
<span class="p_chunk">@@ -337,7 +337,7 @@</span> <span class="p_context"> static int virtio_gpufb_create(struct drm_fb_helper *helper,</span>
 	info-&gt;fbops = &amp;virtio_gpufb_ops;
 	info-&gt;pixmap.flags = FB_PIXMAP_SYSTEM;
 
<span class="p_del">-	info-&gt;screen_base = obj-&gt;vmap;</span>
<span class="p_add">+	info-&gt;screen_buffer = obj-&gt;vmap;</span>
 	info-&gt;screen_size = obj-&gt;gem_base.size;
 	drm_fb_helper_fill_fix(info, fb-&gt;pitches[0], fb-&gt;depth);
 	drm_fb_helper_fill_var(info, &amp;vfbdev-&gt;helper,
<span class="p_header">diff --git a/drivers/infiniband/hw/cxgb4/cm.c b/drivers/infiniband/hw/cxgb4/cm.c</span>
<span class="p_header">index f1510cc76d2d..9398143d7c5e 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/cxgb4/cm.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/cxgb4/cm.c</span>
<span class="p_chunk">@@ -1804,20 +1804,21 @@</span> <span class="p_context"> static int rx_data(struct c4iw_dev *dev, struct sk_buff *skb)</span>
 	skb_trim(skb, dlen);
 	mutex_lock(&amp;ep-&gt;com.mutex);
 
<span class="p_del">-	/* update RX credits */</span>
<span class="p_del">-	update_rx_credits(ep, dlen);</span>
<span class="p_del">-</span>
 	switch (ep-&gt;com.state) {
 	case MPA_REQ_SENT:
<span class="p_add">+		update_rx_credits(ep, dlen);</span>
 		ep-&gt;rcv_seq += dlen;
 		disconnect = process_mpa_reply(ep, skb);
 		break;
 	case MPA_REQ_WAIT:
<span class="p_add">+		update_rx_credits(ep, dlen);</span>
 		ep-&gt;rcv_seq += dlen;
 		disconnect = process_mpa_request(ep, skb);
 		break;
 	case FPDU_MODE: {
 		struct c4iw_qp_attributes attrs;
<span class="p_add">+</span>
<span class="p_add">+		update_rx_credits(ep, dlen);</span>
 		BUG_ON(!ep-&gt;com.qp);
 		if (status)
 			pr_err(&quot;%s Unexpected streaming data.&quot; \
<span class="p_header">diff --git a/drivers/iommu/amd_iommu.c b/drivers/iommu/amd_iommu.c</span>
<span class="p_header">index 41800b6d492e..c380b7e8f1c6 100644</span>
<span class="p_header">--- a/drivers/iommu/amd_iommu.c</span>
<span class="p_header">+++ b/drivers/iommu/amd_iommu.c</span>
<span class="p_chunk">@@ -4294,6 +4294,7 @@</span> <span class="p_context"> static int amd_ir_set_vcpu_affinity(struct irq_data *data, void *vcpu_info)</span>
 		/* Setting */
 		irte-&gt;hi.fields.ga_root_ptr = (pi_data-&gt;base &gt;&gt; 12);
 		irte-&gt;hi.fields.vector = vcpu_pi_info-&gt;vector;
<span class="p_add">+		irte-&gt;lo.fields_vapic.ga_log_intr = 1;</span>
 		irte-&gt;lo.fields_vapic.guest_mode = 1;
 		irte-&gt;lo.fields_vapic.ga_tag = pi_data-&gt;ga_tag;
 
<span class="p_header">diff --git a/drivers/media/pci/saa7164/saa7164-bus.c b/drivers/media/pci/saa7164/saa7164-bus.c</span>
<span class="p_header">index a18fe5d47238..b4857cd7069e 100644</span>
<span class="p_header">--- a/drivers/media/pci/saa7164/saa7164-bus.c</span>
<span class="p_header">+++ b/drivers/media/pci/saa7164/saa7164-bus.c</span>
<span class="p_chunk">@@ -393,11 +393,11 @@</span> <span class="p_context"> int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,</span>
 	msg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);
 	msg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);
 	msg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);
<span class="p_add">+	memcpy(msg, &amp;msg_tmp, sizeof(*msg));</span>
 
 	/* No need to update the read positions, because this was a peek */
 	/* If the caller specifically want to peek, return */
 	if (peekonly) {
<span class="p_del">-		memcpy(msg, &amp;msg_tmp, sizeof(*msg));</span>
 		goto peekout;
 	}
 
<span class="p_chunk">@@ -442,21 +442,15 @@</span> <span class="p_context"> int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,</span>
 		space_rem = bus-&gt;m_dwSizeGetRing - curr_grp;
 
 		if (space_rem &lt; sizeof(*msg)) {
<span class="p_del">-			/* msg wraps around the ring */</span>
<span class="p_del">-			memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, space_rem);</span>
<span class="p_del">-			memcpy_fromio((u8 *)msg + space_rem, bus-&gt;m_pdwGetRing,</span>
<span class="p_del">-				sizeof(*msg) - space_rem);</span>
 			if (buf)
 				memcpy_fromio(buf, bus-&gt;m_pdwGetRing + sizeof(*msg) -
 					space_rem, buf_size);
 
 		} else if (space_rem == sizeof(*msg)) {
<span class="p_del">-			memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, sizeof(*msg));</span>
 			if (buf)
 				memcpy_fromio(buf, bus-&gt;m_pdwGetRing, buf_size);
 		} else {
 			/* Additional data wraps around the ring */
<span class="p_del">-			memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, sizeof(*msg));</span>
 			if (buf) {
 				memcpy_fromio(buf, bus-&gt;m_pdwGetRing + curr_grp +
 					sizeof(*msg), space_rem - sizeof(*msg));
<span class="p_chunk">@@ -469,15 +463,10 @@</span> <span class="p_context"> int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,</span>
 
 	} else {
 		/* No wrapping */
<span class="p_del">-		memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, sizeof(*msg));</span>
 		if (buf)
 			memcpy_fromio(buf, bus-&gt;m_pdwGetRing + curr_grp + sizeof(*msg),
 				buf_size);
 	}
<span class="p_del">-	/* Convert from little endian to CPU */</span>
<span class="p_del">-	msg-&gt;size = le16_to_cpu((__force __le16)msg-&gt;size);</span>
<span class="p_del">-	msg-&gt;command = le32_to_cpu((__force __le32)msg-&gt;command);</span>
<span class="p_del">-	msg-&gt;controlselector = le16_to_cpu((__force __le16)msg-&gt;controlselector);</span>
 
 	/* Update the read positions, adjusting the ring */
 	saa7164_writel(bus-&gt;m_dwGetReadPos, new_grp);
<span class="p_header">diff --git a/drivers/media/platform/davinci/vpfe_capture.c b/drivers/media/platform/davinci/vpfe_capture.c</span>
<span class="p_header">index 6efb2f1631c4..bdb7a0a00932 100644</span>
<span class="p_header">--- a/drivers/media/platform/davinci/vpfe_capture.c</span>
<span class="p_header">+++ b/drivers/media/platform/davinci/vpfe_capture.c</span>
<span class="p_chunk">@@ -1725,27 +1725,9 @@</span> <span class="p_context"> static long vpfe_param_handler(struct file *file, void *priv,</span>
 
 	switch (cmd) {
 	case VPFE_CMD_S_CCDC_RAW_PARAMS:
<span class="p_add">+		ret = -EINVAL;</span>
 		v4l2_warn(&amp;vpfe_dev-&gt;v4l2_dev,
<span class="p_del">-			  &quot;VPFE_CMD_S_CCDC_RAW_PARAMS: experimental ioctl\n&quot;);</span>
<span class="p_del">-		if (ccdc_dev-&gt;hw_ops.set_params) {</span>
<span class="p_del">-			ret = ccdc_dev-&gt;hw_ops.set_params(param);</span>
<span class="p_del">-			if (ret) {</span>
<span class="p_del">-				v4l2_dbg(1, debug, &amp;vpfe_dev-&gt;v4l2_dev,</span>
<span class="p_del">-					&quot;Error setting parameters in CCDC\n&quot;);</span>
<span class="p_del">-				goto unlock_out;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			ret = vpfe_get_ccdc_image_format(vpfe_dev,</span>
<span class="p_del">-							 &amp;vpfe_dev-&gt;fmt);</span>
<span class="p_del">-			if (ret &lt; 0) {</span>
<span class="p_del">-				v4l2_dbg(1, debug, &amp;vpfe_dev-&gt;v4l2_dev,</span>
<span class="p_del">-					&quot;Invalid image format at CCDC\n&quot;);</span>
<span class="p_del">-				goto unlock_out;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			v4l2_dbg(1, debug, &amp;vpfe_dev-&gt;v4l2_dev,</span>
<span class="p_del">-				&quot;VPFE_CMD_S_CCDC_RAW_PARAMS not supported\n&quot;);</span>
<span class="p_del">-		}</span>
<span class="p_add">+			&quot;VPFE_CMD_S_CCDC_RAW_PARAMS not supported\n&quot;);</span>
 		break;
 	default:
 		ret = -ENOTTY;
<span class="p_header">diff --git a/drivers/media/rc/ir-lirc-codec.c b/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_header">index c3277308a70b..b49f80cb49c9 100644</span>
<span class="p_header">--- a/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_header">+++ b/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_chunk">@@ -254,7 +254,7 @@</span> <span class="p_context"> static long ir_lirc_ioctl(struct file *filep, unsigned int cmd,</span>
 		return 0;
 
 	case LIRC_GET_REC_RESOLUTION:
<span class="p_del">-		val = dev-&gt;rx_resolution;</span>
<span class="p_add">+		val = dev-&gt;rx_resolution / 1000;</span>
 		break;
 
 	case LIRC_SET_WIDEBAND_RECEIVER:
<span class="p_header">diff --git a/drivers/mmc/core/host.c b/drivers/mmc/core/host.c</span>
<span class="p_header">index 98f25ffb4258..848b3453517e 100644</span>
<span class="p_header">--- a/drivers/mmc/core/host.c</span>
<span class="p_header">+++ b/drivers/mmc/core/host.c</span>
<span class="p_chunk">@@ -179,19 +179,17 @@</span> <span class="p_context"> static void mmc_retune_timer(unsigned long data)</span>
  */
 int mmc_of_parse(struct mmc_host *host)
 {
<span class="p_del">-	struct device_node *np;</span>
<span class="p_add">+	struct device *dev = host-&gt;parent;</span>
 	u32 bus_width;
 	int ret;
 	bool cd_cap_invert, cd_gpio_invert = false;
 	bool ro_cap_invert, ro_gpio_invert = false;
 
<span class="p_del">-	if (!host-&gt;parent || !host-&gt;parent-&gt;of_node)</span>
<span class="p_add">+	if (!dev || !dev_fwnode(dev))</span>
 		return 0;
 
<span class="p_del">-	np = host-&gt;parent-&gt;of_node;</span>
<span class="p_del">-</span>
 	/* &quot;bus-width&quot; is translated to MMC_CAP_*_BIT_DATA flags */
<span class="p_del">-	if (of_property_read_u32(np, &quot;bus-width&quot;, &amp;bus_width) &lt; 0) {</span>
<span class="p_add">+	if (device_property_read_u32(dev, &quot;bus-width&quot;, &amp;bus_width) &lt; 0) {</span>
 		dev_dbg(host-&gt;parent,
 			&quot;\&quot;bus-width\&quot; property is missing, assuming 1 bit.\n&quot;);
 		bus_width = 1;
<span class="p_chunk">@@ -213,7 +211,7 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	}
 
 	/* f_max is obtained from the optional &quot;max-frequency&quot; property */
<span class="p_del">-	of_property_read_u32(np, &quot;max-frequency&quot;, &amp;host-&gt;f_max);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;max-frequency&quot;, &amp;host-&gt;f_max);</span>
 
 	/*
 	 * Configure CD and WP pins. They are both by default active low to
<span class="p_chunk">@@ -228,12 +226,12 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	 */
 
 	/* Parse Card Detection */
<span class="p_del">-	if (of_property_read_bool(np, &quot;non-removable&quot;)) {</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;non-removable&quot;)) {</span>
 		host-&gt;caps |= MMC_CAP_NONREMOVABLE;
 	} else {
<span class="p_del">-		cd_cap_invert = of_property_read_bool(np, &quot;cd-inverted&quot;);</span>
<span class="p_add">+		cd_cap_invert = device_property_read_bool(dev, &quot;cd-inverted&quot;);</span>
 
<span class="p_del">-		if (of_property_read_bool(np, &quot;broken-cd&quot;))</span>
<span class="p_add">+		if (device_property_read_bool(dev, &quot;broken-cd&quot;))</span>
 			host-&gt;caps |= MMC_CAP_NEEDS_POLL;
 
 		ret = mmc_gpiod_request_cd(host, &quot;cd&quot;, 0, true,
<span class="p_chunk">@@ -259,7 +257,7 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	}
 
 	/* Parse Write Protection */
<span class="p_del">-	ro_cap_invert = of_property_read_bool(np, &quot;wp-inverted&quot;);</span>
<span class="p_add">+	ro_cap_invert = device_property_read_bool(dev, &quot;wp-inverted&quot;);</span>
 
 	ret = mmc_gpiod_request_ro(host, &quot;wp&quot;, 0, false, 0, &amp;ro_gpio_invert);
 	if (!ret)
<span class="p_chunk">@@ -267,62 +265,62 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	else if (ret != -ENOENT &amp;&amp; ret != -ENOSYS)
 		return ret;
 
<span class="p_del">-	if (of_property_read_bool(np, &quot;disable-wp&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;disable-wp&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_WRITE_PROTECT;
 
 	/* See the comment on CD inversion above */
 	if (ro_cap_invert ^ ro_gpio_invert)
 		host-&gt;caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;
 
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-sd-highspeed&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-sd-highspeed&quot;))</span>
 		host-&gt;caps |= MMC_CAP_SD_HIGHSPEED;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-mmc-highspeed&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-mmc-highspeed&quot;))</span>
 		host-&gt;caps |= MMC_CAP_MMC_HIGHSPEED;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr12&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr12&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR12;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr25&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr25&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR25;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr50&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr50&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR50;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr104&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr104&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR104;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-ddr50&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-ddr50&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_DDR50;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-power-off-card&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-power-off-card&quot;))</span>
 		host-&gt;caps |= MMC_CAP_POWER_OFF_CARD;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-mmc-hw-reset&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-mmc-hw-reset&quot;))</span>
 		host-&gt;caps |= MMC_CAP_HW_RESET;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-sdio-irq&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-sdio-irq&quot;))</span>
 		host-&gt;caps |= MMC_CAP_SDIO_IRQ;
<span class="p_del">-	if (of_property_read_bool(np, &quot;full-pwr-cycle&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;full-pwr-cycle&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_FULL_PWR_CYCLE;
<span class="p_del">-	if (of_property_read_bool(np, &quot;keep-power-in-suspend&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;keep-power-in-suspend&quot;))</span>
 		host-&gt;pm_caps |= MMC_PM_KEEP_POWER;
<span class="p_del">-	if (of_property_read_bool(np, &quot;wakeup-source&quot;) ||</span>
<span class="p_del">-	    of_property_read_bool(np, &quot;enable-sdio-wakeup&quot;)) /* legacy */</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;wakeup-source&quot;) ||</span>
<span class="p_add">+	    device_property_read_bool(dev, &quot;enable-sdio-wakeup&quot;)) /* legacy */</span>
 		host-&gt;pm_caps |= MMC_PM_WAKE_SDIO_IRQ;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-ddr-1_8v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-ddr-1_8v&quot;))</span>
 		host-&gt;caps |= MMC_CAP_1_8V_DDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-ddr-1_2v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-ddr-1_2v&quot;))</span>
 		host-&gt;caps |= MMC_CAP_1_2V_DDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs200-1_8v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs200-1_8v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS200_1_8V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs200-1_2v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs200-1_2v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS200_1_2V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs400-1_8v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs400-1_8v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS400_1_8V | MMC_CAP2_HS200_1_8V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs400-1_2v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs400-1_2v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS400_1_2V | MMC_CAP2_HS200_1_2V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs400-enhanced-strobe&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs400-enhanced-strobe&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS400_ES;
<span class="p_del">-	if (of_property_read_bool(np, &quot;no-sdio&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;no-sdio&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_SDIO;
<span class="p_del">-	if (of_property_read_bool(np, &quot;no-sd&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;no-sd&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_SD;
<span class="p_del">-	if (of_property_read_bool(np, &quot;no-mmc&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;no-mmc&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_MMC;
 
<span class="p_del">-	host-&gt;dsr_req = !of_property_read_u32(np, &quot;dsr&quot;, &amp;host-&gt;dsr);</span>
<span class="p_add">+	host-&gt;dsr_req = !device_property_read_u32(dev, &quot;dsr&quot;, &amp;host-&gt;dsr);</span>
 	if (host-&gt;dsr_req &amp;&amp; (host-&gt;dsr &amp; ~0xffff)) {
 		dev_err(host-&gt;parent,
 			&quot;device tree specified broken value for DSR: 0x%x, ignoring\n&quot;,
<span class="p_header">diff --git a/drivers/mmc/core/mmc.c b/drivers/mmc/core/mmc.c</span>
<span class="p_header">index f57700c4b8f0..323dba35bc9a 100644</span>
<span class="p_header">--- a/drivers/mmc/core/mmc.c</span>
<span class="p_header">+++ b/drivers/mmc/core/mmc.c</span>
<span class="p_chunk">@@ -1690,7 +1690,7 @@</span> <span class="p_context"> static int mmc_init_card(struct mmc_host *host, u32 ocr,</span>
 		err = mmc_select_hs400(card);
 		if (err)
 			goto free_card;
<span class="p_del">-	} else {</span>
<span class="p_add">+	} else if (!mmc_card_hs400es(card)) {</span>
 		/* Select the desired bus width optionally */
 		err = mmc_select_bus_width(card);
 		if (err &gt; 0 &amp;&amp; mmc_card_hs(card)) {
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc.c b/drivers/mmc/host/dw_mmc.c</span>
<span class="p_header">index df478ae72e23..f81f4175f49a 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc.c</span>
<span class="p_chunk">@@ -2610,8 +2610,8 @@</span> <span class="p_context"> static int dw_mci_init_slot(struct dw_mci *host, unsigned int id)</span>
 	host-&gt;slot[id] = slot;
 
 	mmc-&gt;ops = &amp;dw_mci_ops;
<span class="p_del">-	if (of_property_read_u32_array(host-&gt;dev-&gt;of_node,</span>
<span class="p_del">-				       &quot;clock-freq-min-max&quot;, freq, 2)) {</span>
<span class="p_add">+	if (device_property_read_u32_array(host-&gt;dev, &quot;clock-freq-min-max&quot;,</span>
<span class="p_add">+					   freq, 2)) {</span>
 		mmc-&gt;f_min = DW_MCI_FREQ_MIN;
 		mmc-&gt;f_max = DW_MCI_FREQ_MAX;
 	} else {
<span class="p_chunk">@@ -2709,7 +2709,6 @@</span> <span class="p_context"> static void dw_mci_init_dma(struct dw_mci *host)</span>
 {
 	int addr_config;
 	struct device *dev = host-&gt;dev;
<span class="p_del">-	struct device_node *np = dev-&gt;of_node;</span>
 
 	/*
 	* Check tansfer mode from HCON[17:16]
<span class="p_chunk">@@ -2770,8 +2769,9 @@</span> <span class="p_context"> static void dw_mci_init_dma(struct dw_mci *host)</span>
 		dev_info(host-&gt;dev, &quot;Using internal DMA controller.\n&quot;);
 	} else {
 		/* TRANS_MODE_EDMAC: check dma bindings again */
<span class="p_del">-		if ((of_property_count_strings(np, &quot;dma-names&quot;) &lt; 0) ||</span>
<span class="p_del">-		    (!of_find_property(np, &quot;dmas&quot;, NULL))) {</span>
<span class="p_add">+		if ((device_property_read_string_array(dev, &quot;dma-names&quot;,</span>
<span class="p_add">+						       NULL, 0) &lt; 0) ||</span>
<span class="p_add">+		    !device_property_present(dev, &quot;dmas&quot;)) {</span>
 			goto no_dma;
 		}
 		host-&gt;dma_ops = &amp;dw_mci_edmac_ops;
<span class="p_chunk">@@ -2931,7 +2931,6 @@</span> <span class="p_context"> static struct dw_mci_board *dw_mci_parse_dt(struct dw_mci *host)</span>
 {
 	struct dw_mci_board *pdata;
 	struct device *dev = host-&gt;dev;
<span class="p_del">-	struct device_node *np = dev-&gt;of_node;</span>
 	const struct dw_mci_drv_data *drv_data = host-&gt;drv_data;
 	int ret;
 	u32 clock_frequency;
<span class="p_chunk">@@ -2948,15 +2947,16 @@</span> <span class="p_context"> static struct dw_mci_board *dw_mci_parse_dt(struct dw_mci *host)</span>
 	}
 
 	/* find out number of slots supported */
<span class="p_del">-	of_property_read_u32(np, &quot;num-slots&quot;, &amp;pdata-&gt;num_slots);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;num-slots&quot;, &amp;pdata-&gt;num_slots);</span>
 
<span class="p_del">-	if (of_property_read_u32(np, &quot;fifo-depth&quot;, &amp;pdata-&gt;fifo_depth))</span>
<span class="p_add">+	if (device_property_read_u32(dev, &quot;fifo-depth&quot;, &amp;pdata-&gt;fifo_depth))</span>
 		dev_info(dev,
 			 &quot;fifo-depth property not found, using value of FIFOTH register as default\n&quot;);
 
<span class="p_del">-	of_property_read_u32(np, &quot;card-detect-delay&quot;, &amp;pdata-&gt;detect_delay_ms);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;card-detect-delay&quot;,</span>
<span class="p_add">+				 &amp;pdata-&gt;detect_delay_ms);</span>
 
<span class="p_del">-	if (!of_property_read_u32(np, &quot;clock-frequency&quot;, &amp;clock_frequency))</span>
<span class="p_add">+	if (!device_property_read_u32(dev, &quot;clock-frequency&quot;, &amp;clock_frequency))</span>
 		pdata-&gt;bus_hz = clock_frequency;
 
 	if (drv_data &amp;&amp; drv_data-&gt;parse_dt) {
<span class="p_header">diff --git a/drivers/mmc/host/sdhci-of-at91.c b/drivers/mmc/host/sdhci-of-at91.c</span>
<span class="p_header">index a8b430ff117b..83b84ffec27d 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci-of-at91.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci-of-at91.c</span>
<span class="p_chunk">@@ -31,6 +31,7 @@</span> <span class="p_context"></span>
 
 #define SDMMC_MC1R	0x204
 #define		SDMMC_MC1R_DDR		BIT(3)
<span class="p_add">+#define		SDMMC_MC1R_FCD		BIT(7)</span>
 #define SDMMC_CACR	0x230
 #define		SDMMC_CACR_CAPWREN	BIT(0)
 #define		SDMMC_CACR_KEY		(0x46 &lt;&lt; 8)
<span class="p_chunk">@@ -43,6 +44,15 @@</span> <span class="p_context"> struct sdhci_at91_priv {</span>
 	struct clk *mainck;
 };
 
<span class="p_add">+static void sdhci_at91_set_force_card_detect(struct sdhci_host *host)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 mc1r;</span>
<span class="p_add">+</span>
<span class="p_add">+	mc1r = readb(host-&gt;ioaddr + SDMMC_MC1R);</span>
<span class="p_add">+	mc1r |= SDMMC_MC1R_FCD;</span>
<span class="p_add">+	writeb(mc1r, host-&gt;ioaddr + SDMMC_MC1R);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void sdhci_at91_set_clock(struct sdhci_host *host, unsigned int clock)
 {
 	u16 clk;
<span class="p_chunk">@@ -112,10 +122,18 @@</span> <span class="p_context"> void sdhci_at91_set_uhs_signaling(struct sdhci_host *host, unsigned int timing)</span>
 	sdhci_set_uhs_signaling(host, timing);
 }
 
<span class="p_add">+static void sdhci_at91_reset(struct sdhci_host *host, u8 mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	sdhci_reset(host, mask);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (host-&gt;mmc-&gt;caps &amp; MMC_CAP_NONREMOVABLE)</span>
<span class="p_add">+		sdhci_at91_set_force_card_detect(host);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static const struct sdhci_ops sdhci_at91_sama5d2_ops = {
 	.set_clock		= sdhci_at91_set_clock,
 	.set_bus_width		= sdhci_set_bus_width,
<span class="p_del">-	.reset			= sdhci_reset,</span>
<span class="p_add">+	.reset			= sdhci_at91_reset,</span>
 	.set_uhs_signaling	= sdhci_at91_set_uhs_signaling,
 	.set_power		= sdhci_at91_set_power,
 };
<span class="p_chunk">@@ -322,6 +340,21 @@</span> <span class="p_context"> static int sdhci_at91_probe(struct platform_device *pdev)</span>
 		host-&gt;quirks &amp;= ~SDHCI_QUIRK_BROKEN_CARD_DETECTION;
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If the device attached to the MMC bus is not removable, it is safer</span>
<span class="p_add">+	 * to set the Force Card Detect bit. People often don&#39;t connect the</span>
<span class="p_add">+	 * card detect signal and use this pin for another purpose. If the card</span>
<span class="p_add">+	 * detect pin is not muxed to SDHCI controller, a default value is</span>
<span class="p_add">+	 * used. This value can be different from a SoC revision to another</span>
<span class="p_add">+	 * one. Problems come when this default value is not card present. To</span>
<span class="p_add">+	 * avoid this case, if the device is non removable then the card</span>
<span class="p_add">+	 * detection procedure using the SDMCC_CD signal is bypassed.</span>
<span class="p_add">+	 * This bit is reset when a software reset for all command is performed</span>
<span class="p_add">+	 * so we need to implement our own reset function to set back this bit.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (host-&gt;mmc-&gt;caps &amp; MMC_CAP_NONREMOVABLE)</span>
<span class="p_add">+		sdhci_at91_set_force_card_detect(host);</span>
<span class="p_add">+</span>
 	pm_runtime_put_autosuspend(&amp;pdev-&gt;dev);
 
 	return 0;
<span class="p_header">diff --git a/drivers/net/dsa/b53/b53_common.c b/drivers/net/dsa/b53/b53_common.c</span>
<span class="p_header">index 947adda3397d..3ec573c13dac 100644</span>
<span class="p_header">--- a/drivers/net/dsa/b53/b53_common.c</span>
<span class="p_header">+++ b/drivers/net/dsa/b53/b53_common.c</span>
<span class="p_chunk">@@ -1558,6 +1558,7 @@</span> <span class="p_context"> static const struct b53_chip_data b53_switch_chips[] = {</span>
 		.dev_name = &quot;BCM53125&quot;,
 		.vlans = 4096,
 		.enabled_ports = 0xff,
<span class="p_add">+		.arl_entries = 4,</span>
 		.cpu_port = B53_CPU_PORT,
 		.vta_regs = B53_VTA_REGS,
 		.duplex_reg = B53_DUPLEX_STAT_GE,
<span class="p_header">diff --git a/drivers/net/ethernet/aurora/nb8800.c b/drivers/net/ethernet/aurora/nb8800.c</span>
<span class="p_header">index e078d8da978c..29d29af612d1 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/aurora/nb8800.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/aurora/nb8800.c</span>
<span class="p_chunk">@@ -609,7 +609,7 @@</span> <span class="p_context"> static void nb8800_mac_config(struct net_device *dev)</span>
 		mac_mode |= HALF_DUPLEX;
 
 	if (gigabit) {
<span class="p_del">-		if (priv-&gt;phy_mode == PHY_INTERFACE_MODE_RGMII)</span>
<span class="p_add">+		if (phy_interface_is_rgmii(dev-&gt;phydev))</span>
 			mac_mode |= RGMII_MODE;
 
 		mac_mode |= GMAC_MODE;
<span class="p_chunk">@@ -1277,11 +1277,10 @@</span> <span class="p_context"> static int nb8800_tangox_init(struct net_device *dev)</span>
 		break;
 
 	case PHY_INTERFACE_MODE_RGMII:
<span class="p_del">-		pad_mode = PAD_MODE_RGMII;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_add">+	case PHY_INTERFACE_MODE_RGMII_ID:</span>
<span class="p_add">+	case PHY_INTERFACE_MODE_RGMII_RXID:</span>
 	case PHY_INTERFACE_MODE_RGMII_TXID:
<span class="p_del">-		pad_mode = PAD_MODE_RGMII | PAD_MODE_GTX_CLK_DELAY;</span>
<span class="p_add">+		pad_mode = PAD_MODE_RGMII;</span>
 		break;
 
 	default:
<span class="p_header">diff --git a/drivers/net/ethernet/broadcom/tg3.c b/drivers/net/ethernet/broadcom/tg3.c</span>
<span class="p_header">index a927a730da10..edae2dcc4927 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/broadcom/tg3.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/broadcom/tg3.c</span>
<span class="p_chunk">@@ -8720,11 +8720,14 @@</span> <span class="p_context"> static void tg3_free_consistent(struct tg3 *tp)</span>
 	tg3_mem_rx_release(tp);
 	tg3_mem_tx_release(tp);
 
<span class="p_add">+	/* Protect tg3_get_stats64() from reading freed tp-&gt;hw_stats. */</span>
<span class="p_add">+	tg3_full_lock(tp, 0);</span>
 	if (tp-&gt;hw_stats) {
 		dma_free_coherent(&amp;tp-&gt;pdev-&gt;dev, sizeof(struct tg3_hw_stats),
 				  tp-&gt;hw_stats, tp-&gt;stats_mapping);
 		tp-&gt;hw_stats = NULL;
 	}
<span class="p_add">+	tg3_full_unlock(tp);</span>
 }
 
 /*
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_header">index cb45390c7623..f7fabecc104f 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_chunk">@@ -770,6 +770,10 @@</span> <span class="p_context"> static void cb_timeout_handler(struct work_struct *work)</span>
 	mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx, true);
 }
 
<span class="p_add">+static void free_msg(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *msg);</span>
<span class="p_add">+static void mlx5_free_cmd_msg(struct mlx5_core_dev *dev,</span>
<span class="p_add">+			      struct mlx5_cmd_msg *msg);</span>
<span class="p_add">+</span>
 static void cmd_work_handler(struct work_struct *work)
 {
 	struct mlx5_cmd_work_ent *ent = container_of(work, struct mlx5_cmd_work_ent, work);
<span class="p_chunk">@@ -779,16 +783,27 @@</span> <span class="p_context"> static void cmd_work_handler(struct work_struct *work)</span>
 	struct mlx5_cmd_layout *lay;
 	struct semaphore *sem;
 	unsigned long flags;
<span class="p_add">+	int alloc_ret;</span>
 
 	sem = ent-&gt;page_queue ? &amp;cmd-&gt;pages_sem : &amp;cmd-&gt;sem;
 	down(sem);
 	if (!ent-&gt;page_queue) {
<span class="p_del">-		ent-&gt;idx = alloc_ent(cmd);</span>
<span class="p_del">-		if (ent-&gt;idx &lt; 0) {</span>
<span class="p_add">+		alloc_ret = alloc_ent(cmd);</span>
<span class="p_add">+		if (alloc_ret &lt; 0) {</span>
<span class="p_add">+			if (ent-&gt;callback) {</span>
<span class="p_add">+				ent-&gt;callback(-EAGAIN, ent-&gt;context);</span>
<span class="p_add">+				mlx5_free_cmd_msg(dev, ent-&gt;out);</span>
<span class="p_add">+				free_msg(dev, ent-&gt;in);</span>
<span class="p_add">+				free_cmd(ent);</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				ent-&gt;ret = -EAGAIN;</span>
<span class="p_add">+				complete(&amp;ent-&gt;done);</span>
<span class="p_add">+			}</span>
 			mlx5_core_err(dev, &quot;failed to allocate command entry\n&quot;);
 			up(sem);
 			return;
 		}
<span class="p_add">+		ent-&gt;idx = alloc_ret;</span>
 	} else {
 		ent-&gt;idx = cmd-&gt;max_reg_cmds;
 		spin_lock_irqsave(&amp;cmd-&gt;alloc_lock, flags);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c b/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c</span>
<span class="p_header">index 13dc388667b6..1612ec0d9103 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c</span>
<span class="p_chunk">@@ -62,12 +62,14 @@</span> <span class="p_context"> static void mlx5e_timestamp_overflow(struct work_struct *work)</span>
 	struct delayed_work *dwork = to_delayed_work(work);
 	struct mlx5e_tstamp *tstamp = container_of(dwork, struct mlx5e_tstamp,
 						   overflow_work);
<span class="p_add">+	struct mlx5e_priv *priv = container_of(tstamp, struct mlx5e_priv, tstamp);</span>
 	unsigned long flags;
 
 	write_lock_irqsave(&amp;tstamp-&gt;lock, flags);
 	timecounter_read(&amp;tstamp-&gt;clock);
 	write_unlock_irqrestore(&amp;tstamp-&gt;lock, flags);
<span class="p_del">-	schedule_delayed_work(&amp;tstamp-&gt;overflow_work, tstamp-&gt;overflow_period);</span>
<span class="p_add">+	queue_delayed_work(priv-&gt;wq, &amp;tstamp-&gt;overflow_work,</span>
<span class="p_add">+			   msecs_to_jiffies(tstamp-&gt;overflow_period * 1000));</span>
 }
 
 int mlx5e_hwstamp_set(struct net_device *dev, struct ifreq *ifr)
<span class="p_chunk">@@ -263,7 +265,7 @@</span> <span class="p_context"> void mlx5e_timestamp_init(struct mlx5e_priv *priv)</span>
 
 	INIT_DELAYED_WORK(&amp;tstamp-&gt;overflow_work, mlx5e_timestamp_overflow);
 	if (tstamp-&gt;overflow_period)
<span class="p_del">-		schedule_delayed_work(&amp;tstamp-&gt;overflow_work, 0);</span>
<span class="p_add">+		queue_delayed_work(priv-&gt;wq, &amp;tstamp-&gt;overflow_work, 0);</span>
 	else
 		mlx5_core_warn(priv-&gt;mdev, &quot;invalid overflow period, overflow_work is not scheduled\n&quot;);
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c b/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c</span>
<span class="p_header">index e034dbc4913d..cf070fc0fb6b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c</span>
<span class="p_chunk">@@ -276,7 +276,7 @@</span> <span class="p_context"> static void add_rule_to_list(struct mlx5e_priv *priv,</span>
 
 static bool outer_header_zero(u32 *match_criteria)
 {
<span class="p_del">-	int size = MLX5_ST_SZ_BYTES(fte_match_param);</span>
<span class="p_add">+	int size = MLX5_FLD_SZ_BYTES(fte_match_param, outer_headers);</span>
 	char *outer_headers_c = MLX5_ADDR_OF(fte_match_param, match_criteria,
 					     outer_headers);
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c</span>
<span class="p_header">index 6ffd5d2a70aa..52a38106448e 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c</span>
<span class="p_chunk">@@ -651,9 +651,14 @@</span> <span class="p_context"> int esw_offloads_init(struct mlx5_eswitch *esw, int nvports)</span>
 	int vport;
 	int err;
 
<span class="p_add">+	/* disable PF RoCE so missed packets don&#39;t go through RoCE steering */</span>
<span class="p_add">+	mlx5_dev_list_lock();</span>
<span class="p_add">+	mlx5_remove_dev_by_protocol(esw-&gt;dev, MLX5_INTERFACE_PROTOCOL_IB);</span>
<span class="p_add">+	mlx5_dev_list_unlock();</span>
<span class="p_add">+</span>
 	err = esw_create_offloads_fdb_table(esw, nvports);
 	if (err)
<span class="p_del">-		return err;</span>
<span class="p_add">+		goto create_fdb_err;</span>
 
 	err = esw_create_offloads_table(esw);
 	if (err)
<span class="p_chunk">@@ -673,11 +678,6 @@</span> <span class="p_context"> int esw_offloads_init(struct mlx5_eswitch *esw, int nvports)</span>
 			goto err_reps;
 	}
 
<span class="p_del">-	/* disable PF RoCE so missed packets don&#39;t go through RoCE steering */</span>
<span class="p_del">-	mlx5_dev_list_lock();</span>
<span class="p_del">-	mlx5_remove_dev_by_protocol(esw-&gt;dev, MLX5_INTERFACE_PROTOCOL_IB);</span>
<span class="p_del">-	mlx5_dev_list_unlock();</span>
<span class="p_del">-</span>
 	return 0;
 
 err_reps:
<span class="p_chunk">@@ -694,6 +694,13 @@</span> <span class="p_context"> int esw_offloads_init(struct mlx5_eswitch *esw, int nvports)</span>
 
 create_ft_err:
 	esw_destroy_offloads_fdb_table(esw);
<span class="p_add">+</span>
<span class="p_add">+create_fdb_err:</span>
<span class="p_add">+	/* enable back PF RoCE */</span>
<span class="p_add">+	mlx5_dev_list_lock();</span>
<span class="p_add">+	mlx5_add_dev_by_protocol(esw-&gt;dev, MLX5_INTERFACE_PROTOCOL_IB);</span>
<span class="p_add">+	mlx5_dev_list_unlock();</span>
<span class="p_add">+</span>
 	return err;
 }
 
<span class="p_chunk">@@ -701,11 +708,6 @@</span> <span class="p_context"> static int esw_offloads_stop(struct mlx5_eswitch *esw)</span>
 {
 	int err, err1, num_vfs = esw-&gt;dev-&gt;priv.sriov.num_vfs;
 
<span class="p_del">-	/* enable back PF RoCE */</span>
<span class="p_del">-	mlx5_dev_list_lock();</span>
<span class="p_del">-	mlx5_add_dev_by_protocol(esw-&gt;dev, MLX5_INTERFACE_PROTOCOL_IB);</span>
<span class="p_del">-	mlx5_dev_list_unlock();</span>
<span class="p_del">-</span>
 	mlx5_eswitch_disable_sriov(esw);
 	err = mlx5_eswitch_enable_sriov(esw, num_vfs, SRIOV_LEGACY);
 	if (err) {
<span class="p_chunk">@@ -715,6 +717,11 @@</span> <span class="p_context"> static int esw_offloads_stop(struct mlx5_eswitch *esw)</span>
 			esw_warn(esw-&gt;dev, &quot;Failed setting eswitch back to offloads, err %d\n&quot;, err);
 	}
 
<span class="p_add">+	/* enable back PF RoCE */</span>
<span class="p_add">+	mlx5_dev_list_lock();</span>
<span class="p_add">+	mlx5_add_dev_by_protocol(esw-&gt;dev, MLX5_INTERFACE_PROTOCOL_IB);</span>
<span class="p_add">+	mlx5_dev_list_unlock();</span>
<span class="p_add">+</span>
 	return err;
 }
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/lag.c b/drivers/net/ethernet/mellanox/mlx5/core/lag.c</span>
<span class="p_header">index b5d5519542e8..0ca4623bda6b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/lag.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/lag.c</span>
<span class="p_chunk">@@ -157,22 +157,17 @@</span> <span class="p_context"> static bool mlx5_lag_is_bonded(struct mlx5_lag *ldev)</span>
 static void mlx5_infer_tx_affinity_mapping(struct lag_tracker *tracker,
 					   u8 *port1, u8 *port2)
 {
<span class="p_del">-	if (tracker-&gt;tx_type == NETDEV_LAG_TX_TYPE_ACTIVEBACKUP) {</span>
<span class="p_del">-		if (tracker-&gt;netdev_state[0].tx_enabled) {</span>
<span class="p_del">-			*port1 = 1;</span>
<span class="p_del">-			*port2 = 1;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			*port1 = 2;</span>
<span class="p_del">-			*port2 = 2;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		*port1 = 1;</span>
<span class="p_del">-		*port2 = 2;</span>
<span class="p_del">-		if (!tracker-&gt;netdev_state[0].link_up)</span>
<span class="p_del">-			*port1 = 2;</span>
<span class="p_del">-		else if (!tracker-&gt;netdev_state[1].link_up)</span>
<span class="p_del">-			*port2 = 1;</span>
<span class="p_add">+	*port1 = 1;</span>
<span class="p_add">+	*port2 = 2;</span>
<span class="p_add">+	if (!tracker-&gt;netdev_state[0].tx_enabled ||</span>
<span class="p_add">+	    !tracker-&gt;netdev_state[0].link_up) {</span>
<span class="p_add">+		*port1 = 2;</span>
<span class="p_add">+		return;</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (!tracker-&gt;netdev_state[1].tx_enabled ||</span>
<span class="p_add">+	    !tracker-&gt;netdev_state[1].link_up)</span>
<span class="p_add">+		*port2 = 1;</span>
 }
 
 static void mlx5_activate_lag(struct mlx5_lag *ldev,
<span class="p_header">diff --git a/drivers/net/ethernet/renesas/sh_eth.c b/drivers/net/ethernet/renesas/sh_eth.c</span>
<span class="p_header">index 12be259394c6..2140dedab712 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/renesas/sh_eth.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/renesas/sh_eth.c</span>
<span class="p_chunk">@@ -574,6 +574,7 @@</span> <span class="p_context"> static struct sh_eth_cpu_data r8a7740_data = {</span>
 	.rpadir_value   = 2 &lt;&lt; 16,
 	.no_trimd	= 1,
 	.no_ade		= 1,
<span class="p_add">+	.hw_crc		= 1,</span>
 	.tsu		= 1,
 	.select_mii	= 1,
 	.shift_rd0	= 1,
<span class="p_chunk">@@ -802,7 +803,7 @@</span> <span class="p_context"> static struct sh_eth_cpu_data sh7734_data = {</span>
 
 	.ecsr_value	= ECSR_ICD | ECSR_MPD,
 	.ecsipr_value	= ECSIPR_LCHNGIP | ECSIPR_ICDIP | ECSIPR_MPDIP,
<span class="p_del">-	.eesipr_value	= DMAC_M_RFRMER | DMAC_M_ECI | 0x003fffff,</span>
<span class="p_add">+	.eesipr_value	= DMAC_M_RFRMER | DMAC_M_ECI | 0x003f07ff,</span>
 
 	.tx_check	= EESR_TC1 | EESR_FTC,
 	.eesr_err_check	= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |
<span class="p_chunk">@@ -832,7 +833,7 @@</span> <span class="p_context"> static struct sh_eth_cpu_data sh7763_data = {</span>
 
 	.ecsr_value	= ECSR_ICD | ECSR_MPD,
 	.ecsipr_value	= ECSIPR_LCHNGIP | ECSIPR_ICDIP | ECSIPR_MPDIP,
<span class="p_del">-	.eesipr_value	= DMAC_M_RFRMER | DMAC_M_ECI | 0x003fffff,</span>
<span class="p_add">+	.eesipr_value	= DMAC_M_RFRMER | DMAC_M_ECI | 0x003f07ff,</span>
 
 	.tx_check	= EESR_TC1 | EESR_FTC,
 	.eesr_err_check	= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |
<span class="p_header">diff --git a/drivers/net/irda/mcs7780.c b/drivers/net/irda/mcs7780.c</span>
<span class="p_header">index bca6a1e72d1d..e1bb802d4a4d 100644</span>
<span class="p_header">--- a/drivers/net/irda/mcs7780.c</span>
<span class="p_header">+++ b/drivers/net/irda/mcs7780.c</span>
<span class="p_chunk">@@ -141,9 +141,19 @@</span> <span class="p_context"> static int mcs_set_reg(struct mcs_cb *mcs, __u16 reg, __u16 val)</span>
 static int mcs_get_reg(struct mcs_cb *mcs, __u16 reg, __u16 * val)
 {
 	struct usb_device *dev = mcs-&gt;usbdev;
<span class="p_del">-	int ret = usb_control_msg(dev, usb_rcvctrlpipe(dev, 0), MCS_RDREQ,</span>
<span class="p_del">-				  MCS_RD_RTYPE, 0, reg, val, 2,</span>
<span class="p_del">-				  msecs_to_jiffies(MCS_CTRL_TIMEOUT));</span>
<span class="p_add">+	void *dmabuf;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf = kmalloc(sizeof(__u16), GFP_KERNEL);</span>
<span class="p_add">+	if (!dmabuf)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = usb_control_msg(dev, usb_rcvctrlpipe(dev, 0), MCS_RDREQ,</span>
<span class="p_add">+			      MCS_RD_RTYPE, 0, reg, dmabuf, 2,</span>
<span class="p_add">+			      msecs_to_jiffies(MCS_CTRL_TIMEOUT));</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(val, dmabuf, sizeof(__u16));</span>
<span class="p_add">+	kfree(dmabuf);</span>
 
 	return ret;
 }
<span class="p_header">diff --git a/drivers/net/phy/dp83867.c b/drivers/net/phy/dp83867.c</span>
<span class="p_header">index 4cad95552cf1..01cf094bee18 100644</span>
<span class="p_header">--- a/drivers/net/phy/dp83867.c</span>
<span class="p_header">+++ b/drivers/net/phy/dp83867.c</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"></span>
 #define MII_DP83867_MICR	0x12
 #define MII_DP83867_ISR		0x13
 #define DP83867_CTRL		0x1f
<span class="p_add">+#define DP83867_CFG3		0x1e</span>
 
 /* Extended Registers */
 #define DP83867_RGMIICTL	0x0032
<span class="p_chunk">@@ -90,6 +91,8 @@</span> <span class="p_context"> static int dp83867_config_intr(struct phy_device *phydev)</span>
 		micr_status |=
 			(MII_DP83867_MICR_AN_ERR_INT_EN |
 			MII_DP83867_MICR_SPEED_CHNG_INT_EN |
<span class="p_add">+			MII_DP83867_MICR_AUTONEG_COMP_INT_EN |</span>
<span class="p_add">+			MII_DP83867_MICR_LINK_STS_CHNG_INT_EN |</span>
 			MII_DP83867_MICR_DUP_MODE_CHNG_INT_EN |
 			MII_DP83867_MICR_SLEEP_MODE_CHNG_INT_EN);
 
<span class="p_chunk">@@ -190,6 +193,13 @@</span> <span class="p_context"> static int dp83867_config_init(struct phy_device *phydev)</span>
 				       DP83867_DEVADDR, delay);
 	}
 
<span class="p_add">+	/* Enable Interrupt output INT_OE in CFG3 register */</span>
<span class="p_add">+	if (phy_interrupt_is_valid(phydev)) {</span>
<span class="p_add">+		val = phy_read(phydev, DP83867_CFG3);</span>
<span class="p_add">+		val |= BIT(7);</span>
<span class="p_add">+		phy_write(phydev, DP83867_CFG3, val);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/net/phy/phy.c b/drivers/net/phy/phy.c</span>
<span class="p_header">index edd30ebbf275..775a6e1fdef9 100644</span>
<span class="p_header">--- a/drivers/net/phy/phy.c</span>
<span class="p_header">+++ b/drivers/net/phy/phy.c</span>
<span class="p_chunk">@@ -674,6 +674,9 @@</span> <span class="p_context"> void phy_stop_machine(struct phy_device *phydev)</span>
 	if (phydev-&gt;state &gt; PHY_UP &amp;&amp; phydev-&gt;state != PHY_HALTED)
 		phydev-&gt;state = PHY_UP;
 	mutex_unlock(&amp;phydev-&gt;lock);
<span class="p_add">+</span>
<span class="p_add">+	/* Now we can run the state machine synchronously */</span>
<span class="p_add">+	phy_state_machine(&amp;phydev-&gt;state_queue.work);</span>
 }
 
 /**
<span class="p_chunk">@@ -1060,6 +1063,15 @@</span> <span class="p_context"> void phy_state_machine(struct work_struct *work)</span>
 			if (old_link != phydev-&gt;link)
 				phydev-&gt;state = PHY_CHANGELINK;
 		}
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Failsafe: check that nobody set phydev-&gt;link=0 between two</span>
<span class="p_add">+		 * poll cycles, otherwise we won&#39;t leave RUNNING state as long</span>
<span class="p_add">+		 * as link remains down.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!phydev-&gt;link &amp;&amp; phydev-&gt;state == PHY_RUNNING) {</span>
<span class="p_add">+			phydev-&gt;state = PHY_CHANGELINK;</span>
<span class="p_add">+			phydev_err(phydev, &quot;no link in PHY_RUNNING\n&quot;);</span>
<span class="p_add">+		}</span>
 		break;
 	case PHY_CHANGELINK:
 		err = phy_read_status(phydev);
<span class="p_header">diff --git a/drivers/net/phy/phy_device.c b/drivers/net/phy/phy_device.c</span>
<span class="p_header">index 9e7b7836774f..bf02f8e4648a 100644</span>
<span class="p_header">--- a/drivers/net/phy/phy_device.c</span>
<span class="p_header">+++ b/drivers/net/phy/phy_device.c</span>
<span class="p_chunk">@@ -1714,6 +1714,8 @@</span> <span class="p_context"> static int phy_remove(struct device *dev)</span>
 {
 	struct phy_device *phydev = to_phy_device(dev);
 
<span class="p_add">+	cancel_delayed_work_sync(&amp;phydev-&gt;state_queue);</span>
<span class="p_add">+</span>
 	mutex_lock(&amp;phydev-&gt;lock);
 	phydev-&gt;state = PHY_DOWN;
 	mutex_unlock(&amp;phydev-&gt;lock);
<span class="p_header">diff --git a/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c b/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c</span>
<span class="p_header">index 8744b9beda33..8e3c6f4bdaa0 100644</span>
<span class="p_header">--- a/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c</span>
<span class="p_header">+++ b/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c</span>
<span class="p_chunk">@@ -4161,11 +4161,6 @@</span> <span class="p_context"> struct brcmf_sdio *brcmf_sdio_probe(struct brcmf_sdio_dev *sdiodev)</span>
 		goto fail;
 	}
 
<span class="p_del">-	/* allocate scatter-gather table. sg support</span>
<span class="p_del">-	 * will be disabled upon allocation failure.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	brcmf_sdiod_sgtable_alloc(bus-&gt;sdiodev);</span>
<span class="p_del">-</span>
 	/* Query the F2 block size, set roundup accordingly */
 	bus-&gt;blocksize = bus-&gt;sdiodev-&gt;func[2]-&gt;cur_blksize;
 	bus-&gt;roundup = min(max_roundup, bus-&gt;blocksize);
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/dvm/tx.c b/drivers/net/wireless/intel/iwlwifi/dvm/tx.c</span>
<span class="p_header">index 4b97371c3b42..838946d17b59 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/dvm/tx.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/dvm/tx.c</span>
<span class="p_chunk">@@ -1190,11 +1190,11 @@</span> <span class="p_context"> void iwlagn_rx_reply_tx(struct iwl_priv *priv, struct iwl_rx_cmd_buffer *rxb)</span>
 				next_reclaimed;
 			IWL_DEBUG_TX_REPLY(priv, &quot;Next reclaimed packet:%d\n&quot;,
 						  next_reclaimed);
<span class="p_add">+			iwlagn_check_ratid_empty(priv, sta_id, tid);</span>
 		}
 
 		iwl_trans_reclaim(priv-&gt;trans, txq_id, ssn, &amp;skbs);
 
<span class="p_del">-		iwlagn_check_ratid_empty(priv, sta_id, tid);</span>
 		freed = 0;
 
 		/* process frames */
<span class="p_header">diff --git a/drivers/net/xen-netback/common.h b/drivers/net/xen-netback/common.h</span>
<span class="p_header">index 3ce1f7da8647..cb7365bdf6e0 100644</span>
<span class="p_header">--- a/drivers/net/xen-netback/common.h</span>
<span class="p_header">+++ b/drivers/net/xen-netback/common.h</span>
<span class="p_chunk">@@ -199,6 +199,7 @@</span> <span class="p_context"> struct xenvif_queue { /* Per-queue data for xenvif */</span>
 	unsigned long   remaining_credit;
 	struct timer_list credit_timeout;
 	u64 credit_window_start;
<span class="p_add">+	bool rate_limited;</span>
 
 	/* Statistics */
 	struct xenvif_stats stats;
<span class="p_header">diff --git a/drivers/net/xen-netback/interface.c b/drivers/net/xen-netback/interface.c</span>
<span class="p_header">index b009d7966b46..5bfaf5578810 100644</span>
<span class="p_header">--- a/drivers/net/xen-netback/interface.c</span>
<span class="p_header">+++ b/drivers/net/xen-netback/interface.c</span>
<span class="p_chunk">@@ -105,7 +105,11 @@</span> <span class="p_context"> static int xenvif_poll(struct napi_struct *napi, int budget)</span>
 
 	if (work_done &lt; budget) {
 		napi_complete(napi);
<span class="p_del">-		xenvif_napi_schedule_or_enable_events(queue);</span>
<span class="p_add">+		/* If the queue is rate-limited, it shall be</span>
<span class="p_add">+		 * rescheduled in the timer callback.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (likely(!queue-&gt;rate_limited))</span>
<span class="p_add">+			xenvif_napi_schedule_or_enable_events(queue);</span>
 	}
 
 	return work_done;
<span class="p_header">diff --git a/drivers/net/xen-netback/netback.c b/drivers/net/xen-netback/netback.c</span>
<span class="p_header">index 47b481095d77..d9b5b73c35a0 100644</span>
<span class="p_header">--- a/drivers/net/xen-netback/netback.c</span>
<span class="p_header">+++ b/drivers/net/xen-netback/netback.c</span>
<span class="p_chunk">@@ -179,6 +179,7 @@</span> <span class="p_context"> static void tx_add_credit(struct xenvif_queue *queue)</span>
 		max_credit = ULONG_MAX; /* wrapped: clamp to ULONG_MAX */
 
 	queue-&gt;remaining_credit = min(max_credit, max_burst);
<span class="p_add">+	queue-&gt;rate_limited = false;</span>
 }
 
 void xenvif_tx_credit_callback(unsigned long data)
<span class="p_chunk">@@ -685,8 +686,10 @@</span> <span class="p_context"> static bool tx_credit_exceeded(struct xenvif_queue *queue, unsigned size)</span>
 		msecs_to_jiffies(queue-&gt;credit_usec / 1000);
 
 	/* Timer could already be pending in rare cases. */
<span class="p_del">-	if (timer_pending(&amp;queue-&gt;credit_timeout))</span>
<span class="p_add">+	if (timer_pending(&amp;queue-&gt;credit_timeout)) {</span>
<span class="p_add">+		queue-&gt;rate_limited = true;</span>
 		return true;
<span class="p_add">+	}</span>
 
 	/* Passed the point where we can replenish credit? */
 	if (time_after_eq64(now, next_credit)) {
<span class="p_chunk">@@ -701,6 +704,7 @@</span> <span class="p_context"> static bool tx_credit_exceeded(struct xenvif_queue *queue, unsigned size)</span>
 		mod_timer(&amp;queue-&gt;credit_timeout,
 			  next_credit);
 		queue-&gt;credit_window_start = next_credit;
<span class="p_add">+		queue-&gt;rate_limited = true;</span>
 
 		return true;
 	}
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_attr.c b/drivers/scsi/qla2xxx/qla_attr.c</span>
<span class="p_header">index ad33238cef17..8c4641b518b5 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_attr.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_attr.c</span>
<span class="p_chunk">@@ -243,12 +243,15 @@</span> <span class="p_context"> qla2x00_sysfs_read_optrom(struct file *filp, struct kobject *kobj,</span>
 	struct qla_hw_data *ha = vha-&gt;hw;
 	ssize_t rval = 0;
 
<span class="p_add">+	mutex_lock(&amp;ha-&gt;optrom_mutex);</span>
<span class="p_add">+</span>
 	if (ha-&gt;optrom_state != QLA_SREADING)
<span class="p_del">-		return 0;</span>
<span class="p_add">+		goto out;</span>
 
<span class="p_del">-	mutex_lock(&amp;ha-&gt;optrom_mutex);</span>
 	rval = memory_read_from_buffer(buf, count, &amp;off, ha-&gt;optrom_buffer,
 	    ha-&gt;optrom_region_size);
<span class="p_add">+</span>
<span class="p_add">+out:</span>
 	mutex_unlock(&amp;ha-&gt;optrom_mutex);
 
 	return rval;
<span class="p_chunk">@@ -263,14 +266,19 @@</span> <span class="p_context"> qla2x00_sysfs_write_optrom(struct file *filp, struct kobject *kobj,</span>
 	    struct device, kobj)));
 	struct qla_hw_data *ha = vha-&gt;hw;
 
<span class="p_del">-	if (ha-&gt;optrom_state != QLA_SWRITING)</span>
<span class="p_add">+	mutex_lock(&amp;ha-&gt;optrom_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ha-&gt;optrom_state != QLA_SWRITING) {</span>
<span class="p_add">+		mutex_unlock(&amp;ha-&gt;optrom_mutex);</span>
 		return -EINVAL;
<span class="p_del">-	if (off &gt; ha-&gt;optrom_region_size)</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (off &gt; ha-&gt;optrom_region_size) {</span>
<span class="p_add">+		mutex_unlock(&amp;ha-&gt;optrom_mutex);</span>
 		return -ERANGE;
<span class="p_add">+	}</span>
 	if (off + count &gt; ha-&gt;optrom_region_size)
 		count = ha-&gt;optrom_region_size - off;
 
<span class="p_del">-	mutex_lock(&amp;ha-&gt;optrom_mutex);</span>
 	memcpy(&amp;ha-&gt;optrom_buffer[off], buf, count);
 	mutex_unlock(&amp;ha-&gt;optrom_mutex);
 
<span class="p_header">diff --git a/drivers/spi/spi-axi-spi-engine.c b/drivers/spi/spi-axi-spi-engine.c</span>
<span class="p_header">index 2b1456e5e221..c1eafbd7610a 100644</span>
<span class="p_header">--- a/drivers/spi/spi-axi-spi-engine.c</span>
<span class="p_header">+++ b/drivers/spi/spi-axi-spi-engine.c</span>
<span class="p_chunk">@@ -494,7 +494,8 @@</span> <span class="p_context"> static int spi_engine_probe(struct platform_device *pdev)</span>
 			SPI_ENGINE_VERSION_MAJOR(version),
 			SPI_ENGINE_VERSION_MINOR(version),
 			SPI_ENGINE_VERSION_PATCH(version));
<span class="p_del">-		return -ENODEV;</span>
<span class="p_add">+		ret = -ENODEV;</span>
<span class="p_add">+		goto err_put_master;</span>
 	}
 
 	spi_engine-&gt;clk = devm_clk_get(&amp;pdev-&gt;dev, &quot;s_axi_aclk&quot;);
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_nego.c b/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_header">index 6693d7c69f97..e8efb4299a95 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_chunk">@@ -490,14 +490,60 @@</span> <span class="p_context"> static void iscsi_target_restore_sock_callbacks(struct iscsi_conn *conn)</span>
 
 static int iscsi_target_do_login(struct iscsi_conn *, struct iscsi_login *);
 
<span class="p_del">-static bool iscsi_target_sk_state_check(struct sock *sk)</span>
<span class="p_add">+static bool __iscsi_target_sk_check_close(struct sock *sk)</span>
 {
 	if (sk-&gt;sk_state == TCP_CLOSE_WAIT || sk-&gt;sk_state == TCP_CLOSE) {
<span class="p_del">-		pr_debug(&quot;iscsi_target_sk_state_check: TCP_CLOSE_WAIT|TCP_CLOSE,&quot;</span>
<span class="p_add">+		pr_debug(&quot;__iscsi_target_sk_check_close: TCP_CLOSE_WAIT|TCP_CLOSE,&quot;</span>
 			&quot;returning FALSE\n&quot;);
<span class="p_del">-		return false;</span>
<span class="p_add">+		return true;</span>
 	}
<span class="p_del">-	return true;</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool iscsi_target_sk_check_close(struct iscsi_conn *conn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool state = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (conn-&gt;sock) {</span>
<span class="p_add">+		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		state = (__iscsi_target_sk_check_close(sk) ||</span>
<span class="p_add">+			 test_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags));</span>
<span class="p_add">+		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return state;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool iscsi_target_sk_check_flag(struct iscsi_conn *conn, unsigned int flag)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool state = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (conn-&gt;sock) {</span>
<span class="p_add">+		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		state = test_bit(flag, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return state;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool iscsi_target_sk_check_and_clear(struct iscsi_conn *conn, unsigned int flag)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool state = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (conn-&gt;sock) {</span>
<span class="p_add">+		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		write_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		state = (__iscsi_target_sk_check_close(sk) ||</span>
<span class="p_add">+			 test_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags));</span>
<span class="p_add">+		if (!state)</span>
<span class="p_add">+			clear_bit(flag, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return state;</span>
 }
 
 static void iscsi_target_login_drop(struct iscsi_conn *conn, struct iscsi_login *login)
<span class="p_chunk">@@ -537,6 +583,20 @@</span> <span class="p_context"> static void iscsi_target_do_login_rx(struct work_struct *work)</span>
 
 	pr_debug(&quot;entering iscsi_target_do_login_rx, conn: %p, %s:%d\n&quot;,
 			conn, current-&gt;comm, current-&gt;pid);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If iscsi_target_do_login_rx() has been invoked by -&gt;sk_data_ready()</span>
<span class="p_add">+	 * before initial PDU processing in iscsi_target_start_negotiation()</span>
<span class="p_add">+	 * has completed, go ahead and retry until it&#39;s cleared.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Otherwise if the TCP connection drops while this is occuring,</span>
<span class="p_add">+	 * iscsi_target_start_negotiation() will detect the failure, call</span>
<span class="p_add">+	 * cancel_delayed_work_sync(&amp;conn-&gt;login_work), and cleanup the</span>
<span class="p_add">+	 * remaining iscsi connection resources from iscsi_np process context.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (iscsi_target_sk_check_flag(conn, LOGIN_FLAGS_INITIAL_PDU)) {</span>
<span class="p_add">+		schedule_delayed_work(&amp;conn-&gt;login_work, msecs_to_jiffies(10));</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
 
 	spin_lock(&amp;tpg-&gt;tpg_state_lock);
 	state = (tpg-&gt;tpg_state == TPG_STATE_ACTIVE);
<span class="p_chunk">@@ -544,26 +604,12 @@</span> <span class="p_context"> static void iscsi_target_do_login_rx(struct work_struct *work)</span>
 
 	if (!state) {
 		pr_debug(&quot;iscsi_target_do_login_rx: tpg_state != TPG_STATE_ACTIVE\n&quot;);
<span class="p_del">-		iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-		iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-		iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_del">-		return;</span>
<span class="p_add">+		goto err;</span>
 	}
 
<span class="p_del">-	if (conn-&gt;sock) {</span>
<span class="p_del">-		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_del">-</span>
<span class="p_del">-		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-		state = iscsi_target_sk_state_check(sk);</span>
<span class="p_del">-		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!state) {</span>
<span class="p_del">-			pr_debug(&quot;iscsi_target_do_login_rx, TCP state CLOSE\n&quot;);</span>
<span class="p_del">-			iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-			iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-			iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	if (iscsi_target_sk_check_close(conn)) {</span>
<span class="p_add">+		pr_debug(&quot;iscsi_target_do_login_rx, TCP state CLOSE\n&quot;);</span>
<span class="p_add">+		goto err;</span>
 	}
 
 	conn-&gt;login_kworker = current;
<span class="p_chunk">@@ -581,34 +627,29 @@</span> <span class="p_context"> static void iscsi_target_do_login_rx(struct work_struct *work)</span>
 	flush_signals(current);
 	conn-&gt;login_kworker = NULL;
 
<span class="p_del">-	if (rc &lt; 0) {</span>
<span class="p_del">-		iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-		iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-		iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (rc &lt; 0)</span>
<span class="p_add">+		goto err;</span>
 
 	pr_debug(&quot;iscsi_target_do_login_rx after rx_login_io, %p, %s:%d\n&quot;,
 			conn, current-&gt;comm, current-&gt;pid);
 
 	rc = iscsi_target_do_login(conn, login);
 	if (rc &lt; 0) {
<span class="p_del">-		iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-		iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-		iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_add">+		goto err;</span>
 	} else if (!rc) {
<span class="p_del">-		if (conn-&gt;sock) {</span>
<span class="p_del">-			struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_del">-</span>
<span class="p_del">-			write_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-			clear_bit(LOGIN_FLAGS_READ_ACTIVE, &amp;conn-&gt;login_flags);</span>
<span class="p_del">-			write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (iscsi_target_sk_check_and_clear(conn, LOGIN_FLAGS_READ_ACTIVE))</span>
<span class="p_add">+			goto err;</span>
 	} else if (rc == 1) {
 		iscsi_target_nego_release(conn);
 		iscsi_post_login_handler(np, conn, zero_tsih);
 		iscsit_deaccess_np(np, tpg, tpg_np);
 	}
<span class="p_add">+	return;</span>
<span class="p_add">+</span>
<span class="p_add">+err:</span>
<span class="p_add">+	iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_add">+	iscsi_target_login_drop(conn, login);</span>
<span class="p_add">+	iscsit_deaccess_np(np, tpg, tpg_np);</span>
 }
 
 static void iscsi_target_do_cleanup(struct work_struct *work)
<span class="p_chunk">@@ -656,31 +697,54 @@</span> <span class="p_context"> static void iscsi_target_sk_state_change(struct sock *sk)</span>
 		orig_state_change(sk);
 		return;
 	}
<span class="p_add">+	state = __iscsi_target_sk_check_close(sk);</span>
<span class="p_add">+	pr_debug(&quot;__iscsi_target_sk_close_change: state: %d\n&quot;, state);</span>
<span class="p_add">+</span>
 	if (test_bit(LOGIN_FLAGS_READ_ACTIVE, &amp;conn-&gt;login_flags)) {
 		pr_debug(&quot;Got LOGIN_FLAGS_READ_ACTIVE=1 sk_state_change&quot;
 			 &quot; conn: %p\n&quot;, conn);
<span class="p_add">+		if (state)</span>
<span class="p_add">+			set_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags);</span>
 		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
 		orig_state_change(sk);
 		return;
 	}
<span class="p_del">-	if (test_and_set_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags)) {</span>
<span class="p_add">+	if (test_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags)) {</span>
 		pr_debug(&quot;Got LOGIN_FLAGS_CLOSED=1 sk_state_change conn: %p\n&quot;,
 			 conn);
 		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
 		orig_state_change(sk);
 		return;
 	}
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If the TCP connection has dropped, go ahead and set LOGIN_FLAGS_CLOSED,</span>
<span class="p_add">+	 * but only queue conn-&gt;login_work -&gt; iscsi_target_do_login_rx()</span>
<span class="p_add">+	 * processing if LOGIN_FLAGS_INITIAL_PDU has already been cleared.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * When iscsi_target_do_login_rx() runs, iscsi_target_sk_check_close()</span>
<span class="p_add">+	 * will detect the dropped TCP connection from delayed workqueue context.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If LOGIN_FLAGS_INITIAL_PDU is still set, which means the initial</span>
<span class="p_add">+	 * iscsi_target_start_negotiation() is running, iscsi_target_do_login()</span>
<span class="p_add">+	 * via iscsi_target_sk_check_close() or iscsi_target_start_negotiation()</span>
<span class="p_add">+	 * via iscsi_target_sk_check_and_clear() is responsible for detecting the</span>
<span class="p_add">+	 * dropped TCP connection in iscsi_np process context, and cleaning up</span>
<span class="p_add">+	 * the remaining iscsi connection resources.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (state) {</span>
<span class="p_add">+		pr_debug(&quot;iscsi_target_sk_state_change got failed state\n&quot;);</span>
<span class="p_add">+		set_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		state = test_bit(LOGIN_FLAGS_INITIAL_PDU, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
 
<span class="p_del">-	state = iscsi_target_sk_state_check(sk);</span>
<span class="p_del">-	write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-	pr_debug(&quot;iscsi_target_sk_state_change: state: %d\n&quot;, state);</span>
<span class="p_add">+		orig_state_change(sk);</span>
 
<span class="p_del">-	if (!state) {</span>
<span class="p_del">-		pr_debug(&quot;iscsi_target_sk_state_change got failed state\n&quot;);</span>
<span class="p_del">-		schedule_delayed_work(&amp;conn-&gt;login_cleanup_work, 0);</span>
<span class="p_add">+		if (!state)</span>
<span class="p_add">+			schedule_delayed_work(&amp;conn-&gt;login_work, 0);</span>
 		return;
 	}
<span class="p_add">+	write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+</span>
 	orig_state_change(sk);
 }
 
<span class="p_chunk">@@ -945,6 +1009,15 @@</span> <span class="p_context"> static int iscsi_target_do_login(struct iscsi_conn *conn, struct iscsi_login *lo</span>
 			if (iscsi_target_handle_csg_one(conn, login) &lt; 0)
 				return -1;
 			if (login_rsp-&gt;flags &amp; ISCSI_FLAG_LOGIN_TRANSIT) {
<span class="p_add">+				/*</span>
<span class="p_add">+				 * Check to make sure the TCP connection has not</span>
<span class="p_add">+				 * dropped asynchronously while session reinstatement</span>
<span class="p_add">+				 * was occuring in this kthread context, before</span>
<span class="p_add">+				 * transitioning to full feature phase operation.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (iscsi_target_sk_check_close(conn))</span>
<span class="p_add">+					return -1;</span>
<span class="p_add">+</span>
 				login-&gt;tsih = conn-&gt;sess-&gt;tsih;
 				login-&gt;login_complete = 1;
 				iscsi_target_restore_sock_callbacks(conn);
<span class="p_chunk">@@ -971,21 +1044,6 @@</span> <span class="p_context"> static int iscsi_target_do_login(struct iscsi_conn *conn, struct iscsi_login *lo</span>
 		break;
 	}
 
<span class="p_del">-	if (conn-&gt;sock) {</span>
<span class="p_del">-		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_del">-		bool state;</span>
<span class="p_del">-</span>
<span class="p_del">-		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-		state = iscsi_target_sk_state_check(sk);</span>
<span class="p_del">-		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!state) {</span>
<span class="p_del">-			pr_debug(&quot;iscsi_target_do_login() failed state for&quot;</span>
<span class="p_del">-				 &quot; conn: %p\n&quot;, conn);</span>
<span class="p_del">-			return -1;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1252,13 +1310,25 @@</span> <span class="p_context"> int iscsi_target_start_negotiation(</span>
        if (conn-&gt;sock) {
                struct sock *sk = conn-&gt;sock-&gt;sk;
 
<span class="p_del">-               write_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-               set_bit(LOGIN_FLAGS_READY, &amp;conn-&gt;login_flags);</span>
<span class="p_del">-               write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-       }</span>
<span class="p_add">+		write_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		set_bit(LOGIN_FLAGS_READY, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		set_bit(LOGIN_FLAGS_INITIAL_PDU, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If iscsi_target_do_login returns zero to signal more PDU</span>
<span class="p_add">+	 * exchanges are required to complete the login, go ahead and</span>
<span class="p_add">+	 * clear LOGIN_FLAGS_INITIAL_PDU but only if the TCP connection</span>
<span class="p_add">+	 * is still active.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Otherwise if TCP connection dropped asynchronously, go ahead</span>
<span class="p_add">+	 * and perform connection cleanup now.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	ret = iscsi_target_do_login(conn, login);</span>
<span class="p_add">+	if (!ret &amp;&amp; iscsi_target_sk_check_and_clear(conn, LOGIN_FLAGS_INITIAL_PDU))</span>
<span class="p_add">+		ret = -1;</span>
 
<span class="p_del">-       ret = iscsi_target_do_login(conn, login);</span>
<span class="p_del">-       if (ret &lt; 0) {</span>
<span class="p_add">+	if (ret &lt; 0) {</span>
 		cancel_delayed_work_sync(&amp;conn-&gt;login_work);
 		cancel_delayed_work_sync(&amp;conn-&gt;login_cleanup_work);
 		iscsi_target_restore_sock_callbacks(conn);
<span class="p_header">diff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c</span>
<span class="p_header">index 14a37ff0b9e3..705bb5f5a87f 100644</span>
<span class="p_header">--- a/fs/btrfs/extent-tree.c</span>
<span class="p_header">+++ b/fs/btrfs/extent-tree.c</span>
<span class="p_chunk">@@ -4759,10 +4759,6 @@</span> <span class="p_context"> static void shrink_delalloc(struct btrfs_root *root, u64 to_reclaim, u64 orig,</span>
 		else
 			flush = BTRFS_RESERVE_NO_FLUSH;
 		spin_lock(&amp;space_info-&gt;lock);
<span class="p_del">-		if (can_overcommit(root, space_info, orig, flush)) {</span>
<span class="p_del">-			spin_unlock(&amp;space_info-&gt;lock);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
 		if (list_empty(&amp;space_info-&gt;tickets) &amp;&amp;
 		    list_empty(&amp;space_info-&gt;priority_tickets)) {
 			spin_unlock(&amp;space_info-&gt;lock);
<span class="p_header">diff --git a/fs/ext4/file.c b/fs/ext4/file.c</span>
<span class="p_header">index 9e77c089e8cb..d17d12ed6f73 100644</span>
<span class="p_header">--- a/fs/ext4/file.c</span>
<span class="p_header">+++ b/fs/ext4/file.c</span>
<span class="p_chunk">@@ -469,6 +469,8 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 				lastoff = page_offset(page);
 				bh = head = page_buffers(page);
 				do {
<span class="p_add">+					if (lastoff + bh-&gt;b_size &lt;= startoff)</span>
<span class="p_add">+						goto next;</span>
 					if (buffer_uptodate(bh) ||
 					    buffer_unwritten(bh)) {
 						if (whence == SEEK_DATA)
<span class="p_chunk">@@ -483,6 +485,7 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 						unlock_page(page);
 						goto out;
 					}
<span class="p_add">+next:</span>
 					lastoff += bh-&gt;b_size;
 					bh = bh-&gt;b_this_page;
 				} while (bh != head);
<span class="p_header">diff --git a/fs/ext4/resize.c b/fs/ext4/resize.c</span>
<span class="p_header">index cf681004b196..95bf46654153 100644</span>
<span class="p_header">--- a/fs/ext4/resize.c</span>
<span class="p_header">+++ b/fs/ext4/resize.c</span>
<span class="p_chunk">@@ -1926,7 +1926,8 @@</span> <span class="p_context"> int ext4_resize_fs(struct super_block *sb, ext4_fsblk_t n_blocks_count)</span>
 			n_desc_blocks = o_desc_blocks +
 				le16_to_cpu(es-&gt;s_reserved_gdt_blocks);
 			n_group = n_desc_blocks * EXT4_DESC_PER_BLOCK(sb);
<span class="p_del">-			n_blocks_count = n_group * EXT4_BLOCKS_PER_GROUP(sb);</span>
<span class="p_add">+			n_blocks_count = (ext4_fsblk_t)n_group *</span>
<span class="p_add">+				EXT4_BLOCKS_PER_GROUP(sb);</span>
 			n_group--; /* set to last group number */
 		}
 
<span class="p_header">diff --git a/fs/f2fs/super.c b/fs/f2fs/super.c</span>
<span class="p_header">index 7e0c002c12e9..eb20b8767f3c 100644</span>
<span class="p_header">--- a/fs/f2fs/super.c</span>
<span class="p_header">+++ b/fs/f2fs/super.c</span>
<span class="p_chunk">@@ -1424,6 +1424,8 @@</span> <span class="p_context"> int sanity_check_ckpt(struct f2fs_sb_info *sbi)</span>
 	unsigned int total, fsmeta;
 	struct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);
 	struct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);
<span class="p_add">+	unsigned int main_segs, blocks_per_seg;</span>
<span class="p_add">+	int i;</span>
 
 	total = le32_to_cpu(raw_super-&gt;segment_count);
 	fsmeta = le32_to_cpu(raw_super-&gt;segment_count_ckpt);
<span class="p_chunk">@@ -1435,6 +1437,20 @@</span> <span class="p_context"> int sanity_check_ckpt(struct f2fs_sb_info *sbi)</span>
 	if (unlikely(fsmeta &gt;= total))
 		return 1;
 
<span class="p_add">+	main_segs = le32_to_cpu(raw_super-&gt;segment_count_main);</span>
<span class="p_add">+	blocks_per_seg = sbi-&gt;blocks_per_seg;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; NR_CURSEG_NODE_TYPE; i++) {</span>
<span class="p_add">+		if (le32_to_cpu(ckpt-&gt;cur_node_segno[i]) &gt;= main_segs ||</span>
<span class="p_add">+			le16_to_cpu(ckpt-&gt;cur_node_blkoff[i]) &gt;= blocks_per_seg)</span>
<span class="p_add">+			return 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	for (i = 0; i &lt; NR_CURSEG_DATA_TYPE; i++) {</span>
<span class="p_add">+		if (le32_to_cpu(ckpt-&gt;cur_data_segno[i]) &gt;= main_segs ||</span>
<span class="p_add">+			le16_to_cpu(ckpt-&gt;cur_data_blkoff[i]) &gt;= blocks_per_seg)</span>
<span class="p_add">+			return 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (unlikely(f2fs_cp_error(sbi))) {
 		f2fs_msg(sbi-&gt;sb, KERN_ERR, &quot;A bug case: need to run fsck&quot;);
 		return 1;
<span class="p_header">diff --git a/fs/nfs/nfs4proc.c b/fs/nfs/nfs4proc.c</span>
<span class="p_header">index 46ca7881d80d..a53b8e0c896a 100644</span>
<span class="p_header">--- a/fs/nfs/nfs4proc.c</span>
<span class="p_header">+++ b/fs/nfs/nfs4proc.c</span>
<span class="p_chunk">@@ -7410,7 +7410,7 @@</span> <span class="p_context"> static void nfs4_exchange_id_done(struct rpc_task *task, void *data)</span>
 			cdata-&gt;res.server_scope = NULL;
 		}
 		/* Save the EXCHANGE_ID verifier session trunk tests */
<span class="p_del">-		memcpy(clp-&gt;cl_confirm.data, cdata-&gt;args.verifier-&gt;data,</span>
<span class="p_add">+		memcpy(clp-&gt;cl_confirm.data, cdata-&gt;args.verifier.data,</span>
 		       sizeof(clp-&gt;cl_confirm.data));
 	}
 out:
<span class="p_chunk">@@ -7447,7 +7447,6 @@</span> <span class="p_context"> static const struct rpc_call_ops nfs4_exchange_id_call_ops = {</span>
 static int _nfs4_proc_exchange_id(struct nfs_client *clp, struct rpc_cred *cred,
 			u32 sp4_how, struct rpc_xprt *xprt)
 {
<span class="p_del">-	nfs4_verifier verifier;</span>
 	struct rpc_message msg = {
 		.rpc_proc = &amp;nfs4_procedures[NFSPROC4_CLNT_EXCHANGE_ID],
 		.rpc_cred = cred,
<span class="p_chunk">@@ -7470,8 +7469,7 @@</span> <span class="p_context"> static int _nfs4_proc_exchange_id(struct nfs_client *clp, struct rpc_cred *cred,</span>
 	if (!calldata)
 		goto out;
 
<span class="p_del">-	if (!xprt)</span>
<span class="p_del">-		nfs4_init_boot_verifier(clp, &amp;verifier);</span>
<span class="p_add">+	nfs4_init_boot_verifier(clp, &amp;calldata-&gt;args.verifier);</span>
 
 	status = nfs4_init_uniform_client_string(clp);
 	if (status)
<span class="p_chunk">@@ -7516,9 +7514,8 @@</span> <span class="p_context"> static int _nfs4_proc_exchange_id(struct nfs_client *clp, struct rpc_cred *cred,</span>
 		task_setup_data.rpc_xprt = xprt;
 		task_setup_data.flags =
 				RPC_TASK_SOFT|RPC_TASK_SOFTCONN|RPC_TASK_ASYNC;
<span class="p_del">-		calldata-&gt;args.verifier = &amp;clp-&gt;cl_confirm;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		calldata-&gt;args.verifier = &amp;verifier;</span>
<span class="p_add">+		memcpy(calldata-&gt;args.verifier.data, clp-&gt;cl_confirm.data,</span>
<span class="p_add">+				sizeof(calldata-&gt;args.verifier.data));</span>
 	}
 	calldata-&gt;args.client = clp;
 #ifdef CONFIG_NFS_V4_1_MIGRATION
<span class="p_header">diff --git a/fs/nfs/nfs4xdr.c b/fs/nfs/nfs4xdr.c</span>
<span class="p_header">index c9c4d9855976..5e2724a928ed 100644</span>
<span class="p_header">--- a/fs/nfs/nfs4xdr.c</span>
<span class="p_header">+++ b/fs/nfs/nfs4xdr.c</span>
<span class="p_chunk">@@ -1761,7 +1761,7 @@</span> <span class="p_context"> static void encode_exchange_id(struct xdr_stream *xdr,</span>
 	int len = 0;
 
 	encode_op_hdr(xdr, OP_EXCHANGE_ID, decode_exchange_id_maxsz, hdr);
<span class="p_del">-	encode_nfs4_verifier(xdr, args-&gt;verifier);</span>
<span class="p_add">+	encode_nfs4_verifier(xdr, &amp;args-&gt;verifier);</span>
 
 	encode_string(xdr, strlen(args-&gt;client-&gt;cl_owner_id),
 			args-&gt;client-&gt;cl_owner_id);
<span class="p_header">diff --git a/include/linux/cpuset.h b/include/linux/cpuset.h</span>
<span class="p_header">index bfc204e70338..cd32a49ae81e 100644</span>
<span class="p_header">--- a/include/linux/cpuset.h</span>
<span class="p_header">+++ b/include/linux/cpuset.h</span>
<span class="p_chunk">@@ -16,6 +16,19 @@</span> <span class="p_context"></span>
 
 #ifdef CONFIG_CPUSETS
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Static branch rewrites can happen in an arbitrary order for a given</span>
<span class="p_add">+ * key. In code paths where we need to loop with read_mems_allowed_begin() and</span>
<span class="p_add">+ * read_mems_allowed_retry() to get a consistent view of mems_allowed, we need</span>
<span class="p_add">+ * to ensure that begin() always gets rewritten before retry() in the</span>
<span class="p_add">+ * disabled -&gt; enabled transition. If not, then if local irqs are disabled</span>
<span class="p_add">+ * around the loop, we can deadlock since retry() would always be</span>
<span class="p_add">+ * comparing the latest value of the mems_allowed seqcount against 0 as</span>
<span class="p_add">+ * begin() still would see cpusets_enabled() as false. The enabled -&gt; disabled</span>
<span class="p_add">+ * transition should happen in reverse order for the same reasons (want to stop</span>
<span class="p_add">+ * looking at real value of mems_allowed.sequence in retry() first).</span>
<span class="p_add">+ */</span>
<span class="p_add">+extern struct static_key_false cpusets_pre_enable_key;</span>
 extern struct static_key_false cpusets_enabled_key;
 static inline bool cpusets_enabled(void)
 {
<span class="p_chunk">@@ -30,12 +43,14 @@</span> <span class="p_context"> static inline int nr_cpusets(void)</span>
 
 static inline void cpuset_inc(void)
 {
<span class="p_add">+	static_branch_inc(&amp;cpusets_pre_enable_key);</span>
 	static_branch_inc(&amp;cpusets_enabled_key);
 }
 
 static inline void cpuset_dec(void)
 {
 	static_branch_dec(&amp;cpusets_enabled_key);
<span class="p_add">+	static_branch_dec(&amp;cpusets_pre_enable_key);</span>
 }
 
 extern int cpuset_init(void);
<span class="p_chunk">@@ -113,7 +128,7 @@</span> <span class="p_context"> extern void cpuset_print_current_mems_allowed(void);</span>
  */
 static inline unsigned int read_mems_allowed_begin(void)
 {
<span class="p_del">-	if (!cpusets_enabled())</span>
<span class="p_add">+	if (!static_branch_unlikely(&amp;cpusets_pre_enable_key))</span>
 		return 0;
 
 	return read_seqcount_begin(&amp;current-&gt;mems_allowed_seq);
<span class="p_chunk">@@ -127,7 +142,7 @@</span> <span class="p_context"> static inline unsigned int read_mems_allowed_begin(void)</span>
  */
 static inline bool read_mems_allowed_retry(unsigned int seq)
 {
<span class="p_del">-	if (!cpusets_enabled())</span>
<span class="p_add">+	if (!static_branch_unlikely(&amp;cpusets_enabled_key))</span>
 		return false;
 
 	return read_seqcount_retry(&amp;current-&gt;mems_allowed_seq, seq);
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 08d947fc4c59..e8471c2ca83a 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -507,6 +507,10 @@</span> <span class="p_context"> struct mm_struct {</span>
 	 * PROT_NONE or PROT_NUMA mapped page.
 	 */
 	bool tlb_flush_pending;
<span class="p_add">+#endif</span>
<span class="p_add">+#ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH</span>
<span class="p_add">+	/* See flush_tlb_batched_pending() */</span>
<span class="p_add">+	bool tlb_flush_batched;</span>
 #endif
 	struct uprobes_state uprobes_state;
 #ifdef CONFIG_X86_INTEL_MPX
<span class="p_header">diff --git a/include/linux/nfs_xdr.h b/include/linux/nfs_xdr.h</span>
<span class="p_header">index beb1e10f446e..3bf867a0c3b3 100644</span>
<span class="p_header">--- a/include/linux/nfs_xdr.h</span>
<span class="p_header">+++ b/include/linux/nfs_xdr.h</span>
<span class="p_chunk">@@ -1199,7 +1199,7 @@</span> <span class="p_context"> struct nfs41_state_protection {</span>
 
 struct nfs41_exchange_id_args {
 	struct nfs_client		*client;
<span class="p_del">-	nfs4_verifier			*verifier;</span>
<span class="p_add">+	nfs4_verifier			verifier;</span>
 	u32				flags;
 	struct nfs41_state_protection	state_protect;
 };
<span class="p_header">diff --git a/include/linux/property.h b/include/linux/property.h</span>
<span class="p_header">index 856e50b2140c..338f9b76914b 100644</span>
<span class="p_header">--- a/include/linux/property.h</span>
<span class="p_header">+++ b/include/linux/property.h</span>
<span class="p_chunk">@@ -33,6 +33,8 @@</span> <span class="p_context"> enum dev_dma_attr {</span>
 	DEV_DMA_COHERENT,
 };
 
<span class="p_add">+struct fwnode_handle *dev_fwnode(struct device *dev);</span>
<span class="p_add">+</span>
 bool device_property_present(struct device *dev, const char *propname);
 int device_property_read_u8_array(struct device *dev, const char *propname,
 				  u8 *val, size_t nval);
<span class="p_header">diff --git a/include/linux/sched.h b/include/linux/sched.h</span>
<span class="p_header">index f425eb3318ab..14f58cf06054 100644</span>
<span class="p_header">--- a/include/linux/sched.h</span>
<span class="p_header">+++ b/include/linux/sched.h</span>
<span class="p_chunk">@@ -830,6 +830,16 @@</span> <span class="p_context"> struct signal_struct {</span>
 
 #define SIGNAL_UNKILLABLE	0x00000040 /* for init: ignore fatal signals */
 
<span class="p_add">+#define SIGNAL_STOP_MASK (SIGNAL_CLD_MASK | SIGNAL_STOP_STOPPED | \</span>
<span class="p_add">+			  SIGNAL_STOP_CONTINUED)</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void signal_set_stop_flags(struct signal_struct *sig,</span>
<span class="p_add">+					 unsigned int flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	WARN_ON(sig-&gt;flags &amp; (SIGNAL_GROUP_EXIT|SIGNAL_GROUP_COREDUMP));</span>
<span class="p_add">+	sig-&gt;flags = (sig-&gt;flags &amp; ~SIGNAL_STOP_MASK) | flags;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* If true, all threads except -&gt;group_exit_task have pending SIGKILL */
 static inline int signal_group_exit(const struct signal_struct *sig)
 {
<span class="p_header">diff --git a/include/linux/slab.h b/include/linux/slab.h</span>
<span class="p_header">index 084b12bad198..4c5363566815 100644</span>
<span class="p_header">--- a/include/linux/slab.h</span>
<span class="p_header">+++ b/include/linux/slab.h</span>
<span class="p_chunk">@@ -226,7 +226,7 @@</span> <span class="p_context"> static inline const char *__check_heap_object(const void *ptr,</span>
  * (PAGE_SIZE*2).  Larger requests are passed to the page allocator.
  */
 #define KMALLOC_SHIFT_HIGH	(PAGE_SHIFT + 1)
<span class="p_del">-#define KMALLOC_SHIFT_MAX	(MAX_ORDER + PAGE_SHIFT)</span>
<span class="p_add">+#define KMALLOC_SHIFT_MAX	(MAX_ORDER + PAGE_SHIFT - 1)</span>
 #ifndef KMALLOC_SHIFT_LOW
 #define KMALLOC_SHIFT_LOW	3
 #endif
<span class="p_chunk">@@ -239,7 +239,7 @@</span> <span class="p_context"> static inline const char *__check_heap_object(const void *ptr,</span>
  * be allocated from the same page.
  */
 #define KMALLOC_SHIFT_HIGH	PAGE_SHIFT
<span class="p_del">-#define KMALLOC_SHIFT_MAX	30</span>
<span class="p_add">+#define KMALLOC_SHIFT_MAX	(MAX_ORDER + PAGE_SHIFT - 1)</span>
 #ifndef KMALLOC_SHIFT_LOW
 #define KMALLOC_SHIFT_LOW	3
 #endif
<span class="p_header">diff --git a/include/linux/workqueue.h b/include/linux/workqueue.h</span>
<span class="p_header">index fc6e22186405..733a21ef8da4 100644</span>
<span class="p_header">--- a/include/linux/workqueue.h</span>
<span class="p_header">+++ b/include/linux/workqueue.h</span>
<span class="p_chunk">@@ -311,6 +311,7 @@</span> <span class="p_context"> enum {</span>
 
 	__WQ_DRAINING		= 1 &lt;&lt; 16, /* internal: workqueue is draining */
 	__WQ_ORDERED		= 1 &lt;&lt; 17, /* internal: workqueue is ordered */
<span class="p_add">+	__WQ_ORDERED_EXPLICIT	= 1 &lt;&lt; 18, /* internal: alloc_ordered_workqueue() */</span>
 	__WQ_LEGACY		= 1 &lt;&lt; 18, /* internal: create*_workqueue() */
 
 	WQ_MAX_ACTIVE		= 512,	  /* I like 512, better ideas? */
<span class="p_chunk">@@ -409,7 +410,8 @@</span> <span class="p_context"> __alloc_workqueue_key(const char *fmt, unsigned int flags, int max_active,</span>
  * Pointer to the allocated workqueue on success, %NULL on failure.
  */
 #define alloc_ordered_workqueue(fmt, flags, args...)			\
<span class="p_del">-	alloc_workqueue(fmt, WQ_UNBOUND | __WQ_ORDERED | (flags), 1, ##args)</span>
<span class="p_add">+	alloc_workqueue(fmt, WQ_UNBOUND | __WQ_ORDERED |		\</span>
<span class="p_add">+			__WQ_ORDERED_EXPLICIT | (flags), 1, ##args)</span>
 
 #define create_workqueue(name)						\
 	alloc_workqueue(&quot;%s&quot;, __WQ_LEGACY | WQ_MEM_RECLAIM, 1, (name))
<span class="p_header">diff --git a/include/net/iw_handler.h b/include/net/iw_handler.h</span>
<span class="p_header">index e0f4109e64c6..c2aa73e5e6bb 100644</span>
<span class="p_header">--- a/include/net/iw_handler.h</span>
<span class="p_header">+++ b/include/net/iw_handler.h</span>
<span class="p_chunk">@@ -556,7 +556,8 @@</span> <span class="p_context"> iwe_stream_add_point(struct iw_request_info *info, char *stream, char *ends,</span>
 		memcpy(stream + lcp_len,
 		       ((char *) &amp;iwe-&gt;u) + IW_EV_POINT_OFF,
 		       IW_EV_POINT_PK_LEN - IW_EV_LCP_PK_LEN);
<span class="p_del">-		memcpy(stream + point_len, extra, iwe-&gt;u.data.length);</span>
<span class="p_add">+		if (iwe-&gt;u.data.length &amp;&amp; extra)</span>
<span class="p_add">+			memcpy(stream + point_len, extra, iwe-&gt;u.data.length);</span>
 		stream += event_len;
 	}
 	return stream;
<span class="p_header">diff --git a/include/net/sctp/sctp.h b/include/net/sctp/sctp.h</span>
<span class="p_header">index 31acc3f4f132..61d9ce89d10d 100644</span>
<span class="p_header">--- a/include/net/sctp/sctp.h</span>
<span class="p_header">+++ b/include/net/sctp/sctp.h</span>
<span class="p_chunk">@@ -460,6 +460,8 @@</span> <span class="p_context"> _sctp_walk_params((pos), (chunk), ntohs((chunk)-&gt;chunk_hdr.length), member)</span>
 
 #define _sctp_walk_params(pos, chunk, end, member)\
 for (pos.v = chunk-&gt;member;\
<span class="p_add">+     (pos.v + offsetof(struct sctp_paramhdr, length) + sizeof(pos.p-&gt;length) &lt;=\</span>
<span class="p_add">+      (void *)chunk + end) &amp;&amp;\</span>
      pos.v &lt;= (void *)chunk + end - ntohs(pos.p-&gt;length) &amp;&amp;\
      ntohs(pos.p-&gt;length) &gt;= sizeof(sctp_paramhdr_t);\
      pos.v += SCTP_PAD4(ntohs(pos.p-&gt;length)))
<span class="p_chunk">@@ -470,6 +472,8 @@</span> <span class="p_context"> _sctp_walk_errors((err), (chunk_hdr), ntohs((chunk_hdr)-&gt;length))</span>
 #define _sctp_walk_errors(err, chunk_hdr, end)\
 for (err = (sctp_errhdr_t *)((void *)chunk_hdr + \
 	    sizeof(sctp_chunkhdr_t));\
<span class="p_add">+     ((void *)err + offsetof(sctp_errhdr_t, length) + sizeof(err-&gt;length) &lt;=\</span>
<span class="p_add">+      (void *)chunk_hdr + end) &amp;&amp;\</span>
      (void *)err &lt;= (void *)chunk_hdr + end - ntohs(err-&gt;length) &amp;&amp;\
      ntohs(err-&gt;length) &gt;= sizeof(sctp_errhdr_t); \
      err = (sctp_errhdr_t *)((void *)err + SCTP_PAD4(ntohs(err-&gt;length))))
<span class="p_header">diff --git a/include/target/iscsi/iscsi_target_core.h b/include/target/iscsi/iscsi_target_core.h</span>
<span class="p_header">index 33b2e75bf2eb..c8132b419148 100644</span>
<span class="p_header">--- a/include/target/iscsi/iscsi_target_core.h</span>
<span class="p_header">+++ b/include/target/iscsi/iscsi_target_core.h</span>
<span class="p_chunk">@@ -563,6 +563,7 @@</span> <span class="p_context"> struct iscsi_conn {</span>
 #define LOGIN_FLAGS_READ_ACTIVE		1
 #define LOGIN_FLAGS_CLOSED		2
 #define LOGIN_FLAGS_READY		4
<span class="p_add">+#define LOGIN_FLAGS_INITIAL_PDU		8</span>
 	unsigned long		login_flags;
 	struct delayed_work	login_work;
 	struct delayed_work	login_cleanup_work;
<span class="p_header">diff --git a/kernel/cgroup.c b/kernel/cgroup.c</span>
<span class="p_header">index 1fde8eec9529..4c233437ee1a 100644</span>
<span class="p_header">--- a/kernel/cgroup.c</span>
<span class="p_header">+++ b/kernel/cgroup.c</span>
<span class="p_chunk">@@ -3487,11 +3487,11 @@</span> <span class="p_context"> static ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,</span>
 	cgrp-&gt;subtree_control &amp;= ~disable;
 
 	ret = cgroup_apply_control(cgrp);
<span class="p_del">-</span>
 	cgroup_finalize_control(cgrp, ret);
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		goto out_unlock;</span>
 
 	kernfs_activate(cgrp-&gt;kn);
<span class="p_del">-	ret = 0;</span>
 out_unlock:
 	cgroup_kn_unlock(of-&gt;kn);
 	return ret ?: nbytes;
<span class="p_chunk">@@ -5718,6 +5718,10 @@</span> <span class="p_context"> int __init cgroup_init(void)</span>
 
 		if (ss-&gt;bind)
 			ss-&gt;bind(init_css_set.subsys[ssid]);
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;cgroup_mutex);</span>
<span class="p_add">+		css_populate_dir(init_css_set.subsys[ssid]);</span>
<span class="p_add">+		mutex_unlock(&amp;cgroup_mutex);</span>
 	}
 
 	/* init_css_set.subsys[] has been updated, re-hash */
<span class="p_header">diff --git a/kernel/cpuset.c b/kernel/cpuset.c</span>
<span class="p_header">index 24d175d2b62d..247afb108343 100644</span>
<span class="p_header">--- a/kernel/cpuset.c</span>
<span class="p_header">+++ b/kernel/cpuset.c</span>
<span class="p_chunk">@@ -61,6 +61,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/cgroup.h&gt;
 #include &lt;linux/wait.h&gt;
 
<span class="p_add">+DEFINE_STATIC_KEY_FALSE(cpusets_pre_enable_key);</span>
 DEFINE_STATIC_KEY_FALSE(cpusets_enabled_key);
 
 /* See &quot;Frequency meter&quot; comments, below. */
<span class="p_header">diff --git a/kernel/signal.c b/kernel/signal.c</span>
<span class="p_header">index deb04d5983ed..e48668c3c972 100644</span>
<span class="p_header">--- a/kernel/signal.c</span>
<span class="p_header">+++ b/kernel/signal.c</span>
<span class="p_chunk">@@ -346,7 +346,7 @@</span> <span class="p_context"> static bool task_participate_group_stop(struct task_struct *task)</span>
 	 * fresh group stop.  Read comment in do_signal_stop() for details.
 	 */
 	if (!sig-&gt;group_stop_count &amp;&amp; !(sig-&gt;flags &amp; SIGNAL_STOP_STOPPED)) {
<span class="p_del">-		sig-&gt;flags = SIGNAL_STOP_STOPPED;</span>
<span class="p_add">+		signal_set_stop_flags(sig, SIGNAL_STOP_STOPPED);</span>
 		return true;
 	}
 	return false;
<span class="p_chunk">@@ -845,7 +845,7 @@</span> <span class="p_context"> static bool prepare_signal(int sig, struct task_struct *p, bool force)</span>
 			 * will take -&gt;siglock, notice SIGNAL_CLD_MASK, and
 			 * notify its parent. See get_signal_to_deliver().
 			 */
<span class="p_del">-			signal-&gt;flags = why | SIGNAL_STOP_CONTINUED;</span>
<span class="p_add">+			signal_set_stop_flags(signal, why | SIGNAL_STOP_CONTINUED);</span>
 			signal-&gt;group_stop_count = 0;
 			signal-&gt;group_exit_code = 0;
 		}
<span class="p_header">diff --git a/kernel/time/timer.c b/kernel/time/timer.c</span>
<span class="p_header">index c611c47de884..944ad64277a6 100644</span>
<span class="p_header">--- a/kernel/time/timer.c</span>
<span class="p_header">+++ b/kernel/time/timer.c</span>
<span class="p_chunk">@@ -1536,7 +1536,7 @@</span> <span class="p_context"> u64 get_next_timer_interrupt(unsigned long basej, u64 basem)</span>
 		base-&gt;is_idle = false;
 	} else {
 		if (!is_max_delta)
<span class="p_del">-			expires = basem + (nextevt - basej) * TICK_NSEC;</span>
<span class="p_add">+			expires = basem + (u64)(nextevt - basej) * TICK_NSEC;</span>
 		/*
 		 * If we expect to sleep more than a tick, mark the base idle:
 		 */
<span class="p_header">diff --git a/kernel/workqueue.c b/kernel/workqueue.c</span>
<span class="p_header">index 479d840db286..776dda02e751 100644</span>
<span class="p_header">--- a/kernel/workqueue.c</span>
<span class="p_header">+++ b/kernel/workqueue.c</span>
<span class="p_chunk">@@ -3730,8 +3730,12 @@</span> <span class="p_context"> static int apply_workqueue_attrs_locked(struct workqueue_struct *wq,</span>
 		return -EINVAL;
 
 	/* creating multiple pwqs breaks ordering guarantee */
<span class="p_del">-	if (WARN_ON((wq-&gt;flags &amp; __WQ_ORDERED) &amp;&amp; !list_empty(&amp;wq-&gt;pwqs)))</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_add">+	if (!list_empty(&amp;wq-&gt;pwqs)) {</span>
<span class="p_add">+		if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED_EXPLICIT))</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		wq-&gt;flags &amp;= ~__WQ_ORDERED;</span>
<span class="p_add">+	}</span>
 
 	ctx = apply_wqattrs_prepare(wq, attrs);
 	if (!ctx)
<span class="p_chunk">@@ -3915,6 +3919,16 @@</span> <span class="p_context"> struct workqueue_struct *__alloc_workqueue_key(const char *fmt,</span>
 	struct workqueue_struct *wq;
 	struct pool_workqueue *pwq;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Unbound &amp;&amp; max_active == 1 used to imply ordered, which is no</span>
<span class="p_add">+	 * longer the case on NUMA machines due to per-node pools.  While</span>
<span class="p_add">+	 * alloc_ordered_workqueue() is the right way to create an ordered</span>
<span class="p_add">+	 * workqueue, keep the previous behavior to avoid subtle breakages</span>
<span class="p_add">+	 * on NUMA.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if ((flags &amp; WQ_UNBOUND) &amp;&amp; max_active == 1)</span>
<span class="p_add">+		flags |= __WQ_ORDERED;</span>
<span class="p_add">+</span>
 	/* see the comment above the definition of WQ_POWER_EFFICIENT */
 	if ((flags &amp; WQ_POWER_EFFICIENT) &amp;&amp; wq_power_efficient)
 		flags |= WQ_UNBOUND;
<span class="p_chunk">@@ -4103,13 +4117,14 @@</span> <span class="p_context"> void workqueue_set_max_active(struct workqueue_struct *wq, int max_active)</span>
 	struct pool_workqueue *pwq;
 
 	/* disallow meddling with max_active for ordered workqueues */
<span class="p_del">-	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED))</span>
<span class="p_add">+	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED_EXPLICIT))</span>
 		return;
 
 	max_active = wq_clamp_max_active(max_active, wq-&gt;flags, wq-&gt;name);
 
 	mutex_lock(&amp;wq-&gt;mutex);
 
<span class="p_add">+	wq-&gt;flags &amp;= ~__WQ_ORDERED;</span>
 	wq-&gt;saved_max_active = max_active;
 
 	for_each_pwq(pwq, wq)
<span class="p_chunk">@@ -5214,7 +5229,7 @@</span> <span class="p_context"> int workqueue_sysfs_register(struct workqueue_struct *wq)</span>
 	 * attributes breaks ordering guarantee.  Disallow exposing ordered
 	 * workqueues.
 	 */
<span class="p_del">-	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED))</span>
<span class="p_add">+	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED_EXPLICIT))</span>
 		return -EINVAL;
 
 	wq-&gt;wq_dev = wq_dev = kzalloc(sizeof(*wq_dev), GFP_KERNEL);
<span class="p_header">diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug</span>
<span class="p_header">index a6c8db1d62f6..f60e67217f18 100644</span>
<span class="p_header">--- a/lib/Kconfig.debug</span>
<span class="p_header">+++ b/lib/Kconfig.debug</span>
<span class="p_chunk">@@ -145,7 +145,7 @@</span> <span class="p_context"> config DEBUG_INFO_REDUCED</span>
 
 config DEBUG_INFO_SPLIT
 	bool &quot;Produce split debuginfo in .dwo files&quot;
<span class="p_del">-	depends on DEBUG_INFO</span>
<span class="p_add">+	depends on DEBUG_INFO &amp;&amp; !FRV</span>
 	help
 	  Generate debug info into separate .dwo files. This significantly
 	  reduces the build directory size for builds with DEBUG_INFO,
<span class="p_header">diff --git a/mm/internal.h b/mm/internal.h</span>
<span class="p_header">index 537ac9951f5f..34a5459e5989 100644</span>
<span class="p_header">--- a/mm/internal.h</span>
<span class="p_header">+++ b/mm/internal.h</span>
<span class="p_chunk">@@ -472,6 +472,7 @@</span> <span class="p_context"> struct tlbflush_unmap_batch;</span>
 #ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH
 void try_to_unmap_flush(void);
 void try_to_unmap_flush_dirty(void);
<span class="p_add">+void flush_tlb_batched_pending(struct mm_struct *mm);</span>
 #else
 static inline void try_to_unmap_flush(void)
 {
<span class="p_chunk">@@ -479,7 +480,9 @@</span> <span class="p_context"> static inline void try_to_unmap_flush(void)</span>
 static inline void try_to_unmap_flush_dirty(void)
 {
 }
<span class="p_del">-</span>
<span class="p_add">+static inline void flush_tlb_batched_pending(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
 #endif /* CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH */
 
 extern const struct trace_print_flags pageflag_names[];
<span class="p_header">diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="p_header">index 93fb63e88b5e..253b1533fba5 100644</span>
<span class="p_header">--- a/mm/madvise.c</span>
<span class="p_header">+++ b/mm/madvise.c</span>
<span class="p_chunk">@@ -21,6 +21,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/swap.h&gt;
 #include &lt;linux/swapops.h&gt;
 #include &lt;linux/mmu_notifier.h&gt;
<span class="p_add">+#include &quot;internal.h&quot;</span>
 
 #include &lt;asm/tlb.h&gt;
 
<span class="p_chunk">@@ -282,6 +283,7 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 		return 0;
 
 	orig_pte = pte = pte_offset_map_lock(mm, pmd, addr, &amp;ptl);
<span class="p_add">+	flush_tlb_batched_pending(mm);</span>
 	arch_enter_lazy_mmu_mode();
 	for (; addr != end; pte++, addr += PAGE_SIZE) {
 		ptent = *pte;
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index e6a5a1f20492..9bf3da0d0e14 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -1124,6 +1124,7 @@</span> <span class="p_context"> static unsigned long zap_pte_range(struct mmu_gather *tlb,</span>
 	init_rss_vec(rss);
 	start_pte = pte_offset_map_lock(mm, pmd, addr, &amp;ptl);
 	pte = start_pte;
<span class="p_add">+	flush_tlb_batched_pending(mm);</span>
 	arch_enter_lazy_mmu_mode();
 	do {
 		pte_t ptent = *pte;
<span class="p_header">diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="p_header">index 11936526b08b..ae740c9b1f9b 100644</span>
<span class="p_header">--- a/mm/mprotect.c</span>
<span class="p_header">+++ b/mm/mprotect.c</span>
<span class="p_chunk">@@ -74,6 +74,7 @@</span> <span class="p_context"> static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
 	if (!pte)
 		return 0;
 
<span class="p_add">+	flush_tlb_batched_pending(vma-&gt;vm_mm);</span>
 	arch_enter_lazy_mmu_mode();
 	do {
 		oldpte = *pte;
<span class="p_header">diff --git a/mm/mremap.c b/mm/mremap.c</span>
<span class="p_header">index 30d7d2482eea..15976716dd40 100644</span>
<span class="p_header">--- a/mm/mremap.c</span>
<span class="p_header">+++ b/mm/mremap.c</span>
<span class="p_chunk">@@ -142,6 +142,7 @@</span> <span class="p_context"> static void move_ptes(struct vm_area_struct *vma, pmd_t *old_pmd,</span>
 	new_ptl = pte_lockptr(mm, new_pmd);
 	if (new_ptl != old_ptl)
 		spin_lock_nested(new_ptl, SINGLE_DEPTH_NESTING);
<span class="p_add">+	flush_tlb_batched_pending(vma-&gt;vm_mm);</span>
 	arch_enter_lazy_mmu_mode();
 
 	for (; old_addr &lt; old_end; old_pte++, old_addr += PAGE_SIZE,
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 56df8c24689d..77b797c2d094 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -1875,14 +1875,14 @@</span> <span class="p_context"> int move_freepages(struct zone *zone,</span>
 #endif
 
 	for (page = start_page; page &lt;= end_page;) {
<span class="p_del">-		/* Make sure we are not inadvertently changing nodes */</span>
<span class="p_del">-		VM_BUG_ON_PAGE(page_to_nid(page) != zone_to_nid(zone), page);</span>
<span class="p_del">-</span>
 		if (!pfn_valid_within(page_to_pfn(page))) {
 			page++;
 			continue;
 		}
 
<span class="p_add">+		/* Make sure we are not inadvertently changing nodes */</span>
<span class="p_add">+		VM_BUG_ON_PAGE(page_to_nid(page) != zone_to_nid(zone), page);</span>
<span class="p_add">+</span>
 		if (!PageBuddy(page)) {
 			page++;
 			continue;
<span class="p_chunk">@@ -6445,8 +6445,8 @@</span> <span class="p_context"> unsigned long free_reserved_area(void *start, void *end, int poison, char *s)</span>
 	}
 
 	if (pages &amp;&amp; s)
<span class="p_del">-		pr_info(&quot;Freeing %s memory: %ldK (%p - %p)\n&quot;,</span>
<span class="p_del">-			s, pages &lt;&lt; (PAGE_SHIFT - 10), start, end);</span>
<span class="p_add">+		pr_info(&quot;Freeing %s memory: %ldK\n&quot;,</span>
<span class="p_add">+			s, pages &lt;&lt; (PAGE_SHIFT - 10));</span>
 
 	return pages;
 }
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index cd37c1c7e21b..94488b0362f8 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -616,6 +616,13 @@</span> <span class="p_context"> static void set_tlb_ubc_flush_pending(struct mm_struct *mm,</span>
 	cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));
 	tlb_ubc-&gt;flush_required = true;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure compiler does not re-order the setting of tlb_flush_batched</span>
<span class="p_add">+	 * before the PTE is cleared.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	barrier();</span>
<span class="p_add">+	mm-&gt;tlb_flush_batched = true;</span>
<span class="p_add">+</span>
 	/*
 	 * If the PTE was dirty then it&#39;s best to assume it&#39;s writable. The
 	 * caller must use try_to_unmap_flush_dirty() or try_to_unmap_flush()
<span class="p_chunk">@@ -643,6 +650,35 @@</span> <span class="p_context"> static bool should_defer_flush(struct mm_struct *mm, enum ttu_flags flags)</span>
 
 	return should_defer;
 }
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Reclaim unmaps pages under the PTL but do not flush the TLB prior to</span>
<span class="p_add">+ * releasing the PTL if TLB flushes are batched. It&#39;s possible for a parallel</span>
<span class="p_add">+ * operation such as mprotect or munmap to race between reclaim unmapping</span>
<span class="p_add">+ * the page and flushing the page. If this race occurs, it potentially allows</span>
<span class="p_add">+ * access to data via a stale TLB entry. Tracking all mm&#39;s that have TLB</span>
<span class="p_add">+ * batching in flight would be expensive during reclaim so instead track</span>
<span class="p_add">+ * whether TLB batching occurred in the past and if so then do a flush here</span>
<span class="p_add">+ * if required. This will cost one additional flush per reclaim cycle paid</span>
<span class="p_add">+ * by the first operation at risk such as mprotect and mumap.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This must be called under the PTL so that an access to tlb_flush_batched</span>
<span class="p_add">+ * that is potentially a &quot;reclaim vs mprotect/munmap/etc&quot; race will synchronise</span>
<span class="p_add">+ * via the PTL.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void flush_tlb_batched_pending(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (mm-&gt;tlb_flush_batched) {</span>
<span class="p_add">+		flush_tlb_mm(mm);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Do not allow the compiler to re-order the clearing of</span>
<span class="p_add">+		 * tlb_flush_batched before the tlb is flushed.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		barrier();</span>
<span class="p_add">+		mm-&gt;tlb_flush_batched = false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
 #else
 static void set_tlb_ubc_flush_pending(struct mm_struct *mm,
 		struct page *page, bool writable)
<span class="p_header">diff --git a/net/core/dev_ioctl.c b/net/core/dev_ioctl.c</span>
<span class="p_header">index b94b1d293506..151e047ce072 100644</span>
<span class="p_header">--- a/net/core/dev_ioctl.c</span>
<span class="p_header">+++ b/net/core/dev_ioctl.c</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"> static int dev_ifname(struct net *net, struct ifreq __user *arg)</span>
 
 	if (copy_from_user(&amp;ifr, arg, sizeof(struct ifreq)))
 		return -EFAULT;
<span class="p_add">+	ifr.ifr_name[IFNAMSIZ-1] = 0;</span>
 
 	error = netdev_get_name(net, ifr.ifr_name, ifr.ifr_ifindex);
 	if (error)
<span class="p_header">diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c</span>
<span class="p_header">index 9c6fd7f83a4a..4d2629781e8b 100644</span>
<span class="p_header">--- a/net/core/rtnetlink.c</span>
<span class="p_header">+++ b/net/core/rtnetlink.c</span>
<span class="p_chunk">@@ -1965,7 +1965,8 @@</span> <span class="p_context"> static int do_setlink(const struct sk_buff *skb,</span>
 		struct sockaddr *sa;
 		int len;
 
<span class="p_del">-		len = sizeof(sa_family_t) + dev-&gt;addr_len;</span>
<span class="p_add">+		len = sizeof(sa_family_t) + max_t(size_t, dev-&gt;addr_len,</span>
<span class="p_add">+						  sizeof(*sa));</span>
 		sa = kmalloc(len, GFP_KERNEL);
 		if (!sa) {
 			err = -ENOMEM;
<span class="p_header">diff --git a/net/dccp/feat.c b/net/dccp/feat.c</span>
<span class="p_header">index 1704948e6a12..f227f002c73d 100644</span>
<span class="p_header">--- a/net/dccp/feat.c</span>
<span class="p_header">+++ b/net/dccp/feat.c</span>
<span class="p_chunk">@@ -1471,9 +1471,12 @@</span> <span class="p_context"> int dccp_feat_init(struct sock *sk)</span>
 	 * singleton values (which always leads to failure).
 	 * These settings can still (later) be overridden via sockopts.
 	 */
<span class="p_del">-	if (ccid_get_builtin_ccids(&amp;tx.val, &amp;tx.len) ||</span>
<span class="p_del">-	    ccid_get_builtin_ccids(&amp;rx.val, &amp;rx.len))</span>
<span class="p_add">+	if (ccid_get_builtin_ccids(&amp;tx.val, &amp;tx.len))</span>
 		return -ENOBUFS;
<span class="p_add">+	if (ccid_get_builtin_ccids(&amp;rx.val, &amp;rx.len)) {</span>
<span class="p_add">+		kfree(tx.val);</span>
<span class="p_add">+		return -ENOBUFS;</span>
<span class="p_add">+	}</span>
 
 	if (!dccp_feat_prefer(sysctl_dccp_tx_ccid, tx.val, tx.len) ||
 	    !dccp_feat_prefer(sysctl_dccp_rx_ccid, rx.val, rx.len))
<span class="p_header">diff --git a/net/dccp/ipv4.c b/net/dccp/ipv4.c</span>
<span class="p_header">index 86b0933ecd45..8fc160098e11 100644</span>
<span class="p_header">--- a/net/dccp/ipv4.c</span>
<span class="p_header">+++ b/net/dccp/ipv4.c</span>
<span class="p_chunk">@@ -637,6 +637,7 @@</span> <span class="p_context"> int dccp_v4_conn_request(struct sock *sk, struct sk_buff *skb)</span>
 		goto drop_and_free;
 
 	inet_csk_reqsk_queue_hash_add(sk, req, DCCP_TIMEOUT_INIT);
<span class="p_add">+	reqsk_put(req);</span>
 	return 0;
 
 drop_and_free:
<span class="p_header">diff --git a/net/dccp/ipv6.c b/net/dccp/ipv6.c</span>
<span class="p_header">index 2ac9d2a1aaab..28e8252cc5ea 100644</span>
<span class="p_header">--- a/net/dccp/ipv6.c</span>
<span class="p_header">+++ b/net/dccp/ipv6.c</span>
<span class="p_chunk">@@ -380,6 +380,7 @@</span> <span class="p_context"> static int dccp_v6_conn_request(struct sock *sk, struct sk_buff *skb)</span>
 		goto drop_and_free;
 
 	inet_csk_reqsk_queue_hash_add(sk, req, DCCP_TIMEOUT_INIT);
<span class="p_add">+	reqsk_put(req);</span>
 	return 0;
 
 drop_and_free:
<span class="p_header">diff --git a/net/ipv4/fib_frontend.c b/net/ipv4/fib_frontend.c</span>
<span class="p_header">index 3d92534c4450..968d8e165e3d 100644</span>
<span class="p_header">--- a/net/ipv4/fib_frontend.c</span>
<span class="p_header">+++ b/net/ipv4/fib_frontend.c</span>
<span class="p_chunk">@@ -1319,13 +1319,14 @@</span> <span class="p_context"> static struct pernet_operations fib_net_ops = {</span>
 
 void __init ip_fib_init(void)
 {
<span class="p_del">-	rtnl_register(PF_INET, RTM_NEWROUTE, inet_rtm_newroute, NULL, NULL);</span>
<span class="p_del">-	rtnl_register(PF_INET, RTM_DELROUTE, inet_rtm_delroute, NULL, NULL);</span>
<span class="p_del">-	rtnl_register(PF_INET, RTM_GETROUTE, NULL, inet_dump_fib, NULL);</span>
<span class="p_add">+	fib_trie_init();</span>
 
 	register_pernet_subsys(&amp;fib_net_ops);
<span class="p_add">+</span>
 	register_netdevice_notifier(&amp;fib_netdev_notifier);
 	register_inetaddr_notifier(&amp;fib_inetaddr_notifier);
 
<span class="p_del">-	fib_trie_init();</span>
<span class="p_add">+	rtnl_register(PF_INET, RTM_NEWROUTE, inet_rtm_newroute, NULL, NULL);</span>
<span class="p_add">+	rtnl_register(PF_INET, RTM_DELROUTE, inet_rtm_delroute, NULL, NULL);</span>
<span class="p_add">+	rtnl_register(PF_INET, RTM_GETROUTE, NULL, inet_dump_fib, NULL);</span>
 }
<span class="p_header">diff --git a/net/ipv4/ip_output.c b/net/ipv4/ip_output.c</span>
<span class="p_header">index e5c1dbef3626..06215ba88b93 100644</span>
<span class="p_header">--- a/net/ipv4/ip_output.c</span>
<span class="p_header">+++ b/net/ipv4/ip_output.c</span>
<span class="p_chunk">@@ -936,7 +936,8 @@</span> <span class="p_context"> static int __ip_append_data(struct sock *sk,</span>
 		csummode = CHECKSUM_PARTIAL;
 
 	cork-&gt;length += length;
<span class="p_del">-	if (((length &gt; mtu) || (skb &amp;&amp; skb_is_gso(skb))) &amp;&amp;</span>
<span class="p_add">+	if ((((length + (skb ? skb-&gt;len : fragheaderlen)) &gt; mtu) ||</span>
<span class="p_add">+	     (skb &amp;&amp; skb_is_gso(skb))) &amp;&amp;</span>
 	    (sk-&gt;sk_protocol == IPPROTO_UDP) &amp;&amp;
 	    (rt-&gt;dst.dev-&gt;features &amp; NETIF_F_UFO) &amp;&amp; !rt-&gt;dst.header_len &amp;&amp;
 	    (sk-&gt;sk_type == SOCK_DGRAM) &amp;&amp; !sk-&gt;sk_no_check_tx) {
<span class="p_header">diff --git a/net/ipv4/netfilter/nf_reject_ipv4.c b/net/ipv4/netfilter/nf_reject_ipv4.c</span>
<span class="p_header">index fd8220213afc..146d86105183 100644</span>
<span class="p_header">--- a/net/ipv4/netfilter/nf_reject_ipv4.c</span>
<span class="p_header">+++ b/net/ipv4/netfilter/nf_reject_ipv4.c</span>
<span class="p_chunk">@@ -126,6 +126,8 @@</span> <span class="p_context"> void nf_send_reset(struct net *net, struct sk_buff *oldskb, int hook)</span>
 	/* ip_route_me_harder expects skb-&gt;dst to be set */
 	skb_dst_set_noref(nskb, skb_dst(oldskb));
 
<span class="p_add">+	nskb-&gt;mark = IP4_REPLY_MARK(net, oldskb-&gt;mark);</span>
<span class="p_add">+</span>
 	skb_reserve(nskb, LL_MAX_HEADER);
 	niph = nf_reject_iphdr_put(nskb, oldskb, IPPROTO_TCP,
 				   ip4_dst_hoplimit(skb_dst(nskb)));
<span class="p_header">diff --git a/net/ipv4/syncookies.c b/net/ipv4/syncookies.c</span>
<span class="p_header">index e3c4043c27de..b6f710d515d0 100644</span>
<span class="p_header">--- a/net/ipv4/syncookies.c</span>
<span class="p_header">+++ b/net/ipv4/syncookies.c</span>
<span class="p_chunk">@@ -334,6 +334,7 @@</span> <span class="p_context"> struct sock *cookie_v4_check(struct sock *sk, struct sk_buff *skb)</span>
 	treq = tcp_rsk(req);
 	treq-&gt;rcv_isn		= ntohl(th-&gt;seq) - 1;
 	treq-&gt;snt_isn		= cookie;
<span class="p_add">+	treq-&gt;txhash		= net_tx_rndhash();</span>
 	req-&gt;mss		= mss;
 	ireq-&gt;ir_num		= ntohs(th-&gt;dest);
 	ireq-&gt;ir_rmt_port	= th-&gt;source;
<span class="p_header">diff --git a/net/ipv4/sysctl_net_ipv4.c b/net/ipv4/sysctl_net_ipv4.c</span>
<span class="p_header">index 80bc36b25de2..566cfc50f7cf 100644</span>
<span class="p_header">--- a/net/ipv4/sysctl_net_ipv4.c</span>
<span class="p_header">+++ b/net/ipv4/sysctl_net_ipv4.c</span>
<span class="p_chunk">@@ -958,7 +958,7 @@</span> <span class="p_context"> static struct ctl_table ipv4_net_table[] = {</span>
 		.data		= &amp;init_net.ipv4.sysctl_tcp_notsent_lowat,
 		.maxlen		= sizeof(unsigned int),
 		.mode		= 0644,
<span class="p_del">-		.proc_handler	= proc_dointvec,</span>
<span class="p_add">+		.proc_handler	= proc_douintvec,</span>
 	},
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 	{
<span class="p_header">diff --git a/net/ipv4/tcp_bbr.c b/net/ipv4/tcp_bbr.c</span>
<span class="p_header">index 0ea66c2c9344..cb8db347c680 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_bbr.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_bbr.c</span>
<span class="p_chunk">@@ -83,7 +83,8 @@</span> <span class="p_context"> struct bbr {</span>
 		cwnd_gain:10,	/* current gain for setting cwnd */
 		full_bw_cnt:3,	/* number of rounds without large bw gains */
 		cycle_idx:3,	/* current index in pacing_gain cycle array */
<span class="p_del">-		unused_b:6;</span>
<span class="p_add">+		has_seen_rtt:1, /* have we seen an RTT sample yet? */</span>
<span class="p_add">+		unused_b:5;</span>
 	u32	prior_cwnd;	/* prior cwnd upon entering loss recovery */
 	u32	full_bw;	/* recent bw, to estimate if pipe is full */
 };
<span class="p_chunk">@@ -182,6 +183,35 @@</span> <span class="p_context"> static u64 bbr_rate_bytes_per_sec(struct sock *sk, u64 rate, int gain)</span>
 	return rate &gt;&gt; BW_SCALE;
 }
 
<span class="p_add">+/* Convert a BBR bw and gain factor to a pacing rate in bytes per second. */</span>
<span class="p_add">+static u32 bbr_bw_to_pacing_rate(struct sock *sk, u32 bw, int gain)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 rate = bw;</span>
<span class="p_add">+</span>
<span class="p_add">+	rate = bbr_rate_bytes_per_sec(sk, rate, gain);</span>
<span class="p_add">+	rate = min_t(u64, rate, sk-&gt;sk_max_pacing_rate);</span>
<span class="p_add">+	return rate;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */</span>
<span class="p_add">+static void bbr_init_pacing_rate_from_rtt(struct sock *sk)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct tcp_sock *tp = tcp_sk(sk);</span>
<span class="p_add">+	struct bbr *bbr = inet_csk_ca(sk);</span>
<span class="p_add">+	u64 bw;</span>
<span class="p_add">+	u32 rtt_us;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tp-&gt;srtt_us) {		/* any RTT sample yet? */</span>
<span class="p_add">+		rtt_us = max(tp-&gt;srtt_us &gt;&gt; 3, 1U);</span>
<span class="p_add">+		bbr-&gt;has_seen_rtt = 1;</span>
<span class="p_add">+	} else {			 /* no RTT sample yet */</span>
<span class="p_add">+		rtt_us = USEC_PER_MSEC;	 /* use nominal default RTT */</span>
<span class="p_add">+	}</span>
<span class="p_add">+	bw = (u64)tp-&gt;snd_cwnd * BW_UNIT;</span>
<span class="p_add">+	do_div(bw, rtt_us);</span>
<span class="p_add">+	sk-&gt;sk_pacing_rate = bbr_bw_to_pacing_rate(sk, bw, bbr_high_gain);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Pace using current bw estimate and a gain factor. In order to help drive the
  * network toward lower queues while maintaining high utilization and low
  * latency, the average pacing rate aims to be slightly (~1%) lower than the
<span class="p_chunk">@@ -191,12 +221,13 @@</span> <span class="p_context"> static u64 bbr_rate_bytes_per_sec(struct sock *sk, u64 rate, int gain)</span>
  */
 static void bbr_set_pacing_rate(struct sock *sk, u32 bw, int gain)
 {
<span class="p_add">+	struct tcp_sock *tp = tcp_sk(sk);</span>
 	struct bbr *bbr = inet_csk_ca(sk);
<span class="p_del">-	u64 rate = bw;</span>
<span class="p_add">+	u32 rate = bbr_bw_to_pacing_rate(sk, bw, gain);</span>
 
<span class="p_del">-	rate = bbr_rate_bytes_per_sec(sk, rate, gain);</span>
<span class="p_del">-	rate = min_t(u64, rate, sk-&gt;sk_max_pacing_rate);</span>
<span class="p_del">-	if (bbr-&gt;mode != BBR_STARTUP || rate &gt; sk-&gt;sk_pacing_rate)</span>
<span class="p_add">+	if (unlikely(!bbr-&gt;has_seen_rtt &amp;&amp; tp-&gt;srtt_us))</span>
<span class="p_add">+		bbr_init_pacing_rate_from_rtt(sk);</span>
<span class="p_add">+	if (bbr_full_bw_reached(sk) || rate &gt; sk-&gt;sk_pacing_rate)</span>
 		sk-&gt;sk_pacing_rate = rate;
 }
 
<span class="p_chunk">@@ -769,7 +800,6 @@</span> <span class="p_context"> static void bbr_init(struct sock *sk)</span>
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
<span class="p_del">-	u64 bw;</span>
 
 	bbr-&gt;prior_cwnd = 0;
 	bbr-&gt;tso_segs_goal = 0;	 /* default segs per skb until first ACK */
<span class="p_chunk">@@ -785,11 +815,8 @@</span> <span class="p_context"> static void bbr_init(struct sock *sk)</span>
 
 	minmax_reset(&amp;bbr-&gt;bw, bbr-&gt;rtt_cnt, 0);  /* init max bw to 0 */
 
<span class="p_del">-	/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */</span>
<span class="p_del">-	bw = (u64)tp-&gt;snd_cwnd * BW_UNIT;</span>
<span class="p_del">-	do_div(bw, (tp-&gt;srtt_us &gt;&gt; 3) ? : USEC_PER_MSEC);</span>
<span class="p_del">-	sk-&gt;sk_pacing_rate = 0;		/* force an update of sk_pacing_rate */</span>
<span class="p_del">-	bbr_set_pacing_rate(sk, bw, bbr_high_gain);</span>
<span class="p_add">+	bbr-&gt;has_seen_rtt = 0;</span>
<span class="p_add">+	bbr_init_pacing_rate_from_rtt(sk);</span>
 
 	bbr-&gt;restore_cwnd = 0;
 	bbr-&gt;round_start = 0;
<span class="p_header">diff --git a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c</span>
<span class="p_header">index 5a4b8e7bcedd..a5cdf2a23609 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_output.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_output.c</span>
<span class="p_chunk">@@ -662,8 +662,6 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 		*prevhdr = NEXTHDR_FRAGMENT;
 		tmp_hdr = kmemdup(skb_network_header(skb), hlen, GFP_ATOMIC);
 		if (!tmp_hdr) {
<span class="p_del">-			IP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),</span>
<span class="p_del">-				      IPSTATS_MIB_FRAGFAILS);</span>
 			err = -ENOMEM;
 			goto fail;
 		}
<span class="p_chunk">@@ -782,8 +780,6 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 		frag = alloc_skb(len + hlen + sizeof(struct frag_hdr) +
 				 hroom + troom, GFP_ATOMIC);
 		if (!frag) {
<span class="p_del">-			IP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),</span>
<span class="p_del">-				      IPSTATS_MIB_FRAGFAILS);</span>
 			err = -ENOMEM;
 			goto fail;
 		}
<span class="p_chunk">@@ -1376,7 +1372,7 @@</span> <span class="p_context"> static int __ip6_append_data(struct sock *sk,</span>
 	 */
 
 	cork-&gt;length += length;
<span class="p_del">-	if ((((length + fragheaderlen) &gt; mtu) ||</span>
<span class="p_add">+	if ((((length + (skb ? skb-&gt;len : headersize)) &gt; mtu) ||</span>
 	     (skb &amp;&amp; skb_is_gso(skb))) &amp;&amp;
 	    (sk-&gt;sk_protocol == IPPROTO_UDP) &amp;&amp;
 	    (rt-&gt;dst.dev-&gt;features &amp; NETIF_F_UFO) &amp;&amp; !rt-&gt;dst.header_len &amp;&amp;
<span class="p_header">diff --git a/net/ipv6/netfilter/nf_reject_ipv6.c b/net/ipv6/netfilter/nf_reject_ipv6.c</span>
<span class="p_header">index 10090400c72f..eedee5d108d9 100644</span>
<span class="p_header">--- a/net/ipv6/netfilter/nf_reject_ipv6.c</span>
<span class="p_header">+++ b/net/ipv6/netfilter/nf_reject_ipv6.c</span>
<span class="p_chunk">@@ -157,6 +157,7 @@</span> <span class="p_context"> void nf_send_reset6(struct net *net, struct sk_buff *oldskb, int hook)</span>
 	fl6.fl6_sport = otcph-&gt;dest;
 	fl6.fl6_dport = otcph-&gt;source;
 	fl6.flowi6_oif = l3mdev_master_ifindex(skb_dst(oldskb)-&gt;dev);
<span class="p_add">+	fl6.flowi6_mark = IP6_REPLY_MARK(net, oldskb-&gt;mark);</span>
 	security_skb_classify_flow(oldskb, flowi6_to_flowi(&amp;fl6));
 	dst = ip6_route_output(net, NULL, &amp;fl6);
 	if (dst-&gt;error) {
<span class="p_chunk">@@ -180,6 +181,8 @@</span> <span class="p_context"> void nf_send_reset6(struct net *net, struct sk_buff *oldskb, int hook)</span>
 
 	skb_dst_set(nskb, dst);
 
<span class="p_add">+	nskb-&gt;mark = fl6.flowi6_mark;</span>
<span class="p_add">+</span>
 	skb_reserve(nskb, hh_len + dst-&gt;header_len);
 	ip6h = nf_reject_ip6hdr_put(nskb, oldskb, IPPROTO_TCP,
 				    ip6_dst_hoplimit(dst));
<span class="p_header">diff --git a/net/ipv6/output_core.c b/net/ipv6/output_core.c</span>
<span class="p_header">index e9065b8d3af8..abb2c307fbe8 100644</span>
<span class="p_header">--- a/net/ipv6/output_core.c</span>
<span class="p_header">+++ b/net/ipv6/output_core.c</span>
<span class="p_chunk">@@ -78,7 +78,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(ipv6_select_ident);</span>
 
 int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)
 {
<span class="p_del">-	u16 offset = sizeof(struct ipv6hdr);</span>
<span class="p_add">+	unsigned int offset = sizeof(struct ipv6hdr);</span>
 	unsigned int packet_len = skb_tail_pointer(skb) -
 		skb_network_header(skb);
 	int found_rhdr = 0;
<span class="p_chunk">@@ -86,6 +86,7 @@</span> <span class="p_context"> int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)</span>
 
 	while (offset &lt;= packet_len) {
 		struct ipv6_opt_hdr *exthdr;
<span class="p_add">+		unsigned int len;</span>
 
 		switch (**nexthdr) {
 
<span class="p_chunk">@@ -111,7 +112,10 @@</span> <span class="p_context"> int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)</span>
 
 		exthdr = (struct ipv6_opt_hdr *)(skb_network_header(skb) +
 						 offset);
<span class="p_del">-		offset += ipv6_optlen(exthdr);</span>
<span class="p_add">+		len = ipv6_optlen(exthdr);</span>
<span class="p_add">+		if (len + offset &gt;= IPV6_MAXPLEN)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		offset += len;</span>
 		*nexthdr = &amp;exthdr-&gt;nexthdr;
 	}
 
<span class="p_header">diff --git a/net/ipv6/syncookies.c b/net/ipv6/syncookies.c</span>
<span class="p_header">index 59c483937aec..7a86433d8896 100644</span>
<span class="p_header">--- a/net/ipv6/syncookies.c</span>
<span class="p_header">+++ b/net/ipv6/syncookies.c</span>
<span class="p_chunk">@@ -209,6 +209,7 @@</span> <span class="p_context"> struct sock *cookie_v6_check(struct sock *sk, struct sk_buff *skb)</span>
 	treq-&gt;snt_synack.v64	= 0;
 	treq-&gt;rcv_isn = ntohl(th-&gt;seq) - 1;
 	treq-&gt;snt_isn = cookie;
<span class="p_add">+	treq-&gt;txhash = net_tx_rndhash();</span>
 
 	/*
 	 * We need to lookup the dst_entry to get the correct window size.
<span class="p_header">diff --git a/net/openvswitch/conntrack.c b/net/openvswitch/conntrack.c</span>
<span class="p_header">index 48386bff8b4e..b28e45b691de 100644</span>
<span class="p_header">--- a/net/openvswitch/conntrack.c</span>
<span class="p_header">+++ b/net/openvswitch/conntrack.c</span>
<span class="p_chunk">@@ -1088,8 +1088,8 @@</span> <span class="p_context"> static int parse_ct(const struct nlattr *attr, struct ovs_conntrack_info *info,</span>
 
 	nla_for_each_nested(a, attr, rem) {
 		int type = nla_type(a);
<span class="p_del">-		int maxlen = ovs_ct_attr_lens[type].maxlen;</span>
<span class="p_del">-		int minlen = ovs_ct_attr_lens[type].minlen;</span>
<span class="p_add">+		int maxlen;</span>
<span class="p_add">+		int minlen;</span>
 
 		if (type &gt; OVS_CT_ATTR_MAX) {
 			OVS_NLERR(log,
<span class="p_chunk">@@ -1097,6 +1097,9 @@</span> <span class="p_context"> static int parse_ct(const struct nlattr *attr, struct ovs_conntrack_info *info,</span>
 				  type, OVS_CT_ATTR_MAX);
 			return -EINVAL;
 		}
<span class="p_add">+</span>
<span class="p_add">+		maxlen = ovs_ct_attr_lens[type].maxlen;</span>
<span class="p_add">+		minlen = ovs_ct_attr_lens[type].minlen;</span>
 		if (nla_len(a) &lt; minlen || nla_len(a) &gt; maxlen) {
 			OVS_NLERR(log,
 				  &quot;Conntrack attr type has unexpected length (type=%d, length=%d, expected=%d)&quot;,
<span class="p_header">diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c</span>
<span class="p_header">index 6a563e6e24de..365c83fcee02 100644</span>
<span class="p_header">--- a/net/packet/af_packet.c</span>
<span class="p_header">+++ b/net/packet/af_packet.c</span>
<span class="p_chunk">@@ -4322,7 +4322,7 @@</span> <span class="p_context"> static int packet_set_ring(struct sock *sk, union tpacket_req_u *req_u,</span>
 		register_prot_hook(sk);
 	}
 	spin_unlock(&amp;po-&gt;bind_lock);
<span class="p_del">-	if (closing &amp;&amp; (po-&gt;tp_version &gt; TPACKET_V2)) {</span>
<span class="p_add">+	if (pg_vec &amp;&amp; (po-&gt;tp_version &gt; TPACKET_V2)) {</span>
 		/* Because we don&#39;t support block-based V3 on tx-ring */
 		if (!tx_ring)
 			prb_shutdown_retire_blk_timer(po, rb_queue);
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index bb1aad39d987..6f337f00ba58 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -2233,6 +2233,7 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc882_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x1043, 0x8691, &quot;ASUS ROG Ranger VIII&quot;, ALC882_FIXUP_GPIO3),
 	SND_PCI_QUIRK(0x104d, 0x9047, &quot;Sony Vaio TT&quot;, ALC889_FIXUP_VAIO_TT),
 	SND_PCI_QUIRK(0x104d, 0x905a, &quot;Sony Vaio Z&quot;, ALC882_FIXUP_NO_PRIMARY_HP),
<span class="p_add">+	SND_PCI_QUIRK(0x104d, 0x9060, &quot;Sony Vaio VPCL14M1R&quot;, ALC882_FIXUP_NO_PRIMARY_HP),</span>
 	SND_PCI_QUIRK(0x104d, 0x9043, &quot;Sony Vaio VGC-LN51JGB&quot;, ALC882_FIXUP_NO_PRIMARY_HP),
 	SND_PCI_QUIRK(0x104d, 0x9044, &quot;Sony VAIO AiO&quot;, ALC882_FIXUP_NO_PRIMARY_HP),
 
<span class="p_header">diff --git a/sound/soc/codecs/rt5645.c b/sound/soc/codecs/rt5645.c</span>
<span class="p_header">index 10c2a564a715..1ac96ef9ee20 100644</span>
<span class="p_header">--- a/sound/soc/codecs/rt5645.c</span>
<span class="p_header">+++ b/sound/soc/codecs/rt5645.c</span>
<span class="p_chunk">@@ -3833,6 +3833,9 @@</span> <span class="p_context"> static int rt5645_i2c_probe(struct i2c_client *i2c,</span>
 		}
 	}
 
<span class="p_add">+	regmap_update_bits(rt5645-&gt;regmap, RT5645_ADDA_CLK1,</span>
<span class="p_add">+		RT5645_I2S_PD1_MASK, RT5645_I2S_PD1_2);</span>
<span class="p_add">+</span>
 	if (rt5645-&gt;pdata.jd_invert) {
 		regmap_update_bits(rt5645-&gt;regmap, RT5645_IRQ_CTRL2,
 			RT5645_JD_1_1_MASK, RT5645_JD_1_1_INV);
<span class="p_header">diff --git a/sound/soc/soc-pcm.c b/sound/soc/soc-pcm.c</span>
<span class="p_header">index 21c3ef01c438..80088c98ce27 100644</span>
<span class="p_header">--- a/sound/soc/soc-pcm.c</span>
<span class="p_header">+++ b/sound/soc/soc-pcm.c</span>
<span class="p_chunk">@@ -181,6 +181,10 @@</span> <span class="p_context"> int dpcm_dapm_stream_event(struct snd_soc_pcm_runtime *fe, int dir,</span>
 		dev_dbg(be-&gt;dev, &quot;ASoC: BE %s event %d dir %d\n&quot;,
 				be-&gt;dai_link-&gt;name, event, dir);
 
<span class="p_add">+		if ((event == SND_SOC_DAPM_STREAM_STOP) &amp;&amp;</span>
<span class="p_add">+		    (be-&gt;dpcm[dir].users &gt;= 1))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		snd_soc_dapm_stream_event(be, dir, event);
 	}
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



