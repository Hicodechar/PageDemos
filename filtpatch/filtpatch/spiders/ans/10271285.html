
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.14.25 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.14.25</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 9, 2018, 4:53 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180309165355.GB29447@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10271285/mbox/"
   >mbox</a>
|
   <a href="/patch/10271285/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10271285/">/patch/10271285/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A1E4B60594 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  9 Mar 2018 16:54:19 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6FB8229442
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  9 Mar 2018 16:54:19 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 6254329C58; Fri,  9 Mar 2018 16:54:19 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id EC60D29442
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  9 Mar 2018 16:54:12 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751282AbeCIQyG (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 9 Mar 2018 11:54:06 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:44334 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751159AbeCIQxz (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 9 Mar 2018 11:53:55 -0500
Received: from localhost (unknown [185.236.200.248])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 05FF2DEE;
	Fri,  9 Mar 2018 16:53:53 +0000 (UTC)
Date: Fri, 9 Mar 2018 08:53:55 -0800
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.14.25
Message-ID: &lt;20180309165355.GB29447@kroah.com&gt;
References: &lt;20180309165347.GA29447@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20180309165347.GA29447@kroah.com&gt;
User-Agent: Mutt/1.9.4 (2018-02-28)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - March 9, 2018, 4:53 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/networking/ip-sysctl.txt b/Documentation/networking/ip-sysctl.txt</span>
<span class="p_header">index 77f4de59dc9c..d499676890d8 100644</span>
<span class="p_header">--- a/Documentation/networking/ip-sysctl.txt</span>
<span class="p_header">+++ b/Documentation/networking/ip-sysctl.txt</span>
<span class="p_chunk">@@ -508,7 +508,7 @@</span> <span class="p_context"> tcp_rmem - vector of 3 INTEGERs: min, default, max</span>
 	min: Minimal size of receive buffer used by TCP sockets.
 	It is guaranteed to each TCP socket, even under moderate memory
 	pressure.
<span class="p_del">-	Default: 1 page</span>
<span class="p_add">+	Default: 4K</span>
 
 	default: initial size of receive buffer used by TCP sockets.
 	This value overrides net.core.rmem_default used by other protocols.
<span class="p_chunk">@@ -666,7 +666,7 @@</span> <span class="p_context"> tcp_window_scaling - BOOLEAN</span>
 tcp_wmem - vector of 3 INTEGERs: min, default, max
 	min: Amount of memory reserved for send buffers for TCP sockets.
 	Each TCP socket has rights to use it due to fact of its birth.
<span class="p_del">-	Default: 1 page</span>
<span class="p_add">+	Default: 4K</span>
 
 	default: initial size of send buffer used by TCP sockets.  This
 	value overrides net.core.wmem_default used by other protocols.
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 38acc6047d7d..0fdae0f455ef 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,7 +1,7 @@</span> <span class="p_context"></span>
 # SPDX-License-Identifier: GPL-2.0
 VERSION = 4
 PATCHLEVEL = 14
<span class="p_del">-SUBLEVEL = 24</span>
<span class="p_add">+SUBLEVEL = 25</span>
 EXTRAVERSION =
 NAME = Petit Gorille
 
<span class="p_header">diff --git a/arch/arm/boot/dts/logicpd-som-lv.dtsi b/arch/arm/boot/dts/logicpd-som-lv.dtsi</span>
<span class="p_header">index 4f2c5ec75714..e262fa9ef334 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/logicpd-som-lv.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/logicpd-som-lv.dtsi</span>
<span class="p_chunk">@@ -97,6 +97,8 @@</span> <span class="p_context"></span>
 };
 
 &amp;i2c1 {
<span class="p_add">+	pinctrl-names = &quot;default&quot;;</span>
<span class="p_add">+	pinctrl-0 = &lt;&amp;i2c1_pins&gt;;</span>
 	clock-frequency = &lt;2600000&gt;;
 
 	twl: twl@48 {
<span class="p_chunk">@@ -215,7 +217,12 @@</span> <span class="p_context"></span>
 		&gt;;
 	};
 
<span class="p_del">-</span>
<span class="p_add">+	i2c1_pins: pinmux_i2c1_pins {</span>
<span class="p_add">+		pinctrl-single,pins = &lt;</span>
<span class="p_add">+			OMAP3_CORE1_IOPAD(0x21ba, PIN_INPUT | MUX_MODE0)        /* i2c1_scl.i2c1_scl */</span>
<span class="p_add">+			OMAP3_CORE1_IOPAD(0x21bc, PIN_INPUT | MUX_MODE0)        /* i2c1_sda.i2c1_sda */</span>
<span class="p_add">+		&gt;;</span>
<span class="p_add">+	};</span>
 };
 
 &amp;omap3_pmx_wkup {
<span class="p_header">diff --git a/arch/arm/boot/dts/logicpd-torpedo-som.dtsi b/arch/arm/boot/dts/logicpd-torpedo-som.dtsi</span>
<span class="p_header">index 6d89736c7b44..cf22b35f0a28 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/logicpd-torpedo-som.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/logicpd-torpedo-som.dtsi</span>
<span class="p_chunk">@@ -104,6 +104,8 @@</span> <span class="p_context"></span>
 };
 
 &amp;i2c1 {
<span class="p_add">+	pinctrl-names = &quot;default&quot;;</span>
<span class="p_add">+	pinctrl-0 = &lt;&amp;i2c1_pins&gt;;</span>
 	clock-frequency = &lt;2600000&gt;;
 
 	twl: twl@48 {
<span class="p_chunk">@@ -211,6 +213,12 @@</span> <span class="p_context"></span>
 			OMAP3_CORE1_IOPAD(0x21b8, PIN_INPUT | MUX_MODE0)	/* hsusb0_data7.hsusb0_data7 */
 		&gt;;
 	};
<span class="p_add">+	i2c1_pins: pinmux_i2c1_pins {</span>
<span class="p_add">+		pinctrl-single,pins = &lt;</span>
<span class="p_add">+			OMAP3_CORE1_IOPAD(0x21ba, PIN_INPUT | MUX_MODE0)        /* i2c1_scl.i2c1_scl */</span>
<span class="p_add">+			OMAP3_CORE1_IOPAD(0x21bc, PIN_INPUT | MUX_MODE0)        /* i2c1_sda.i2c1_sda */</span>
<span class="p_add">+		&gt;;</span>
<span class="p_add">+	};</span>
 };
 
 &amp;uart2 {
<span class="p_header">diff --git a/arch/arm/boot/dts/rk3288-phycore-som.dtsi b/arch/arm/boot/dts/rk3288-phycore-som.dtsi</span>
<span class="p_header">index 99cfae875e12..5eae4776ffde 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/rk3288-phycore-som.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/rk3288-phycore-som.dtsi</span>
<span class="p_chunk">@@ -110,26 +110,6 @@</span> <span class="p_context"></span>
 	};
 };
 
<span class="p_del">-&amp;cpu0 {</span>
<span class="p_del">-	cpu0-supply = &lt;&amp;vdd_cpu&gt;;</span>
<span class="p_del">-	operating-points = &lt;</span>
<span class="p_del">-		/* KHz    uV */</span>
<span class="p_del">-		1800000	1400000</span>
<span class="p_del">-		1608000	1350000</span>
<span class="p_del">-		1512000 1300000</span>
<span class="p_del">-		1416000 1200000</span>
<span class="p_del">-		1200000 1100000</span>
<span class="p_del">-		1008000 1050000</span>
<span class="p_del">-		 816000 1000000</span>
<span class="p_del">-		 696000  950000</span>
<span class="p_del">-		 600000  900000</span>
<span class="p_del">-		 408000  900000</span>
<span class="p_del">-		 312000  900000</span>
<span class="p_del">-		 216000  900000</span>
<span class="p_del">-		 126000  900000</span>
<span class="p_del">-	&gt;;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 &amp;emmc {
 	status = &quot;okay&quot;;
 	bus-width = &lt;8&gt;;
<span class="p_header">diff --git a/arch/arm/kvm/hyp/Makefile b/arch/arm/kvm/hyp/Makefile</span>
<span class="p_header">index 5638ce0c9524..63d6b404d88e 100644</span>
<span class="p_header">--- a/arch/arm/kvm/hyp/Makefile</span>
<span class="p_header">+++ b/arch/arm/kvm/hyp/Makefile</span>
<span class="p_chunk">@@ -7,6 +7,8 @@</span> <span class="p_context"> ccflags-y += -fno-stack-protector -DDISABLE_BRANCH_PROFILING</span>
 
 KVM=../../../../virt/kvm
 
<span class="p_add">+CFLAGS_ARMV7VE		   :=$(call cc-option, -march=armv7ve)</span>
<span class="p_add">+</span>
 obj-$(CONFIG_KVM_ARM_HOST) += $(KVM)/arm/hyp/vgic-v2-sr.o
 obj-$(CONFIG_KVM_ARM_HOST) += $(KVM)/arm/hyp/vgic-v3-sr.o
 obj-$(CONFIG_KVM_ARM_HOST) += $(KVM)/arm/hyp/timer-sr.o
<span class="p_chunk">@@ -15,7 +17,10 @@</span> <span class="p_context"> obj-$(CONFIG_KVM_ARM_HOST) += tlb.o</span>
 obj-$(CONFIG_KVM_ARM_HOST) += cp15-sr.o
 obj-$(CONFIG_KVM_ARM_HOST) += vfp.o
 obj-$(CONFIG_KVM_ARM_HOST) += banked-sr.o
<span class="p_add">+CFLAGS_banked-sr.o	   += $(CFLAGS_ARMV7VE)</span>
<span class="p_add">+</span>
 obj-$(CONFIG_KVM_ARM_HOST) += entry.o
 obj-$(CONFIG_KVM_ARM_HOST) += hyp-entry.o
 obj-$(CONFIG_KVM_ARM_HOST) += switch.o
<span class="p_add">+CFLAGS_switch.o		   += $(CFLAGS_ARMV7VE)</span>
 obj-$(CONFIG_KVM_ARM_HOST) += s2-setup.o
<span class="p_header">diff --git a/arch/arm/kvm/hyp/banked-sr.c b/arch/arm/kvm/hyp/banked-sr.c</span>
<span class="p_header">index 111bda8cdebd..be4b8b0a40ad 100644</span>
<span class="p_header">--- a/arch/arm/kvm/hyp/banked-sr.c</span>
<span class="p_header">+++ b/arch/arm/kvm/hyp/banked-sr.c</span>
<span class="p_chunk">@@ -20,6 +20,10 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/kvm_hyp.h&gt;
 
<span class="p_add">+/*</span>
<span class="p_add">+ * gcc before 4.9 doesn&#39;t understand -march=armv7ve, so we have to</span>
<span class="p_add">+ * trick the assembler.</span>
<span class="p_add">+ */</span>
 __asm__(&quot;.arch_extension     virt&quot;);
 
 void __hyp_text __banked_save_state(struct kvm_cpu_context *ctxt)
<span class="p_header">diff --git a/arch/arm/mach-mvebu/Kconfig b/arch/arm/mach-mvebu/Kconfig</span>
<span class="p_header">index 9b49867154bf..63fa79f9f121 100644</span>
<span class="p_header">--- a/arch/arm/mach-mvebu/Kconfig</span>
<span class="p_header">+++ b/arch/arm/mach-mvebu/Kconfig</span>
<span class="p_chunk">@@ -42,7 +42,7 @@</span> <span class="p_context"> config MACH_ARMADA_375</span>
 	depends on ARCH_MULTI_V7
 	select ARMADA_370_XP_IRQ
 	select ARM_ERRATA_720789
<span class="p_del">-	select ARM_ERRATA_753970</span>
<span class="p_add">+	select PL310_ERRATA_753970</span>
 	select ARM_GIC
 	select ARMADA_375_CLK
 	select HAVE_ARM_SCU
<span class="p_chunk">@@ -58,7 +58,7 @@</span> <span class="p_context"> config MACH_ARMADA_38X</span>
 	bool &quot;Marvell Armada 380/385 boards&quot;
 	depends on ARCH_MULTI_V7
 	select ARM_ERRATA_720789
<span class="p_del">-	select ARM_ERRATA_753970</span>
<span class="p_add">+	select PL310_ERRATA_753970</span>
 	select ARM_GIC
 	select ARM_GLOBAL_TIMER
 	select CLKSRC_ARM_GLOBAL_TIMER_SCHED_CLOCK
<span class="p_header">diff --git a/arch/arm/plat-orion/common.c b/arch/arm/plat-orion/common.c</span>
<span class="p_header">index aff6994950ba..a2399fd66e97 100644</span>
<span class="p_header">--- a/arch/arm/plat-orion/common.c</span>
<span class="p_header">+++ b/arch/arm/plat-orion/common.c</span>
<span class="p_chunk">@@ -472,28 +472,27 @@</span> <span class="p_context"> void __init orion_ge11_init(struct mv643xx_eth_platform_data *eth_data,</span>
 /*****************************************************************************
  * Ethernet switch
  ****************************************************************************/
<span class="p_del">-static __initconst const char *orion_ge00_mvmdio_bus_name = &quot;orion-mii&quot;;</span>
<span class="p_del">-static __initdata struct mdio_board_info</span>
<span class="p_del">-		  orion_ge00_switch_board_info;</span>
<span class="p_add">+static __initdata struct mdio_board_info orion_ge00_switch_board_info = {</span>
<span class="p_add">+	.bus_id   = &quot;orion-mii&quot;,</span>
<span class="p_add">+	.modalias = &quot;mv88e6085&quot;,</span>
<span class="p_add">+};</span>
 
 void __init orion_ge00_switch_init(struct dsa_chip_data *d)
 {
<span class="p_del">-	struct mdio_board_info *bd;</span>
 	unsigned int i;
 
 	if (!IS_BUILTIN(CONFIG_PHYLIB))
 		return;
 
<span class="p_del">-	for (i = 0; i &lt; ARRAY_SIZE(d-&gt;port_names); i++)</span>
<span class="p_del">-		if (!strcmp(d-&gt;port_names[i], &quot;cpu&quot;))</span>
<span class="p_add">+	for (i = 0; i &lt; ARRAY_SIZE(d-&gt;port_names); i++) {</span>
<span class="p_add">+		if (!strcmp(d-&gt;port_names[i], &quot;cpu&quot;)) {</span>
<span class="p_add">+			d-&gt;netdev[i] = &amp;orion_ge00.dev;</span>
 			break;
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	bd = &amp;orion_ge00_switch_board_info;</span>
<span class="p_del">-	bd-&gt;bus_id = orion_ge00_mvmdio_bus_name;</span>
<span class="p_del">-	bd-&gt;mdio_addr = d-&gt;sw_addr;</span>
<span class="p_del">-	d-&gt;netdev[i] = &amp;orion_ge00.dev;</span>
<span class="p_del">-	strcpy(bd-&gt;modalias, &quot;mv88e6085&quot;);</span>
<span class="p_del">-	bd-&gt;platform_data = d;</span>
<span class="p_add">+	orion_ge00_switch_board_info.mdio_addr = d-&gt;sw_addr;</span>
<span class="p_add">+	orion_ge00_switch_board_info.platform_data = d;</span>
 
 	mdiobus_register_board_info(&amp;orion_ge00_switch_board_info, 1);
 }
<span class="p_header">diff --git a/arch/parisc/include/asm/cacheflush.h b/arch/parisc/include/asm/cacheflush.h</span>
<span class="p_header">index 3742508cc534..bd5ce31936f5 100644</span>
<span class="p_header">--- a/arch/parisc/include/asm/cacheflush.h</span>
<span class="p_header">+++ b/arch/parisc/include/asm/cacheflush.h</span>
<span class="p_chunk">@@ -26,6 +26,7 @@</span> <span class="p_context"> void flush_user_icache_range_asm(unsigned long, unsigned long);</span>
 void flush_kernel_icache_range_asm(unsigned long, unsigned long);
 void flush_user_dcache_range_asm(unsigned long, unsigned long);
 void flush_kernel_dcache_range_asm(unsigned long, unsigned long);
<span class="p_add">+void purge_kernel_dcache_range_asm(unsigned long, unsigned long);</span>
 void flush_kernel_dcache_page_asm(void *);
 void flush_kernel_icache_page(void *);
 
<span class="p_header">diff --git a/arch/parisc/include/asm/processor.h b/arch/parisc/include/asm/processor.h</span>
<span class="p_header">index 0e6ab6e4a4e9..2dbe5580a1a4 100644</span>
<span class="p_header">--- a/arch/parisc/include/asm/processor.h</span>
<span class="p_header">+++ b/arch/parisc/include/asm/processor.h</span>
<span class="p_chunk">@@ -316,6 +316,8 @@</span> <span class="p_context"> extern int _parisc_requires_coherency;</span>
 #define parisc_requires_coherency()	(0)
 #endif
 
<span class="p_add">+extern int running_on_qemu;</span>
<span class="p_add">+</span>
 #endif /* __ASSEMBLY__ */
 
 #endif /* __ASM_PARISC_PROCESSOR_H */
<span class="p_header">diff --git a/arch/parisc/kernel/cache.c b/arch/parisc/kernel/cache.c</span>
<span class="p_header">index 19c0c141bc3f..79089778725b 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/cache.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/cache.c</span>
<span class="p_chunk">@@ -465,10 +465,10 @@</span> <span class="p_context"> EXPORT_SYMBOL(copy_user_page);</span>
 int __flush_tlb_range(unsigned long sid, unsigned long start,
 		      unsigned long end)
 {
<span class="p_del">-	unsigned long flags, size;</span>
<span class="p_add">+	unsigned long flags;</span>
 
<span class="p_del">-	size = (end - start);</span>
<span class="p_del">-	if (size &gt;= parisc_tlb_flush_threshold) {</span>
<span class="p_add">+	if ((!IS_ENABLED(CONFIG_SMP) || !arch_irqs_disabled()) &amp;&amp;</span>
<span class="p_add">+	    end - start &gt;= parisc_tlb_flush_threshold) {</span>
 		flush_tlb_all();
 		return 1;
 	}
<span class="p_chunk">@@ -539,13 +539,11 @@</span> <span class="p_context"> void flush_cache_mm(struct mm_struct *mm)</span>
 	struct vm_area_struct *vma;
 	pgd_t *pgd;
 
<span class="p_del">-	/* Flush the TLB to avoid speculation if coherency is required. */</span>
<span class="p_del">-	if (parisc_requires_coherency())</span>
<span class="p_del">-		flush_tlb_all();</span>
<span class="p_del">-</span>
 	/* Flushing the whole cache on each cpu takes forever on
 	   rp3440, etc.  So, avoid it if the mm isn&#39;t too big.  */
<span class="p_del">-	if (mm_total_size(mm) &gt;= parisc_cache_flush_threshold) {</span>
<span class="p_add">+	if ((!IS_ENABLED(CONFIG_SMP) || !arch_irqs_disabled()) &amp;&amp;</span>
<span class="p_add">+	    mm_total_size(mm) &gt;= parisc_cache_flush_threshold) {</span>
<span class="p_add">+		flush_tlb_all();</span>
 		flush_cache_all();
 		return;
 	}
<span class="p_chunk">@@ -553,9 +551,9 @@</span> <span class="p_context"> void flush_cache_mm(struct mm_struct *mm)</span>
 	if (mm-&gt;context == mfsp(3)) {
 		for (vma = mm-&gt;mmap; vma; vma = vma-&gt;vm_next) {
 			flush_user_dcache_range_asm(vma-&gt;vm_start, vma-&gt;vm_end);
<span class="p_del">-			if ((vma-&gt;vm_flags &amp; VM_EXEC) == 0)</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			flush_user_icache_range_asm(vma-&gt;vm_start, vma-&gt;vm_end);</span>
<span class="p_add">+			if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+				flush_user_icache_range_asm(vma-&gt;vm_start, vma-&gt;vm_end);</span>
<span class="p_add">+			flush_tlb_range(vma, vma-&gt;vm_start, vma-&gt;vm_end);</span>
 		}
 		return;
 	}
<span class="p_chunk">@@ -581,14 +579,9 @@</span> <span class="p_context"> void flush_cache_mm(struct mm_struct *mm)</span>
 void flush_cache_range(struct vm_area_struct *vma,
 		unsigned long start, unsigned long end)
 {
<span class="p_del">-	BUG_ON(!vma-&gt;vm_mm-&gt;context);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Flush the TLB to avoid speculation if coherency is required. */</span>
<span class="p_del">-	if (parisc_requires_coherency())</span>
<span class="p_add">+	if ((!IS_ENABLED(CONFIG_SMP) || !arch_irqs_disabled()) &amp;&amp;</span>
<span class="p_add">+	    end - start &gt;= parisc_cache_flush_threshold) {</span>
 		flush_tlb_range(vma, start, end);
<span class="p_del">-</span>
<span class="p_del">-	if ((end - start) &gt;= parisc_cache_flush_threshold</span>
<span class="p_del">-	    || vma-&gt;vm_mm-&gt;context != mfsp(3)) {</span>
 		flush_cache_all();
 		return;
 	}
<span class="p_chunk">@@ -596,6 +589,7 @@</span> <span class="p_context"> void flush_cache_range(struct vm_area_struct *vma,</span>
 	flush_user_dcache_range_asm(start, end);
 	if (vma-&gt;vm_flags &amp; VM_EXEC)
 		flush_user_icache_range_asm(start, end);
<span class="p_add">+	flush_tlb_range(vma, start, end);</span>
 }
 
 void
<span class="p_chunk">@@ -604,8 +598,7 @@</span> <span class="p_context"> flush_cache_page(struct vm_area_struct *vma, unsigned long vmaddr, unsigned long</span>
 	BUG_ON(!vma-&gt;vm_mm-&gt;context);
 
 	if (pfn_valid(pfn)) {
<span class="p_del">-		if (parisc_requires_coherency())</span>
<span class="p_del">-			flush_tlb_page(vma, vmaddr);</span>
<span class="p_add">+		flush_tlb_page(vma, vmaddr);</span>
 		__flush_cache_page(vma, vmaddr, PFN_PHYS(pfn));
 	}
 }
<span class="p_chunk">@@ -613,21 +606,33 @@</span> <span class="p_context"> flush_cache_page(struct vm_area_struct *vma, unsigned long vmaddr, unsigned long</span>
 void flush_kernel_vmap_range(void *vaddr, int size)
 {
 	unsigned long start = (unsigned long)vaddr;
<span class="p_add">+	unsigned long end = start + size;</span>
 
<span class="p_del">-	if ((unsigned long)size &gt; parisc_cache_flush_threshold)</span>
<span class="p_add">+	if ((!IS_ENABLED(CONFIG_SMP) || !arch_irqs_disabled()) &amp;&amp;</span>
<span class="p_add">+	    (unsigned long)size &gt;= parisc_cache_flush_threshold) {</span>
<span class="p_add">+		flush_tlb_kernel_range(start, end);</span>
 		flush_data_cache();
<span class="p_del">-	else</span>
<span class="p_del">-		flush_kernel_dcache_range_asm(start, start + size);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	flush_kernel_dcache_range_asm(start, end);</span>
<span class="p_add">+	flush_tlb_kernel_range(start, end);</span>
 }
 EXPORT_SYMBOL(flush_kernel_vmap_range);
 
 void invalidate_kernel_vmap_range(void *vaddr, int size)
 {
 	unsigned long start = (unsigned long)vaddr;
<span class="p_add">+	unsigned long end = start + size;</span>
 
<span class="p_del">-	if ((unsigned long)size &gt; parisc_cache_flush_threshold)</span>
<span class="p_add">+	if ((!IS_ENABLED(CONFIG_SMP) || !arch_irqs_disabled()) &amp;&amp;</span>
<span class="p_add">+	    (unsigned long)size &gt;= parisc_cache_flush_threshold) {</span>
<span class="p_add">+		flush_tlb_kernel_range(start, end);</span>
 		flush_data_cache();
<span class="p_del">-	else</span>
<span class="p_del">-		flush_kernel_dcache_range_asm(start, start + size);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	purge_kernel_dcache_range_asm(start, end);</span>
<span class="p_add">+	flush_tlb_kernel_range(start, end);</span>
 }
 EXPORT_SYMBOL(invalidate_kernel_vmap_range);
<span class="p_header">diff --git a/arch/parisc/kernel/pacache.S b/arch/parisc/kernel/pacache.S</span>
<span class="p_header">index 2d40c4ff3f69..67b0f7532e83 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/pacache.S</span>
<span class="p_header">+++ b/arch/parisc/kernel/pacache.S</span>
<span class="p_chunk">@@ -1110,6 +1110,28 @@</span> <span class="p_context"> ENTRY_CFI(flush_kernel_dcache_range_asm)</span>
 	.procend
 ENDPROC_CFI(flush_kernel_dcache_range_asm)
 
<span class="p_add">+ENTRY_CFI(purge_kernel_dcache_range_asm)</span>
<span class="p_add">+	.proc</span>
<span class="p_add">+	.callinfo NO_CALLS</span>
<span class="p_add">+	.entry</span>
<span class="p_add">+</span>
<span class="p_add">+	ldil		L%dcache_stride, %r1</span>
<span class="p_add">+	ldw		R%dcache_stride(%r1), %r23</span>
<span class="p_add">+	ldo		-1(%r23), %r21</span>
<span class="p_add">+	ANDCM		%r26, %r21, %r26</span>
<span class="p_add">+</span>
<span class="p_add">+1:      cmpb,COND(&lt;&lt;),n	%r26, %r25,1b</span>
<span class="p_add">+	pdc,m		%r23(%r26)</span>
<span class="p_add">+</span>
<span class="p_add">+	sync</span>
<span class="p_add">+	syncdma</span>
<span class="p_add">+	bv		%r0(%r2)</span>
<span class="p_add">+	nop</span>
<span class="p_add">+	.exit</span>
<span class="p_add">+</span>
<span class="p_add">+	.procend</span>
<span class="p_add">+ENDPROC_CFI(purge_kernel_dcache_range_asm)</span>
<span class="p_add">+</span>
 ENTRY_CFI(flush_user_icache_range_asm)
 	.proc
 	.callinfo NO_CALLS
<span class="p_header">diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c</span>
<span class="p_header">index 4b8fd6dc22da..f7e684560186 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/time.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/time.c</span>
<span class="p_chunk">@@ -76,10 +76,10 @@</span> <span class="p_context"> irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)</span>
 	next_tick = cpuinfo-&gt;it_value;
 
 	/* Calculate how many ticks have elapsed. */
<span class="p_add">+	now = mfctl(16);</span>
 	do {
 		++ticks_elapsed;
 		next_tick += cpt;
<span class="p_del">-		now = mfctl(16);</span>
 	} while (next_tick - now &gt; cpt);
 
 	/* Store (in CR16 cycles) up to when we are accounting right now. */
<span class="p_chunk">@@ -103,16 +103,17 @@</span> <span class="p_context"> irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)</span>
 	 * if one or the other wrapped. If &quot;now&quot; is &quot;bigger&quot; we&#39;ll end up
 	 * with a very large unsigned number.
 	 */
<span class="p_del">-	while (next_tick - mfctl(16) &gt; cpt)</span>
<span class="p_add">+	now = mfctl(16);</span>
<span class="p_add">+	while (next_tick - now &gt; cpt)</span>
 		next_tick += cpt;
 
 	/* Program the IT when to deliver the next interrupt.
 	 * Only bottom 32-bits of next_tick are writable in CR16!
 	 * Timer interrupt will be delivered at least a few hundred cycles
<span class="p_del">-	 * after the IT fires, so if we are too close (&lt;= 500 cycles) to the</span>
<span class="p_add">+	 * after the IT fires, so if we are too close (&lt;= 8000 cycles) to the</span>
 	 * next cycle, simply skip it.
 	 */
<span class="p_del">-	if (next_tick - mfctl(16) &lt;= 500)</span>
<span class="p_add">+	if (next_tick - now &lt;= 8000)</span>
 		next_tick += cpt;
 	mtctl(next_tick, 16);
 
<span class="p_chunk">@@ -248,7 +249,7 @@</span> <span class="p_context"> static int __init init_cr16_clocksource(void)</span>
 	 * different sockets, so mark them unstable and lower rating on
 	 * multi-socket SMP systems.
 	 */
<span class="p_del">-	if (num_online_cpus() &gt; 1) {</span>
<span class="p_add">+	if (num_online_cpus() &gt; 1 &amp;&amp; !running_on_qemu) {</span>
 		int cpu;
 		unsigned long cpu0_loc;
 		cpu0_loc = per_cpu(cpu_data, 0).cpu_loc;
<span class="p_header">diff --git a/arch/s390/kvm/interrupt.c b/arch/s390/kvm/interrupt.c</span>
<span class="p_header">index a832ad031cee..5185be314661 100644</span>
<span class="p_header">--- a/arch/s390/kvm/interrupt.c</span>
<span class="p_header">+++ b/arch/s390/kvm/interrupt.c</span>
<span class="p_chunk">@@ -173,8 +173,15 @@</span> <span class="p_context"> static int ckc_interrupts_enabled(struct kvm_vcpu *vcpu)</span>
 
 static int ckc_irq_pending(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	if (vcpu-&gt;arch.sie_block-&gt;ckc &gt;= kvm_s390_get_tod_clock_fast(vcpu-&gt;kvm))</span>
<span class="p_add">+	const u64 now = kvm_s390_get_tod_clock_fast(vcpu-&gt;kvm);</span>
<span class="p_add">+	const u64 ckc = vcpu-&gt;arch.sie_block-&gt;ckc;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vcpu-&gt;arch.sie_block-&gt;gcr[0] &amp; 0x0020000000000000ul) {</span>
<span class="p_add">+		if ((s64)ckc &gt;= (s64)now)</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+	} else if (ckc &gt;= now) {</span>
 		return 0;
<span class="p_add">+	}</span>
 	return ckc_interrupts_enabled(vcpu);
 }
 
<span class="p_chunk">@@ -1004,13 +1011,19 @@</span> <span class="p_context"> int kvm_cpu_has_pending_timer(struct kvm_vcpu *vcpu)</span>
 
 static u64 __calculate_sltime(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	u64 now, cputm, sltime = 0;</span>
<span class="p_add">+	const u64 now = kvm_s390_get_tod_clock_fast(vcpu-&gt;kvm);</span>
<span class="p_add">+	const u64 ckc = vcpu-&gt;arch.sie_block-&gt;ckc;</span>
<span class="p_add">+	u64 cputm, sltime = 0;</span>
 
 	if (ckc_interrupts_enabled(vcpu)) {
<span class="p_del">-		now = kvm_s390_get_tod_clock_fast(vcpu-&gt;kvm);</span>
<span class="p_del">-		sltime = tod_to_ns(vcpu-&gt;arch.sie_block-&gt;ckc - now);</span>
<span class="p_del">-		/* already expired or overflow? */</span>
<span class="p_del">-		if (!sltime || vcpu-&gt;arch.sie_block-&gt;ckc &lt;= now)</span>
<span class="p_add">+		if (vcpu-&gt;arch.sie_block-&gt;gcr[0] &amp; 0x0020000000000000ul) {</span>
<span class="p_add">+			if ((s64)now &lt; (s64)ckc)</span>
<span class="p_add">+				sltime = tod_to_ns((s64)ckc - (s64)now);</span>
<span class="p_add">+		} else if (now &lt; ckc) {</span>
<span class="p_add">+			sltime = tod_to_ns(ckc - now);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		/* already expired */</span>
<span class="p_add">+		if (!sltime)</span>
 			return 0;
 		if (cpu_timer_interrupts_enabled(vcpu)) {
 			cputm = kvm_s390_get_cpu_timer(vcpu);
<span class="p_header">diff --git a/arch/s390/kvm/kvm-s390.c b/arch/s390/kvm/kvm-s390.c</span>
<span class="p_header">index 6e3d80b2048e..f4f12ecd0cec 100644</span>
<span class="p_header">--- a/arch/s390/kvm/kvm-s390.c</span>
<span class="p_header">+++ b/arch/s390/kvm/kvm-s390.c</span>
<span class="p_chunk">@@ -169,6 +169,28 @@</span> <span class="p_context"> int kvm_arch_hardware_enable(void)</span>
 static void kvm_gmap_notifier(struct gmap *gmap, unsigned long start,
 			      unsigned long end);
 
<span class="p_add">+static void kvm_clock_sync_scb(struct kvm_s390_sie_block *scb, u64 delta)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 delta_idx = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The TOD jumps by delta, we have to compensate this by adding</span>
<span class="p_add">+	 * -delta to the epoch.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	delta = -delta;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* sign-extension - we&#39;re adding to signed values below */</span>
<span class="p_add">+	if ((s64)delta &lt; 0)</span>
<span class="p_add">+		delta_idx = -1;</span>
<span class="p_add">+</span>
<span class="p_add">+	scb-&gt;epoch += delta;</span>
<span class="p_add">+	if (scb-&gt;ecd &amp; ECD_MEF) {</span>
<span class="p_add">+		scb-&gt;epdx += delta_idx;</span>
<span class="p_add">+		if (scb-&gt;epoch &lt; delta)</span>
<span class="p_add">+			scb-&gt;epdx += 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * This callback is executed during stop_machine(). All CPUs are therefore
  * temporarily stopped. In order not to change guest behavior, we have to
<span class="p_chunk">@@ -184,13 +206,17 @@</span> <span class="p_context"> static int kvm_clock_sync(struct notifier_block *notifier, unsigned long val,</span>
 	unsigned long long *delta = v;
 
 	list_for_each_entry(kvm, &amp;vm_list, vm_list) {
<span class="p_del">-		kvm-&gt;arch.epoch -= *delta;</span>
 		kvm_for_each_vcpu(i, vcpu, kvm) {
<span class="p_del">-			vcpu-&gt;arch.sie_block-&gt;epoch -= *delta;</span>
<span class="p_add">+			kvm_clock_sync_scb(vcpu-&gt;arch.sie_block, *delta);</span>
<span class="p_add">+			if (i == 0) {</span>
<span class="p_add">+				kvm-&gt;arch.epoch = vcpu-&gt;arch.sie_block-&gt;epoch;</span>
<span class="p_add">+				kvm-&gt;arch.epdx = vcpu-&gt;arch.sie_block-&gt;epdx;</span>
<span class="p_add">+			}</span>
 			if (vcpu-&gt;arch.cputm_enabled)
 				vcpu-&gt;arch.cputm_start += *delta;
 			if (vcpu-&gt;arch.vsie_block)
<span class="p_del">-				vcpu-&gt;arch.vsie_block-&gt;epoch -= *delta;</span>
<span class="p_add">+				kvm_clock_sync_scb(vcpu-&gt;arch.vsie_block,</span>
<span class="p_add">+						   *delta);</span>
 		}
 	}
 	return NOTIFY_OK;
<span class="p_chunk">@@ -888,12 +914,9 @@</span> <span class="p_context"> static int kvm_s390_set_tod_ext(struct kvm *kvm, struct kvm_device_attr *attr)</span>
 	if (copy_from_user(&amp;gtod, (void __user *)attr-&gt;addr, sizeof(gtod)))
 		return -EFAULT;
 
<span class="p_del">-	if (test_kvm_facility(kvm, 139))</span>
<span class="p_del">-		kvm_s390_set_tod_clock_ext(kvm, &amp;gtod);</span>
<span class="p_del">-	else if (gtod.epoch_idx == 0)</span>
<span class="p_del">-		kvm_s390_set_tod_clock(kvm, gtod.tod);</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (!test_kvm_facility(kvm, 139) &amp;&amp; gtod.epoch_idx)</span>
 		return -EINVAL;
<span class="p_add">+	kvm_s390_set_tod_clock(kvm, &amp;gtod);</span>
 
 	VM_EVENT(kvm, 3, &quot;SET: TOD extension: 0x%x, TOD base: 0x%llx&quot;,
 		gtod.epoch_idx, gtod.tod);
<span class="p_chunk">@@ -918,13 +941,14 @@</span> <span class="p_context"> static int kvm_s390_set_tod_high(struct kvm *kvm, struct kvm_device_attr *attr)</span>
 
 static int kvm_s390_set_tod_low(struct kvm *kvm, struct kvm_device_attr *attr)
 {
<span class="p_del">-	u64 gtod;</span>
<span class="p_add">+	struct kvm_s390_vm_tod_clock gtod = { 0 };</span>
 
<span class="p_del">-	if (copy_from_user(&amp;gtod, (void __user *)attr-&gt;addr, sizeof(gtod)))</span>
<span class="p_add">+	if (copy_from_user(&amp;gtod.tod, (void __user *)attr-&gt;addr,</span>
<span class="p_add">+			   sizeof(gtod.tod)))</span>
 		return -EFAULT;
 
<span class="p_del">-	kvm_s390_set_tod_clock(kvm, gtod);</span>
<span class="p_del">-	VM_EVENT(kvm, 3, &quot;SET: TOD base: 0x%llx&quot;, gtod);</span>
<span class="p_add">+	kvm_s390_set_tod_clock(kvm, &amp;gtod);</span>
<span class="p_add">+	VM_EVENT(kvm, 3, &quot;SET: TOD base: 0x%llx&quot;, gtod.tod);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -2359,6 +2383,7 @@</span> <span class="p_context"> void kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu)</span>
 	mutex_lock(&amp;vcpu-&gt;kvm-&gt;lock);
 	preempt_disable();
 	vcpu-&gt;arch.sie_block-&gt;epoch = vcpu-&gt;kvm-&gt;arch.epoch;
<span class="p_add">+	vcpu-&gt;arch.sie_block-&gt;epdx = vcpu-&gt;kvm-&gt;arch.epdx;</span>
 	preempt_enable();
 	mutex_unlock(&amp;vcpu-&gt;kvm-&gt;lock);
 	if (!kvm_is_ucontrol(vcpu-&gt;kvm)) {
<span class="p_chunk">@@ -2945,8 +2970,8 @@</span> <span class="p_context"> static int kvm_s390_handle_requests(struct kvm_vcpu *vcpu)</span>
 	return 0;
 }
 
<span class="p_del">-void kvm_s390_set_tod_clock_ext(struct kvm *kvm,</span>
<span class="p_del">-				 const struct kvm_s390_vm_tod_clock *gtod)</span>
<span class="p_add">+void kvm_s390_set_tod_clock(struct kvm *kvm,</span>
<span class="p_add">+			    const struct kvm_s390_vm_tod_clock *gtod)</span>
 {
 	struct kvm_vcpu *vcpu;
 	struct kvm_s390_tod_clock_ext htod;
<span class="p_chunk">@@ -2958,10 +2983,12 @@</span> <span class="p_context"> void kvm_s390_set_tod_clock_ext(struct kvm *kvm,</span>
 	get_tod_clock_ext((char *)&amp;htod);
 
 	kvm-&gt;arch.epoch = gtod-&gt;tod - htod.tod;
<span class="p_del">-	kvm-&gt;arch.epdx = gtod-&gt;epoch_idx - htod.epoch_idx;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kvm-&gt;arch.epoch &gt; gtod-&gt;tod)</span>
<span class="p_del">-		kvm-&gt;arch.epdx -= 1;</span>
<span class="p_add">+	kvm-&gt;arch.epdx = 0;</span>
<span class="p_add">+	if (test_kvm_facility(kvm, 139)) {</span>
<span class="p_add">+		kvm-&gt;arch.epdx = gtod-&gt;epoch_idx - htod.epoch_idx;</span>
<span class="p_add">+		if (kvm-&gt;arch.epoch &gt; gtod-&gt;tod)</span>
<span class="p_add">+			kvm-&gt;arch.epdx -= 1;</span>
<span class="p_add">+	}</span>
 
 	kvm_s390_vcpu_block_all(kvm);
 	kvm_for_each_vcpu(i, vcpu, kvm) {
<span class="p_chunk">@@ -2974,22 +3001,6 @@</span> <span class="p_context"> void kvm_s390_set_tod_clock_ext(struct kvm *kvm,</span>
 	mutex_unlock(&amp;kvm-&gt;lock);
 }
 
<span class="p_del">-void kvm_s390_set_tod_clock(struct kvm *kvm, u64 tod)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kvm_vcpu *vcpu;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	mutex_lock(&amp;kvm-&gt;lock);</span>
<span class="p_del">-	preempt_disable();</span>
<span class="p_del">-	kvm-&gt;arch.epoch = tod - get_tod_clock();</span>
<span class="p_del">-	kvm_s390_vcpu_block_all(kvm);</span>
<span class="p_del">-	kvm_for_each_vcpu(i, vcpu, kvm)</span>
<span class="p_del">-		vcpu-&gt;arch.sie_block-&gt;epoch = kvm-&gt;arch.epoch;</span>
<span class="p_del">-	kvm_s390_vcpu_unblock_all(kvm);</span>
<span class="p_del">-	preempt_enable();</span>
<span class="p_del">-	mutex_unlock(&amp;kvm-&gt;lock);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /**
  * kvm_arch_fault_in_page - fault-in guest page if necessary
  * @vcpu: The corresponding virtual cpu
<span class="p_header">diff --git a/arch/s390/kvm/kvm-s390.h b/arch/s390/kvm/kvm-s390.h</span>
<span class="p_header">index 9f8fdd7b2311..e22d94f494a7 100644</span>
<span class="p_header">--- a/arch/s390/kvm/kvm-s390.h</span>
<span class="p_header">+++ b/arch/s390/kvm/kvm-s390.h</span>
<span class="p_chunk">@@ -272,9 +272,8 @@</span> <span class="p_context"> int kvm_s390_handle_sigp_pei(struct kvm_vcpu *vcpu);</span>
 int handle_sthyi(struct kvm_vcpu *vcpu);
 
 /* implemented in kvm-s390.c */
<span class="p_del">-void kvm_s390_set_tod_clock_ext(struct kvm *kvm,</span>
<span class="p_del">-				 const struct kvm_s390_vm_tod_clock *gtod);</span>
<span class="p_del">-void kvm_s390_set_tod_clock(struct kvm *kvm, u64 tod);</span>
<span class="p_add">+void kvm_s390_set_tod_clock(struct kvm *kvm,</span>
<span class="p_add">+			    const struct kvm_s390_vm_tod_clock *gtod);</span>
 long kvm_arch_fault_in_page(struct kvm_vcpu *vcpu, gpa_t gpa, int writable);
 int kvm_s390_store_status_unloaded(struct kvm_vcpu *vcpu, unsigned long addr);
 int kvm_s390_vcpu_store_status(struct kvm_vcpu *vcpu, unsigned long addr);
<span class="p_header">diff --git a/arch/s390/kvm/priv.c b/arch/s390/kvm/priv.c</span>
<span class="p_header">index 7bd3a59232f0..734283a21677 100644</span>
<span class="p_header">--- a/arch/s390/kvm/priv.c</span>
<span class="p_header">+++ b/arch/s390/kvm/priv.c</span>
<span class="p_chunk">@@ -84,9 +84,10 @@</span> <span class="p_context"> int kvm_s390_handle_e3(struct kvm_vcpu *vcpu)</span>
 /* Handle SCK (SET CLOCK) interception */
 static int handle_set_clock(struct kvm_vcpu *vcpu)
 {
<span class="p_add">+	struct kvm_s390_vm_tod_clock gtod = { 0 };</span>
 	int rc;
 	u8 ar;
<span class="p_del">-	u64 op2, val;</span>
<span class="p_add">+	u64 op2;</span>
 
 	if (vcpu-&gt;arch.sie_block-&gt;gpsw.mask &amp; PSW_MASK_PSTATE)
 		return kvm_s390_inject_program_int(vcpu, PGM_PRIVILEGED_OP);
<span class="p_chunk">@@ -94,12 +95,12 @@</span> <span class="p_context"> static int handle_set_clock(struct kvm_vcpu *vcpu)</span>
 	op2 = kvm_s390_get_base_disp_s(vcpu, &amp;ar);
 	if (op2 &amp; 7)	/* Operand must be on a doubleword boundary */
 		return kvm_s390_inject_program_int(vcpu, PGM_SPECIFICATION);
<span class="p_del">-	rc = read_guest(vcpu, op2, ar, &amp;val, sizeof(val));</span>
<span class="p_add">+	rc = read_guest(vcpu, op2, ar, &amp;gtod.tod, sizeof(gtod.tod));</span>
 	if (rc)
 		return kvm_s390_inject_prog_cond(vcpu, rc);
 
<span class="p_del">-	VCPU_EVENT(vcpu, 3, &quot;SCK: setting guest TOD to 0x%llx&quot;, val);</span>
<span class="p_del">-	kvm_s390_set_tod_clock(vcpu-&gt;kvm, val);</span>
<span class="p_add">+	VCPU_EVENT(vcpu, 3, &quot;SCK: setting guest TOD to 0x%llx&quot;, gtod.tod);</span>
<span class="p_add">+	kvm_s390_set_tod_clock(vcpu-&gt;kvm, &amp;gtod);</span>
 
 	kvm_s390_set_psw_cc(vcpu, 0);
 	return 0;
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index 8b8f1f14a0bf..5c790e93657d 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -350,14 +350,14 @@</span> <span class="p_context"> static inline pmd_t pmd_set_flags(pmd_t pmd, pmdval_t set)</span>
 {
 	pmdval_t v = native_pmd_val(pmd);
 
<span class="p_del">-	return __pmd(v | set);</span>
<span class="p_add">+	return native_make_pmd(v | set);</span>
 }
 
 static inline pmd_t pmd_clear_flags(pmd_t pmd, pmdval_t clear)
 {
 	pmdval_t v = native_pmd_val(pmd);
 
<span class="p_del">-	return __pmd(v &amp; ~clear);</span>
<span class="p_add">+	return native_make_pmd(v &amp; ~clear);</span>
 }
 
 static inline pmd_t pmd_mkold(pmd_t pmd)
<span class="p_chunk">@@ -409,14 +409,14 @@</span> <span class="p_context"> static inline pud_t pud_set_flags(pud_t pud, pudval_t set)</span>
 {
 	pudval_t v = native_pud_val(pud);
 
<span class="p_del">-	return __pud(v | set);</span>
<span class="p_add">+	return native_make_pud(v | set);</span>
 }
 
 static inline pud_t pud_clear_flags(pud_t pud, pudval_t clear)
 {
 	pudval_t v = native_pud_val(pud);
 
<span class="p_del">-	return __pud(v &amp; ~clear);</span>
<span class="p_add">+	return native_make_pud(v &amp; ~clear);</span>
 }
 
 static inline pud_t pud_mkold(pud_t pud)
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_32.h b/arch/x86/include/asm/pgtable_32.h</span>
<span class="p_header">index e55466760ff8..b3ec519e3982 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_32.h</span>
<span class="p_chunk">@@ -32,6 +32,7 @@</span> <span class="p_context"> extern pmd_t initial_pg_pmd[];</span>
 static inline void pgtable_cache_init(void) { }
 static inline void check_pgt_cache(void) { }
 void paging_init(void);
<span class="p_add">+void sync_initial_page_table(void);</span>
 
 /*
  * Define this if things work differently on an i386 and an i486:
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_64.h b/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_header">index 81462e9a34f6..1149d2112b2e 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"> extern pgd_t init_top_pgt[];</span>
 #define swapper_pg_dir init_top_pgt
 
 extern void paging_init(void);
<span class="p_add">+static inline void sync_initial_page_table(void) { }</span>
 
 #define pte_ERROR(e)					\
 	pr_err(&quot;%s:%d: bad pte %p(%016lx)\n&quot;,		\
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">index 3696398a9475..246f15b4e64c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_chunk">@@ -323,6 +323,11 @@</span> <span class="p_context"> static inline pudval_t native_pud_val(pud_t pud)</span>
 #else
 #include &lt;asm-generic/pgtable-nopud.h&gt;
 
<span class="p_add">+static inline pud_t native_make_pud(pudval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (pud_t) { .p4d.pgd = native_make_pgd(val) };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline pudval_t native_pud_val(pud_t pud)
 {
 	return native_pgd_val(pud.p4d.pgd);
<span class="p_chunk">@@ -344,6 +349,11 @@</span> <span class="p_context"> static inline pmdval_t native_pmd_val(pmd_t pmd)</span>
 #else
 #include &lt;asm-generic/pgtable-nopmd.h&gt;
 
<span class="p_add">+static inline pmd_t native_make_pmd(pmdval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (pmd_t) { .pud.p4d.pgd = native_make_pgd(val) };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline pmdval_t native_pmd_val(pmd_t pmd)
 {
 	return native_pgd_val(pmd.pud.p4d.pgd);
<span class="p_header">diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c</span>
<span class="p_header">index c54361a22f59..efbcf5283520 100644</span>
<span class="p_header">--- a/arch/x86/kernel/setup.c</span>
<span class="p_header">+++ b/arch/x86/kernel/setup.c</span>
<span class="p_chunk">@@ -1238,20 +1238,13 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 
 	kasan_init();
 
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-	/* sync back kernel address range */</span>
<span class="p_del">-	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,</span>
<span class="p_del">-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,</span>
<span class="p_del">-			KERNEL_PGD_PTRS);</span>
<span class="p_del">-</span>
 	/*
<span class="p_del">-	 * sync back low identity map too.  It is used for example</span>
<span class="p_del">-	 * in the 32-bit EFI stub.</span>
<span class="p_add">+	 * Sync back kernel address range.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * FIXME: Can the later sync in setup_cpu_entry_areas() replace</span>
<span class="p_add">+	 * this call?</span>
 	 */
<span class="p_del">-	clone_pgd_range(initial_page_table,</span>
<span class="p_del">-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,</span>
<span class="p_del">-			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	sync_initial_page_table();</span>
 
 	tboot_probe();
 
<span class="p_header">diff --git a/arch/x86/kernel/setup_percpu.c b/arch/x86/kernel/setup_percpu.c</span>
<span class="p_header">index 497aa766fab3..ea554f812ee1 100644</span>
<span class="p_header">--- a/arch/x86/kernel/setup_percpu.c</span>
<span class="p_header">+++ b/arch/x86/kernel/setup_percpu.c</span>
<span class="p_chunk">@@ -287,24 +287,15 @@</span> <span class="p_context"> void __init setup_per_cpu_areas(void)</span>
 	/* Setup cpu initialized, callin, callout masks */
 	setup_cpu_local_masks();
 
<span class="p_del">-#ifdef CONFIG_X86_32</span>
 	/*
 	 * Sync back kernel address range again.  We already did this in
 	 * setup_arch(), but percpu data also needs to be available in
 	 * the smpboot asm.  We can&#39;t reliably pick up percpu mappings
 	 * using vmalloc_fault(), because exception dispatch needs
 	 * percpu data.
<span class="p_add">+	 *</span>
<span class="p_add">+	 * FIXME: Can the later sync in setup_cpu_entry_areas() replace</span>
<span class="p_add">+	 * this call?</span>
 	 */
<span class="p_del">-	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,</span>
<span class="p_del">-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,</span>
<span class="p_del">-			KERNEL_PGD_PTRS);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * sync back low identity map too.  It is used for example</span>
<span class="p_del">-	 * in the 32-bit EFI stub.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	clone_pgd_range(initial_page_table,</span>
<span class="p_del">-			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,</span>
<span class="p_del">-			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	sync_initial_page_table();</span>
 }
<span class="p_header">diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c</span>
<span class="p_header">index ef03efba1c23..8cfdb6484fd0 100644</span>
<span class="p_header">--- a/arch/x86/kvm/lapic.c</span>
<span class="p_header">+++ b/arch/x86/kvm/lapic.c</span>
<span class="p_chunk">@@ -1944,14 +1944,13 @@</span> <span class="p_context"> void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)</span>
 
 void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 {
<span class="p_del">-	struct kvm_lapic *apic;</span>
<span class="p_add">+	struct kvm_lapic *apic = vcpu-&gt;arch.apic;</span>
 	int i;
 
<span class="p_del">-	apic_debug(&quot;%s\n&quot;, __func__);</span>
<span class="p_add">+	if (!apic)</span>
<span class="p_add">+		return;</span>
 
<span class="p_del">-	ASSERT(vcpu);</span>
<span class="p_del">-	apic = vcpu-&gt;arch.apic;</span>
<span class="p_del">-	ASSERT(apic != NULL);</span>
<span class="p_add">+	apic_debug(&quot;%s\n&quot;, __func__);</span>
 
 	/* Stop the timer in case it&#39;s a reset to an active apic */
 	hrtimer_cancel(&amp;apic-&gt;lapic_timer.timer);
<span class="p_chunk">@@ -2107,7 +2106,6 @@</span> <span class="p_context"> int kvm_create_lapic(struct kvm_vcpu *vcpu)</span>
 	 */
 	vcpu-&gt;arch.apic_base = MSR_IA32_APICBASE_ENABLE;
 	static_key_slow_inc(&amp;apic_sw_disabled.key); /* sw disabled at reset */
<span class="p_del">-	kvm_lapic_reset(vcpu, false);</span>
 	kvm_iodevice_init(&amp;apic-&gt;dev, &amp;apic_mmio_ops);
 
 	return 0;
<span class="p_chunk">@@ -2511,7 +2509,6 @@</span> <span class="p_context"> void kvm_apic_accept_events(struct kvm_vcpu *vcpu)</span>
 
 	pe = xchg(&amp;apic-&gt;pending_events, 0);
 	if (test_bit(KVM_APIC_INIT, &amp;pe)) {
<span class="p_del">-		kvm_lapic_reset(vcpu, true);</span>
 		kvm_vcpu_reset(vcpu, true);
 		if (kvm_vcpu_is_bsp(apic-&gt;vcpu))
 			vcpu-&gt;arch.mp_state = KVM_MP_STATE_RUNNABLE;
<span class="p_header">diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c</span>
<span class="p_header">index ca000fc644bc..2b6f8a4f2731 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.c</span>
<span class="p_chunk">@@ -150,6 +150,20 @@</span> <span class="p_context"> module_param(dbg, bool, 0644);</span>
 /* make pte_list_desc fit well in cache line */
 #define PTE_LIST_EXT 3
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Return values of handle_mmio_page_fault and mmu.page_fault:</span>
<span class="p_add">+ * RET_PF_RETRY: let CPU fault again on the address.</span>
<span class="p_add">+ * RET_PF_EMULATE: mmio page fault, emulate the instruction directly.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * For handle_mmio_page_fault only:</span>
<span class="p_add">+ * RET_PF_INVALID: the spte is invalid, let the real page fault path update it.</span>
<span class="p_add">+ */</span>
<span class="p_add">+enum {</span>
<span class="p_add">+	RET_PF_RETRY = 0,</span>
<span class="p_add">+	RET_PF_EMULATE = 1,</span>
<span class="p_add">+	RET_PF_INVALID = 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 struct pte_list_desc {
 	u64 *sptes[PTE_LIST_EXT];
 	struct pte_list_desc *more;
<span class="p_chunk">@@ -2794,13 +2808,13 @@</span> <span class="p_context"> static int set_spte(struct kvm_vcpu *vcpu, u64 *sptep,</span>
 	return ret;
 }
 
<span class="p_del">-static bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,</span>
<span class="p_del">-			 int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,</span>
<span class="p_del">-			 bool speculative, bool host_writable)</span>
<span class="p_add">+static int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,</span>
<span class="p_add">+			int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,</span>
<span class="p_add">+		       	bool speculative, bool host_writable)</span>
 {
 	int was_rmapped = 0;
 	int rmap_count;
<span class="p_del">-	bool emulate = false;</span>
<span class="p_add">+	int ret = RET_PF_RETRY;</span>
 
 	pgprintk(&quot;%s: spte %llx write_fault %d gfn %llx\n&quot;, __func__,
 		 *sptep, write_fault, gfn);
<span class="p_chunk">@@ -2830,12 +2844,12 @@</span> <span class="p_context"> static bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,</span>
 	if (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,
 	      true, host_writable)) {
 		if (write_fault)
<span class="p_del">-			emulate = true;</span>
<span class="p_add">+			ret = RET_PF_EMULATE;</span>
 		kvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);
 	}
 
 	if (unlikely(is_mmio_spte(*sptep)))
<span class="p_del">-		emulate = true;</span>
<span class="p_add">+		ret = RET_PF_EMULATE;</span>
 
 	pgprintk(&quot;%s: setting spte %llx\n&quot;, __func__, *sptep);
 	pgprintk(&quot;instantiating %s PTE (%s) at %llx (%llx) addr %p\n&quot;,
<span class="p_chunk">@@ -2855,7 +2869,7 @@</span> <span class="p_context"> static bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,</span>
 
 	kvm_release_pfn_clean(pfn);
 
<span class="p_del">-	return emulate;</span>
<span class="p_add">+	return ret;</span>
 }
 
 static kvm_pfn_t pte_prefetch_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn,
<span class="p_chunk">@@ -2994,17 +3008,16 @@</span> <span class="p_context"> static int kvm_handle_bad_page(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn)</span>
 	 * Do not cache the mmio info caused by writing the readonly gfn
 	 * into the spte otherwise read access on readonly gfn also can
 	 * caused mmio page fault and treat it as mmio access.
<span class="p_del">-	 * Return 1 to tell kvm to emulate it.</span>
 	 */
 	if (pfn == KVM_PFN_ERR_RO_FAULT)
<span class="p_del">-		return 1;</span>
<span class="p_add">+		return RET_PF_EMULATE;</span>
 
 	if (pfn == KVM_PFN_ERR_HWPOISON) {
 		kvm_send_hwpoison_signal(kvm_vcpu_gfn_to_hva(vcpu, gfn), current);
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 	}
 
<span class="p_del">-	return -EFAULT;</span>
<span class="p_add">+	return RET_PF_EMULATE;</span>
 }
 
 static void transparent_hugepage_adjust(struct kvm_vcpu *vcpu,
<span class="p_chunk">@@ -3286,13 +3299,13 @@</span> <span class="p_context"> static int nonpaging_map(struct kvm_vcpu *vcpu, gva_t v, u32 error_code,</span>
 	}
 
 	if (fast_page_fault(vcpu, v, level, error_code))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 
 	mmu_seq = vcpu-&gt;kvm-&gt;mmu_notifier_seq;
 	smp_rmb();
 
 	if (try_async_pf(vcpu, prefault, gfn, v, &amp;pfn, write, &amp;map_writable))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 
 	if (handle_abnormal_pfn(vcpu, v, gfn, pfn, ACC_ALL, &amp;r))
 		return r;
<span class="p_chunk">@@ -3312,7 +3325,7 @@</span> <span class="p_context"> static int nonpaging_map(struct kvm_vcpu *vcpu, gva_t v, u32 error_code,</span>
 out_unlock:
 	spin_unlock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);
 	kvm_release_pfn_clean(pfn);
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return RET_PF_RETRY;</span>
 }
 
 
<span class="p_chunk">@@ -3659,54 +3672,38 @@</span> <span class="p_context"> walk_shadow_page_get_mmio_spte(struct kvm_vcpu *vcpu, u64 addr, u64 *sptep)</span>
 	return reserved;
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Return values of handle_mmio_page_fault:</span>
<span class="p_del">- * RET_MMIO_PF_EMULATE: it is a real mmio page fault, emulate the instruction</span>
<span class="p_del">- *			directly.</span>
<span class="p_del">- * RET_MMIO_PF_INVALID: invalid spte is detected then let the real page</span>
<span class="p_del">- *			fault path update the mmio spte.</span>
<span class="p_del">- * RET_MMIO_PF_RETRY: let CPU fault again on the address.</span>
<span class="p_del">- * RET_MMIO_PF_BUG: a bug was detected (and a WARN was printed).</span>
<span class="p_del">- */</span>
<span class="p_del">-enum {</span>
<span class="p_del">-	RET_MMIO_PF_EMULATE = 1,</span>
<span class="p_del">-	RET_MMIO_PF_INVALID = 2,</span>
<span class="p_del">-	RET_MMIO_PF_RETRY = 0,</span>
<span class="p_del">-	RET_MMIO_PF_BUG = -1</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 static int handle_mmio_page_fault(struct kvm_vcpu *vcpu, u64 addr, bool direct)
 {
 	u64 spte;
 	bool reserved;
 
 	if (mmio_info_in_cache(vcpu, addr, direct))
<span class="p_del">-		return RET_MMIO_PF_EMULATE;</span>
<span class="p_add">+		return RET_PF_EMULATE;</span>
 
 	reserved = walk_shadow_page_get_mmio_spte(vcpu, addr, &amp;spte);
 	if (WARN_ON(reserved))
<span class="p_del">-		return RET_MMIO_PF_BUG;</span>
<span class="p_add">+		return -EINVAL;</span>
 
 	if (is_mmio_spte(spte)) {
 		gfn_t gfn = get_mmio_spte_gfn(spte);
 		unsigned access = get_mmio_spte_access(spte);
 
 		if (!check_mmio_spte(vcpu, spte))
<span class="p_del">-			return RET_MMIO_PF_INVALID;</span>
<span class="p_add">+			return RET_PF_INVALID;</span>
 
 		if (direct)
 			addr = 0;
 
 		trace_handle_mmio_page_fault(addr, gfn, access);
 		vcpu_cache_mmio_info(vcpu, addr, gfn, access);
<span class="p_del">-		return RET_MMIO_PF_EMULATE;</span>
<span class="p_add">+		return RET_PF_EMULATE;</span>
 	}
 
 	/*
 	 * If the page table is zapped by other cpus, let CPU fault again on
 	 * the address.
 	 */
<span class="p_del">-	return RET_MMIO_PF_RETRY;</span>
<span class="p_add">+	return RET_PF_RETRY;</span>
 }
 EXPORT_SYMBOL_GPL(handle_mmio_page_fault);
 
<span class="p_chunk">@@ -3756,7 +3753,7 @@</span> <span class="p_context"> static int nonpaging_page_fault(struct kvm_vcpu *vcpu, gva_t gva,</span>
 	pgprintk(&quot;%s: gva %lx error %x\n&quot;, __func__, gva, error_code);
 
 	if (page_fault_handle_page_track(vcpu, error_code, gfn))
<span class="p_del">-		return 1;</span>
<span class="p_add">+		return RET_PF_EMULATE;</span>
 
 	r = mmu_topup_memory_caches(vcpu);
 	if (r)
<span class="p_chunk">@@ -3877,7 +3874,7 @@</span> <span class="p_context"> static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code,</span>
 	MMU_WARN_ON(!VALID_PAGE(vcpu-&gt;arch.mmu.root_hpa));
 
 	if (page_fault_handle_page_track(vcpu, error_code, gfn))
<span class="p_del">-		return 1;</span>
<span class="p_add">+		return RET_PF_EMULATE;</span>
 
 	r = mmu_topup_memory_caches(vcpu);
 	if (r)
<span class="p_chunk">@@ -3894,13 +3891,13 @@</span> <span class="p_context"> static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code,</span>
 	}
 
 	if (fast_page_fault(vcpu, gpa, level, error_code))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 
 	mmu_seq = vcpu-&gt;kvm-&gt;mmu_notifier_seq;
 	smp_rmb();
 
 	if (try_async_pf(vcpu, prefault, gfn, gpa, &amp;pfn, write, &amp;map_writable))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 
 	if (handle_abnormal_pfn(vcpu, 0, gfn, pfn, ACC_ALL, &amp;r))
 		return r;
<span class="p_chunk">@@ -3920,7 +3917,7 @@</span> <span class="p_context"> static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code,</span>
 out_unlock:
 	spin_unlock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);
 	kvm_release_pfn_clean(pfn);
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return RET_PF_RETRY;</span>
 }
 
 static void nonpaging_init_context(struct kvm_vcpu *vcpu,
<span class="p_chunk">@@ -4919,25 +4916,25 @@</span> <span class="p_context"> int kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t cr2, u64 error_code,</span>
 		vcpu-&gt;arch.gpa_val = cr2;
 	}
 
<span class="p_add">+	r = RET_PF_INVALID;</span>
 	if (unlikely(error_code &amp; PFERR_RSVD_MASK)) {
 		r = handle_mmio_page_fault(vcpu, cr2, direct);
<span class="p_del">-		if (r == RET_MMIO_PF_EMULATE) {</span>
<span class="p_add">+		if (r == RET_PF_EMULATE) {</span>
 			emulation_type = 0;
 			goto emulate;
 		}
<span class="p_del">-		if (r == RET_MMIO_PF_RETRY)</span>
<span class="p_del">-			return 1;</span>
<span class="p_del">-		if (r &lt; 0)</span>
<span class="p_del">-			return r;</span>
<span class="p_del">-		/* Must be RET_MMIO_PF_INVALID.  */</span>
 	}
 
<span class="p_del">-	r = vcpu-&gt;arch.mmu.page_fault(vcpu, cr2, lower_32_bits(error_code),</span>
<span class="p_del">-				      false);</span>
<span class="p_add">+	if (r == RET_PF_INVALID) {</span>
<span class="p_add">+		r = vcpu-&gt;arch.mmu.page_fault(vcpu, cr2, lower_32_bits(error_code),</span>
<span class="p_add">+					      false);</span>
<span class="p_add">+		WARN_ON(r == RET_PF_INVALID);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (r == RET_PF_RETRY)</span>
<span class="p_add">+		return 1;</span>
 	if (r &lt; 0)
 		return r;
<span class="p_del">-	if (!r)</span>
<span class="p_del">-		return 1;</span>
 
 	/*
 	 * Before emulating the instruction, check if the error code
<span class="p_header">diff --git a/arch/x86/kvm/paging_tmpl.h b/arch/x86/kvm/paging_tmpl.h</span>
<span class="p_header">index f18d1f8d332b..5abae72266b7 100644</span>
<span class="p_header">--- a/arch/x86/kvm/paging_tmpl.h</span>
<span class="p_header">+++ b/arch/x86/kvm/paging_tmpl.h</span>
<span class="p_chunk">@@ -593,7 +593,7 @@</span> <span class="p_context"> static int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,</span>
 	struct kvm_mmu_page *sp = NULL;
 	struct kvm_shadow_walk_iterator it;
 	unsigned direct_access, access = gw-&gt;pt_access;
<span class="p_del">-	int top_level, emulate;</span>
<span class="p_add">+	int top_level, ret;</span>
 
 	direct_access = gw-&gt;pte_access;
 
<span class="p_chunk">@@ -659,15 +659,15 @@</span> <span class="p_context"> static int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,</span>
 	}
 
 	clear_sp_write_flooding_count(it.sptep);
<span class="p_del">-	emulate = mmu_set_spte(vcpu, it.sptep, gw-&gt;pte_access, write_fault,</span>
<span class="p_del">-			       it.level, gw-&gt;gfn, pfn, prefault, map_writable);</span>
<span class="p_add">+	ret = mmu_set_spte(vcpu, it.sptep, gw-&gt;pte_access, write_fault,</span>
<span class="p_add">+			   it.level, gw-&gt;gfn, pfn, prefault, map_writable);</span>
 	FNAME(pte_prefetch)(vcpu, gw, it.sptep);
 
<span class="p_del">-	return emulate;</span>
<span class="p_add">+	return ret;</span>
 
 out_gpte_changed:
 	kvm_release_pfn_clean(pfn);
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return RET_PF_RETRY;</span>
 }
 
  /*
<span class="p_chunk">@@ -762,12 +762,12 @@</span> <span class="p_context"> static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code,</span>
 		if (!prefault)
 			inject_page_fault(vcpu, &amp;walker.fault);
 
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 	}
 
 	if (page_fault_handle_page_track(vcpu, error_code, walker.gfn)) {
 		shadow_page_table_clear_flood(vcpu, addr);
<span class="p_del">-		return 1;</span>
<span class="p_add">+		return RET_PF_EMULATE;</span>
 	}
 
 	vcpu-&gt;arch.write_fault_to_shadow_pgtable = false;
<span class="p_chunk">@@ -789,7 +789,7 @@</span> <span class="p_context"> static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code,</span>
 
 	if (try_async_pf(vcpu, prefault, walker.gfn, addr, &amp;pfn, write_fault,
 			 &amp;map_writable))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return RET_PF_RETRY;</span>
 
 	if (handle_abnormal_pfn(vcpu, addr, walker.gfn, pfn, walker.pte_access, &amp;r))
 		return r;
<span class="p_chunk">@@ -834,7 +834,7 @@</span> <span class="p_context"> static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code,</span>
 out_unlock:
 	spin_unlock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);
 	kvm_release_pfn_clean(pfn);
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return RET_PF_RETRY;</span>
 }
 
 static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)
<span class="p_header">diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c</span>
<span class="p_header">index e0bc3ad0f6cd..9fb0daf628cb 100644</span>
<span class="p_header">--- a/arch/x86/kvm/svm.c</span>
<span class="p_header">+++ b/arch/x86/kvm/svm.c</span>
<span class="p_chunk">@@ -45,6 +45,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/debugreg.h&gt;
 #include &lt;asm/kvm_para.h&gt;
 #include &lt;asm/irq_remapping.h&gt;
<span class="p_add">+#include &lt;asm/microcode.h&gt;</span>
 #include &lt;asm/nospec-branch.h&gt;
 
 #include &lt;asm/virtext.h&gt;
<span class="p_chunk">@@ -5015,7 +5016,7 @@</span> <span class="p_context"> static void svm_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * being speculatively taken.
 	 */
 	if (svm-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, svm-&gt;spec_ctrl);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, svm-&gt;spec_ctrl);</span>
 
 	asm volatile (
 		&quot;push %%&quot; _ASM_BP &quot;; \n\t&quot;
<span class="p_chunk">@@ -5124,11 +5125,11 @@</span> <span class="p_context"> static void svm_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * If the L02 MSR bitmap does not intercept the MSR, then we need to
 	 * save it.
 	 */
<span class="p_del">-	if (!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL))</span>
<span class="p_del">-		rdmsrl(MSR_IA32_SPEC_CTRL, svm-&gt;spec_ctrl);</span>
<span class="p_add">+	if (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))</span>
<span class="p_add">+		svm-&gt;spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);</span>
 
 	if (svm-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
 
 	/* Eliminate branch target predictions from guest mode */
 	vmexit_fill_RSB();
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index 5ffde16253cb..315fccb2684b 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -51,6 +51,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/apic.h&gt;
 #include &lt;asm/irq_remapping.h&gt;
 #include &lt;asm/mmu_context.h&gt;
<span class="p_add">+#include &lt;asm/microcode.h&gt;</span>
 #include &lt;asm/nospec-branch.h&gt;
 
 #include &quot;trace.h&quot;
<span class="p_chunk">@@ -9431,7 +9432,7 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * being speculatively taken.
 	 */
 	if (vmx-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, vmx-&gt;spec_ctrl);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, vmx-&gt;spec_ctrl);</span>
 
 	vmx-&gt;__launched = vmx-&gt;loaded_vmcs-&gt;launched;
 	asm(
<span class="p_chunk">@@ -9566,11 +9567,11 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * If the L02 MSR bitmap does not intercept the MSR, then we need to
 	 * save it.
 	 */
<span class="p_del">-	if (!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL))</span>
<span class="p_del">-		rdmsrl(MSR_IA32_SPEC_CTRL, vmx-&gt;spec_ctrl);</span>
<span class="p_add">+	if (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))</span>
<span class="p_add">+		vmx-&gt;spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);</span>
 
 	if (vmx-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
 
 	/* Eliminate branch target predictions from guest mode */
 	vmexit_fill_RSB();
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index 0dcd7bf45dc1..b9afb4784d12 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -7482,13 +7482,13 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(kvm_task_switch);</span>
 
 int kvm_valid_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 {
<span class="p_del">-	if ((sregs-&gt;efer &amp; EFER_LME) &amp;&amp; (sregs-&gt;cr0 &amp; X86_CR0_PG_BIT)) {</span>
<span class="p_add">+	if ((sregs-&gt;efer &amp; EFER_LME) &amp;&amp; (sregs-&gt;cr0 &amp; X86_CR0_PG)) {</span>
 		/*
 		 * When EFER.LME and CR0.PG are set, the processor is in
 		 * 64-bit mode (though maybe in a 32-bit code segment).
 		 * CR4.PAE and EFER.LMA must be set.
 		 */
<span class="p_del">-		if (!(sregs-&gt;cr4 &amp; X86_CR4_PAE_BIT)</span>
<span class="p_add">+		if (!(sregs-&gt;cr4 &amp; X86_CR4_PAE)</span>
 		    || !(sregs-&gt;efer &amp; EFER_LMA))
 			return -EINVAL;
 	} else {
<span class="p_chunk">@@ -7821,6 +7821,8 @@</span> <span class="p_context"> void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)</span>
 
 void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 {
<span class="p_add">+	kvm_lapic_reset(vcpu, init_event);</span>
<span class="p_add">+</span>
 	vcpu-&gt;arch.hflags = 0;
 
 	vcpu-&gt;arch.smi_pending = 0;
<span class="p_chunk">@@ -8249,10 +8251,8 @@</span> <span class="p_context"> int __x86_set_memory_region(struct kvm *kvm, int id, gpa_t gpa, u32 size)</span>
 			return r;
 	}
 
<span class="p_del">-	if (!size) {</span>
<span class="p_del">-		r = vm_munmap(old.userspace_addr, old.npages * PAGE_SIZE);</span>
<span class="p_del">-		WARN_ON(r &lt; 0);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (!size)</span>
<span class="p_add">+		vm_munmap(old.userspace_addr, old.npages * PAGE_SIZE);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/arch/x86/mm/cpu_entry_area.c b/arch/x86/mm/cpu_entry_area.c</span>
<span class="p_header">index b9283cc27622..476d810639a8 100644</span>
<span class="p_header">--- a/arch/x86/mm/cpu_entry_area.c</span>
<span class="p_header">+++ b/arch/x86/mm/cpu_entry_area.c</span>
<span class="p_chunk">@@ -163,4 +163,10 @@</span> <span class="p_context"> void __init setup_cpu_entry_areas(void)</span>
 
 	for_each_possible_cpu(cpu)
 		setup_cpu_entry_area(cpu);
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This is the last essential update to swapper_pgdir which needs</span>
<span class="p_add">+	 * to be synchronized to initial_page_table on 32bit.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	sync_initial_page_table();</span>
 }
<span class="p_header">diff --git a/arch/x86/mm/init_32.c b/arch/x86/mm/init_32.c</span>
<span class="p_header">index 135c9a7898c7..3141e67ec24c 100644</span>
<span class="p_header">--- a/arch/x86/mm/init_32.c</span>
<span class="p_header">+++ b/arch/x86/mm/init_32.c</span>
<span class="p_chunk">@@ -453,6 +453,21 @@</span> <span class="p_context"> static inline void permanent_kmaps_init(pgd_t *pgd_base)</span>
 }
 #endif /* CONFIG_HIGHMEM */
 
<span class="p_add">+void __init sync_initial_page_table(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,</span>
<span class="p_add">+			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,</span>
<span class="p_add">+			KERNEL_PGD_PTRS);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * sync back low identity map too.  It is used for example</span>
<span class="p_add">+	 * in the 32-bit EFI stub.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	clone_pgd_range(initial_page_table,</span>
<span class="p_add">+			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,</span>
<span class="p_add">+			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init native_pagetable_init(void)
 {
 	unsigned long pfn, va;
<span class="p_header">diff --git a/arch/x86/platform/intel-mid/intel-mid.c b/arch/x86/platform/intel-mid/intel-mid.c</span>
<span class="p_header">index 86676cec99a1..09dd7f3cf621 100644</span>
<span class="p_header">--- a/arch/x86/platform/intel-mid/intel-mid.c</span>
<span class="p_header">+++ b/arch/x86/platform/intel-mid/intel-mid.c</span>
<span class="p_chunk">@@ -79,7 +79,7 @@</span> <span class="p_context"> static void intel_mid_power_off(void)</span>
 
 static void intel_mid_reboot(void)
 {
<span class="p_del">-	intel_scu_ipc_simple_command(IPCMSG_COLD_BOOT, 0);</span>
<span class="p_add">+	intel_scu_ipc_simple_command(IPCMSG_COLD_RESET, 0);</span>
 }
 
 static unsigned long __init intel_mid_calibrate_tsc(void)
<span class="p_header">diff --git a/arch/x86/xen/suspend.c b/arch/x86/xen/suspend.c</span>
<span class="p_header">index 92bf5ecb6baf..3e3a58ea669e 100644</span>
<span class="p_header">--- a/arch/x86/xen/suspend.c</span>
<span class="p_header">+++ b/arch/x86/xen/suspend.c</span>
<span class="p_chunk">@@ -1,12 +1,15 @@</span> <span class="p_context"></span>
 // SPDX-License-Identifier: GPL-2.0
 #include &lt;linux/types.h&gt;
 #include &lt;linux/tick.h&gt;
<span class="p_add">+#include &lt;linux/percpu-defs.h&gt;</span>
 
 #include &lt;xen/xen.h&gt;
 #include &lt;xen/interface/xen.h&gt;
 #include &lt;xen/grant_table.h&gt;
 #include &lt;xen/events.h&gt;
 
<span class="p_add">+#include &lt;asm/cpufeatures.h&gt;</span>
<span class="p_add">+#include &lt;asm/msr-index.h&gt;</span>
 #include &lt;asm/xen/hypercall.h&gt;
 #include &lt;asm/xen/page.h&gt;
 #include &lt;asm/fixmap.h&gt;
<span class="p_chunk">@@ -15,6 +18,8 @@</span> <span class="p_context"></span>
 #include &quot;mmu.h&quot;
 #include &quot;pmu.h&quot;
 
<span class="p_add">+static DEFINE_PER_CPU(u64, spec_ctrl);</span>
<span class="p_add">+</span>
 void xen_arch_pre_suspend(void)
 {
 	if (xen_pv_domain())
<span class="p_chunk">@@ -31,6 +36,9 @@</span> <span class="p_context"> void xen_arch_post_suspend(int cancelled)</span>
 
 static void xen_vcpu_notify_restore(void *data)
 {
<span class="p_add">+	if (xen_pv_domain() &amp;&amp; boot_cpu_has(X86_FEATURE_SPEC_CTRL))</span>
<span class="p_add">+		wrmsrl(MSR_IA32_SPEC_CTRL, this_cpu_read(spec_ctrl));</span>
<span class="p_add">+</span>
 	/* Boot processor notified via generic timekeeping_resume() */
 	if (smp_processor_id() == 0)
 		return;
<span class="p_chunk">@@ -40,7 +48,15 @@</span> <span class="p_context"> static void xen_vcpu_notify_restore(void *data)</span>
 
 static void xen_vcpu_notify_suspend(void *data)
 {
<span class="p_add">+	u64 tmp;</span>
<span class="p_add">+</span>
 	tick_suspend_local();
<span class="p_add">+</span>
<span class="p_add">+	if (xen_pv_domain() &amp;&amp; boot_cpu_has(X86_FEATURE_SPEC_CTRL)) {</span>
<span class="p_add">+		rdmsrl(MSR_IA32_SPEC_CTRL, tmp);</span>
<span class="p_add">+		this_cpu_write(spec_ctrl, tmp);</span>
<span class="p_add">+		wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
<span class="p_add">+	}</span>
 }
 
 void xen_arch_resume(void)
<span class="p_header">diff --git a/block/blk-core.c b/block/blk-core.c</span>
<span class="p_header">index 95b7ea996ac2..c01f4907dbbc 100644</span>
<span class="p_header">--- a/block/blk-core.c</span>
<span class="p_header">+++ b/block/blk-core.c</span>
<span class="p_chunk">@@ -2277,7 +2277,7 @@</span> <span class="p_context"> blk_qc_t submit_bio(struct bio *bio)</span>
 		unsigned int count;
 
 		if (unlikely(bio_op(bio) == REQ_OP_WRITE_SAME))
<span class="p_del">-			count = queue_logical_block_size(bio-&gt;bi_disk-&gt;queue);</span>
<span class="p_add">+			count = queue_logical_block_size(bio-&gt;bi_disk-&gt;queue) &gt;&gt; 9;</span>
 		else
 			count = bio_sectors(bio);
 
<span class="p_header">diff --git a/block/blk-mq.c b/block/blk-mq.c</span>
<span class="p_header">index b60798a30ea2..f1fb126a3be5 100644</span>
<span class="p_header">--- a/block/blk-mq.c</span>
<span class="p_header">+++ b/block/blk-mq.c</span>
<span class="p_chunk">@@ -638,7 +638,6 @@</span> <span class="p_context"> static void __blk_mq_requeue_request(struct request *rq)</span>
 
 	trace_block_rq_requeue(q, rq);
 	wbt_requeue(q-&gt;rq_wb, &amp;rq-&gt;issue_stat);
<span class="p_del">-	blk_mq_sched_requeue_request(rq);</span>
 
 	if (test_and_clear_bit(REQ_ATOM_STARTED, &amp;rq-&gt;atomic_flags)) {
 		if (q-&gt;dma_drain_size &amp;&amp; blk_rq_bytes(rq))
<span class="p_chunk">@@ -650,6 +649,9 @@</span> <span class="p_context"> void blk_mq_requeue_request(struct request *rq, bool kick_requeue_list)</span>
 {
 	__blk_mq_requeue_request(rq);
 
<span class="p_add">+	/* this request will be re-inserted to io scheduler queue */</span>
<span class="p_add">+	blk_mq_sched_requeue_request(rq);</span>
<span class="p_add">+</span>
 	BUG_ON(blk_queued_rq(rq));
 	blk_mq_add_to_requeue_list(rq, true, kick_requeue_list);
 }
<span class="p_header">diff --git a/block/kyber-iosched.c b/block/kyber-iosched.c</span>
<span class="p_header">index f58cab82105b..09cd5cf2e459 100644</span>
<span class="p_header">--- a/block/kyber-iosched.c</span>
<span class="p_header">+++ b/block/kyber-iosched.c</span>
<span class="p_chunk">@@ -814,6 +814,7 @@</span> <span class="p_context"> static struct elevator_type kyber_sched = {</span>
 		.limit_depth = kyber_limit_depth,
 		.prepare_request = kyber_prepare_request,
 		.finish_request = kyber_finish_request,
<span class="p_add">+		.requeue_request = kyber_finish_request,</span>
 		.completed_request = kyber_completed_request,
 		.dispatch_request = kyber_dispatch_request,
 		.has_work = kyber_has_work,
<span class="p_header">diff --git a/drivers/acpi/bus.c b/drivers/acpi/bus.c</span>
<span class="p_header">index 4d0979e02a28..b6d58cc58f5f 100644</span>
<span class="p_header">--- a/drivers/acpi/bus.c</span>
<span class="p_header">+++ b/drivers/acpi/bus.c</span>
<span class="p_chunk">@@ -66,10 +66,37 @@</span> <span class="p_context"> static int set_copy_dsdt(const struct dmi_system_id *id)</span>
 	return 0;
 }
 #endif
<span class="p_add">+static int set_gbl_term_list(const struct dmi_system_id *id)</span>
<span class="p_add">+{</span>
<span class="p_add">+	acpi_gbl_parse_table_as_term_list = 1;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
 
<span class="p_del">-static const struct dmi_system_id dsdt_dmi_table[] __initconst = {</span>
<span class="p_add">+static const struct dmi_system_id acpi_quirks_dmi_table[] __initconst = {</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Touchpad on Dell XPS 9570/Precision M5530 doesn&#39;t work under I2C</span>
<span class="p_add">+	 * mode.</span>
<span class="p_add">+	 * https://bugzilla.kernel.org/show_bug.cgi?id=198515</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.callback = set_gbl_term_list,</span>
<span class="p_add">+		.ident = &quot;Dell Precision M5530&quot;,</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;Dell Inc.&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;Precision M5530&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.callback = set_gbl_term_list,</span>
<span class="p_add">+		.ident = &quot;Dell XPS 15 9570&quot;,</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;Dell Inc.&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;XPS 15 9570&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
 	/*
 	 * Invoke DSDT corruption work-around on all Toshiba Satellite.
<span class="p_add">+	 * DSDT will be copied to memory.</span>
 	 * https://bugzilla.kernel.org/show_bug.cgi?id=14679
 	 */
 	{
<span class="p_chunk">@@ -83,7 +110,7 @@</span> <span class="p_context"> static const struct dmi_system_id dsdt_dmi_table[] __initconst = {</span>
 	{}
 };
 #else
<span class="p_del">-static const struct dmi_system_id dsdt_dmi_table[] __initconst = {</span>
<span class="p_add">+static const struct dmi_system_id acpi_quirks_dmi_table[] __initconst = {</span>
 	{}
 };
 #endif
<span class="p_chunk">@@ -1001,11 +1028,8 @@</span> <span class="p_context"> void __init acpi_early_init(void)</span>
 
 	acpi_permanent_mmap = true;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the machine falls into the DMI check table,</span>
<span class="p_del">-	 * DSDT will be copied to memory</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	dmi_check_system(dsdt_dmi_table);</span>
<span class="p_add">+	/* Check machine-specific quirks */</span>
<span class="p_add">+	dmi_check_system(acpi_quirks_dmi_table);</span>
 
 	status = acpi_reallocate_root_table();
 	if (ACPI_FAILURE(status)) {
<span class="p_header">diff --git a/drivers/bluetooth/btusb.c b/drivers/bluetooth/btusb.c</span>
<span class="p_header">index d54c3f6f728c..673698c7b143 100644</span>
<span class="p_header">--- a/drivers/bluetooth/btusb.c</span>
<span class="p_header">+++ b/drivers/bluetooth/btusb.c</span>
<span class="p_chunk">@@ -21,6 +21,7 @@</span> <span class="p_context"></span>
  *
  */
 
<span class="p_add">+#include &lt;linux/dmi.h&gt;</span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/usb.h&gt;
 #include &lt;linux/usb/quirks.h&gt;
<span class="p_chunk">@@ -381,6 +382,21 @@</span> <span class="p_context"> static const struct usb_device_id blacklist_table[] = {</span>
 	{ }	/* Terminating entry */
 };
 
<span class="p_add">+/* The Bluetooth USB module build into some devices needs to be reset on resume,</span>
<span class="p_add">+ * this is a problem with the platform (likely shutting off all power) not with</span>
<span class="p_add">+ * the module itself. So we use a DMI list to match known broken platforms.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static const struct dmi_system_id btusb_needs_reset_resume_table[] = {</span>
<span class="p_add">+	{</span>
<span class="p_add">+		/* Lenovo Yoga 920 (QCA Rome device 0cf3:e300) */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;LENOVO&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_VERSION, &quot;Lenovo YOGA 920&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{}</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 #define BTUSB_MAX_ISOC_FRAMES	10
 
 #define BTUSB_INTR_RUNNING	0
<span class="p_chunk">@@ -3013,6 +3029,9 @@</span> <span class="p_context"> static int btusb_probe(struct usb_interface *intf,</span>
 	hdev-&gt;send   = btusb_send_frame;
 	hdev-&gt;notify = btusb_notify;
 
<span class="p_add">+	if (dmi_check_system(btusb_needs_reset_resume_table))</span>
<span class="p_add">+		interface_to_usbdev(intf)-&gt;quirks |= USB_QUIRK_RESET_RESUME;</span>
<span class="p_add">+</span>
 #ifdef CONFIG_PM
 	err = btusb_config_oob_wake(hdev);
 	if (err)
<span class="p_chunk">@@ -3099,12 +3118,6 @@</span> <span class="p_context"> static int btusb_probe(struct usb_interface *intf,</span>
 	if (id-&gt;driver_info &amp; BTUSB_QCA_ROME) {
 		data-&gt;setup_on_usb = btusb_setup_qca;
 		hdev-&gt;set_bdaddr = btusb_set_bdaddr_ath3012;
<span class="p_del">-</span>
<span class="p_del">-		/* QCA Rome devices lose their updated firmware over suspend,</span>
<span class="p_del">-		 * but the USB hub doesn&#39;t notice any status change.</span>
<span class="p_del">-		 * explicitly request a device reset on resume.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		interface_to_usbdev(intf)-&gt;quirks |= USB_QUIRK_RESET_RESUME;</span>
 	}
 
 #ifdef CONFIG_BT_HCIBTUSB_RTL
<span class="p_header">diff --git a/drivers/char/tpm/st33zp24/st33zp24.c b/drivers/char/tpm/st33zp24/st33zp24.c</span>
<span class="p_header">index 4d1dc8b46877..f95b9c75175b 100644</span>
<span class="p_header">--- a/drivers/char/tpm/st33zp24/st33zp24.c</span>
<span class="p_header">+++ b/drivers/char/tpm/st33zp24/st33zp24.c</span>
<span class="p_chunk">@@ -457,7 +457,7 @@</span> <span class="p_context"> static int st33zp24_recv(struct tpm_chip *chip, unsigned char *buf,</span>
 			    size_t count)
 {
 	int size = 0;
<span class="p_del">-	int expected;</span>
<span class="p_add">+	u32 expected;</span>
 
 	if (!chip)
 		return -EBUSY;
<span class="p_chunk">@@ -474,7 +474,7 @@</span> <span class="p_context"> static int st33zp24_recv(struct tpm_chip *chip, unsigned char *buf,</span>
 	}
 
 	expected = be32_to_cpu(*(__be32 *)(buf + 2));
<span class="p_del">-	if (expected &gt; count) {</span>
<span class="p_add">+	if (expected &gt; count || expected &lt; TPM_HEADER_SIZE) {</span>
 		size = -EIO;
 		goto out;
 	}
<span class="p_header">diff --git a/drivers/char/tpm/tpm-interface.c b/drivers/char/tpm/tpm-interface.c</span>
<span class="p_header">index 1d6729be4cd6..3cec403a80b3 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm-interface.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm-interface.c</span>
<span class="p_chunk">@@ -1228,6 +1228,10 @@</span> <span class="p_context"> int tpm_get_random(u32 chip_num, u8 *out, size_t max)</span>
 			break;
 
 		recd = be32_to_cpu(tpm_cmd.params.getrandom_out.rng_data_len);
<span class="p_add">+		if (recd &gt; num_bytes) {</span>
<span class="p_add">+			total = -EFAULT;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
 
 		rlength = be32_to_cpu(tpm_cmd.header.out.length);
 		if (rlength &lt; offsetof(struct tpm_getrandom_out, rng_data) +
<span class="p_header">diff --git a/drivers/char/tpm/tpm2-cmd.c b/drivers/char/tpm/tpm2-cmd.c</span>
<span class="p_header">index e1a41b788f08..44a3d16231f6 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm2-cmd.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm2-cmd.c</span>
<span class="p_chunk">@@ -683,6 +683,10 @@</span> <span class="p_context"> static int tpm2_unseal_cmd(struct tpm_chip *chip,</span>
 	if (!rc) {
 		data_len = be16_to_cpup(
 			(__be16 *) &amp;buf.data[TPM_HEADER_SIZE + 4]);
<span class="p_add">+		if (data_len &lt; MIN_KEY_SIZE ||  data_len &gt; MAX_KEY_SIZE + 1) {</span>
<span class="p_add">+			rc = -EFAULT;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
 
 		rlength = be32_to_cpu(((struct tpm2_cmd *)&amp;buf)
 					-&gt;header.out.length);
<span class="p_header">diff --git a/drivers/char/tpm/tpm_i2c_infineon.c b/drivers/char/tpm/tpm_i2c_infineon.c</span>
<span class="p_header">index 79d6bbb58e39..d5b44cadac56 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm_i2c_infineon.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm_i2c_infineon.c</span>
<span class="p_chunk">@@ -473,7 +473,8 @@</span> <span class="p_context"> static int recv_data(struct tpm_chip *chip, u8 *buf, size_t count)</span>
 static int tpm_tis_i2c_recv(struct tpm_chip *chip, u8 *buf, size_t count)
 {
 	int size = 0;
<span class="p_del">-	int expected, status;</span>
<span class="p_add">+	int status;</span>
<span class="p_add">+	u32 expected;</span>
 
 	if (count &lt; TPM_HEADER_SIZE) {
 		size = -EIO;
<span class="p_chunk">@@ -488,7 +489,7 @@</span> <span class="p_context"> static int tpm_tis_i2c_recv(struct tpm_chip *chip, u8 *buf, size_t count)</span>
 	}
 
 	expected = be32_to_cpu(*(__be32 *)(buf + 2));
<span class="p_del">-	if ((size_t) expected &gt; count) {</span>
<span class="p_add">+	if (((size_t) expected &gt; count) || (expected &lt; TPM_HEADER_SIZE)) {</span>
 		size = -EIO;
 		goto out;
 	}
<span class="p_header">diff --git a/drivers/char/tpm/tpm_i2c_nuvoton.c b/drivers/char/tpm/tpm_i2c_nuvoton.c</span>
<span class="p_header">index c6428771841f..caa86b19c76d 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm_i2c_nuvoton.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm_i2c_nuvoton.c</span>
<span class="p_chunk">@@ -281,7 +281,11 @@</span> <span class="p_context"> static int i2c_nuvoton_recv(struct tpm_chip *chip, u8 *buf, size_t count)</span>
 	struct device *dev = chip-&gt;dev.parent;
 	struct i2c_client *client = to_i2c_client(dev);
 	s32 rc;
<span class="p_del">-	int expected, status, burst_count, retries, size = 0;</span>
<span class="p_add">+	int status;</span>
<span class="p_add">+	int burst_count;</span>
<span class="p_add">+	int retries;</span>
<span class="p_add">+	int size = 0;</span>
<span class="p_add">+	u32 expected;</span>
 
 	if (count &lt; TPM_HEADER_SIZE) {
 		i2c_nuvoton_ready(chip);    /* return to idle */
<span class="p_chunk">@@ -323,7 +327,7 @@</span> <span class="p_context"> static int i2c_nuvoton_recv(struct tpm_chip *chip, u8 *buf, size_t count)</span>
 		 * to machine native
 		 */
 		expected = be32_to_cpu(*(__be32 *) (buf + 2));
<span class="p_del">-		if (expected &gt; count) {</span>
<span class="p_add">+		if (expected &gt; count || expected &lt; size) {</span>
 			dev_err(dev, &quot;%s() expected &gt; count\n&quot;, __func__);
 			size = -EIO;
 			continue;
<span class="p_header">diff --git a/drivers/char/tpm/tpm_tis.c b/drivers/char/tpm/tpm_tis.c</span>
<span class="p_header">index 7e55aa9ce680..ebd0e75a3e4d 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm_tis.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm_tis.c</span>
<span class="p_chunk">@@ -223,7 +223,7 @@</span> <span class="p_context"> static int tpm_tcg_read_bytes(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 }
 
 static int tpm_tcg_write_bytes(struct tpm_tis_data *data, u32 addr, u16 len,
<span class="p_del">-			       u8 *value)</span>
<span class="p_add">+			       const u8 *value)</span>
 {
 	struct tpm_tis_tcg_phy *phy = to_tpm_tis_tcg_phy(data);
 
<span class="p_header">diff --git a/drivers/char/tpm/tpm_tis_core.c b/drivers/char/tpm/tpm_tis_core.c</span>
<span class="p_header">index 63bc6c3b949e..083578b2517e 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm_tis_core.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm_tis_core.c</span>
<span class="p_chunk">@@ -202,7 +202,8 @@</span> <span class="p_context"> static int tpm_tis_recv(struct tpm_chip *chip, u8 *buf, size_t count)</span>
 {
 	struct tpm_tis_data *priv = dev_get_drvdata(&amp;chip-&gt;dev);
 	int size = 0;
<span class="p_del">-	int expected, status;</span>
<span class="p_add">+	int status;</span>
<span class="p_add">+	u32 expected;</span>
 
 	if (count &lt; TPM_HEADER_SIZE) {
 		size = -EIO;
<span class="p_chunk">@@ -217,7 +218,7 @@</span> <span class="p_context"> static int tpm_tis_recv(struct tpm_chip *chip, u8 *buf, size_t count)</span>
 	}
 
 	expected = be32_to_cpu(*(__be32 *) (buf + 2));
<span class="p_del">-	if (expected &gt; count) {</span>
<span class="p_add">+	if (expected &gt; count || expected &lt; TPM_HEADER_SIZE) {</span>
 		size = -EIO;
 		goto out;
 	}
<span class="p_chunk">@@ -252,7 +253,7 @@</span> <span class="p_context"> static int tpm_tis_recv(struct tpm_chip *chip, u8 *buf, size_t count)</span>
  * tpm.c can skip polling for the data to be available as the interrupt is
  * waited for here
  */
<span class="p_del">-static int tpm_tis_send_data(struct tpm_chip *chip, u8 *buf, size_t len)</span>
<span class="p_add">+static int tpm_tis_send_data(struct tpm_chip *chip, const u8 *buf, size_t len)</span>
 {
 	struct tpm_tis_data *priv = dev_get_drvdata(&amp;chip-&gt;dev);
 	int rc, status, burstcnt;
<span class="p_chunk">@@ -343,7 +344,7 @@</span> <span class="p_context"> static void disable_interrupts(struct tpm_chip *chip)</span>
  * tpm.c can skip polling for the data to be available as the interrupt is
  * waited for here
  */
<span class="p_del">-static int tpm_tis_send_main(struct tpm_chip *chip, u8 *buf, size_t len)</span>
<span class="p_add">+static int tpm_tis_send_main(struct tpm_chip *chip, const u8 *buf, size_t len)</span>
 {
 	struct tpm_tis_data *priv = dev_get_drvdata(&amp;chip-&gt;dev);
 	int rc;
<span class="p_header">diff --git a/drivers/char/tpm/tpm_tis_core.h b/drivers/char/tpm/tpm_tis_core.h</span>
<span class="p_header">index e2212f021a02..6bbac319ff3b 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm_tis_core.h</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm_tis_core.h</span>
<span class="p_chunk">@@ -98,7 +98,7 @@</span> <span class="p_context"> struct tpm_tis_phy_ops {</span>
 	int (*read_bytes)(struct tpm_tis_data *data, u32 addr, u16 len,
 			  u8 *result);
 	int (*write_bytes)(struct tpm_tis_data *data, u32 addr, u16 len,
<span class="p_del">-			   u8 *value);</span>
<span class="p_add">+			   const u8 *value);</span>
 	int (*read16)(struct tpm_tis_data *data, u32 addr, u16 *result);
 	int (*read32)(struct tpm_tis_data *data, u32 addr, u32 *result);
 	int (*write32)(struct tpm_tis_data *data, u32 addr, u32 src);
<span class="p_chunk">@@ -128,7 +128,7 @@</span> <span class="p_context"> static inline int tpm_tis_read32(struct tpm_tis_data *data, u32 addr,</span>
 }
 
 static inline int tpm_tis_write_bytes(struct tpm_tis_data *data, u32 addr,
<span class="p_del">-				      u16 len, u8 *value)</span>
<span class="p_add">+				      u16 len, const u8 *value)</span>
 {
 	return data-&gt;phy_ops-&gt;write_bytes(data, addr, len, value);
 }
<span class="p_header">diff --git a/drivers/char/tpm/tpm_tis_spi.c b/drivers/char/tpm/tpm_tis_spi.c</span>
<span class="p_header">index 88fe72ae967f..8ab0bd8445f6 100644</span>
<span class="p_header">--- a/drivers/char/tpm/tpm_tis_spi.c</span>
<span class="p_header">+++ b/drivers/char/tpm/tpm_tis_spi.c</span>
<span class="p_chunk">@@ -46,9 +46,7 @@</span> <span class="p_context"></span>
 struct tpm_tis_spi_phy {
 	struct tpm_tis_data priv;
 	struct spi_device *spi_device;
<span class="p_del">-</span>
<span class="p_del">-	u8 tx_buf[4];</span>
<span class="p_del">-	u8 rx_buf[4];</span>
<span class="p_add">+	u8 *iobuf;</span>
 };
 
 static inline struct tpm_tis_spi_phy *to_tpm_tis_spi_phy(struct tpm_tis_data *data)
<span class="p_chunk">@@ -57,7 +55,7 @@</span> <span class="p_context"> static inline struct tpm_tis_spi_phy *to_tpm_tis_spi_phy(struct tpm_tis_data *da</span>
 }
 
 static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,
<span class="p_del">-				u8 *buffer, u8 direction)</span>
<span class="p_add">+				u8 *in, const u8 *out)</span>
 {
 	struct tpm_tis_spi_phy *phy = to_tpm_tis_spi_phy(data);
 	int ret = 0;
<span class="p_chunk">@@ -71,14 +69,14 @@</span> <span class="p_context"> static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 	while (len) {
 		transfer_len = min_t(u16, len, MAX_SPI_FRAMESIZE);
 
<span class="p_del">-		phy-&gt;tx_buf[0] = direction | (transfer_len - 1);</span>
<span class="p_del">-		phy-&gt;tx_buf[1] = 0xd4;</span>
<span class="p_del">-		phy-&gt;tx_buf[2] = addr &gt;&gt; 8;</span>
<span class="p_del">-		phy-&gt;tx_buf[3] = addr;</span>
<span class="p_add">+		phy-&gt;iobuf[0] = (in ? 0x80 : 0) | (transfer_len - 1);</span>
<span class="p_add">+		phy-&gt;iobuf[1] = 0xd4;</span>
<span class="p_add">+		phy-&gt;iobuf[2] = addr &gt;&gt; 8;</span>
<span class="p_add">+		phy-&gt;iobuf[3] = addr;</span>
 
 		memset(&amp;spi_xfer, 0, sizeof(spi_xfer));
<span class="p_del">-		spi_xfer.tx_buf = phy-&gt;tx_buf;</span>
<span class="p_del">-		spi_xfer.rx_buf = phy-&gt;rx_buf;</span>
<span class="p_add">+		spi_xfer.tx_buf = phy-&gt;iobuf;</span>
<span class="p_add">+		spi_xfer.rx_buf = phy-&gt;iobuf;</span>
 		spi_xfer.len = 4;
 		spi_xfer.cs_change = 1;
 
<span class="p_chunk">@@ -88,9 +86,9 @@</span> <span class="p_context"> static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 		if (ret &lt; 0)
 			goto exit;
 
<span class="p_del">-		if ((phy-&gt;rx_buf[3] &amp; 0x01) == 0) {</span>
<span class="p_add">+		if ((phy-&gt;iobuf[3] &amp; 0x01) == 0) {</span>
 			// handle SPI wait states
<span class="p_del">-			phy-&gt;tx_buf[0] = 0;</span>
<span class="p_add">+			phy-&gt;iobuf[0] = 0;</span>
 
 			for (i = 0; i &lt; TPM_RETRY; i++) {
 				spi_xfer.len = 1;
<span class="p_chunk">@@ -99,7 +97,7 @@</span> <span class="p_context"> static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 				ret = spi_sync_locked(phy-&gt;spi_device, &amp;m);
 				if (ret &lt; 0)
 					goto exit;
<span class="p_del">-				if (phy-&gt;rx_buf[0] &amp; 0x01)</span>
<span class="p_add">+				if (phy-&gt;iobuf[0] &amp; 0x01)</span>
 					break;
 			}
 
<span class="p_chunk">@@ -113,12 +111,12 @@</span> <span class="p_context"> static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 		spi_xfer.len = transfer_len;
 		spi_xfer.delay_usecs = 5;
 
<span class="p_del">-		if (direction) {</span>
<span class="p_add">+		if (in) {</span>
 			spi_xfer.tx_buf = NULL;
<span class="p_del">-			spi_xfer.rx_buf = buffer;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			spi_xfer.tx_buf = buffer;</span>
<span class="p_add">+		} else if (out) {</span>
 			spi_xfer.rx_buf = NULL;
<span class="p_add">+			memcpy(phy-&gt;iobuf, out, transfer_len);</span>
<span class="p_add">+			out += transfer_len;</span>
 		}
 
 		spi_message_init(&amp;m);
<span class="p_chunk">@@ -127,8 +125,12 @@</span> <span class="p_context"> static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 		if (ret &lt; 0)
 			goto exit;
 
<span class="p_add">+		if (in) {</span>
<span class="p_add">+			memcpy(in, phy-&gt;iobuf, transfer_len);</span>
<span class="p_add">+			in += transfer_len;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		len -= transfer_len;
<span class="p_del">-		buffer += transfer_len;</span>
 	}
 
 exit:
<span class="p_chunk">@@ -139,13 +141,13 @@</span> <span class="p_context"> static int tpm_tis_spi_transfer(struct tpm_tis_data *data, u32 addr, u16 len,</span>
 static int tpm_tis_spi_read_bytes(struct tpm_tis_data *data, u32 addr,
 				  u16 len, u8 *result)
 {
<span class="p_del">-	return tpm_tis_spi_transfer(data, addr, len, result, 0x80);</span>
<span class="p_add">+	return tpm_tis_spi_transfer(data, addr, len, result, NULL);</span>
 }
 
 static int tpm_tis_spi_write_bytes(struct tpm_tis_data *data, u32 addr,
<span class="p_del">-				   u16 len, u8 *value)</span>
<span class="p_add">+				   u16 len, const u8 *value)</span>
 {
<span class="p_del">-	return tpm_tis_spi_transfer(data, addr, len, value, 0);</span>
<span class="p_add">+	return tpm_tis_spi_transfer(data, addr, len, NULL, value);</span>
 }
 
 static int tpm_tis_spi_read16(struct tpm_tis_data *data, u32 addr, u16 *result)
<span class="p_chunk">@@ -194,6 +196,10 @@</span> <span class="p_context"> static int tpm_tis_spi_probe(struct spi_device *dev)</span>
 
 	phy-&gt;spi_device = dev;
 
<span class="p_add">+	phy-&gt;iobuf = devm_kmalloc(&amp;dev-&gt;dev, MAX_SPI_FRAMESIZE, GFP_KERNEL);</span>
<span class="p_add">+	if (!phy-&gt;iobuf)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
 	return tpm_tis_core_init(&amp;dev-&gt;dev, &amp;phy-&gt;priv, -1, &amp;tpm_spi_phy_ops,
 				 NULL);
 }
<span class="p_header">diff --git a/drivers/cpufreq/s3c24xx-cpufreq.c b/drivers/cpufreq/s3c24xx-cpufreq.c</span>
<span class="p_header">index 7b596fa38ad2..6bebc1f9f55a 100644</span>
<span class="p_header">--- a/drivers/cpufreq/s3c24xx-cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/s3c24xx-cpufreq.c</span>
<span class="p_chunk">@@ -351,7 +351,13 @@</span> <span class="p_context"> struct clk *s3c_cpufreq_clk_get(struct device *dev, const char *name)</span>
 static int s3c_cpufreq_init(struct cpufreq_policy *policy)
 {
 	policy-&gt;clk = clk_arm;
<span class="p_del">-	return cpufreq_generic_init(policy, ftab, cpu_cur.info-&gt;latency);</span>
<span class="p_add">+</span>
<span class="p_add">+	policy-&gt;cpuinfo.transition_latency = cpu_cur.info-&gt;latency;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ftab)</span>
<span class="p_add">+		return cpufreq_table_validate_and_show(policy, ftab);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
 }
 
 static int __init s3c_cpufreq_initclks(void)
<span class="p_header">diff --git a/drivers/edac/sb_edac.c b/drivers/edac/sb_edac.c</span>
<span class="p_header">index cd9d6ba03579..0dc0d595c47c 100644</span>
<span class="p_header">--- a/drivers/edac/sb_edac.c</span>
<span class="p_header">+++ b/drivers/edac/sb_edac.c</span>
<span class="p_chunk">@@ -279,7 +279,7 @@</span> <span class="p_context"> static const u32 correrrthrsld[] = {</span>
  * sbridge structs
  */
 
<span class="p_del">-#define NUM_CHANNELS		4	/* Max channels per MC */</span>
<span class="p_add">+#define NUM_CHANNELS		6	/* Max channels per MC */</span>
 #define MAX_DIMMS		3	/* Max DIMMS per channel */
 #define KNL_MAX_CHAS		38	/* KNL max num. of Cache Home Agents */
 #define KNL_MAX_CHANNELS	6	/* KNL max num. of PCI channels */
<span class="p_header">diff --git a/drivers/md/md.c b/drivers/md/md.c</span>
<span class="p_header">index 6bf093cef958..e058c209bbcf 100644</span>
<span class="p_header">--- a/drivers/md/md.c</span>
<span class="p_header">+++ b/drivers/md/md.c</span>
<span class="p_chunk">@@ -8522,6 +8522,10 @@</span> <span class="p_context"> static int remove_and_add_spares(struct mddev *mddev,</span>
 	int removed = 0;
 	bool remove_some = false;
 
<span class="p_add">+	if (this &amp;&amp; test_bit(MD_RECOVERY_RUNNING, &amp;mddev-&gt;recovery))</span>
<span class="p_add">+		/* Mustn&#39;t remove devices when resync thread is running */</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	rdev_for_each(rdev, mddev) {
 		if ((this == NULL || rdev == this) &amp;&amp;
 		    rdev-&gt;raid_disk &gt;= 0 &amp;&amp;
<span class="p_header">diff --git a/drivers/media/dvb-frontends/m88ds3103.c b/drivers/media/dvb-frontends/m88ds3103.c</span>
<span class="p_header">index 50bce68ffd66..65d157fe76d1 100644</span>
<span class="p_header">--- a/drivers/media/dvb-frontends/m88ds3103.c</span>
<span class="p_header">+++ b/drivers/media/dvb-frontends/m88ds3103.c</span>
<span class="p_chunk">@@ -1262,11 +1262,12 @@</span> <span class="p_context"> static int m88ds3103_select(struct i2c_mux_core *muxc, u32 chan)</span>
  * New users must use I2C client binding directly!
  */
 struct dvb_frontend *m88ds3103_attach(const struct m88ds3103_config *cfg,
<span class="p_del">-		struct i2c_adapter *i2c, struct i2c_adapter **tuner_i2c_adapter)</span>
<span class="p_add">+				      struct i2c_adapter *i2c,</span>
<span class="p_add">+				      struct i2c_adapter **tuner_i2c_adapter)</span>
 {
 	struct i2c_client *client;
 	struct i2c_board_info board_info;
<span class="p_del">-	struct m88ds3103_platform_data pdata;</span>
<span class="p_add">+	struct m88ds3103_platform_data pdata = {};</span>
 
 	pdata.clk = cfg-&gt;clock;
 	pdata.i2c_wr_max = cfg-&gt;i2c_wr_max;
<span class="p_chunk">@@ -1409,6 +1410,8 @@</span> <span class="p_context"> static int m88ds3103_probe(struct i2c_client *client,</span>
 	case M88DS3103_CHIP_ID:
 		break;
 	default:
<span class="p_add">+		ret = -ENODEV;</span>
<span class="p_add">+		dev_err(&amp;client-&gt;dev, &quot;Unknown device. Chip_id=%02x\n&quot;, dev-&gt;chip_id);</span>
 		goto err_kfree;
 	}
 
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc-exynos.c b/drivers/mmc/host/dw_mmc-exynos.c</span>
<span class="p_header">index 35026795be28..fa41d9422d57 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc-exynos.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc-exynos.c</span>
<span class="p_chunk">@@ -487,6 +487,7 @@</span> <span class="p_context"> static unsigned long exynos_dwmmc_caps[4] = {</span>
 
 static const struct dw_mci_drv_data exynos_drv_data = {
 	.caps			= exynos_dwmmc_caps,
<span class="p_add">+	.num_caps		= ARRAY_SIZE(exynos_dwmmc_caps),</span>
 	.init			= dw_mci_exynos_priv_init,
 	.set_ios		= dw_mci_exynos_set_ios,
 	.parse_dt		= dw_mci_exynos_parse_dt,
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc-k3.c b/drivers/mmc/host/dw_mmc-k3.c</span>
<span class="p_header">index 64cda84b2302..864e7fcaffaf 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc-k3.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc-k3.c</span>
<span class="p_chunk">@@ -135,6 +135,9 @@</span> <span class="p_context"> static int dw_mci_hi6220_parse_dt(struct dw_mci *host)</span>
 	if (priv-&gt;ctrl_id &lt; 0)
 		priv-&gt;ctrl_id = 0;
 
<span class="p_add">+	if (priv-&gt;ctrl_id &gt;= TIMING_MODE)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	host-&gt;priv = priv;
 	return 0;
 }
<span class="p_chunk">@@ -207,6 +210,7 @@</span> <span class="p_context"> static int dw_mci_hi6220_execute_tuning(struct dw_mci_slot *slot, u32 opcode)</span>
 
 static const struct dw_mci_drv_data hi6220_data = {
 	.caps			= dw_mci_hi6220_caps,
<span class="p_add">+	.num_caps		= ARRAY_SIZE(dw_mci_hi6220_caps),</span>
 	.switch_voltage		= dw_mci_hi6220_switch_voltage,
 	.set_ios		= dw_mci_hi6220_set_ios,
 	.parse_dt		= dw_mci_hi6220_parse_dt,
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc-rockchip.c b/drivers/mmc/host/dw_mmc-rockchip.c</span>
<span class="p_header">index a3f1c2b30145..339295212935 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc-rockchip.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc-rockchip.c</span>
<span class="p_chunk">@@ -319,6 +319,7 @@</span> <span class="p_context"> static const struct dw_mci_drv_data rk2928_drv_data = {</span>
 
 static const struct dw_mci_drv_data rk3288_drv_data = {
 	.caps			= dw_mci_rk3288_dwmmc_caps,
<span class="p_add">+	.num_caps		= ARRAY_SIZE(dw_mci_rk3288_dwmmc_caps),</span>
 	.set_ios		= dw_mci_rk3288_set_ios,
 	.execute_tuning		= dw_mci_rk3288_execute_tuning,
 	.parse_dt		= dw_mci_rk3288_parse_dt,
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc-zx.c b/drivers/mmc/host/dw_mmc-zx.c</span>
<span class="p_header">index d38e94ae2b85..c06b5393312f 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc-zx.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc-zx.c</span>
<span class="p_chunk">@@ -195,6 +195,7 @@</span> <span class="p_context"> static unsigned long zx_dwmmc_caps[3] = {</span>
 
 static const struct dw_mci_drv_data zx_drv_data = {
 	.caps			= zx_dwmmc_caps,
<span class="p_add">+	.num_caps		= ARRAY_SIZE(zx_dwmmc_caps),</span>
 	.execute_tuning		= dw_mci_zx_execute_tuning,
 	.prepare_hs400_tuning	= dw_mci_zx_prepare_hs400_tuning,
 	.parse_dt               = dw_mci_zx_parse_dt,
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc.c b/drivers/mmc/host/dw_mmc.c</span>
<span class="p_header">index 4f2806720c5c..60341a814055 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc.c</span>
<span class="p_chunk">@@ -165,6 +165,8 @@</span> <span class="p_context"> static int dw_mci_regs_show(struct seq_file *s, void *v)</span>
 {
 	struct dw_mci *host = s-&gt;private;
 
<span class="p_add">+	pm_runtime_get_sync(host-&gt;dev);</span>
<span class="p_add">+</span>
 	seq_printf(s, &quot;STATUS:\t0x%08x\n&quot;, mci_readl(host, STATUS));
 	seq_printf(s, &quot;RINTSTS:\t0x%08x\n&quot;, mci_readl(host, RINTSTS));
 	seq_printf(s, &quot;CMD:\t0x%08x\n&quot;, mci_readl(host, CMD));
<span class="p_chunk">@@ -172,6 +174,8 @@</span> <span class="p_context"> static int dw_mci_regs_show(struct seq_file *s, void *v)</span>
 	seq_printf(s, &quot;INTMASK:\t0x%08x\n&quot;, mci_readl(host, INTMASK));
 	seq_printf(s, &quot;CLKENA:\t0x%08x\n&quot;, mci_readl(host, CLKENA));
 
<span class="p_add">+	pm_runtime_put_autosuspend(host-&gt;dev);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -2758,12 +2762,57 @@</span> <span class="p_context"> static irqreturn_t dw_mci_interrupt(int irq, void *dev_id)</span>
 	return IRQ_HANDLED;
 }
 
<span class="p_add">+static int dw_mci_init_slot_caps(struct dw_mci_slot *slot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct dw_mci *host = slot-&gt;host;</span>
<span class="p_add">+	const struct dw_mci_drv_data *drv_data = host-&gt;drv_data;</span>
<span class="p_add">+	struct mmc_host *mmc = slot-&gt;mmc;</span>
<span class="p_add">+	int ctrl_id;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (host-&gt;pdata-&gt;caps)</span>
<span class="p_add">+		mmc-&gt;caps = host-&gt;pdata-&gt;caps;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Support MMC_CAP_ERASE by default.</span>
<span class="p_add">+	 * It needs to use trim/discard/erase commands.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mmc-&gt;caps |= MMC_CAP_ERASE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (host-&gt;pdata-&gt;pm_caps)</span>
<span class="p_add">+		mmc-&gt;pm_caps = host-&gt;pdata-&gt;pm_caps;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (host-&gt;dev-&gt;of_node) {</span>
<span class="p_add">+		ctrl_id = of_alias_get_id(host-&gt;dev-&gt;of_node, &quot;mshc&quot;);</span>
<span class="p_add">+		if (ctrl_id &lt; 0)</span>
<span class="p_add">+			ctrl_id = 0;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		ctrl_id = to_platform_device(host-&gt;dev)-&gt;id;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (drv_data &amp;&amp; drv_data-&gt;caps) {</span>
<span class="p_add">+		if (ctrl_id &gt;= drv_data-&gt;num_caps) {</span>
<span class="p_add">+			dev_err(host-&gt;dev, &quot;invalid controller id %d\n&quot;,</span>
<span class="p_add">+				ctrl_id);</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		mmc-&gt;caps |= drv_data-&gt;caps[ctrl_id];</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (host-&gt;pdata-&gt;caps2)</span>
<span class="p_add">+		mmc-&gt;caps2 = host-&gt;pdata-&gt;caps2;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Process SDIO IRQs through the sdio_irq_work. */</span>
<span class="p_add">+	if (mmc-&gt;caps &amp; MMC_CAP_SDIO_IRQ)</span>
<span class="p_add">+		mmc-&gt;caps2 |= MMC_CAP2_SDIO_IRQ_NOTHREAD;</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int dw_mci_init_slot(struct dw_mci *host)
 {
 	struct mmc_host *mmc;
 	struct dw_mci_slot *slot;
<span class="p_del">-	const struct dw_mci_drv_data *drv_data = host-&gt;drv_data;</span>
<span class="p_del">-	int ctrl_id, ret;</span>
<span class="p_add">+	int ret;</span>
 	u32 freq[2];
 
 	mmc = mmc_alloc_host(sizeof(struct dw_mci_slot), host-&gt;dev);
<span class="p_chunk">@@ -2797,38 +2846,13 @@</span> <span class="p_context"> static int dw_mci_init_slot(struct dw_mci *host)</span>
 	if (!mmc-&gt;ocr_avail)
 		mmc-&gt;ocr_avail = MMC_VDD_32_33 | MMC_VDD_33_34;
 
<span class="p_del">-	if (host-&gt;pdata-&gt;caps)</span>
<span class="p_del">-		mmc-&gt;caps = host-&gt;pdata-&gt;caps;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Support MMC_CAP_ERASE by default.</span>
<span class="p_del">-	 * It needs to use trim/discard/erase commands.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	mmc-&gt;caps |= MMC_CAP_ERASE;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (host-&gt;pdata-&gt;pm_caps)</span>
<span class="p_del">-		mmc-&gt;pm_caps = host-&gt;pdata-&gt;pm_caps;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (host-&gt;dev-&gt;of_node) {</span>
<span class="p_del">-		ctrl_id = of_alias_get_id(host-&gt;dev-&gt;of_node, &quot;mshc&quot;);</span>
<span class="p_del">-		if (ctrl_id &lt; 0)</span>
<span class="p_del">-			ctrl_id = 0;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		ctrl_id = to_platform_device(host-&gt;dev)-&gt;id;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (drv_data &amp;&amp; drv_data-&gt;caps)</span>
<span class="p_del">-		mmc-&gt;caps |= drv_data-&gt;caps[ctrl_id];</span>
<span class="p_del">-</span>
<span class="p_del">-	if (host-&gt;pdata-&gt;caps2)</span>
<span class="p_del">-		mmc-&gt;caps2 = host-&gt;pdata-&gt;caps2;</span>
<span class="p_del">-</span>
 	ret = mmc_of_parse(mmc);
 	if (ret)
 		goto err_host_allocated;
 
<span class="p_del">-	/* Process SDIO IRQs through the sdio_irq_work. */</span>
<span class="p_del">-	if (mmc-&gt;caps &amp; MMC_CAP_SDIO_IRQ)</span>
<span class="p_del">-		mmc-&gt;caps2 |= MMC_CAP2_SDIO_IRQ_NOTHREAD;</span>
<span class="p_add">+	ret = dw_mci_init_slot_caps(slot);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		goto err_host_allocated;</span>
 
 	/* Useful defaults if platform data is unset. */
 	if (host-&gt;use_dma == TRANS_MODE_IDMAC) {
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc.h b/drivers/mmc/host/dw_mmc.h</span>
<span class="p_header">index 34474ad731aa..044c87ce6725 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc.h</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc.h</span>
<span class="p_chunk">@@ -542,6 +542,7 @@</span> <span class="p_context"> struct dw_mci_slot {</span>
 /**
  * dw_mci driver data - dw-mshc implementation specific driver data.
  * @caps: mmc subsystem specified capabilities of the controller(s).
<span class="p_add">+ * @num_caps: number of capabilities specified by @caps.</span>
  * @init: early implementation specific initialization.
  * @set_ios: handle bus specific extensions.
  * @parse_dt: parse implementation specific device tree properties.
<span class="p_chunk">@@ -553,6 +554,7 @@</span> <span class="p_context"> struct dw_mci_slot {</span>
  */
 struct dw_mci_drv_data {
 	unsigned long	*caps;
<span class="p_add">+	u32		num_caps;</span>
 	int		(*init)(struct dw_mci *host);
 	void		(*set_ios)(struct dw_mci *host, struct mmc_ios *ios);
 	int		(*parse_dt)(struct dw_mci *host);
<span class="p_header">diff --git a/drivers/mmc/host/sdhci-pci-core.c b/drivers/mmc/host/sdhci-pci-core.c</span>
<span class="p_header">index 67d787fa3306..070f5da06fd2 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci-pci-core.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci-pci-core.c</span>
<span class="p_chunk">@@ -594,9 +594,36 @@</span> <span class="p_context"> static void byt_read_dsm(struct sdhci_pci_slot *slot)</span>
 	slot-&gt;chip-&gt;rpm_retune = intel_host-&gt;d3_retune;
 }
 
<span class="p_del">-static int byt_emmc_probe_slot(struct sdhci_pci_slot *slot)</span>
<span class="p_add">+static int intel_execute_tuning(struct mmc_host *mmc, u32 opcode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int err = sdhci_execute_tuning(mmc, opcode);</span>
<span class="p_add">+	struct sdhci_host *host = mmc_priv(mmc);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Tuning can leave the IP in an active state (Buffer Read Enable bit</span>
<span class="p_add">+	 * set) which prevents the entry to low power states (i.e. S0i3). Data</span>
<span class="p_add">+	 * reset will clear it.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	sdhci_reset(host, SDHCI_RESET_DATA);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void byt_probe_slot(struct sdhci_pci_slot *slot)</span>
 {
<span class="p_add">+	struct mmc_host_ops *ops = &amp;slot-&gt;host-&gt;mmc_host_ops;</span>
<span class="p_add">+</span>
 	byt_read_dsm(slot);
<span class="p_add">+</span>
<span class="p_add">+	ops-&gt;execute_tuning = intel_execute_tuning;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int byt_emmc_probe_slot(struct sdhci_pci_slot *slot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	byt_probe_slot(slot);</span>
 	slot-&gt;host-&gt;mmc-&gt;caps |= MMC_CAP_8_BIT_DATA | MMC_CAP_NONREMOVABLE |
 				 MMC_CAP_HW_RESET | MMC_CAP_1_8V_DDR |
 				 MMC_CAP_CMD_DURING_TFR |
<span class="p_chunk">@@ -651,7 +678,7 @@</span> <span class="p_context"> static int ni_byt_sdio_probe_slot(struct sdhci_pci_slot *slot)</span>
 {
 	int err;
 
<span class="p_del">-	byt_read_dsm(slot);</span>
<span class="p_add">+	byt_probe_slot(slot);</span>
 
 	err = ni_set_max_freq(slot);
 	if (err)
<span class="p_chunk">@@ -664,7 +691,7 @@</span> <span class="p_context"> static int ni_byt_sdio_probe_slot(struct sdhci_pci_slot *slot)</span>
 
 static int byt_sdio_probe_slot(struct sdhci_pci_slot *slot)
 {
<span class="p_del">-	byt_read_dsm(slot);</span>
<span class="p_add">+	byt_probe_slot(slot);</span>
 	slot-&gt;host-&gt;mmc-&gt;caps |= MMC_CAP_POWER_OFF_CARD | MMC_CAP_NONREMOVABLE |
 				 MMC_CAP_WAIT_WHILE_BUSY;
 	return 0;
<span class="p_chunk">@@ -672,7 +699,7 @@</span> <span class="p_context"> static int byt_sdio_probe_slot(struct sdhci_pci_slot *slot)</span>
 
 static int byt_sd_probe_slot(struct sdhci_pci_slot *slot)
 {
<span class="p_del">-	byt_read_dsm(slot);</span>
<span class="p_add">+	byt_probe_slot(slot);</span>
 	slot-&gt;host-&gt;mmc-&gt;caps |= MMC_CAP_WAIT_WHILE_BUSY |
 				 MMC_CAP_AGGRESSIVE_PM | MMC_CAP_CD_WAKE;
 	slot-&gt;cd_idx = 0;
<span class="p_header">diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c</span>
<span class="p_header">index 608693d11bd7..75c4455e2271 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c</span>
<span class="p_chunk">@@ -595,7 +595,7 @@</span> <span class="p_context"> static void xgbe_isr_task(unsigned long data)</span>
 
 		reissue_mask = 1 &lt;&lt; 0;
 		if (!pdata-&gt;per_channel_irq)
<span class="p_del">-			reissue_mask |= 0xffff &lt; 4;</span>
<span class="p_add">+			reissue_mask |= 0xffff &lt;&lt; 4;</span>
 
 		XP_IOWRITE(pdata, XP_INT_REISSUE_EN, reissue_mask);
 	}
<span class="p_header">diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-pci.c b/drivers/net/ethernet/amd/xgbe/xgbe-pci.c</span>
<span class="p_header">index 3e5833cf1fab..eb23f9ba1a9a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/amd/xgbe/xgbe-pci.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/amd/xgbe/xgbe-pci.c</span>
<span class="p_chunk">@@ -426,6 +426,8 @@</span> <span class="p_context"> static int xgbe_pci_resume(struct pci_dev *pdev)</span>
 	struct net_device *netdev = pdata-&gt;netdev;
 	int ret = 0;
 
<span class="p_add">+	XP_IOWRITE(pdata, XP_INT_EN, 0x1fffff);</span>
<span class="p_add">+</span>
 	pdata-&gt;lpm_ctrl &amp;= ~MDIO_CTRL1_LPOWER;
 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, pdata-&gt;lpm_ctrl);
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_header">index 879a9c4cef59..29f600fd6977 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_chunk">@@ -1877,6 +1877,14 @@</span> <span class="p_context"> static void ixgbe_dma_sync_frag(struct ixgbe_ring *rx_ring,</span>
 				     ixgbe_rx_pg_size(rx_ring),
 				     DMA_FROM_DEVICE,
 				     IXGBE_RX_DMA_ATTR);
<span class="p_add">+	} else if (ring_uses_build_skb(rx_ring)) {</span>
<span class="p_add">+		unsigned long offset = (unsigned long)(skb-&gt;data) &amp; ~PAGE_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+		dma_sync_single_range_for_cpu(rx_ring-&gt;dev,</span>
<span class="p_add">+					      IXGBE_CB(skb)-&gt;dma,</span>
<span class="p_add">+					      offset,</span>
<span class="p_add">+					      skb_headlen(skb),</span>
<span class="p_add">+					      DMA_FROM_DEVICE);</span>
 	} else {
 		struct skb_frag_struct *frag = &amp;skb_shinfo(skb)-&gt;frags[0];
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">index 3cdb932cae76..a863572882b2 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_chunk">@@ -1918,13 +1918,16 @@</span> <span class="p_context"> static void mlx5e_build_rq_param(struct mlx5e_priv *priv,</span>
 	param-&gt;wq.linear = 1;
 }
 
<span class="p_del">-static void mlx5e_build_drop_rq_param(struct mlx5e_rq_param *param)</span>
<span class="p_add">+static void mlx5e_build_drop_rq_param(struct mlx5_core_dev *mdev,</span>
<span class="p_add">+				      struct mlx5e_rq_param *param)</span>
 {
 	void *rqc = param-&gt;rqc;
 	void *wq = MLX5_ADDR_OF(rqc, rqc, wq);
 
 	MLX5_SET(wq, wq, wq_type, MLX5_WQ_TYPE_LINKED_LIST);
 	MLX5_SET(wq, wq, log_wq_stride,    ilog2(sizeof(struct mlx5e_rx_wqe)));
<span class="p_add">+</span>
<span class="p_add">+	param-&gt;wq.buf_numa_node = dev_to_node(&amp;mdev-&gt;pdev-&gt;dev);</span>
 }
 
 static void mlx5e_build_sq_param_common(struct mlx5e_priv *priv,
<span class="p_chunk">@@ -2778,6 +2781,9 @@</span> <span class="p_context"> static int mlx5e_alloc_drop_cq(struct mlx5_core_dev *mdev,</span>
 			       struct mlx5e_cq *cq,
 			       struct mlx5e_cq_param *param)
 {
<span class="p_add">+	param-&gt;wq.buf_numa_node = dev_to_node(&amp;mdev-&gt;pdev-&gt;dev);</span>
<span class="p_add">+	param-&gt;wq.db_numa_node  = dev_to_node(&amp;mdev-&gt;pdev-&gt;dev);</span>
<span class="p_add">+</span>
 	return mlx5e_alloc_cq_common(mdev, param, cq);
 }
 
<span class="p_chunk">@@ -2789,7 +2795,7 @@</span> <span class="p_context"> static int mlx5e_open_drop_rq(struct mlx5_core_dev *mdev,</span>
 	struct mlx5e_cq *cq = &amp;drop_rq-&gt;cq;
 	int err;
 
<span class="p_del">-	mlx5e_build_drop_rq_param(&amp;rq_param);</span>
<span class="p_add">+	mlx5e_build_drop_rq_param(mdev, &amp;rq_param);</span>
 
 	err = mlx5e_alloc_drop_cq(mdev, cq, &amp;cq_param);
 	if (err)
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_header">index 91b1b0938931..3476f594c195 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_chunk">@@ -36,6 +36,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/tcp.h&gt;
 #include &lt;linux/bpf_trace.h&gt;
 #include &lt;net/busy_poll.h&gt;
<span class="p_add">+#include &lt;net/ip6_checksum.h&gt;</span>
 #include &quot;en.h&quot;
 #include &quot;en_tc.h&quot;
 #include &quot;eswitch.h&quot;
<span class="p_chunk">@@ -546,20 +547,33 @@</span> <span class="p_context"> bool mlx5e_post_rx_mpwqes(struct mlx5e_rq *rq)</span>
 	return true;
 }
 
<span class="p_add">+static void mlx5e_lro_update_tcp_hdr(struct mlx5_cqe64 *cqe, struct tcphdr *tcp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 l4_hdr_type = get_cqe_l4_hdr_type(cqe);</span>
<span class="p_add">+	u8 tcp_ack     = (l4_hdr_type == CQE_L4_HDR_TYPE_TCP_ACK_NO_DATA) ||</span>
<span class="p_add">+			 (l4_hdr_type == CQE_L4_HDR_TYPE_TCP_ACK_AND_DATA);</span>
<span class="p_add">+</span>
<span class="p_add">+	tcp-&gt;check                      = 0;</span>
<span class="p_add">+	tcp-&gt;psh                        = get_cqe_lro_tcppsh(cqe);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tcp_ack) {</span>
<span class="p_add">+		tcp-&gt;ack                = 1;</span>
<span class="p_add">+		tcp-&gt;ack_seq            = cqe-&gt;lro_ack_seq_num;</span>
<span class="p_add">+		tcp-&gt;window             = cqe-&gt;lro_tcp_win;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void mlx5e_lro_update_hdr(struct sk_buff *skb, struct mlx5_cqe64 *cqe,
 				 u32 cqe_bcnt)
 {
 	struct ethhdr	*eth = (struct ethhdr *)(skb-&gt;data);
 	struct tcphdr	*tcp;
 	int network_depth = 0;
<span class="p_add">+	__wsum check;</span>
 	__be16 proto;
 	u16 tot_len;
 	void *ip_p;
 
<span class="p_del">-	u8 l4_hdr_type = get_cqe_l4_hdr_type(cqe);</span>
<span class="p_del">-	u8 tcp_ack = (l4_hdr_type == CQE_L4_HDR_TYPE_TCP_ACK_NO_DATA) ||</span>
<span class="p_del">-		(l4_hdr_type == CQE_L4_HDR_TYPE_TCP_ACK_AND_DATA);</span>
<span class="p_del">-</span>
 	skb-&gt;mac_len = ETH_HLEN;
 	proto = __vlan_get_protocol(skb, eth-&gt;h_proto, &amp;network_depth);
 
<span class="p_chunk">@@ -577,23 +591,30 @@</span> <span class="p_context"> static void mlx5e_lro_update_hdr(struct sk_buff *skb, struct mlx5_cqe64 *cqe,</span>
 		ipv4-&gt;check             = 0;
 		ipv4-&gt;check             = ip_fast_csum((unsigned char *)ipv4,
 						       ipv4-&gt;ihl);
<span class="p_add">+</span>
<span class="p_add">+		mlx5e_lro_update_tcp_hdr(cqe, tcp);</span>
<span class="p_add">+		check = csum_partial(tcp, tcp-&gt;doff * 4,</span>
<span class="p_add">+				     csum_unfold((__force __sum16)cqe-&gt;check_sum));</span>
<span class="p_add">+		/* Almost done, don&#39;t forget the pseudo header */</span>
<span class="p_add">+		tcp-&gt;check = csum_tcpudp_magic(ipv4-&gt;saddr, ipv4-&gt;daddr,</span>
<span class="p_add">+					       tot_len - sizeof(struct iphdr),</span>
<span class="p_add">+					       IPPROTO_TCP, check);</span>
 	} else {
<span class="p_add">+		u16 payload_len = tot_len - sizeof(struct ipv6hdr);</span>
 		struct ipv6hdr *ipv6 = ip_p;
 
 		tcp = ip_p + sizeof(struct ipv6hdr);
 		skb_shinfo(skb)-&gt;gso_type = SKB_GSO_TCPV6;
 
 		ipv6-&gt;hop_limit         = cqe-&gt;lro_min_ttl;
<span class="p_del">-		ipv6-&gt;payload_len       = cpu_to_be16(tot_len -</span>
<span class="p_del">-						      sizeof(struct ipv6hdr));</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	tcp-&gt;psh = get_cqe_lro_tcppsh(cqe);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (tcp_ack) {</span>
<span class="p_del">-		tcp-&gt;ack                = 1;</span>
<span class="p_del">-		tcp-&gt;ack_seq            = cqe-&gt;lro_ack_seq_num;</span>
<span class="p_del">-		tcp-&gt;window             = cqe-&gt;lro_tcp_win;</span>
<span class="p_add">+		ipv6-&gt;payload_len       = cpu_to_be16(payload_len);</span>
<span class="p_add">+</span>
<span class="p_add">+		mlx5e_lro_update_tcp_hdr(cqe, tcp);</span>
<span class="p_add">+		check = csum_partial(tcp, tcp-&gt;doff * 4,</span>
<span class="p_add">+				     csum_unfold((__force __sum16)cqe-&gt;check_sum));</span>
<span class="p_add">+		/* Almost done, don&#39;t forget the pseudo header */</span>
<span class="p_add">+		tcp-&gt;check = csum_ipv6_magic(&amp;ipv6-&gt;saddr, &amp;ipv6-&gt;daddr, payload_len,</span>
<span class="p_add">+					     IPPROTO_TCP, check);</span>
 	}
 }
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c b/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c</span>
<span class="p_header">index 5a4608281f38..707976482c09 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c</span>
<span class="p_chunk">@@ -216,7 +216,8 @@</span> <span class="p_context"> mlx5e_test_loopback_validate(struct sk_buff *skb,</span>
 	if (iph-&gt;protocol != IPPROTO_UDP)
 		goto out;
 
<span class="p_del">-	udph = udp_hdr(skb);</span>
<span class="p_add">+	/* Don&#39;t assume skb_transport_header() was set */</span>
<span class="p_add">+	udph = (struct udphdr *)((u8 *)iph + 4 * iph-&gt;ihl);</span>
 	if (udph-&gt;dest != htons(9))
 		goto out;
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c</span>
<span class="p_header">index 1d6925d4369a..eea7f931cad3 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c</span>
<span class="p_chunk">@@ -155,7 +155,7 @@</span> <span class="p_context"> static inline u16 mlx5e_calc_min_inline(enum mlx5_inline_modes mode,</span>
 	default:
 		hlen = mlx5e_skb_l2_header_offset(skb);
 	}
<span class="p_del">-	return min_t(u16, hlen, skb-&gt;len);</span>
<span class="p_add">+	return min_t(u16, hlen, skb_headlen(skb));</span>
 }
 
 static inline void mlx5e_tx_skb_pull_inline(unsigned char **skb_data,
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_header">index 7bef80676464..516e63244606 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_chunk">@@ -729,26 +729,29 @@</span> <span class="p_context"> static struct mlxsw_sp_fib *mlxsw_sp_vr_fib(const struct mlxsw_sp_vr *vr,</span>
 static struct mlxsw_sp_vr *mlxsw_sp_vr_create(struct mlxsw_sp *mlxsw_sp,
 					      u32 tb_id)
 {
<span class="p_add">+	struct mlxsw_sp_fib *fib4;</span>
<span class="p_add">+	struct mlxsw_sp_fib *fib6;</span>
 	struct mlxsw_sp_vr *vr;
 	int err;
 
 	vr = mlxsw_sp_vr_find_unused(mlxsw_sp);
 	if (!vr)
 		return ERR_PTR(-EBUSY);
<span class="p_del">-	vr-&gt;fib4 = mlxsw_sp_fib_create(vr, MLXSW_SP_L3_PROTO_IPV4);</span>
<span class="p_del">-	if (IS_ERR(vr-&gt;fib4))</span>
<span class="p_del">-		return ERR_CAST(vr-&gt;fib4);</span>
<span class="p_del">-	vr-&gt;fib6 = mlxsw_sp_fib_create(vr, MLXSW_SP_L3_PROTO_IPV6);</span>
<span class="p_del">-	if (IS_ERR(vr-&gt;fib6)) {</span>
<span class="p_del">-		err = PTR_ERR(vr-&gt;fib6);</span>
<span class="p_add">+	fib4 = mlxsw_sp_fib_create(vr, MLXSW_SP_L3_PROTO_IPV4);</span>
<span class="p_add">+	if (IS_ERR(fib4))</span>
<span class="p_add">+		return ERR_CAST(fib4);</span>
<span class="p_add">+	fib6 = mlxsw_sp_fib_create(vr, MLXSW_SP_L3_PROTO_IPV6);</span>
<span class="p_add">+	if (IS_ERR(fib6)) {</span>
<span class="p_add">+		err = PTR_ERR(fib6);</span>
 		goto err_fib6_create;
 	}
<span class="p_add">+	vr-&gt;fib4 = fib4;</span>
<span class="p_add">+	vr-&gt;fib6 = fib6;</span>
 	vr-&gt;tb_id = tb_id;
 	return vr;
 
 err_fib6_create:
<span class="p_del">-	mlxsw_sp_fib_destroy(vr-&gt;fib4);</span>
<span class="p_del">-	vr-&gt;fib4 = NULL;</span>
<span class="p_add">+	mlxsw_sp_fib_destroy(fib4);</span>
 	return ERR_PTR(err);
 }
 
<span class="p_chunk">@@ -3029,6 +3032,9 @@</span> <span class="p_context"> mlxsw_sp_fib4_entry_offload_unset(struct mlxsw_sp_fib_entry *fib_entry)</span>
 	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry-&gt;nh_group;
 	int i;
 
<span class="p_add">+	if (!list_is_singular(&amp;nh_grp-&gt;fib_list))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; nh_grp-&gt;count; i++) {
 		struct mlxsw_sp_nexthop *nh = &amp;nh_grp-&gt;nexthops[i];
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum_switchdev.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum_switchdev.c</span>
<span class="p_header">index f5863e5bec81..42a6afcaae03 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_switchdev.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_switchdev.c</span>
<span class="p_chunk">@@ -1098,6 +1098,7 @@</span> <span class="p_context"> static int __mlxsw_sp_port_fdb_uc_op(struct mlxsw_sp *mlxsw_sp, u8 local_port,</span>
 				     bool dynamic)
 {
 	char *sfd_pl;
<span class="p_add">+	u8 num_rec;</span>
 	int err;
 
 	sfd_pl = kmalloc(MLXSW_REG_SFD_LEN, GFP_KERNEL);
<span class="p_chunk">@@ -1107,9 +1108,16 @@</span> <span class="p_context"> static int __mlxsw_sp_port_fdb_uc_op(struct mlxsw_sp *mlxsw_sp, u8 local_port,</span>
 	mlxsw_reg_sfd_pack(sfd_pl, mlxsw_sp_sfd_op(adding), 0);
 	mlxsw_reg_sfd_uc_pack(sfd_pl, 0, mlxsw_sp_sfd_rec_policy(dynamic),
 			      mac, fid, action, local_port);
<span class="p_add">+	num_rec = mlxsw_reg_sfd_num_rec_get(sfd_pl);</span>
 	err = mlxsw_reg_write(mlxsw_sp-&gt;core, MLXSW_REG(sfd), sfd_pl);
<span class="p_del">-	kfree(sfd_pl);</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (num_rec != mlxsw_reg_sfd_num_rec_get(sfd_pl))</span>
<span class="p_add">+		err = -EBUSY;</span>
 
<span class="p_add">+out:</span>
<span class="p_add">+	kfree(sfd_pl);</span>
 	return err;
 }
 
<span class="p_chunk">@@ -1134,6 +1142,7 @@</span> <span class="p_context"> static int mlxsw_sp_port_fdb_uc_lag_op(struct mlxsw_sp *mlxsw_sp, u16 lag_id,</span>
 				       bool adding, bool dynamic)
 {
 	char *sfd_pl;
<span class="p_add">+	u8 num_rec;</span>
 	int err;
 
 	sfd_pl = kmalloc(MLXSW_REG_SFD_LEN, GFP_KERNEL);
<span class="p_chunk">@@ -1144,9 +1153,16 @@</span> <span class="p_context"> static int mlxsw_sp_port_fdb_uc_lag_op(struct mlxsw_sp *mlxsw_sp, u16 lag_id,</span>
 	mlxsw_reg_sfd_uc_lag_pack(sfd_pl, 0, mlxsw_sp_sfd_rec_policy(dynamic),
 				  mac, fid, MLXSW_REG_SFD_REC_ACTION_NOP,
 				  lag_vid, lag_id);
<span class="p_add">+	num_rec = mlxsw_reg_sfd_num_rec_get(sfd_pl);</span>
 	err = mlxsw_reg_write(mlxsw_sp-&gt;core, MLXSW_REG(sfd), sfd_pl);
<span class="p_del">-	kfree(sfd_pl);</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (num_rec != mlxsw_reg_sfd_num_rec_get(sfd_pl))</span>
<span class="p_add">+		err = -EBUSY;</span>
 
<span class="p_add">+out:</span>
<span class="p_add">+	kfree(sfd_pl);</span>
 	return err;
 }
 
<span class="p_chunk">@@ -1191,6 +1207,7 @@</span> <span class="p_context"> static int mlxsw_sp_port_mdb_op(struct mlxsw_sp *mlxsw_sp, const char *addr,</span>
 				u16 fid, u16 mid, bool adding)
 {
 	char *sfd_pl;
<span class="p_add">+	u8 num_rec;</span>
 	int err;
 
 	sfd_pl = kmalloc(MLXSW_REG_SFD_LEN, GFP_KERNEL);
<span class="p_chunk">@@ -1200,7 +1217,15 @@</span> <span class="p_context"> static int mlxsw_sp_port_mdb_op(struct mlxsw_sp *mlxsw_sp, const char *addr,</span>
 	mlxsw_reg_sfd_pack(sfd_pl, mlxsw_sp_sfd_op(adding), 0);
 	mlxsw_reg_sfd_mc_pack(sfd_pl, 0, addr, fid,
 			      MLXSW_REG_SFD_REC_ACTION_NOP, mid);
<span class="p_add">+	num_rec = mlxsw_reg_sfd_num_rec_get(sfd_pl);</span>
 	err = mlxsw_reg_write(mlxsw_sp-&gt;core, MLXSW_REG(sfd), sfd_pl);
<span class="p_add">+	if (err)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (num_rec != mlxsw_reg_sfd_num_rec_get(sfd_pl))</span>
<span class="p_add">+		err = -EBUSY;</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
 	kfree(sfd_pl);
 	return err;
 }
<span class="p_header">diff --git a/drivers/net/ethernet/ti/cpsw.c b/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_header">index db8a4bcfc6c7..14b646b3b084 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_chunk">@@ -1618,6 +1618,7 @@</span> <span class="p_context"> static netdev_tx_t cpsw_ndo_start_xmit(struct sk_buff *skb,</span>
 		q_idx = q_idx % cpsw-&gt;tx_ch_num;
 
 	txch = cpsw-&gt;txv[q_idx].ch;
<span class="p_add">+	txq = netdev_get_tx_queue(ndev, q_idx);</span>
 	ret = cpsw_tx_packet_submit(priv, skb, txch);
 	if (unlikely(ret != 0)) {
 		cpsw_err(priv, tx_err, &quot;desc submit failed\n&quot;);
<span class="p_chunk">@@ -1628,15 +1629,26 @@</span> <span class="p_context"> static netdev_tx_t cpsw_ndo_start_xmit(struct sk_buff *skb,</span>
 	 * tell the kernel to stop sending us tx frames.
 	 */
 	if (unlikely(!cpdma_check_free_tx_desc(txch))) {
<span class="p_del">-		txq = netdev_get_tx_queue(ndev, q_idx);</span>
 		netif_tx_stop_queue(txq);
<span class="p_add">+</span>
<span class="p_add">+		/* Barrier, so that stop_queue visible to other cpus */</span>
<span class="p_add">+		smp_mb__after_atomic();</span>
<span class="p_add">+</span>
<span class="p_add">+		if (cpdma_check_free_tx_desc(txch))</span>
<span class="p_add">+			netif_tx_wake_queue(txq);</span>
 	}
 
 	return NETDEV_TX_OK;
 fail:
 	ndev-&gt;stats.tx_dropped++;
<span class="p_del">-	txq = netdev_get_tx_queue(ndev, skb_get_queue_mapping(skb));</span>
 	netif_tx_stop_queue(txq);
<span class="p_add">+</span>
<span class="p_add">+	/* Barrier, so that stop_queue visible to other cpus */</span>
<span class="p_add">+	smp_mb__after_atomic();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpdma_check_free_tx_desc(txch))</span>
<span class="p_add">+		netif_tx_wake_queue(txq);</span>
<span class="p_add">+</span>
 	return NETDEV_TX_BUSY;
 }
 
<span class="p_header">diff --git a/drivers/net/phy/phy.c b/drivers/net/phy/phy.c</span>
<span class="p_header">index 2b1e67bc1e73..3d860de5e342 100644</span>
<span class="p_header">--- a/drivers/net/phy/phy.c</span>
<span class="p_header">+++ b/drivers/net/phy/phy.c</span>
<span class="p_chunk">@@ -842,7 +842,7 @@</span> <span class="p_context"> void phy_start(struct phy_device *phydev)</span>
 		break;
 	case PHY_HALTED:
 		/* make sure interrupts are re-enabled for the PHY */
<span class="p_del">-		if (phydev-&gt;irq != PHY_POLL) {</span>
<span class="p_add">+		if (phy_interrupt_is_valid(phydev)) {</span>
 			err = phy_enable_interrupts(phydev);
 			if (err &lt; 0)
 				break;
<span class="p_header">diff --git a/drivers/net/ppp/ppp_generic.c b/drivers/net/ppp/ppp_generic.c</span>
<span class="p_header">index 8c6b8918ec31..38cd2e8fae23 100644</span>
<span class="p_header">--- a/drivers/net/ppp/ppp_generic.c</span>
<span class="p_header">+++ b/drivers/net/ppp/ppp_generic.c</span>
<span class="p_chunk">@@ -3158,6 +3158,15 @@</span> <span class="p_context"> ppp_connect_channel(struct channel *pch, int unit)</span>
 		goto outl;
 
 	ppp_lock(ppp);
<span class="p_add">+	spin_lock_bh(&amp;pch-&gt;downl);</span>
<span class="p_add">+	if (!pch-&gt;chan) {</span>
<span class="p_add">+		/* Don&#39;t connect unregistered channels */</span>
<span class="p_add">+		spin_unlock_bh(&amp;pch-&gt;downl);</span>
<span class="p_add">+		ppp_unlock(ppp);</span>
<span class="p_add">+		ret = -ENOTCONN;</span>
<span class="p_add">+		goto outl;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock_bh(&amp;pch-&gt;downl);</span>
 	if (pch-&gt;file.hdrlen &gt; ppp-&gt;file.hdrlen)
 		ppp-&gt;file.hdrlen = pch-&gt;file.hdrlen;
 	hdrlen = pch-&gt;file.hdrlen + 2;	/* for protocol bytes */
<span class="p_header">diff --git a/drivers/net/tun.c b/drivers/net/tun.c</span>
<span class="p_header">index fa51b7b0e9ea..bc38d54e37b9 100644</span>
<span class="p_header">--- a/drivers/net/tun.c</span>
<span class="p_header">+++ b/drivers/net/tun.c</span>
<span class="p_chunk">@@ -1315,6 +1315,7 @@</span> <span class="p_context"> static struct sk_buff *tun_build_skb(struct tun_struct *tun,</span>
 	else
 		*skb_xdp = 0;
 
<span class="p_add">+	preempt_disable();</span>
 	rcu_read_lock();
 	xdp_prog = rcu_dereference(tun-&gt;xdp_prog);
 	if (xdp_prog &amp;&amp; !*skb_xdp) {
<span class="p_chunk">@@ -1333,9 +1334,11 @@</span> <span class="p_context"> static struct sk_buff *tun_build_skb(struct tun_struct *tun,</span>
 			get_page(alloc_frag-&gt;page);
 			alloc_frag-&gt;offset += buflen;
 			err = xdp_do_redirect(tun-&gt;dev, &amp;xdp, xdp_prog);
<span class="p_add">+			xdp_do_flush_map();</span>
 			if (err)
 				goto err_redirect;
 			rcu_read_unlock();
<span class="p_add">+			preempt_enable();</span>
 			return NULL;
 		case XDP_TX:
 			xdp_xmit = true;
<span class="p_chunk">@@ -1357,6 +1360,7 @@</span> <span class="p_context"> static struct sk_buff *tun_build_skb(struct tun_struct *tun,</span>
 	skb = build_skb(buf, buflen);
 	if (!skb) {
 		rcu_read_unlock();
<span class="p_add">+		preempt_enable();</span>
 		return ERR_PTR(-ENOMEM);
 	}
 
<span class="p_chunk">@@ -1369,10 +1373,12 @@</span> <span class="p_context"> static struct sk_buff *tun_build_skb(struct tun_struct *tun,</span>
 		skb-&gt;dev = tun-&gt;dev;
 		generic_xdp_tx(skb, xdp_prog);
 		rcu_read_unlock();
<span class="p_add">+		preempt_enable();</span>
 		return NULL;
 	}
 
 	rcu_read_unlock();
<span class="p_add">+	preempt_enable();</span>
 
 	return skb;
 
<span class="p_chunk">@@ -1380,6 +1386,7 @@</span> <span class="p_context"> static struct sk_buff *tun_build_skb(struct tun_struct *tun,</span>
 	put_page(alloc_frag-&gt;page);
 err_xdp:
 	rcu_read_unlock();
<span class="p_add">+	preempt_enable();</span>
 	this_cpu_inc(tun-&gt;pcpu_stats-&gt;rx_dropped);
 	return NULL;
 }
<span class="p_header">diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c</span>
<span class="p_header">index 7927e28f5336..6a785595b9b8 100644</span>
<span class="p_header">--- a/drivers/net/virtio_net.c</span>
<span class="p_header">+++ b/drivers/net/virtio_net.c</span>
<span class="p_chunk">@@ -1995,8 +1995,9 @@</span> <span class="p_context"> static int virtnet_xdp_set(struct net_device *dev, struct bpf_prog *prog,</span>
 	}
 
 	/* Make sure NAPI is not using any XDP TX queues for RX. */
<span class="p_del">-	for (i = 0; i &lt; vi-&gt;max_queue_pairs; i++)</span>
<span class="p_del">-		napi_disable(&amp;vi-&gt;rq[i].napi);</span>
<span class="p_add">+	if (netif_running(dev))</span>
<span class="p_add">+		for (i = 0; i &lt; vi-&gt;max_queue_pairs; i++)</span>
<span class="p_add">+			napi_disable(&amp;vi-&gt;rq[i].napi);</span>
 
 	netif_set_real_num_rx_queues(dev, curr_qp + xdp_qp);
 	err = _virtnet_set_queues(vi, curr_qp + xdp_qp);
<span class="p_chunk">@@ -2015,7 +2016,8 @@</span> <span class="p_context"> static int virtnet_xdp_set(struct net_device *dev, struct bpf_prog *prog,</span>
 		}
 		if (old_prog)
 			bpf_prog_put(old_prog);
<span class="p_del">-		virtnet_napi_enable(vi-&gt;rq[i].vq, &amp;vi-&gt;rq[i].napi);</span>
<span class="p_add">+		if (netif_running(dev))</span>
<span class="p_add">+			virtnet_napi_enable(vi-&gt;rq[i].vq, &amp;vi-&gt;rq[i].napi);</span>
 	}
 
 	return 0;
<span class="p_header">diff --git a/drivers/net/wan/hdlc_ppp.c b/drivers/net/wan/hdlc_ppp.c</span>
<span class="p_header">index 0d2e00ece804..f3c1d5245978 100644</span>
<span class="p_header">--- a/drivers/net/wan/hdlc_ppp.c</span>
<span class="p_header">+++ b/drivers/net/wan/hdlc_ppp.c</span>
<span class="p_chunk">@@ -574,7 +574,10 @@</span> <span class="p_context"> static void ppp_timer(unsigned long arg)</span>
 			ppp_cp_event(proto-&gt;dev, proto-&gt;pid, TO_GOOD, 0, 0,
 				     0, NULL);
 			proto-&gt;restart_counter--;
<span class="p_del">-		} else</span>
<span class="p_add">+		} else if (netif_carrier_ok(proto-&gt;dev))</span>
<span class="p_add">+			ppp_cp_event(proto-&gt;dev, proto-&gt;pid, TO_GOOD, 0, 0,</span>
<span class="p_add">+				     0, NULL);</span>
<span class="p_add">+		else</span>
 			ppp_cp_event(proto-&gt;dev, proto-&gt;pid, TO_BAD, 0, 0,
 				     0, NULL);
 		break;
<span class="p_header">diff --git a/drivers/nvme/host/rdma.c b/drivers/nvme/host/rdma.c</span>
<span class="p_header">index 33d4431c2b4b..93a082e0bdd4 100644</span>
<span class="p_header">--- a/drivers/nvme/host/rdma.c</span>
<span class="p_header">+++ b/drivers/nvme/host/rdma.c</span>
<span class="p_chunk">@@ -88,7 +88,6 @@</span> <span class="p_context"> enum nvme_rdma_queue_flags {</span>
 
 struct nvme_rdma_queue {
 	struct nvme_rdma_qe	*rsp_ring;
<span class="p_del">-	atomic_t		sig_count;</span>
 	int			queue_size;
 	size_t			cmnd_capsule_len;
 	struct nvme_rdma_ctrl	*ctrl;
<span class="p_chunk">@@ -521,7 +520,6 @@</span> <span class="p_context"> static int nvme_rdma_alloc_queue(struct nvme_rdma_ctrl *ctrl,</span>
 		queue-&gt;cmnd_capsule_len = sizeof(struct nvme_command);
 
 	queue-&gt;queue_size = queue_size;
<span class="p_del">-	atomic_set(&amp;queue-&gt;sig_count, 0);</span>
 
 	queue-&gt;cm_id = rdma_create_id(&amp;init_net, nvme_rdma_cm_handler, queue,
 			RDMA_PS_TCP, IB_QPT_RC);
<span class="p_chunk">@@ -1232,21 +1230,9 @@</span> <span class="p_context"> static void nvme_rdma_send_done(struct ib_cq *cq, struct ib_wc *wc)</span>
 		nvme_end_request(rq, req-&gt;status, req-&gt;result);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * We want to signal completion at least every queue depth/2.  This returns the</span>
<span class="p_del">- * largest power of two that is not above half of (queue size + 1) to optimize</span>
<span class="p_del">- * (avoid divisions).</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline bool nvme_rdma_queue_sig_limit(struct nvme_rdma_queue *queue)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int limit = 1 &lt;&lt; ilog2((queue-&gt;queue_size + 1) / 2);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (atomic_inc_return(&amp;queue-&gt;sig_count) &amp; (limit - 1)) == 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int nvme_rdma_post_send(struct nvme_rdma_queue *queue,
 		struct nvme_rdma_qe *qe, struct ib_sge *sge, u32 num_sge,
<span class="p_del">-		struct ib_send_wr *first, bool flush)</span>
<span class="p_add">+		struct ib_send_wr *first)</span>
 {
 	struct ib_send_wr wr, *bad_wr;
 	int ret;
<span class="p_chunk">@@ -1255,31 +1241,12 @@</span> <span class="p_context"> static int nvme_rdma_post_send(struct nvme_rdma_queue *queue,</span>
 	sge-&gt;length = sizeof(struct nvme_command),
 	sge-&gt;lkey   = queue-&gt;device-&gt;pd-&gt;local_dma_lkey;
 
<span class="p_del">-	qe-&gt;cqe.done = nvme_rdma_send_done;</span>
<span class="p_del">-</span>
 	wr.next       = NULL;
 	wr.wr_cqe     = &amp;qe-&gt;cqe;
 	wr.sg_list    = sge;
 	wr.num_sge    = num_sge;
 	wr.opcode     = IB_WR_SEND;
<span class="p_del">-	wr.send_flags = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Unsignalled send completions are another giant desaster in the</span>
<span class="p_del">-	 * IB Verbs spec:  If we don&#39;t regularly post signalled sends</span>
<span class="p_del">-	 * the send queue will fill up and only a QP reset will rescue us.</span>
<span class="p_del">-	 * Would have been way to obvious to handle this in hardware or</span>
<span class="p_del">-	 * at least the RDMA stack..</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Always signal the flushes. The magic request used for the flush</span>
<span class="p_del">-	 * sequencer is not allocated in our driver&#39;s tagset and it&#39;s</span>
<span class="p_del">-	 * triggered to be freed by blk_cleanup_queue(). So we need to</span>
<span class="p_del">-	 * always mark it as signaled to ensure that the &quot;wr_cqe&quot;, which is</span>
<span class="p_del">-	 * embedded in request&#39;s payload, is not freed when __ib_process_cq()</span>
<span class="p_del">-	 * calls wr_cqe-&gt;done().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (nvme_rdma_queue_sig_limit(queue) || flush)</span>
<span class="p_del">-		wr.send_flags |= IB_SEND_SIGNALED;</span>
<span class="p_add">+	wr.send_flags = IB_SEND_SIGNALED;</span>
 
 	if (first)
 		first-&gt;next = &amp;wr;
<span class="p_chunk">@@ -1329,6 +1296,12 @@</span> <span class="p_context"> static struct blk_mq_tags *nvme_rdma_tagset(struct nvme_rdma_queue *queue)</span>
 	return queue-&gt;ctrl-&gt;tag_set.tags[queue_idx - 1];
 }
 
<span class="p_add">+static void nvme_rdma_async_done(struct ib_cq *cq, struct ib_wc *wc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely(wc-&gt;status != IB_WC_SUCCESS))</span>
<span class="p_add">+		nvme_rdma_wr_error(cq, wc, &quot;ASYNC&quot;);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void nvme_rdma_submit_async_event(struct nvme_ctrl *arg, int aer_idx)
 {
 	struct nvme_rdma_ctrl *ctrl = to_rdma_ctrl(arg);
<span class="p_chunk">@@ -1350,10 +1323,12 @@</span> <span class="p_context"> static void nvme_rdma_submit_async_event(struct nvme_ctrl *arg, int aer_idx)</span>
 	cmd-&gt;common.flags |= NVME_CMD_SGL_METABUF;
 	nvme_rdma_set_sg_null(cmd);
 
<span class="p_add">+	sqe-&gt;cqe.done = nvme_rdma_async_done;</span>
<span class="p_add">+</span>
 	ib_dma_sync_single_for_device(dev, sqe-&gt;dma, sizeof(*cmd),
 			DMA_TO_DEVICE);
 
<span class="p_del">-	ret = nvme_rdma_post_send(queue, sqe, &amp;sge, 1, NULL, false);</span>
<span class="p_add">+	ret = nvme_rdma_post_send(queue, sqe, &amp;sge, 1, NULL);</span>
 	WARN_ON_ONCE(ret);
 }
 
<span class="p_chunk">@@ -1639,7 +1614,6 @@</span> <span class="p_context"> static blk_status_t nvme_rdma_queue_rq(struct blk_mq_hw_ctx *hctx,</span>
 	struct nvme_rdma_request *req = blk_mq_rq_to_pdu(rq);
 	struct nvme_rdma_qe *sqe = &amp;req-&gt;sqe;
 	struct nvme_command *c = sqe-&gt;data;
<span class="p_del">-	bool flush = false;</span>
 	struct ib_device *dev;
 	blk_status_t ret;
 	int err;
<span class="p_chunk">@@ -1668,13 +1642,13 @@</span> <span class="p_context"> static blk_status_t nvme_rdma_queue_rq(struct blk_mq_hw_ctx *hctx,</span>
 		goto err;
 	}
 
<span class="p_add">+	sqe-&gt;cqe.done = nvme_rdma_send_done;</span>
<span class="p_add">+</span>
 	ib_dma_sync_single_for_device(dev, sqe-&gt;dma,
 			sizeof(struct nvme_command), DMA_TO_DEVICE);
 
<span class="p_del">-	if (req_op(rq) == REQ_OP_FLUSH)</span>
<span class="p_del">-		flush = true;</span>
 	err = nvme_rdma_post_send(queue, sqe, req-&gt;sge, req-&gt;num_sge,
<span class="p_del">-			req-&gt;mr-&gt;need_inval ? &amp;req-&gt;reg_wr.wr : NULL, flush);</span>
<span class="p_add">+			req-&gt;mr-&gt;need_inval ? &amp;req-&gt;reg_wr.wr : NULL);</span>
 	if (unlikely(err)) {
 		nvme_rdma_unmap_data(queue, rq);
 		goto err;
<span class="p_header">diff --git a/drivers/pci/pcie/aspm.c b/drivers/pci/pcie/aspm.c</span>
<span class="p_header">index cae54f8320be..633e55c57b13 100644</span>
<span class="p_header">--- a/drivers/pci/pcie/aspm.c</span>
<span class="p_header">+++ b/drivers/pci/pcie/aspm.c</span>
<span class="p_chunk">@@ -803,10 +803,14 @@</span> <span class="p_context"> static struct pcie_link_state *alloc_pcie_link_state(struct pci_dev *pdev)</span>
 
 	/*
 	 * Root Ports and PCI/PCI-X to PCIe Bridges are roots of PCIe
<span class="p_del">-	 * hierarchies.</span>
<span class="p_add">+	 * hierarchies.  Note that some PCIe host implementations omit</span>
<span class="p_add">+	 * the root ports entirely, in which case a downstream port on</span>
<span class="p_add">+	 * a switch may become the root of the link state chain for all</span>
<span class="p_add">+	 * its subordinate endpoints.</span>
 	 */
 	if (pci_pcie_type(pdev) == PCI_EXP_TYPE_ROOT_PORT ||
<span class="p_del">-	    pci_pcie_type(pdev) == PCI_EXP_TYPE_PCIE_BRIDGE) {</span>
<span class="p_add">+	    pci_pcie_type(pdev) == PCI_EXP_TYPE_PCIE_BRIDGE ||</span>
<span class="p_add">+	    !pdev-&gt;bus-&gt;parent-&gt;self) {</span>
 		link-&gt;root = link;
 	} else {
 		struct pcie_link_state *parent;
<span class="p_header">diff --git a/drivers/s390/net/qeth_core.h b/drivers/s390/net/qeth_core.h</span>
<span class="p_header">index 92dd4aef21a3..6b1e83539a9d 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_core.h</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_core.h</span>
<span class="p_chunk">@@ -580,6 +580,11 @@</span> <span class="p_context"> struct qeth_cmd_buffer {</span>
 	void (*callback) (struct qeth_channel *, struct qeth_cmd_buffer *);
 };
 
<span class="p_add">+static inline struct qeth_ipa_cmd *__ipa_cmd(struct qeth_cmd_buffer *iob)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (struct qeth_ipa_cmd *)(iob-&gt;data + IPA_PDU_HEADER_SIZE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * definition of a qeth channel, used for read and write
  */
<span class="p_chunk">@@ -834,7 +839,7 @@</span> <span class="p_context"> struct qeth_trap_id {</span>
  */
 static inline int qeth_get_elements_for_range(addr_t start, addr_t end)
 {
<span class="p_del">-	return PFN_UP(end - 1) - PFN_DOWN(start);</span>
<span class="p_add">+	return PFN_UP(end) - PFN_DOWN(start);</span>
 }
 
 static inline int qeth_get_micros(void)
<span class="p_header">diff --git a/drivers/s390/net/qeth_core_main.c b/drivers/s390/net/qeth_core_main.c</span>
<span class="p_header">index 7c7a244b6684..145b57762d8f 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_core_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_core_main.c</span>
<span class="p_chunk">@@ -2073,7 +2073,7 @@</span> <span class="p_context"> int qeth_send_control_data(struct qeth_card *card, int len,</span>
 	unsigned long flags;
 	struct qeth_reply *reply = NULL;
 	unsigned long timeout, event_timeout;
<span class="p_del">-	struct qeth_ipa_cmd *cmd;</span>
<span class="p_add">+	struct qeth_ipa_cmd *cmd = NULL;</span>
 
 	QETH_CARD_TEXT(card, 2, &quot;sendctl&quot;);
 
<span class="p_chunk">@@ -2087,23 +2087,27 @@</span> <span class="p_context"> int qeth_send_control_data(struct qeth_card *card, int len,</span>
 	}
 	reply-&gt;callback = reply_cb;
 	reply-&gt;param = reply_param;
<span class="p_del">-	if (card-&gt;state == CARD_STATE_DOWN)</span>
<span class="p_del">-		reply-&gt;seqno = QETH_IDX_COMMAND_SEQNO;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		reply-&gt;seqno = card-&gt;seqno.ipa++;</span>
<span class="p_add">+</span>
 	init_waitqueue_head(&amp;reply-&gt;wait_q);
<span class="p_del">-	spin_lock_irqsave(&amp;card-&gt;lock, flags);</span>
<span class="p_del">-	list_add_tail(&amp;reply-&gt;list, &amp;card-&gt;cmd_waiter_list);</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;card-&gt;lock, flags);</span>
 	QETH_DBF_HEX(CTRL, 2, iob-&gt;data, QETH_DBF_CTRL_LEN);
 
 	while (atomic_cmpxchg(&amp;card-&gt;write.irq_pending, 0, 1)) ;
<span class="p_del">-	qeth_prepare_control_data(card, len, iob);</span>
 
<span class="p_del">-	if (IS_IPA(iob-&gt;data))</span>
<span class="p_add">+	if (IS_IPA(iob-&gt;data)) {</span>
<span class="p_add">+		cmd = __ipa_cmd(iob);</span>
<span class="p_add">+		cmd-&gt;hdr.seqno = card-&gt;seqno.ipa++;</span>
<span class="p_add">+		reply-&gt;seqno = cmd-&gt;hdr.seqno;</span>
 		event_timeout = QETH_IPA_TIMEOUT;
<span class="p_del">-	else</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		reply-&gt;seqno = QETH_IDX_COMMAND_SEQNO;</span>
 		event_timeout = QETH_TIMEOUT;
<span class="p_add">+	}</span>
<span class="p_add">+	qeth_prepare_control_data(card, len, iob);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;card-&gt;lock, flags);</span>
<span class="p_add">+	list_add_tail(&amp;reply-&gt;list, &amp;card-&gt;cmd_waiter_list);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;card-&gt;lock, flags);</span>
<span class="p_add">+</span>
 	timeout = jiffies + event_timeout;
 
 	QETH_CARD_TEXT(card, 6, &quot;noirqpnd&quot;);
<span class="p_chunk">@@ -2128,9 +2132,8 @@</span> <span class="p_context"> int qeth_send_control_data(struct qeth_card *card, int len,</span>
 
 	/* we have only one long running ipassist, since we can ensure
 	   process context of this command we can sleep */
<span class="p_del">-	cmd = (struct qeth_ipa_cmd *)(iob-&gt;data+IPA_PDU_HEADER_SIZE);</span>
<span class="p_del">-	if ((cmd-&gt;hdr.command == IPA_CMD_SETIP) &amp;&amp;</span>
<span class="p_del">-	    (cmd-&gt;hdr.prot_version == QETH_PROT_IPV4)) {</span>
<span class="p_add">+	if (cmd &amp;&amp; cmd-&gt;hdr.command == IPA_CMD_SETIP &amp;&amp;</span>
<span class="p_add">+	    cmd-&gt;hdr.prot_version == QETH_PROT_IPV4) {</span>
 		if (!wait_event_timeout(reply-&gt;wait_q,
 		    atomic_read(&amp;reply-&gt;received), event_timeout))
 			goto time_err;
<span class="p_chunk">@@ -2894,7 +2897,7 @@</span> <span class="p_context"> static void qeth_fill_ipacmd_header(struct qeth_card *card,</span>
 	memset(cmd, 0, sizeof(struct qeth_ipa_cmd));
 	cmd-&gt;hdr.command = command;
 	cmd-&gt;hdr.initiator = IPA_CMD_INITIATOR_HOST;
<span class="p_del">-	cmd-&gt;hdr.seqno = card-&gt;seqno.ipa;</span>
<span class="p_add">+	/* cmd-&gt;hdr.seqno is set by qeth_send_control_data() */</span>
 	cmd-&gt;hdr.adapter_type = qeth_get_ipa_adp_type(card-&gt;info.link_type);
 	cmd-&gt;hdr.rel_adapter_no = (__u8) card-&gt;info.portno;
 	if (card-&gt;options.layer2)
<span class="p_chunk">@@ -3859,10 +3862,12 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(qeth_get_elements_for_frags);</span>
 int qeth_get_elements_no(struct qeth_card *card,
 		     struct sk_buff *skb, int extra_elems, int data_offset)
 {
<span class="p_del">-	int elements = qeth_get_elements_for_range(</span>
<span class="p_del">-				(addr_t)skb-&gt;data + data_offset,</span>
<span class="p_del">-				(addr_t)skb-&gt;data + skb_headlen(skb)) +</span>
<span class="p_del">-			qeth_get_elements_for_frags(skb);</span>
<span class="p_add">+	addr_t end = (addr_t)skb-&gt;data + skb_headlen(skb);</span>
<span class="p_add">+	int elements = qeth_get_elements_for_frags(skb);</span>
<span class="p_add">+	addr_t start = (addr_t)skb-&gt;data + data_offset;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (start != end)</span>
<span class="p_add">+		elements += qeth_get_elements_for_range(start, end);</span>
 
 	if ((elements + extra_elems) &gt; QETH_MAX_BUFFER_ELEMENTS(card)) {
 		QETH_DBF_MESSAGE(2, &quot;Invalid size of IP packet &quot;
<span class="p_header">diff --git a/drivers/s390/net/qeth_l3.h b/drivers/s390/net/qeth_l3.h</span>
<span class="p_header">index e5833837b799..8727b9517de8 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l3.h</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l3.h</span>
<span class="p_chunk">@@ -40,8 +40,40 @@</span> <span class="p_context"> struct qeth_ipaddr {</span>
 			unsigned int pfxlen;
 		} a6;
 	} u;
<span class="p_del">-</span>
 };
<span class="p_add">+</span>
<span class="p_add">+static inline bool qeth_l3_addr_match_ip(struct qeth_ipaddr *a1,</span>
<span class="p_add">+					 struct qeth_ipaddr *a2)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (a1-&gt;proto != a2-&gt;proto)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	if (a1-&gt;proto == QETH_PROT_IPV6)</span>
<span class="p_add">+		return ipv6_addr_equal(&amp;a1-&gt;u.a6.addr, &amp;a2-&gt;u.a6.addr);</span>
<span class="p_add">+	return a1-&gt;u.a4.addr == a2-&gt;u.a4.addr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool qeth_l3_addr_match_all(struct qeth_ipaddr *a1,</span>
<span class="p_add">+					  struct qeth_ipaddr *a2)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Assumes that the pair was obtained via qeth_l3_addr_find_by_ip(),</span>
<span class="p_add">+	 * so &#39;proto&#39; and &#39;addr&#39; match for sure.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * For ucast:</span>
<span class="p_add">+	 * -	&#39;mac&#39; is always 0.</span>
<span class="p_add">+	 * -	&#39;mask&#39;/&#39;pfxlen&#39; for RXIP/VIPA is always 0. For NORMAL, matching</span>
<span class="p_add">+	 *	values are required to avoid mixups in takeover eligibility.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * For mcast,</span>
<span class="p_add">+	 * -	&#39;mac&#39; is mapped from the IP, and thus always matches.</span>
<span class="p_add">+	 * -	&#39;mask&#39;/&#39;pfxlen&#39; is always 0.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (a1-&gt;type != a2-&gt;type)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	if (a1-&gt;proto == QETH_PROT_IPV6)</span>
<span class="p_add">+		return a1-&gt;u.a6.pfxlen == a2-&gt;u.a6.pfxlen;</span>
<span class="p_add">+	return a1-&gt;u.a4.mask == a2-&gt;u.a4.mask;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline  u64 qeth_l3_ipaddr_hash(struct qeth_ipaddr *addr)
 {
 	u64  ret = 0;
<span class="p_header">diff --git a/drivers/s390/net/qeth_l3_main.c b/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_header">index 36dee176f8e2..96576e729222 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_chunk">@@ -149,6 +149,24 @@</span> <span class="p_context"> int qeth_l3_string_to_ipaddr(const char *buf, enum qeth_prot_versions proto,</span>
 		return -EINVAL;
 }
 
<span class="p_add">+static struct qeth_ipaddr *qeth_l3_find_addr_by_ip(struct qeth_card *card,</span>
<span class="p_add">+						   struct qeth_ipaddr *query)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 key = qeth_l3_ipaddr_hash(query);</span>
<span class="p_add">+	struct qeth_ipaddr *addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (query-&gt;is_multicast) {</span>
<span class="p_add">+		hash_for_each_possible(card-&gt;ip_mc_htable, addr, hnode, key)</span>
<span class="p_add">+			if (qeth_l3_addr_match_ip(addr, query))</span>
<span class="p_add">+				return addr;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		hash_for_each_possible(card-&gt;ip_htable,  addr, hnode, key)</span>
<span class="p_add">+			if (qeth_l3_addr_match_ip(addr, query))</span>
<span class="p_add">+				return addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void qeth_l3_convert_addr_to_bits(u8 *addr, u8 *bits, int len)
 {
 	int i, j;
<span class="p_chunk">@@ -202,34 +220,6 @@</span> <span class="p_context"> static bool qeth_l3_is_addr_covered_by_ipato(struct qeth_card *card,</span>
 	return rc;
 }
 
<span class="p_del">-inline int</span>
<span class="p_del">-qeth_l3_ipaddrs_is_equal(struct qeth_ipaddr *addr1, struct qeth_ipaddr *addr2)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return addr1-&gt;proto == addr2-&gt;proto &amp;&amp;</span>
<span class="p_del">-		!memcmp(&amp;addr1-&gt;u, &amp;addr2-&gt;u, sizeof(addr1-&gt;u))  &amp;&amp;</span>
<span class="p_del">-		!memcmp(&amp;addr1-&gt;mac, &amp;addr2-&gt;mac, sizeof(addr1-&gt;mac));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static struct qeth_ipaddr *</span>
<span class="p_del">-qeth_l3_ip_from_hash(struct qeth_card *card, struct qeth_ipaddr *tmp_addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct qeth_ipaddr *addr;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (tmp_addr-&gt;is_multicast) {</span>
<span class="p_del">-		hash_for_each_possible(card-&gt;ip_mc_htable,  addr,</span>
<span class="p_del">-				hnode, qeth_l3_ipaddr_hash(tmp_addr))</span>
<span class="p_del">-			if (qeth_l3_ipaddrs_is_equal(tmp_addr, addr))</span>
<span class="p_del">-				return addr;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		hash_for_each_possible(card-&gt;ip_htable,  addr,</span>
<span class="p_del">-				hnode, qeth_l3_ipaddr_hash(tmp_addr))</span>
<span class="p_del">-			if (qeth_l3_ipaddrs_is_equal(tmp_addr, addr))</span>
<span class="p_del">-				return addr;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return NULL;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 int qeth_l3_delete_ip(struct qeth_card *card, struct qeth_ipaddr *tmp_addr)
 {
 	int rc = 0;
<span class="p_chunk">@@ -244,23 +234,18 @@</span> <span class="p_context"> int qeth_l3_delete_ip(struct qeth_card *card, struct qeth_ipaddr *tmp_addr)</span>
 		QETH_CARD_HEX(card, 4, ((char *)&amp;tmp_addr-&gt;u.a6.addr) + 8, 8);
 	}
 
<span class="p_del">-	addr = qeth_l3_ip_from_hash(card, tmp_addr);</span>
<span class="p_del">-	if (!addr)</span>
<span class="p_add">+	addr = qeth_l3_find_addr_by_ip(card, tmp_addr);</span>
<span class="p_add">+	if (!addr || !qeth_l3_addr_match_all(addr, tmp_addr))</span>
 		return -ENOENT;
 
 	addr-&gt;ref_counter--;
<span class="p_del">-	if (addr-&gt;ref_counter &gt; 0 &amp;&amp; (addr-&gt;type == QETH_IP_TYPE_NORMAL ||</span>
<span class="p_del">-				      addr-&gt;type == QETH_IP_TYPE_RXIP))</span>
<span class="p_add">+	if (addr-&gt;type == QETH_IP_TYPE_NORMAL &amp;&amp; addr-&gt;ref_counter &gt; 0)</span>
 		return rc;
 	if (addr-&gt;in_progress)
 		return -EINPROGRESS;
 
<span class="p_del">-	if (!qeth_card_hw_is_reachable(card)) {</span>
<span class="p_del">-		addr-&gt;disp_flag = QETH_DISP_ADDR_DELETE;</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	rc = qeth_l3_deregister_addr_entry(card, addr);</span>
<span class="p_add">+	if (qeth_card_hw_is_reachable(card))</span>
<span class="p_add">+		rc = qeth_l3_deregister_addr_entry(card, addr);</span>
 
 	hash_del(&amp;addr-&gt;hnode);
 	kfree(addr);
<span class="p_chunk">@@ -272,6 +257,7 @@</span> <span class="p_context"> int qeth_l3_add_ip(struct qeth_card *card, struct qeth_ipaddr *tmp_addr)</span>
 {
 	int rc = 0;
 	struct qeth_ipaddr *addr;
<span class="p_add">+	char buf[40];</span>
 
 	QETH_CARD_TEXT(card, 4, &quot;addip&quot;);
 
<span class="p_chunk">@@ -282,8 +268,20 @@</span> <span class="p_context"> int qeth_l3_add_ip(struct qeth_card *card, struct qeth_ipaddr *tmp_addr)</span>
 		QETH_CARD_HEX(card, 4, ((char *)&amp;tmp_addr-&gt;u.a6.addr) + 8, 8);
 	}
 
<span class="p_del">-	addr = qeth_l3_ip_from_hash(card, tmp_addr);</span>
<span class="p_del">-	if (!addr) {</span>
<span class="p_add">+	addr = qeth_l3_find_addr_by_ip(card, tmp_addr);</span>
<span class="p_add">+	if (addr) {</span>
<span class="p_add">+		if (tmp_addr-&gt;type != QETH_IP_TYPE_NORMAL)</span>
<span class="p_add">+			return -EADDRINUSE;</span>
<span class="p_add">+		if (qeth_l3_addr_match_all(addr, tmp_addr)) {</span>
<span class="p_add">+			addr-&gt;ref_counter++;</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		qeth_l3_ipaddr_to_string(tmp_addr-&gt;proto, (u8 *)&amp;tmp_addr-&gt;u,</span>
<span class="p_add">+					 buf);</span>
<span class="p_add">+		dev_warn(&amp;card-&gt;gdev-&gt;dev,</span>
<span class="p_add">+			 &quot;Registering IP address %s failed\n&quot;, buf);</span>
<span class="p_add">+		return -EADDRINUSE;</span>
<span class="p_add">+	} else {</span>
 		addr = qeth_l3_get_addr_buffer(tmp_addr-&gt;proto);
 		if (!addr)
 			return -ENOMEM;
<span class="p_chunk">@@ -323,19 +321,15 @@</span> <span class="p_context"> int qeth_l3_add_ip(struct qeth_card *card, struct qeth_ipaddr *tmp_addr)</span>
 				(rc == IPA_RC_LAN_OFFLINE)) {
 			addr-&gt;disp_flag = QETH_DISP_ADDR_DO_NOTHING;
 			if (addr-&gt;ref_counter &lt; 1) {
<span class="p_del">-				qeth_l3_delete_ip(card, addr);</span>
<span class="p_add">+				qeth_l3_deregister_addr_entry(card, addr);</span>
<span class="p_add">+				hash_del(&amp;addr-&gt;hnode);</span>
 				kfree(addr);
 			}
 		} else {
 			hash_del(&amp;addr-&gt;hnode);
 			kfree(addr);
 		}
<span class="p_del">-	} else {</span>
<span class="p_del">-		if (addr-&gt;type == QETH_IP_TYPE_NORMAL ||</span>
<span class="p_del">-		    addr-&gt;type == QETH_IP_TYPE_RXIP)</span>
<span class="p_del">-			addr-&gt;ref_counter++;</span>
 	}
<span class="p_del">-</span>
 	return rc;
 }
 
<span class="p_chunk">@@ -403,11 +397,7 @@</span> <span class="p_context"> static void qeth_l3_recover_ip(struct qeth_card *card)</span>
 	spin_lock_bh(&amp;card-&gt;ip_lock);
 
 	hash_for_each_safe(card-&gt;ip_htable, i, tmp, addr, hnode) {
<span class="p_del">-		if (addr-&gt;disp_flag == QETH_DISP_ADDR_DELETE) {</span>
<span class="p_del">-			qeth_l3_deregister_addr_entry(card, addr);</span>
<span class="p_del">-			hash_del(&amp;addr-&gt;hnode);</span>
<span class="p_del">-			kfree(addr);</span>
<span class="p_del">-		} else if (addr-&gt;disp_flag == QETH_DISP_ADDR_ADD) {</span>
<span class="p_add">+		if (addr-&gt;disp_flag == QETH_DISP_ADDR_ADD) {</span>
 			if (addr-&gt;proto == QETH_PROT_IPV4) {
 				addr-&gt;in_progress = 1;
 				spin_unlock_bh(&amp;card-&gt;ip_lock);
<span class="p_chunk">@@ -723,12 +713,7 @@</span> <span class="p_context"> int qeth_l3_add_vipa(struct qeth_card *card, enum qeth_prot_versions proto,</span>
 		return -ENOMEM;
 
 	spin_lock_bh(&amp;card-&gt;ip_lock);
<span class="p_del">-</span>
<span class="p_del">-	if (qeth_l3_ip_from_hash(card, ipaddr))</span>
<span class="p_del">-		rc = -EEXIST;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		qeth_l3_add_ip(card, ipaddr);</span>
<span class="p_del">-</span>
<span class="p_add">+	rc = qeth_l3_add_ip(card, ipaddr);</span>
 	spin_unlock_bh(&amp;card-&gt;ip_lock);
 
 	kfree(ipaddr);
<span class="p_chunk">@@ -791,12 +776,7 @@</span> <span class="p_context"> int qeth_l3_add_rxip(struct qeth_card *card, enum qeth_prot_versions proto,</span>
 		return -ENOMEM;
 
 	spin_lock_bh(&amp;card-&gt;ip_lock);
<span class="p_del">-</span>
<span class="p_del">-	if (qeth_l3_ip_from_hash(card, ipaddr))</span>
<span class="p_del">-		rc = -EEXIST;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		qeth_l3_add_ip(card, ipaddr);</span>
<span class="p_del">-</span>
<span class="p_add">+	rc = qeth_l3_add_ip(card, ipaddr);</span>
 	spin_unlock_bh(&amp;card-&gt;ip_lock);
 
 	kfree(ipaddr);
<span class="p_chunk">@@ -1404,8 +1384,9 @@</span> <span class="p_context"> qeth_l3_add_mc_to_hash(struct qeth_card *card, struct in_device *in4_dev)</span>
 		memcpy(tmp-&gt;mac, buf, sizeof(tmp-&gt;mac));
 		tmp-&gt;is_multicast = 1;
 
<span class="p_del">-		ipm = qeth_l3_ip_from_hash(card, tmp);</span>
<span class="p_add">+		ipm = qeth_l3_find_addr_by_ip(card, tmp);</span>
 		if (ipm) {
<span class="p_add">+			/* for mcast, by-IP match means full match */</span>
 			ipm-&gt;disp_flag = QETH_DISP_ADDR_DO_NOTHING;
 		} else {
 			ipm = qeth_l3_get_addr_buffer(QETH_PROT_IPV4);
<span class="p_chunk">@@ -1488,8 +1469,9 @@</span> <span class="p_context"> qeth_l3_add_mc6_to_hash(struct qeth_card *card, struct inet6_dev *in6_dev)</span>
 		       sizeof(struct in6_addr));
 		tmp-&gt;is_multicast = 1;
 
<span class="p_del">-		ipm = qeth_l3_ip_from_hash(card, tmp);</span>
<span class="p_add">+		ipm = qeth_l3_find_addr_by_ip(card, tmp);</span>
 		if (ipm) {
<span class="p_add">+			/* for mcast, by-IP match means full match */</span>
 			ipm-&gt;disp_flag = QETH_DISP_ADDR_DO_NOTHING;
 			continue;
 		}
<span class="p_chunk">@@ -2633,11 +2615,12 @@</span> <span class="p_context"> static void qeth_tso_fill_header(struct qeth_card *card,</span>
 static int qeth_l3_get_elements_no_tso(struct qeth_card *card,
 			struct sk_buff *skb, int extra_elems)
 {
<span class="p_del">-	addr_t tcpdptr = (addr_t)tcp_hdr(skb) + tcp_hdrlen(skb);</span>
<span class="p_del">-	int elements = qeth_get_elements_for_range(</span>
<span class="p_del">-				tcpdptr,</span>
<span class="p_del">-				(addr_t)skb-&gt;data + skb_headlen(skb)) +</span>
<span class="p_del">-				qeth_get_elements_for_frags(skb);</span>
<span class="p_add">+	addr_t start = (addr_t)tcp_hdr(skb) + tcp_hdrlen(skb);</span>
<span class="p_add">+	addr_t end = (addr_t)skb-&gt;data + skb_headlen(skb);</span>
<span class="p_add">+	int elements = qeth_get_elements_for_frags(skb);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (start != end)</span>
<span class="p_add">+		elements += qeth_get_elements_for_range(start, end);</span>
 
 	if ((elements + extra_elems) &gt; QETH_MAX_BUFFER_ELEMENTS(card)) {
 		QETH_DBF_MESSAGE(2,
<span class="p_header">diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="p_header">index 92155cce926d..fb4e6a7ee521 100644</span>
<span class="p_header">--- a/drivers/vfio/vfio_iommu_type1.c</span>
<span class="p_header">+++ b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="p_chunk">@@ -338,11 +338,12 @@</span> <span class="p_context"> static int vaddr_get_pfn(struct mm_struct *mm, unsigned long vaddr,</span>
 {
 	struct page *page[1];
 	struct vm_area_struct *vma;
<span class="p_add">+	struct vm_area_struct *vmas[1];</span>
 	int ret;
 
 	if (mm == current-&gt;mm) {
<span class="p_del">-		ret = get_user_pages_fast(vaddr, 1, !!(prot &amp; IOMMU_WRITE),</span>
<span class="p_del">-					  page);</span>
<span class="p_add">+		ret = get_user_pages_longterm(vaddr, 1, !!(prot &amp; IOMMU_WRITE),</span>
<span class="p_add">+					      page, vmas);</span>
 	} else {
 		unsigned int flags = 0;
 
<span class="p_chunk">@@ -351,7 +352,18 @@</span> <span class="p_context"> static int vaddr_get_pfn(struct mm_struct *mm, unsigned long vaddr,</span>
 
 		down_read(&amp;mm-&gt;mmap_sem);
 		ret = get_user_pages_remote(NULL, mm, vaddr, 1, flags, page,
<span class="p_del">-					    NULL, NULL);</span>
<span class="p_add">+					    vmas, NULL);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * The lifetime of a vaddr_get_pfn() page pin is</span>
<span class="p_add">+		 * userspace-controlled. In the fs-dax case this could</span>
<span class="p_add">+		 * lead to indefinite stalls in filesystem operations.</span>
<span class="p_add">+		 * Disallow attempts to pin fs-dax pages via this</span>
<span class="p_add">+		 * interface.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (ret &gt; 0 &amp;&amp; vma_is_fsdax(vmas[0])) {</span>
<span class="p_add">+			ret = -EOPNOTSUPP;</span>
<span class="p_add">+			put_page(page[0]);</span>
<span class="p_add">+		}</span>
 		up_read(&amp;mm-&gt;mmap_sem);
 	}
 
<span class="p_header">diff --git a/fs/btrfs/sysfs.c b/fs/btrfs/sysfs.c</span>
<span class="p_header">index 883881b16c86..4447e0fe9b55 100644</span>
<span class="p_header">--- a/fs/btrfs/sysfs.c</span>
<span class="p_header">+++ b/fs/btrfs/sysfs.c</span>
<span class="p_chunk">@@ -422,7 +422,7 @@</span> <span class="p_context"> static ssize_t btrfs_nodesize_show(struct kobject *kobj,</span>
 {
 	struct btrfs_fs_info *fs_info = to_fs_info(kobj);
 
<span class="p_del">-	return snprintf(buf, PAGE_SIZE, &quot;%u\n&quot;, fs_info-&gt;super_copy-&gt;nodesize);</span>
<span class="p_add">+	return snprintf(buf, PAGE_SIZE, &quot;%u\n&quot;, fs_info-&gt;nodesize);</span>
 }
 
 BTRFS_ATTR(nodesize, btrfs_nodesize_show);
<span class="p_chunk">@@ -432,8 +432,7 @@</span> <span class="p_context"> static ssize_t btrfs_sectorsize_show(struct kobject *kobj,</span>
 {
 	struct btrfs_fs_info *fs_info = to_fs_info(kobj);
 
<span class="p_del">-	return snprintf(buf, PAGE_SIZE, &quot;%u\n&quot;,</span>
<span class="p_del">-			fs_info-&gt;super_copy-&gt;sectorsize);</span>
<span class="p_add">+	return snprintf(buf, PAGE_SIZE, &quot;%u\n&quot;, fs_info-&gt;sectorsize);</span>
 }
 
 BTRFS_ATTR(sectorsize, btrfs_sectorsize_show);
<span class="p_chunk">@@ -443,8 +442,7 @@</span> <span class="p_context"> static ssize_t btrfs_clone_alignment_show(struct kobject *kobj,</span>
 {
 	struct btrfs_fs_info *fs_info = to_fs_info(kobj);
 
<span class="p_del">-	return snprintf(buf, PAGE_SIZE, &quot;%u\n&quot;,</span>
<span class="p_del">-			fs_info-&gt;super_copy-&gt;sectorsize);</span>
<span class="p_add">+	return snprintf(buf, PAGE_SIZE, &quot;%u\n&quot;, fs_info-&gt;sectorsize);</span>
 }
 
 BTRFS_ATTR(clone_alignment, btrfs_clone_alignment_show);
<span class="p_header">diff --git a/fs/btrfs/transaction.c b/fs/btrfs/transaction.c</span>
<span class="p_header">index f615d59b0489..46bda13e5727 100644</span>
<span class="p_header">--- a/fs/btrfs/transaction.c</span>
<span class="p_header">+++ b/fs/btrfs/transaction.c</span>
<span class="p_chunk">@@ -1722,19 +1722,23 @@</span> <span class="p_context"> static void update_super_roots(struct btrfs_fs_info *fs_info)</span>
 
 	super = fs_info-&gt;super_copy;
 
<span class="p_add">+	/* update latest btrfs_super_block::chunk_root refs */</span>
 	root_item = &amp;fs_info-&gt;chunk_root-&gt;root_item;
<span class="p_del">-	super-&gt;chunk_root = root_item-&gt;bytenr;</span>
<span class="p_del">-	super-&gt;chunk_root_generation = root_item-&gt;generation;</span>
<span class="p_del">-	super-&gt;chunk_root_level = root_item-&gt;level;</span>
<span class="p_add">+	btrfs_set_super_chunk_root(super, root_item-&gt;bytenr);</span>
<span class="p_add">+	btrfs_set_super_chunk_root_generation(super, root_item-&gt;generation);</span>
<span class="p_add">+	btrfs_set_super_chunk_root_level(super, root_item-&gt;level);</span>
 
<span class="p_add">+	/* update latest btrfs_super_block::root refs */</span>
 	root_item = &amp;fs_info-&gt;tree_root-&gt;root_item;
<span class="p_del">-	super-&gt;root = root_item-&gt;bytenr;</span>
<span class="p_del">-	super-&gt;generation = root_item-&gt;generation;</span>
<span class="p_del">-	super-&gt;root_level = root_item-&gt;level;</span>
<span class="p_add">+	btrfs_set_super_root(super, root_item-&gt;bytenr);</span>
<span class="p_add">+	btrfs_set_super_generation(super, root_item-&gt;generation);</span>
<span class="p_add">+	btrfs_set_super_root_level(super, root_item-&gt;level);</span>
<span class="p_add">+</span>
 	if (btrfs_test_opt(fs_info, SPACE_CACHE))
<span class="p_del">-		super-&gt;cache_generation = root_item-&gt;generation;</span>
<span class="p_add">+		btrfs_set_super_cache_generation(super, root_item-&gt;generation);</span>
 	if (test_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &amp;fs_info-&gt;flags))
<span class="p_del">-		super-&gt;uuid_tree_generation = root_item-&gt;generation;</span>
<span class="p_add">+		btrfs_set_super_uuid_tree_generation(super,</span>
<span class="p_add">+						     root_item-&gt;generation);</span>
 }
 
 int btrfs_transaction_in_commit(struct btrfs_fs_info *info)
<span class="p_header">diff --git a/fs/direct-io.c b/fs/direct-io.c</span>
<span class="p_header">index b53e66d9abd7..625a84aa6484 100644</span>
<span class="p_header">--- a/fs/direct-io.c</span>
<span class="p_header">+++ b/fs/direct-io.c</span>
<span class="p_chunk">@@ -1252,8 +1252,7 @@</span> <span class="p_context"> do_blockdev_direct_IO(struct kiocb *iocb, struct inode *inode,</span>
 	 */
 	if (dio-&gt;is_async &amp;&amp; iov_iter_rw(iter) == WRITE) {
 		retval = 0;
<span class="p_del">-		if ((iocb-&gt;ki_filp-&gt;f_flags &amp; O_DSYNC) ||</span>
<span class="p_del">-		    IS_SYNC(iocb-&gt;ki_filp-&gt;f_mapping-&gt;host))</span>
<span class="p_add">+		if (iocb-&gt;ki_flags &amp; IOCB_DSYNC)</span>
 			retval = dio_set_defer_completion(dio);
 		else if (!dio-&gt;inode-&gt;i_sb-&gt;s_dio_done_wq) {
 			/*
<span class="p_header">diff --git a/include/linux/fs.h b/include/linux/fs.h</span>
<span class="p_header">index 440281f8564d..d54f41a63dbf 100644</span>
<span class="p_header">--- a/include/linux/fs.h</span>
<span class="p_header">+++ b/include/linux/fs.h</span>
<span class="p_chunk">@@ -3185,7 +3185,7 @@</span> <span class="p_context"> static inline bool vma_is_fsdax(struct vm_area_struct *vma)</span>
 	if (!vma_is_dax(vma))
 		return false;
 	inode = file_inode(vma-&gt;vm_file);
<span class="p_del">-	if (inode-&gt;i_mode == S_IFCHR)</span>
<span class="p_add">+	if (S_ISCHR(inode-&gt;i_mode))</span>
 		return false; /* device-dax */
 	return true;
 }
<span class="p_header">diff --git a/include/linux/nospec.h b/include/linux/nospec.h</span>
<span class="p_header">index fbc98e2c8228..132e3f5a2e0d 100644</span>
<span class="p_header">--- a/include/linux/nospec.h</span>
<span class="p_header">+++ b/include/linux/nospec.h</span>
<span class="p_chunk">@@ -72,7 +72,6 @@</span> <span class="p_context"> static inline unsigned long array_index_mask_nospec(unsigned long index,</span>
 	BUILD_BUG_ON(sizeof(_i) &gt; sizeof(long));			\
 	BUILD_BUG_ON(sizeof(_s) &gt; sizeof(long));			\
 									\
<span class="p_del">-	_i &amp;= _mask;							\</span>
<span class="p_del">-	_i;								\</span>
<span class="p_add">+	(typeof(_i)) (_i &amp; _mask);					\</span>
 })
 #endif /* _LINUX_NOSPEC_H */
<span class="p_header">diff --git a/include/net/udplite.h b/include/net/udplite.h</span>
<span class="p_header">index 81bdbf97319b..9185e45b997f 100644</span>
<span class="p_header">--- a/include/net/udplite.h</span>
<span class="p_header">+++ b/include/net/udplite.h</span>
<span class="p_chunk">@@ -64,6 +64,7 @@</span> <span class="p_context"> static inline int udplite_checksum_init(struct sk_buff *skb, struct udphdr *uh)</span>
 		UDP_SKB_CB(skb)-&gt;cscov = cscov;
 		if (skb-&gt;ip_summed == CHECKSUM_COMPLETE)
 			skb-&gt;ip_summed = CHECKSUM_NONE;
<span class="p_add">+		skb-&gt;csum_valid = 0;</span>
         }
 
 	return 0;
<span class="p_header">diff --git a/kernel/time/timer.c b/kernel/time/timer.c</span>
<span class="p_header">index db5e6daadd94..9fe525f410bf 100644</span>
<span class="p_header">--- a/kernel/time/timer.c</span>
<span class="p_header">+++ b/kernel/time/timer.c</span>
<span class="p_chunk">@@ -1834,6 +1834,12 @@</span> <span class="p_context"> int timers_dead_cpu(unsigned int cpu)</span>
 		raw_spin_lock_irq(&amp;new_base-&gt;lock);
 		raw_spin_lock_nested(&amp;old_base-&gt;lock, SINGLE_DEPTH_NESTING);
 
<span class="p_add">+		/*</span>
<span class="p_add">+		 * The current CPUs base clock might be stale. Update it</span>
<span class="p_add">+		 * before moving the timers over.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		forward_timer_base(new_base);</span>
<span class="p_add">+</span>
 		BUG_ON(old_base-&gt;running_timer);
 
 		for (i = 0; i &lt; WHEEL_SIZE; i++)
<span class="p_header">diff --git a/net/bridge/br_sysfs_if.c b/net/bridge/br_sysfs_if.c</span>
<span class="p_header">index 5d5d413a6cf8..a097a8613a02 100644</span>
<span class="p_header">--- a/net/bridge/br_sysfs_if.c</span>
<span class="p_header">+++ b/net/bridge/br_sysfs_if.c</span>
<span class="p_chunk">@@ -235,6 +235,9 @@</span> <span class="p_context"> static ssize_t brport_show(struct kobject *kobj,</span>
 	struct brport_attribute *brport_attr = to_brport_attr(attr);
 	struct net_bridge_port *p = to_brport(kobj);
 
<span class="p_add">+	if (!brport_attr-&gt;show)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	return brport_attr-&gt;show(p, buf);
 }
 
<span class="p_header">diff --git a/net/bridge/br_vlan.c b/net/bridge/br_vlan.c</span>
<span class="p_header">index 233a30040c91..9b8a53568b0f 100644</span>
<span class="p_header">--- a/net/bridge/br_vlan.c</span>
<span class="p_header">+++ b/net/bridge/br_vlan.c</span>
<span class="p_chunk">@@ -157,6 +157,8 @@</span> <span class="p_context"> static struct net_bridge_vlan *br_vlan_get_master(struct net_bridge *br, u16 vid</span>
 		masterv = br_vlan_find(vg, vid);
 		if (WARN_ON(!masterv))
 			return NULL;
<span class="p_add">+		refcount_set(&amp;masterv-&gt;refcnt, 1);</span>
<span class="p_add">+		return masterv;</span>
 	}
 	refcount_inc(&amp;masterv-&gt;refcnt);
 
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index d33bbed640b1..c75ef9d8105a 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -2343,8 +2343,11 @@</span> <span class="p_context"> EXPORT_SYMBOL(netdev_set_num_tc);</span>
  */
 int netif_set_real_num_tx_queues(struct net_device *dev, unsigned int txq)
 {
<span class="p_add">+	bool disabling;</span>
 	int rc;
 
<span class="p_add">+	disabling = txq &lt; dev-&gt;real_num_tx_queues;</span>
<span class="p_add">+</span>
 	if (txq &lt; 1 || txq &gt; dev-&gt;num_tx_queues)
 		return -EINVAL;
 
<span class="p_chunk">@@ -2360,15 +2363,19 @@</span> <span class="p_context"> int netif_set_real_num_tx_queues(struct net_device *dev, unsigned int txq)</span>
 		if (dev-&gt;num_tc)
 			netif_setup_tc(dev, txq);
 
<span class="p_del">-		if (txq &lt; dev-&gt;real_num_tx_queues) {</span>
<span class="p_add">+		dev-&gt;real_num_tx_queues = txq;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (disabling) {</span>
<span class="p_add">+			synchronize_net();</span>
 			qdisc_reset_all_tx_gt(dev, txq);
 #ifdef CONFIG_XPS
 			netif_reset_xps_queues_gt(dev, txq);
 #endif
 		}
<span class="p_add">+	} else {</span>
<span class="p_add">+		dev-&gt;real_num_tx_queues = txq;</span>
 	}
 
<span class="p_del">-	dev-&gt;real_num_tx_queues = txq;</span>
 	return 0;
 }
 EXPORT_SYMBOL(netif_set_real_num_tx_queues);
<span class="p_header">diff --git a/net/core/gen_estimator.c b/net/core/gen_estimator.c</span>
<span class="p_header">index 00ecec4891f3..7f980bd7426e 100644</span>
<span class="p_header">--- a/net/core/gen_estimator.c</span>
<span class="p_header">+++ b/net/core/gen_estimator.c</span>
<span class="p_chunk">@@ -66,6 +66,7 @@</span> <span class="p_context"> struct net_rate_estimator {</span>
 static void est_fetch_counters(struct net_rate_estimator *e,
 			       struct gnet_stats_basic_packed *b)
 {
<span class="p_add">+	memset(b, 0, sizeof(*b));</span>
 	if (e-&gt;stats_lock)
 		spin_lock(e-&gt;stats_lock);
 
<span class="p_header">diff --git a/net/ipv4/fib_semantics.c b/net/ipv4/fib_semantics.c</span>
<span class="p_header">index aff3751df950..1ee6c0d8dde4 100644</span>
<span class="p_header">--- a/net/ipv4/fib_semantics.c</span>
<span class="p_header">+++ b/net/ipv4/fib_semantics.c</span>
<span class="p_chunk">@@ -654,6 +654,11 @@</span> <span class="p_context"> int fib_nh_match(struct fib_config *cfg, struct fib_info *fi,</span>
 					    fi-&gt;fib_nh, cfg, extack))
 				return 1;
 		}
<span class="p_add">+#ifdef CONFIG_IP_ROUTE_CLASSID</span>
<span class="p_add">+		if (cfg-&gt;fc_flow &amp;&amp;</span>
<span class="p_add">+		    cfg-&gt;fc_flow != fi-&gt;fib_nh-&gt;nh_tclassid)</span>
<span class="p_add">+			return 1;</span>
<span class="p_add">+#endif</span>
 		if ((!cfg-&gt;fc_oif || cfg-&gt;fc_oif == fi-&gt;fib_nh-&gt;nh_oif) &amp;&amp;
 		    (!cfg-&gt;fc_gw  || cfg-&gt;fc_gw == fi-&gt;fib_nh-&gt;nh_gw))
 			return 0;
<span class="p_header">diff --git a/net/ipv4/route.c b/net/ipv4/route.c</span>
<span class="p_header">index 0ba88efca7ad..9ff06c5051ae 100644</span>
<span class="p_header">--- a/net/ipv4/route.c</span>
<span class="p_header">+++ b/net/ipv4/route.c</span>
<span class="p_chunk">@@ -128,10 +128,13 @@</span> <span class="p_context"> static int ip_rt_redirect_silence __read_mostly	= ((HZ / 50) &lt;&lt; (9 + 1));</span>
 static int ip_rt_error_cost __read_mostly	= HZ;
 static int ip_rt_error_burst __read_mostly	= 5 * HZ;
 static int ip_rt_mtu_expires __read_mostly	= 10 * 60 * HZ;
<span class="p_del">-static int ip_rt_min_pmtu __read_mostly		= 512 + 20 + 20;</span>
<span class="p_add">+static u32 ip_rt_min_pmtu __read_mostly		= 512 + 20 + 20;</span>
 static int ip_rt_min_advmss __read_mostly	= 256;
 
 static int ip_rt_gc_timeout __read_mostly	= RT_GC_TIMEOUT;
<span class="p_add">+</span>
<span class="p_add">+static int ip_min_valid_pmtu __read_mostly	= IPV4_MIN_MTU;</span>
<span class="p_add">+</span>
 /*
  *	Interface to generic destination cache.
  */
<span class="p_chunk">@@ -1829,6 +1832,8 @@</span> <span class="p_context"> int fib_multipath_hash(const struct fib_info *fi, const struct flowi4 *fl4,</span>
 				return skb_get_hash_raw(skb) &gt;&gt; 1;
 			memset(&amp;hash_keys, 0, sizeof(hash_keys));
 			skb_flow_dissect_flow_keys(skb, &amp;keys, flag);
<span class="p_add">+</span>
<span class="p_add">+			hash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;</span>
 			hash_keys.addrs.v4addrs.src = keys.addrs.v4addrs.src;
 			hash_keys.addrs.v4addrs.dst = keys.addrs.v4addrs.dst;
 			hash_keys.ports.src = keys.ports.src;
<span class="p_chunk">@@ -2934,7 +2939,8 @@</span> <span class="p_context"> static struct ctl_table ipv4_route_table[] = {</span>
 		.data		= &amp;ip_rt_min_pmtu,
 		.maxlen		= sizeof(int),
 		.mode		= 0644,
<span class="p_del">-		.proc_handler	= proc_dointvec,</span>
<span class="p_add">+		.proc_handler	= proc_dointvec_minmax,</span>
<span class="p_add">+		.extra1		= &amp;ip_min_valid_pmtu,</span>
 	},
 	{
 		.procname	= &quot;min_adv_mss&quot;,
<span class="p_header">diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="p_header">index d9d215e27b8a..14474acea0bb 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_input.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_input.c</span>
<span class="p_chunk">@@ -2013,11 +2013,6 @@</span> <span class="p_context"> void tcp_enter_loss(struct sock *sk)</span>
 	/* F-RTO RFC5682 sec 3.1 step 1: retransmit SND.UNA if no previous
 	 * loss recovery is underway except recurring timeout(s) on
 	 * the same SND.UNA (sec 3.2). Disable F-RTO on path MTU probing
<span class="p_del">-	 *</span>
<span class="p_del">-	 * In theory F-RTO can be used repeatedly during loss recovery.</span>
<span class="p_del">-	 * In practice this interacts badly with broken middle-boxes that</span>
<span class="p_del">-	 * falsely raise the receive window, which results in repeated</span>
<span class="p_del">-	 * timeouts and stop-and-go behavior.</span>
 	 */
 	tp-&gt;frto = sysctl_tcp_frto &amp;&amp;
 		   (new_recovery || icsk-&gt;icsk_retransmits) &amp;&amp;
<span class="p_chunk">@@ -2699,18 +2694,14 @@</span> <span class="p_context"> static void tcp_process_loss(struct sock *sk, int flag, bool is_dupack,</span>
 	    tcp_try_undo_loss(sk, false))
 		return;
 
<span class="p_del">-	/* The ACK (s)acks some never-retransmitted data meaning not all</span>
<span class="p_del">-	 * the data packets before the timeout were lost. Therefore we</span>
<span class="p_del">-	 * undo the congestion window and state. This is essentially</span>
<span class="p_del">-	 * the operation in F-RTO (RFC5682 section 3.1 step 3.b). Since</span>
<span class="p_del">-	 * a retransmitted skb is permantly marked, we can apply such an</span>
<span class="p_del">-	 * operation even if F-RTO was not used.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if ((flag &amp; FLAG_ORIG_SACK_ACKED) &amp;&amp;</span>
<span class="p_del">-	    tcp_try_undo_loss(sk, tp-&gt;undo_marker))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
 	if (tp-&gt;frto) { /* F-RTO RFC5682 sec 3.1 (sack enhanced version). */
<span class="p_add">+		/* Step 3.b. A timeout is spurious if not all data are</span>
<span class="p_add">+		 * lost, i.e., never-retransmitted data are (s)acked.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if ((flag &amp; FLAG_ORIG_SACK_ACKED) &amp;&amp;</span>
<span class="p_add">+		    tcp_try_undo_loss(sk, true))</span>
<span class="p_add">+			return;</span>
<span class="p_add">+</span>
 		if (after(tp-&gt;snd_nxt, tp-&gt;high_seq)) {
 			if (flag &amp; FLAG_DATA_SACKED || is_dupack)
 				tp-&gt;frto = 0; /* Step 3.a. loss was real */
<span class="p_chunk">@@ -4020,6 +4011,7 @@</span> <span class="p_context"> void tcp_reset(struct sock *sk)</span>
 	/* This barrier is coupled with smp_rmb() in tcp_poll() */
 	smp_wmb();
 
<span class="p_add">+	tcp_write_queue_purge(sk);</span>
 	tcp_done(sk);
 
 	if (!sock_flag(sk, SOCK_DEAD))
<span class="p_header">diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c</span>
<span class="p_header">index cd3d60bb7cc8..83d11cd2eb65 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_output.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_output.c</span>
<span class="p_chunk">@@ -1681,7 +1681,7 @@</span> <span class="p_context"> u32 tcp_tso_autosize(const struct sock *sk, unsigned int mss_now,</span>
 	 */
 	segs = max_t(u32, bytes / mss_now, min_tso_segs);
 
<span class="p_del">-	return min_t(u32, segs, sk-&gt;sk_gso_max_segs);</span>
<span class="p_add">+	return segs;</span>
 }
 EXPORT_SYMBOL(tcp_tso_autosize);
 
<span class="p_chunk">@@ -1693,8 +1693,10 @@</span> <span class="p_context"> static u32 tcp_tso_segs(struct sock *sk, unsigned int mss_now)</span>
 	const struct tcp_congestion_ops *ca_ops = inet_csk(sk)-&gt;icsk_ca_ops;
 	u32 tso_segs = ca_ops-&gt;tso_segs_goal ? ca_ops-&gt;tso_segs_goal(sk) : 0;
 
<span class="p_del">-	return tso_segs ? :</span>
<span class="p_del">-		tcp_tso_autosize(sk, mss_now, sysctl_tcp_min_tso_segs);</span>
<span class="p_add">+	if (!tso_segs)</span>
<span class="p_add">+		tso_segs = tcp_tso_autosize(sk, mss_now,</span>
<span class="p_add">+					    sysctl_tcp_min_tso_segs);</span>
<span class="p_add">+	return min_t(u32, tso_segs, sk-&gt;sk_gso_max_segs);</span>
 }
 
 /* Returns the portion of skb which can be sent right away */
<span class="p_chunk">@@ -1973,6 +1975,24 @@</span> <span class="p_context"> static inline void tcp_mtu_check_reprobe(struct sock *sk)</span>
 	}
 }
 
<span class="p_add">+static bool tcp_can_coalesce_send_queue_head(struct sock *sk, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct sk_buff *skb, *next;</span>
<span class="p_add">+</span>
<span class="p_add">+	skb = tcp_send_head(sk);</span>
<span class="p_add">+	tcp_for_write_queue_from_safe(skb, next, sk) {</span>
<span class="p_add">+		if (len &lt;= skb-&gt;len)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(TCP_SKB_CB(skb)-&gt;eor))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+</span>
<span class="p_add">+		len -= skb-&gt;len;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Create a new MTU probe if we are ready.
  * MTU probe is regularly attempting to increase the path MTU by
  * deliberately sending larger packets.  This discovers routing
<span class="p_chunk">@@ -2045,6 +2065,9 @@</span> <span class="p_context"> static int tcp_mtu_probe(struct sock *sk)</span>
 			return 0;
 	}
 
<span class="p_add">+	if (!tcp_can_coalesce_send_queue_head(sk, probe_size))</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+</span>
 	/* We&#39;re allowed to probe.  Build it now. */
 	nskb = sk_stream_alloc_skb(sk, probe_size, GFP_ATOMIC, false);
 	if (!nskb)
<span class="p_chunk">@@ -2080,6 +2103,10 @@</span> <span class="p_context"> static int tcp_mtu_probe(struct sock *sk)</span>
 			/* We&#39;ve eaten all the data from this skb.
 			 * Throw it away. */
 			TCP_SKB_CB(nskb)-&gt;tcp_flags |= TCP_SKB_CB(skb)-&gt;tcp_flags;
<span class="p_add">+			/* If this is the last SKB we copy and eor is set</span>
<span class="p_add">+			 * we need to propagate it to the new skb.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			TCP_SKB_CB(nskb)-&gt;eor = TCP_SKB_CB(skb)-&gt;eor;</span>
 			tcp_unlink_write_queue(skb, sk);
 			sk_wmem_free_skb(sk, skb);
 		} else {
<span class="p_header">diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c</span>
<span class="p_header">index ebfbccae62fd..c79fa6f6b758 100644</span>
<span class="p_header">--- a/net/ipv4/udp.c</span>
<span class="p_header">+++ b/net/ipv4/udp.c</span>
<span class="p_chunk">@@ -2032,6 +2032,11 @@</span> <span class="p_context"> static inline int udp4_csum_init(struct sk_buff *skb, struct udphdr *uh,</span>
 		err = udplite_checksum_init(skb, uh);
 		if (err)
 			return err;
<span class="p_add">+</span>
<span class="p_add">+		if (UDP_SKB_CB(skb)-&gt;partial_cov) {</span>
<span class="p_add">+			skb-&gt;csum = inet_compute_pseudo(skb, proto);</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+		}</span>
 	}
 
 	/* Note, we are only interested in != 0 or == 0, thus the
<span class="p_header">diff --git a/net/ipv6/ip6_checksum.c b/net/ipv6/ip6_checksum.c</span>
<span class="p_header">index ec43d18b5ff9..547515e8450a 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_checksum.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_checksum.c</span>
<span class="p_chunk">@@ -73,6 +73,11 @@</span> <span class="p_context"> int udp6_csum_init(struct sk_buff *skb, struct udphdr *uh, int proto)</span>
 		err = udplite_checksum_init(skb, uh);
 		if (err)
 			return err;
<span class="p_add">+</span>
<span class="p_add">+		if (UDP_SKB_CB(skb)-&gt;partial_cov) {</span>
<span class="p_add">+			skb-&gt;csum = ip6_compute_pseudo(skb, proto);</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+		}</span>
 	}
 
 	/* To support RFC 6936 (allow zero checksum in UDP/IPV6 for tunnels)
<span class="p_header">diff --git a/net/ipv6/sit.c b/net/ipv6/sit.c</span>
<span class="p_header">index e79854cc5790..cac815cc8600 100644</span>
<span class="p_header">--- a/net/ipv6/sit.c</span>
<span class="p_header">+++ b/net/ipv6/sit.c</span>
<span class="p_chunk">@@ -176,7 +176,7 @@</span> <span class="p_context"> static void ipip6_tunnel_clone_6rd(struct net_device *dev, struct sit_net *sitn)</span>
 #ifdef CONFIG_IPV6_SIT_6RD
 	struct ip_tunnel *t = netdev_priv(dev);
 
<span class="p_del">-	if (t-&gt;dev == sitn-&gt;fb_tunnel_dev) {</span>
<span class="p_add">+	if (dev == sitn-&gt;fb_tunnel_dev) {</span>
 		ipv6_addr_set(&amp;t-&gt;ip6rd.prefix, htonl(0x20020000), 0, 0, 0);
 		t-&gt;ip6rd.relay_prefix = 0;
 		t-&gt;ip6rd.prefixlen = 16;
<span class="p_header">diff --git a/net/netlink/af_netlink.c b/net/netlink/af_netlink.c</span>
<span class="p_header">index 533fd0503ba0..9219bc134109 100644</span>
<span class="p_header">--- a/net/netlink/af_netlink.c</span>
<span class="p_header">+++ b/net/netlink/af_netlink.c</span>
<span class="p_chunk">@@ -2276,7 +2276,7 @@</span> <span class="p_context"> int __netlink_dump_start(struct sock *ssk, struct sk_buff *skb,</span>
 	if (cb-&gt;start) {
 		ret = cb-&gt;start(cb);
 		if (ret)
<span class="p_del">-			goto error_unlock;</span>
<span class="p_add">+			goto error_put;</span>
 	}
 
 	nlk-&gt;cb_running = true;
<span class="p_chunk">@@ -2296,6 +2296,8 @@</span> <span class="p_context"> int __netlink_dump_start(struct sock *ssk, struct sk_buff *skb,</span>
 	 */
 	return -EINTR;
 
<span class="p_add">+error_put:</span>
<span class="p_add">+	module_put(control-&gt;module);</span>
 error_unlock:
 	sock_put(sk);
 	mutex_unlock(nlk-&gt;cb_mutex);
<span class="p_header">diff --git a/net/netlink/genetlink.c b/net/netlink/genetlink.c</span>
<span class="p_header">index d444daf1ac04..6f02499ef007 100644</span>
<span class="p_header">--- a/net/netlink/genetlink.c</span>
<span class="p_header">+++ b/net/netlink/genetlink.c</span>
<span class="p_chunk">@@ -1081,6 +1081,7 @@</span> <span class="p_context"> static int genlmsg_mcast(struct sk_buff *skb, u32 portid, unsigned long group,</span>
 {
 	struct sk_buff *tmp;
 	struct net *net, *prev = NULL;
<span class="p_add">+	bool delivered = false;</span>
 	int err;
 
 	for_each_net_rcu(net) {
<span class="p_chunk">@@ -1092,14 +1093,21 @@</span> <span class="p_context"> static int genlmsg_mcast(struct sk_buff *skb, u32 portid, unsigned long group,</span>
 			}
 			err = nlmsg_multicast(prev-&gt;genl_sock, tmp,
 					      portid, group, flags);
<span class="p_del">-			if (err)</span>
<span class="p_add">+			if (!err)</span>
<span class="p_add">+				delivered = true;</span>
<span class="p_add">+			else if (err != -ESRCH)</span>
 				goto error;
 		}
 
 		prev = net;
 	}
 
<span class="p_del">-	return nlmsg_multicast(prev-&gt;genl_sock, skb, portid, group, flags);</span>
<span class="p_add">+	err = nlmsg_multicast(prev-&gt;genl_sock, skb, portid, group, flags);</span>
<span class="p_add">+	if (!err)</span>
<span class="p_add">+		delivered = true;</span>
<span class="p_add">+	else if (err != -ESRCH)</span>
<span class="p_add">+		goto error;</span>
<span class="p_add">+	return delivered ? 0 : -ESRCH;</span>
  error:
 	kfree_skb(skb);
 	return err;
<span class="p_header">diff --git a/net/rxrpc/output.c b/net/rxrpc/output.c</span>
<span class="p_header">index 71e6f713fbe7..5b67cb5d47f0 100644</span>
<span class="p_header">--- a/net/rxrpc/output.c</span>
<span class="p_header">+++ b/net/rxrpc/output.c</span>
<span class="p_chunk">@@ -395,7 +395,7 @@</span> <span class="p_context"> int rxrpc_send_data_packet(struct rxrpc_call *call, struct sk_buff *skb,</span>
 					(char *)&amp;opt, sizeof(opt));
 		if (ret == 0) {
 			ret = kernel_sendmsg(conn-&gt;params.local-&gt;socket, &amp;msg,
<span class="p_del">-					     iov, 1, iov[0].iov_len);</span>
<span class="p_add">+					     iov, 2, len);</span>
 
 			opt = IPV6_PMTUDISC_DO;
 			kernel_setsockopt(conn-&gt;params.local-&gt;socket,
<span class="p_header">diff --git a/net/sched/cls_api.c b/net/sched/cls_api.c</span>
<span class="p_header">index 934c239cf98d..c2fab4bcb8be 100644</span>
<span class="p_header">--- a/net/sched/cls_api.c</span>
<span class="p_header">+++ b/net/sched/cls_api.c</span>
<span class="p_chunk">@@ -871,13 +871,18 @@</span> <span class="p_context"> static int tc_dump_tfilter(struct sk_buff *skb, struct netlink_callback *cb)</span>
 		if (tca[TCA_CHAIN] &amp;&amp;
 		    nla_get_u32(tca[TCA_CHAIN]) != chain-&gt;index)
 			continue;
<span class="p_del">-		if (!tcf_chain_dump(chain, skb, cb, index_start, &amp;index))</span>
<span class="p_add">+		if (!tcf_chain_dump(chain, skb, cb, index_start, &amp;index)) {</span>
<span class="p_add">+			err = -EMSGSIZE;</span>
 			break;
<span class="p_add">+		}</span>
 	}
 
 	cb-&gt;args[0] = index;
 
 out:
<span class="p_add">+	/* If we did no progress, the error (EMSGSIZE) is real */</span>
<span class="p_add">+	if (skb-&gt;len == 0 &amp;&amp; err)</span>
<span class="p_add">+		return err;</span>
 	return skb-&gt;len;
 }
 
<span class="p_header">diff --git a/net/sched/cls_u32.c b/net/sched/cls_u32.c</span>
<span class="p_header">index b58eccb21f03..ba37d8f57e68 100644</span>
<span class="p_header">--- a/net/sched/cls_u32.c</span>
<span class="p_header">+++ b/net/sched/cls_u32.c</span>
<span class="p_chunk">@@ -398,10 +398,12 @@</span> <span class="p_context"> static int u32_init(struct tcf_proto *tp)</span>
 static int u32_destroy_key(struct tcf_proto *tp, struct tc_u_knode *n,
 			   bool free_pf)
 {
<span class="p_add">+	struct tc_u_hnode *ht = rtnl_dereference(n-&gt;ht_down);</span>
<span class="p_add">+</span>
 	tcf_exts_destroy(&amp;n-&gt;exts);
 	tcf_exts_put_net(&amp;n-&gt;exts);
<span class="p_del">-	if (n-&gt;ht_down)</span>
<span class="p_del">-		n-&gt;ht_down-&gt;refcnt--;</span>
<span class="p_add">+	if (ht &amp;&amp; --ht-&gt;refcnt == 0)</span>
<span class="p_add">+		kfree(ht);</span>
 #ifdef CONFIG_CLS_U32_PERF
 	if (free_pf)
 		free_percpu(n-&gt;pf);
<span class="p_chunk">@@ -649,16 +651,15 @@</span> <span class="p_context"> static void u32_destroy(struct tcf_proto *tp)</span>
 
 		hlist_del(&amp;tp_c-&gt;hnode);
 
<span class="p_del">-		for (ht = rtnl_dereference(tp_c-&gt;hlist);</span>
<span class="p_del">-		     ht;</span>
<span class="p_del">-		     ht = rtnl_dereference(ht-&gt;next)) {</span>
<span class="p_del">-			ht-&gt;refcnt--;</span>
<span class="p_del">-			u32_clear_hnode(tp, ht);</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		while ((ht = rtnl_dereference(tp_c-&gt;hlist)) != NULL) {
<span class="p_add">+			u32_clear_hnode(tp, ht);</span>
 			RCU_INIT_POINTER(tp_c-&gt;hlist, ht-&gt;next);
<span class="p_del">-			kfree_rcu(ht, rcu);</span>
<span class="p_add">+</span>
<span class="p_add">+			/* u32_destroy_key() will later free ht for us, if it&#39;s</span>
<span class="p_add">+			 * still referenced by some knode</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (--ht-&gt;refcnt == 0)</span>
<span class="p_add">+				kfree_rcu(ht, rcu);</span>
 		}
 
 		kfree(tp_c);
<span class="p_chunk">@@ -927,7 +928,8 @@</span> <span class="p_context"> static int u32_change(struct net *net, struct sk_buff *in_skb,</span>
 		if (TC_U32_KEY(n-&gt;handle) == 0)
 			return -EINVAL;
 
<span class="p_del">-		if (n-&gt;flags != flags)</span>
<span class="p_add">+		if ((n-&gt;flags ^ flags) &amp;</span>
<span class="p_add">+		    ~(TCA_CLS_FLAGS_IN_HW | TCA_CLS_FLAGS_NOT_IN_HW))</span>
 			return -EINVAL;
 
 		new = u32_init_knode(tp, n);
<span class="p_header">diff --git a/net/sctp/input.c b/net/sctp/input.c</span>
<span class="p_header">index 141c9c466ec1..0247cc432e02 100644</span>
<span class="p_header">--- a/net/sctp/input.c</span>
<span class="p_header">+++ b/net/sctp/input.c</span>
<span class="p_chunk">@@ -897,15 +897,12 @@</span> <span class="p_context"> int sctp_hash_transport(struct sctp_transport *t)</span>
 	rhl_for_each_entry_rcu(transport, tmp, list, node)
 		if (transport-&gt;asoc-&gt;ep == t-&gt;asoc-&gt;ep) {
 			rcu_read_unlock();
<span class="p_del">-			err = -EEXIST;</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+			return -EEXIST;</span>
 		}
 	rcu_read_unlock();
 
 	err = rhltable_insert_key(&amp;sctp_transport_hashtable, &amp;arg,
 				  &amp;t-&gt;node, sctp_hash_params);
<span class="p_del">-</span>
<span class="p_del">-out:</span>
 	if (err)
 		pr_err_once(&quot;insert transport fail, errno %d\n&quot;, err);
 
<span class="p_header">diff --git a/net/sctp/ipv6.c b/net/sctp/ipv6.c</span>
<span class="p_header">index 3b18085e3b10..f27a9718554c 100644</span>
<span class="p_header">--- a/net/sctp/ipv6.c</span>
<span class="p_header">+++ b/net/sctp/ipv6.c</span>
<span class="p_chunk">@@ -326,8 +326,10 @@</span> <span class="p_context"> static void sctp_v6_get_dst(struct sctp_transport *t, union sctp_addr *saddr,</span>
 		final_p = fl6_update_dst(fl6, rcu_dereference(np-&gt;opt), &amp;final);
 		bdst = ip6_dst_lookup_flow(sk, fl6, final_p);
 
<span class="p_del">-		if (!IS_ERR(bdst) &amp;&amp;</span>
<span class="p_del">-		    ipv6_chk_addr(dev_net(bdst-&gt;dev),</span>
<span class="p_add">+		if (IS_ERR(bdst))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (ipv6_chk_addr(dev_net(bdst-&gt;dev),</span>
 				  &amp;laddr-&gt;a.v6.sin6_addr, bdst-&gt;dev, 1)) {
 			if (!IS_ERR_OR_NULL(dst))
 				dst_release(dst);
<span class="p_chunk">@@ -336,8 +338,10 @@</span> <span class="p_context"> static void sctp_v6_get_dst(struct sctp_transport *t, union sctp_addr *saddr,</span>
 		}
 
 		bmatchlen = sctp_v6_addr_match_len(daddr, &amp;laddr-&gt;a);
<span class="p_del">-		if (matchlen &gt; bmatchlen)</span>
<span class="p_add">+		if (matchlen &gt; bmatchlen) {</span>
<span class="p_add">+			dst_release(bdst);</span>
 			continue;
<span class="p_add">+		}</span>
 
 		if (!IS_ERR_OR_NULL(dst))
 			dst_release(dst);
<span class="p_header">diff --git a/net/sctp/protocol.c b/net/sctp/protocol.c</span>
<span class="p_header">index fcd80feb293f..df22a9c352ad 100644</span>
<span class="p_header">--- a/net/sctp/protocol.c</span>
<span class="p_header">+++ b/net/sctp/protocol.c</span>
<span class="p_chunk">@@ -514,22 +514,20 @@</span> <span class="p_context"> static void sctp_v4_get_dst(struct sctp_transport *t, union sctp_addr *saddr,</span>
 		if (IS_ERR(rt))
 			continue;
 
<span class="p_del">-		if (!dst)</span>
<span class="p_del">-			dst = &amp;rt-&gt;dst;</span>
<span class="p_del">-</span>
 		/* Ensure the src address belongs to the output
 		 * interface.
 		 */
 		odev = __ip_dev_find(sock_net(sk), laddr-&gt;a.v4.sin_addr.s_addr,
 				     false);
 		if (!odev || odev-&gt;ifindex != fl4-&gt;flowi4_oif) {
<span class="p_del">-			if (&amp;rt-&gt;dst != dst)</span>
<span class="p_add">+			if (!dst)</span>
<span class="p_add">+				dst = &amp;rt-&gt;dst;</span>
<span class="p_add">+			else</span>
 				dst_release(&amp;rt-&gt;dst);
 			continue;
 		}
 
<span class="p_del">-		if (dst != &amp;rt-&gt;dst)</span>
<span class="p_del">-			dst_release(dst);</span>
<span class="p_add">+		dst_release(dst);</span>
 		dst = &amp;rt-&gt;dst;
 		break;
 	}
<span class="p_header">diff --git a/net/sctp/sm_make_chunk.c b/net/sctp/sm_make_chunk.c</span>
<span class="p_header">index 514465b03829..e4a400f88168 100644</span>
<span class="p_header">--- a/net/sctp/sm_make_chunk.c</span>
<span class="p_header">+++ b/net/sctp/sm_make_chunk.c</span>
<span class="p_chunk">@@ -1378,9 +1378,14 @@</span> <span class="p_context"> static struct sctp_chunk *_sctp_make_chunk(const struct sctp_association *asoc,</span>
 	struct sctp_chunk *retval;
 	struct sk_buff *skb;
 	struct sock *sk;
<span class="p_add">+	int chunklen;</span>
<span class="p_add">+</span>
<span class="p_add">+	chunklen = SCTP_PAD4(sizeof(*chunk_hdr) + paylen);</span>
<span class="p_add">+	if (chunklen &gt; SCTP_MAX_CHUNK_LEN)</span>
<span class="p_add">+		goto nodata;</span>
 
 	/* No need to allocate LL here, as this is only a chunk. */
<span class="p_del">-	skb = alloc_skb(SCTP_PAD4(sizeof(*chunk_hdr) + paylen), gfp);</span>
<span class="p_add">+	skb = alloc_skb(chunklen, gfp);</span>
 	if (!skb)
 		goto nodata;
 
<span class="p_header">diff --git a/sound/core/control.c b/sound/core/control.c</span>
<span class="p_header">index 56b3e2d49c82..af7e6165e21e 100644</span>
<span class="p_header">--- a/sound/core/control.c</span>
<span class="p_header">+++ b/sound/core/control.c</span>
<span class="p_chunk">@@ -888,7 +888,7 @@</span> <span class="p_context"> static int snd_ctl_elem_read(struct snd_card *card,</span>
 
 	index_offset = snd_ctl_get_ioff(kctl, &amp;control-&gt;id);
 	vd = &amp;kctl-&gt;vd[index_offset];
<span class="p_del">-	if (!(vd-&gt;access &amp; SNDRV_CTL_ELEM_ACCESS_READ) &amp;&amp; kctl-&gt;get == NULL)</span>
<span class="p_add">+	if (!(vd-&gt;access &amp; SNDRV_CTL_ELEM_ACCESS_READ) || kctl-&gt;get == NULL)</span>
 		return -EPERM;
 
 	snd_ctl_build_ioff(&amp;control-&gt;id, kctl, index_offset);
<span class="p_header">diff --git a/sound/pci/hda/hda_intel.c b/sound/pci/hda/hda_intel.c</span>
<span class="p_header">index c71dcacea807..96143df19b21 100644</span>
<span class="p_header">--- a/sound/pci/hda/hda_intel.c</span>
<span class="p_header">+++ b/sound/pci/hda/hda_intel.c</span>
<span class="p_chunk">@@ -181,7 +181,7 @@</span> <span class="p_context"> static const struct kernel_param_ops param_ops_xint = {</span>
 };
 #define param_check_xint param_check_int
 
<span class="p_del">-static int power_save = CONFIG_SND_HDA_POWER_SAVE_DEFAULT;</span>
<span class="p_add">+static int power_save = -1;</span>
 module_param(power_save, xint, 0644);
 MODULE_PARM_DESC(power_save, &quot;Automatic power-saving timeout &quot;
 		 &quot;(in second, 0 = disable).&quot;);
<span class="p_chunk">@@ -2186,6 +2186,24 @@</span> <span class="p_context"> static int azx_probe(struct pci_dev *pci,</span>
 	return err;
 }
 
<span class="p_add">+#ifdef CONFIG_PM</span>
<span class="p_add">+/* On some boards setting power_save to a non 0 value leads to clicking /</span>
<span class="p_add">+ * popping sounds when ever we enter/leave powersaving mode. Ideally we would</span>
<span class="p_add">+ * figure out how to avoid these sounds, but that is not always feasible.</span>
<span class="p_add">+ * So we keep a list of devices where we disable powersaving as its known</span>
<span class="p_add">+ * to causes problems on these devices.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static struct snd_pci_quirk power_save_blacklist[] = {</span>
<span class="p_add">+	/* https://bugzilla.redhat.com/show_bug.cgi?id=1525104 */</span>
<span class="p_add">+	SND_PCI_QUIRK(0x1849, 0x0c0c, &quot;Asrock B85M-ITX&quot;, 0),</span>
<span class="p_add">+	/* https://bugzilla.redhat.com/show_bug.cgi?id=1525104 */</span>
<span class="p_add">+	SND_PCI_QUIRK(0x1043, 0x8733, &quot;Asus Prime X370-Pro&quot;, 0),</span>
<span class="p_add">+	/* https://bugzilla.kernel.org/show_bug.cgi?id=198611 */</span>
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x2227, &quot;Lenovo X1 Carbon 3rd Gen&quot;, 0),</span>
<span class="p_add">+	{}</span>
<span class="p_add">+};</span>
<span class="p_add">+#endif /* CONFIG_PM */</span>
<span class="p_add">+</span>
 /* number of codec slots for each chipset: 0 = default slots (i.e. 4) */
 static unsigned int azx_max_codecs[AZX_NUM_DRIVERS] = {
 	[AZX_DRIVER_NVIDIA] = 8,
<span class="p_chunk">@@ -2198,6 +2216,7 @@</span> <span class="p_context"> static int azx_probe_continue(struct azx *chip)</span>
 	struct hdac_bus *bus = azx_bus(chip);
 	struct pci_dev *pci = chip-&gt;pci;
 	int dev = chip-&gt;dev_index;
<span class="p_add">+	int val;</span>
 	int err;
 
 	hda-&gt;probe_continued = 1;
<span class="p_chunk">@@ -2278,7 +2297,22 @@</span> <span class="p_context"> static int azx_probe_continue(struct azx *chip)</span>
 
 	chip-&gt;running = 1;
 	azx_add_card_list(chip);
<span class="p_del">-	snd_hda_set_power_save(&amp;chip-&gt;bus, power_save * 1000);</span>
<span class="p_add">+</span>
<span class="p_add">+	val = power_save;</span>
<span class="p_add">+#ifdef CONFIG_PM</span>
<span class="p_add">+	if (val == -1) {</span>
<span class="p_add">+		const struct snd_pci_quirk *q;</span>
<span class="p_add">+</span>
<span class="p_add">+		val = CONFIG_SND_HDA_POWER_SAVE_DEFAULT;</span>
<span class="p_add">+		q = snd_pci_quirk_lookup(chip-&gt;pci, power_save_blacklist);</span>
<span class="p_add">+		if (q &amp;&amp; val) {</span>
<span class="p_add">+			dev_info(chip-&gt;card-&gt;dev, &quot;device %04x:%04x is on the power_save blacklist, forcing power_save to 0\n&quot;,</span>
<span class="p_add">+				 q-&gt;subvendor, q-&gt;subdevice);</span>
<span class="p_add">+			val = 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif /* CONFIG_PM */</span>
<span class="p_add">+	snd_hda_set_power_save(&amp;chip-&gt;bus, val * 1000);</span>
 	if (azx_has_pm_runtime(chip) || hda-&gt;use_vga_switcheroo)
 		pm_runtime_put_autosuspend(&amp;pci-&gt;dev);
 
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index b7acffdf16a4..454476b47b79 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -4852,13 +4852,14 @@</span> <span class="p_context"> static void alc_fixup_tpt470_dock(struct hda_codec *codec,</span>
 
 	if (action == HDA_FIXUP_ACT_PRE_PROBE) {
 		spec-&gt;parse_flags = HDA_PINCFG_NO_HP_FIXUP;
<span class="p_add">+		snd_hda_apply_pincfgs(codec, pincfgs);</span>
<span class="p_add">+	} else if (action == HDA_FIXUP_ACT_INIT) {</span>
 		/* Enable DOCK device */
 		snd_hda_codec_write(codec, 0x17, 0,
 			    AC_VERB_SET_CONFIG_DEFAULT_BYTES_3, 0);
 		/* Enable DOCK device */
 		snd_hda_codec_write(codec, 0x19, 0,
 			    AC_VERB_SET_CONFIG_DEFAULT_BYTES_3, 0);
<span class="p_del">-		snd_hda_apply_pincfgs(codec, pincfgs);</span>
 	}
 }
 
<span class="p_header">diff --git a/sound/usb/quirks-table.h b/sound/usb/quirks-table.h</span>
<span class="p_header">index 8a59d4782a0f..69bf5cf1e91e 100644</span>
<span class="p_header">--- a/sound/usb/quirks-table.h</span>
<span class="p_header">+++ b/sound/usb/quirks-table.h</span>
<span class="p_chunk">@@ -3277,4 +3277,51 @@</span> <span class="p_context"> AU0828_DEVICE(0x2040, 0x7270, &quot;Hauppauge&quot;, &quot;HVR-950Q&quot;),</span>
 	}
 },
 
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Bower&#39;s &amp; Wilkins PX headphones only support the 48 kHz sample rate</span>
<span class="p_add">+	 * even though it advertises more. The capture interface doesn&#39;t work</span>
<span class="p_add">+	 * even on windows.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	USB_DEVICE(0x19b5, 0x0021),</span>
<span class="p_add">+	.driver_info = (unsigned long) &amp;(const struct snd_usb_audio_quirk) {</span>
<span class="p_add">+		.ifnum = QUIRK_ANY_INTERFACE,</span>
<span class="p_add">+		.type = QUIRK_COMPOSITE,</span>
<span class="p_add">+		.data = (const struct snd_usb_audio_quirk[]) {</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 0,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_MIXER,</span>
<span class="p_add">+			},</span>
<span class="p_add">+			/* Capture */</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 1,</span>
<span class="p_add">+				.type = QUIRK_IGNORE_INTERFACE,</span>
<span class="p_add">+			},</span>
<span class="p_add">+			/* Playback */</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 2,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_FIXED_ENDPOINT,</span>
<span class="p_add">+				.data = &amp;(const struct audioformat) {</span>
<span class="p_add">+					.formats = SNDRV_PCM_FMTBIT_S16_LE,</span>
<span class="p_add">+					.channels = 2,</span>
<span class="p_add">+					.iface = 2,</span>
<span class="p_add">+					.altsetting = 1,</span>
<span class="p_add">+					.altset_idx = 1,</span>
<span class="p_add">+					.attributes = UAC_EP_CS_ATTR_FILL_MAX |</span>
<span class="p_add">+						UAC_EP_CS_ATTR_SAMPLE_RATE,</span>
<span class="p_add">+					.endpoint = 0x03,</span>
<span class="p_add">+					.ep_attr = USB_ENDPOINT_XFER_ISOC,</span>
<span class="p_add">+					.rates = SNDRV_PCM_RATE_48000,</span>
<span class="p_add">+					.rate_min = 48000,</span>
<span class="p_add">+					.rate_max = 48000,</span>
<span class="p_add">+					.nr_rates = 1,</span>
<span class="p_add">+					.rate_table = (unsigned int[]) {</span>
<span class="p_add">+						48000</span>
<span class="p_add">+					}</span>
<span class="p_add">+				}</span>
<span class="p_add">+			},</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+},</span>
<span class="p_add">+</span>
 #undef USB_DEVICE_VENDOR_SPEC
<span class="p_header">diff --git a/sound/x86/intel_hdmi_audio.c b/sound/x86/intel_hdmi_audio.c</span>
<span class="p_header">index a0951505c7f5..697872d8308e 100644</span>
<span class="p_header">--- a/sound/x86/intel_hdmi_audio.c</span>
<span class="p_header">+++ b/sound/x86/intel_hdmi_audio.c</span>
<span class="p_chunk">@@ -1827,6 +1827,8 @@</span> <span class="p_context"> static int hdmi_lpe_audio_probe(struct platform_device *pdev)</span>
 		ctx-&gt;port = port;
 		ctx-&gt;pipe = -1;
 
<span class="p_add">+		spin_lock_init(&amp;ctx-&gt;had_spinlock);</span>
<span class="p_add">+		mutex_init(&amp;ctx-&gt;mutex);</span>
 		INIT_WORK(&amp;ctx-&gt;hdmi_audio_wq, had_audio_wq);
 
 		ret = snd_pcm_new(card, INTEL_HAD, port, MAX_PB_STREAMS,
<span class="p_header">diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c</span>
<span class="p_header">index 8401774f5aeb..d81af263f50b 100644</span>
<span class="p_header">--- a/virt/kvm/kvm_main.c</span>
<span class="p_header">+++ b/virt/kvm/kvm_main.c</span>
<span class="p_chunk">@@ -975,8 +975,7 @@</span> <span class="p_context"> int __kvm_set_memory_region(struct kvm *kvm,</span>
 		/* Check for overlaps */
 		r = -EEXIST;
 		kvm_for_each_memslot(slot, __kvm_memslots(kvm, as_id)) {
<span class="p_del">-			if ((slot-&gt;id &gt;= KVM_USER_MEM_SLOTS) ||</span>
<span class="p_del">-			    (slot-&gt;id == id))</span>
<span class="p_add">+			if (slot-&gt;id == id)</span>
 				continue;
 			if (!((base_gfn + npages &lt;= slot-&gt;base_gfn) ||
 			      (base_gfn &gt;= slot-&gt;base_gfn + slot-&gt;npages)))

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



