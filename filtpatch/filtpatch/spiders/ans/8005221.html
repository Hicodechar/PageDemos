
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[GIT,PULL] x86/cleanups changes for v4.5 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [GIT,PULL] x86/cleanups changes for v4.5</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 11, 2016, 2:56 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160111145640.GA25396@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8005221/mbox/"
   >mbox</a>
|
   <a href="/patch/8005221/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8005221/">/patch/8005221/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id D048DBEEE5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 11 Jan 2016 14:56:58 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 0803B201FE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 11 Jan 2016 14:56:56 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id DCB9A20117
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 11 Jan 2016 14:56:52 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1760260AbcAKO4t (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 11 Jan 2016 09:56:49 -0500
Received: from mail-wm0-f66.google.com ([74.125.82.66]:35183 &quot;EHLO
	mail-wm0-f66.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S932701AbcAKO4p (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 11 Jan 2016 09:56:45 -0500
Received: by mail-wm0-f66.google.com with SMTP id f206so26649020wmf.2
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 11 Jan 2016 06:56:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20120113;
	h=sender:date:from:to:cc:subject:message-id:mime-version:content-type
	:content-disposition:user-agent;
	bh=wXvtFQ91dij2KROS6DRe43IjsBAXYdOmf6ltYvtS6Qk=;
	b=zz0aZObf0ekBry2x67ccE6NmFiw560olyiUCrd7DP5/gUyHb/okAK4uvZcVUUA+UHJ
	Icv1f6I6CsSKrJir4RA/Nlb8O63haiaRpLwjZm9Dy6lD7v3gGqstbgZzKdFrGo8FKWz1
	1O3nXw8uHHKqsgYKIxZtV9tGrwXOavA9OPhJw/Yk61IWnayQvyrqyUU/tYEq7VMjt3yo
	mU2vYK0dQkr0pOVITg5YwAtzrz/7yFTvPbG3Vh1aR/wjA8Fc5aezP2c2GA9ipZnyHR+n
	lTLXod5i6LnML33XH/Ajz+NTBBfjKNx58PRPIhW1WlXre4/MoC5f69BBP/uvqLiWWfWd
	zipQ==
X-Received: by 10.28.230.74 with SMTP id d71mr13438667wmh.97.1452524203647; 
	Mon, 11 Jan 2016 06:56:43 -0800 (PST)
Received: from gmail.com (54033495.catv.pool.telekom.hu. [84.3.52.149])
	by smtp.gmail.com with ESMTPSA id
	qs1sm59450080wjc.2.2016.01.11.06.56.42
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Mon, 11 Jan 2016 06:56:42 -0800 (PST)
Date: Mon, 11 Jan 2016 15:56:40 +0100
From: Ingo Molnar &lt;mingo@kernel.org&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: linux-kernel@vger.kernel.org, Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Peter Zijlstra &lt;a.p.zijlstra@chello.nl&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;
Subject: [GIT PULL] x86/cleanups changes for v4.5
Message-ID: &lt;20160111145640.GA25396@gmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: Mutt/1.5.23 (2014-03-12)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.8 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,RP_MATCHES_RCVD,T_DKIM_INVALID,UNPARSEABLE_RELAY
	autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a> - Jan. 11, 2016, 2:56 p.m.</div>
<pre class="content">
Linus,

Please pull the latest x86-cleanups-for-linus git tree from:

   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86-cleanups-for-linus

   # HEAD: 0105c8d8334fc941e0297ca6708fa57854114c0e arch/x86/kernel/ptrace.c: Remove unused arg_offs_table

The main changes in this cycle were:

 - code patching and cpu_has cleanups (Borislav Petkov)

 - paravirt cleanups (Juergen Gross)

 - TSC cleanup (Thomas Gleixner)

 - ptrace cleanup (Chen Gang)

  out-of-topic modifications in x86-cleanups-for-linus:
  -------------------------------------------------------
  drivers/char/hw_random/via-rng.c   # 362f924b64ba: x86/cpufeature: Remove unuse
  drivers/crypto/padlock-aes.c       # 362f924b64ba: x86/cpufeature: Remove unuse
  drivers/crypto/padlock-sha.c       # 362f924b64ba: x86/cpufeature: Remove unuse
  drivers/iommu/intel_irq_remapping.c# 362f924b64ba: x86/cpufeature: Remove unuse
  fs/btrfs/disk-io.c                 # 362f924b64ba: x86/cpufeature: Remove unuse

 Thanks,

	Ingo

------------------&gt;
Borislav Petkov (6):
      x86/paravirt: Kill some unused patching functions
      x86/cpufeature: Move some of the scattered feature bits to x86_capability
      x86/cpufeature: Cleanup get_cpu_cap()
      x86/cpufeature: Remove unused and seldomly used cpu_has_xx macros
      x86/cpu: Provide a config option to disable static_cpu_has
      x86/mm: Align macro defines

Juergen Gross (3):
      x86: Remove unused function cpu_has_ht_siblings()
      x86/paravirt: Remove unused pv_apic_ops structure
      x86/paravirt: Remove paravirt ops pmd_update[_defer] and pte_update_defer

Thomas Gleixner (1):
      x86/tsc: Remove unused tsc_pre_init() hook

chengang@emindsoft.com.cn (1):
      arch/x86/kernel/ptrace.c: Remove unused arg_offs_table


 arch/x86/Kconfig                            |  11 +++
 arch/x86/crypto/chacha20_glue.c             |   2 +-
 arch/x86/crypto/crc32c-intel_glue.c         |   2 +-
 arch/x86/include/asm/cmpxchg_32.h           |   2 +-
 arch/x86/include/asm/cmpxchg_64.h           |   2 +-
 arch/x86/include/asm/cpufeature.h           | 115 ++++++++++++++--------------
 arch/x86/include/asm/page_types.h           |   6 +-
 arch/x86/include/asm/paravirt.h             |  26 -------
 arch/x86/include/asm/paravirt_types.h       |  18 -----
 arch/x86/include/asm/pgtable.h              |  15 +---
 arch/x86/include/asm/smp.h                  |  12 ---
 arch/x86/include/asm/x86_init.h             |   2 -
 arch/x86/include/asm/xor_32.h               |   2 +-
 arch/x86/kernel/cpu/amd.c                   |   4 +-
 arch/x86/kernel/cpu/centaur.c               |   2 +-
 arch/x86/kernel/cpu/common.c                |  52 +++++++------
 arch/x86/kernel/cpu/intel.c                 |   3 +-
 arch/x86/kernel/cpu/intel_cacheinfo.c       |   6 +-
 arch/x86/kernel/cpu/mtrr/generic.c          |   2 +-
 arch/x86/kernel/cpu/mtrr/main.c             |   2 +-
 arch/x86/kernel/cpu/perf_event_amd.c        |   4 +-
 arch/x86/kernel/cpu/perf_event_amd_uncore.c |  11 +--
 arch/x86/kernel/cpu/scattered.c             |  20 -----
 arch/x86/kernel/cpu/transmeta.c             |   4 +-
 arch/x86/kernel/fpu/init.c                  |   4 +-
 arch/x86/kernel/hw_breakpoint.c             |   6 +-
 arch/x86/kernel/paravirt.c                  |  24 +-----
 arch/x86/kernel/ptrace.c                    |  15 ----
 arch/x86/kernel/smpboot.c                   |   9 +--
 arch/x86/kernel/tsc.c                       |   2 -
 arch/x86/kernel/vm86_32.c                   |   4 +-
 arch/x86/kernel/x86_init.c                  |   1 -
 arch/x86/lguest/boot.c                      |   1 -
 arch/x86/mm/pgtable.c                       |   7 +-
 arch/x86/mm/setup_nx.c                      |   4 +-
 arch/x86/xen/enlighten.c                    |   7 --
 arch/x86/xen/mmu.c                          |   1 -
 drivers/char/hw_random/via-rng.c            |   5 +-
 drivers/crypto/padlock-aes.c                |   2 +-
 drivers/crypto/padlock-sha.c                |   2 +-
 drivers/iommu/intel_irq_remapping.c         |   2 +-
 fs/btrfs/disk-io.c                          |   2 +-
 42 files changed, 148 insertions(+), 275 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index db3622f22b61..a2abc2fb6970 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -349,6 +349,17 @@</span> <span class="p_context"> config X86_FEATURE_NAMES</span>
 
 	  If in doubt, say Y.
 
<span class="p_add">+config X86_FAST_FEATURE_TESTS</span>
<span class="p_add">+	bool &quot;Fast CPU feature tests&quot; if EMBEDDED</span>
<span class="p_add">+	default y</span>
<span class="p_add">+	---help---</span>
<span class="p_add">+	  Some fast-paths in the kernel depend on the capabilities of the CPU.</span>
<span class="p_add">+	  Say Y here for the kernel to patch in the appropriate code at runtime</span>
<span class="p_add">+	  based on the capabilities of the CPU. The infrastructure for patching</span>
<span class="p_add">+	  code at runtime takes up some additional space; space-constrained</span>
<span class="p_add">+	  embedded systems may wish to say N here to produce smaller, slightly</span>
<span class="p_add">+	  slower code.</span>
<span class="p_add">+</span>
 config X86_X2APIC
 	bool &quot;Support x2apic&quot;
 	depends on X86_LOCAL_APIC &amp;&amp; X86_64 &amp;&amp; (IRQ_REMAP || HYPERVISOR_GUEST)
<span class="p_header">diff --git a/arch/x86/crypto/chacha20_glue.c b/arch/x86/crypto/chacha20_glue.c</span>
<span class="p_header">index 722bacea040e..8baaff5af0b5 100644</span>
<span class="p_header">--- a/arch/x86/crypto/chacha20_glue.c</span>
<span class="p_header">+++ b/arch/x86/crypto/chacha20_glue.c</span>
<span class="p_chunk">@@ -125,7 +125,7 @@</span> <span class="p_context"> static struct crypto_alg alg = {</span>
 
 static int __init chacha20_simd_mod_init(void)
 {
<span class="p_del">-	if (!cpu_has_ssse3)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_SSSE3))</span>
 		return -ENODEV;
 
 #ifdef CONFIG_AS_AVX2
<span class="p_header">diff --git a/arch/x86/crypto/crc32c-intel_glue.c b/arch/x86/crypto/crc32c-intel_glue.c</span>
<span class="p_header">index 81a595d75cf5..0e9871693f24 100644</span>
<span class="p_header">--- a/arch/x86/crypto/crc32c-intel_glue.c</span>
<span class="p_header">+++ b/arch/x86/crypto/crc32c-intel_glue.c</span>
<span class="p_chunk">@@ -257,7 +257,7 @@</span> <span class="p_context"> static int __init crc32c_intel_mod_init(void)</span>
 	if (!x86_match_cpu(crc32c_cpu_id))
 		return -ENODEV;
 #ifdef CONFIG_X86_64
<span class="p_del">-	if (cpu_has_pclmulqdq) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PCLMULQDQ)) {</span>
 		alg.update = crc32c_pcl_intel_update;
 		alg.finup = crc32c_pcl_intel_finup;
 		alg.digest = crc32c_pcl_intel_digest;
<span class="p_header">diff --git a/arch/x86/include/asm/cmpxchg_32.h b/arch/x86/include/asm/cmpxchg_32.h</span>
<span class="p_header">index f7e142926481..e4959d023af8 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cmpxchg_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cmpxchg_32.h</span>
<span class="p_chunk">@@ -109,6 +109,6 @@</span> <span class="p_context"> static inline u64 __cmpxchg64_local(volatile u64 *ptr, u64 old, u64 new)</span>
 
 #endif
 
<span class="p_del">-#define system_has_cmpxchg_double() cpu_has_cx8</span>
<span class="p_add">+#define system_has_cmpxchg_double() boot_cpu_has(X86_FEATURE_CX8)</span>
 
 #endif /* _ASM_X86_CMPXCHG_32_H */
<span class="p_header">diff --git a/arch/x86/include/asm/cmpxchg_64.h b/arch/x86/include/asm/cmpxchg_64.h</span>
<span class="p_header">index 1af94697aae5..caa23a34c963 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cmpxchg_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cmpxchg_64.h</span>
<span class="p_chunk">@@ -18,6 +18,6 @@</span> <span class="p_context"> static inline void set_64bit(volatile u64 *ptr, u64 val)</span>
 	cmpxchg_local((ptr), (o), (n));					\
 })
 
<span class="p_del">-#define system_has_cmpxchg_double() cpu_has_cx16</span>
<span class="p_add">+#define system_has_cmpxchg_double() boot_cpu_has(X86_FEATURE_CX16)</span>
 
 #endif /* _ASM_X86_CMPXCHG_64_H */
<span class="p_header">diff --git a/arch/x86/include/asm/cpufeature.h b/arch/x86/include/asm/cpufeature.h</span>
<span class="p_header">index e4f8010f22e0..43e144474043 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cpufeature.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cpufeature.h</span>
<span class="p_chunk">@@ -12,7 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/disabled-features.h&gt;
 #endif
 
<span class="p_del">-#define NCAPINTS	14	/* N 32-bit words worth of info */</span>
<span class="p_add">+#define NCAPINTS	16	/* N 32-bit words worth of info */</span>
 #define NBUGINTS	1	/* N 32-bit bug flags */
 
 /*
<span class="p_chunk">@@ -181,22 +181,17 @@</span> <span class="p_context"></span>
 
 /*
  * Auxiliary flags: Linux defined - For features scattered in various
<span class="p_del">- * CPUID levels like 0x6, 0xA etc, word 7</span>
<span class="p_add">+ * CPUID levels like 0x6, 0xA etc, word 7.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Reuse free bits when adding new feature flags!</span>
  */
<span class="p_del">-#define X86_FEATURE_IDA		( 7*32+ 0) /* Intel Dynamic Acceleration */</span>
<span class="p_del">-#define X86_FEATURE_ARAT	( 7*32+ 1) /* Always Running APIC Timer */</span>
<span class="p_add">+</span>
 #define X86_FEATURE_CPB		( 7*32+ 2) /* AMD Core Performance Boost */
 #define X86_FEATURE_EPB		( 7*32+ 3) /* IA32_ENERGY_PERF_BIAS support */
<span class="p_del">-#define X86_FEATURE_PLN		( 7*32+ 5) /* Intel Power Limit Notification */</span>
<span class="p_del">-#define X86_FEATURE_PTS		( 7*32+ 6) /* Intel Package Thermal Status */</span>
<span class="p_del">-#define X86_FEATURE_DTHERM	( 7*32+ 7) /* Digital Thermal Sensor */</span>
<span class="p_add">+</span>
 #define X86_FEATURE_HW_PSTATE	( 7*32+ 8) /* AMD HW-PState */
 #define X86_FEATURE_PROC_FEEDBACK ( 7*32+ 9) /* AMD ProcFeedbackInterface */
<span class="p_del">-#define X86_FEATURE_HWP		( 7*32+ 10) /* &quot;hwp&quot; Intel HWP */</span>
<span class="p_del">-#define X86_FEATURE_HWP_NOTIFY	( 7*32+ 11) /* Intel HWP_NOTIFY */</span>
<span class="p_del">-#define X86_FEATURE_HWP_ACT_WINDOW ( 7*32+ 12) /* Intel HWP_ACT_WINDOW */</span>
<span class="p_del">-#define X86_FEATURE_HWP_EPP	( 7*32+13) /* Intel HWP_EPP */</span>
<span class="p_del">-#define X86_FEATURE_HWP_PKG_REQ ( 7*32+14) /* Intel HWP_PKG_REQ */</span>
<span class="p_add">+</span>
 #define X86_FEATURE_INTEL_PT	( 7*32+15) /* Intel Processor Trace */
 
 /* Virtualization flags: Linux defined, word 8 */
<span class="p_chunk">@@ -205,16 +200,7 @@</span> <span class="p_context"></span>
 #define X86_FEATURE_FLEXPRIORITY ( 8*32+ 2) /* Intel FlexPriority */
 #define X86_FEATURE_EPT         ( 8*32+ 3) /* Intel Extended Page Table */
 #define X86_FEATURE_VPID        ( 8*32+ 4) /* Intel Virtual Processor ID */
<span class="p_del">-#define X86_FEATURE_NPT		( 8*32+ 5) /* AMD Nested Page Table support */</span>
<span class="p_del">-#define X86_FEATURE_LBRV	( 8*32+ 6) /* AMD LBR Virtualization support */</span>
<span class="p_del">-#define X86_FEATURE_SVML	( 8*32+ 7) /* &quot;svm_lock&quot; AMD SVM locking MSR */</span>
<span class="p_del">-#define X86_FEATURE_NRIPS	( 8*32+ 8) /* &quot;nrip_save&quot; AMD SVM next_rip save */</span>
<span class="p_del">-#define X86_FEATURE_TSCRATEMSR  ( 8*32+ 9) /* &quot;tsc_scale&quot; AMD TSC scaling support */</span>
<span class="p_del">-#define X86_FEATURE_VMCBCLEAN   ( 8*32+10) /* &quot;vmcb_clean&quot; AMD VMCB clean bits support */</span>
<span class="p_del">-#define X86_FEATURE_FLUSHBYASID ( 8*32+11) /* AMD flush-by-ASID support */</span>
<span class="p_del">-#define X86_FEATURE_DECODEASSISTS ( 8*32+12) /* AMD Decode Assists support */</span>
<span class="p_del">-#define X86_FEATURE_PAUSEFILTER ( 8*32+13) /* AMD filtered pause intercept */</span>
<span class="p_del">-#define X86_FEATURE_PFTHRESHOLD ( 8*32+14) /* AMD pause filter threshold */</span>
<span class="p_add">+</span>
 #define X86_FEATURE_VMMCALL     ( 8*32+15) /* Prefer vmmcall to vmcall */
 
 
<span class="p_chunk">@@ -258,6 +244,30 @@</span> <span class="p_context"></span>
 /* AMD-defined CPU features, CPUID level 0x80000008 (ebx), word 13 */
 #define X86_FEATURE_CLZERO	(13*32+0) /* CLZERO instruction */
 
<span class="p_add">+/* Thermal and Power Management Leaf, CPUID level 0x00000006 (eax), word 14 */</span>
<span class="p_add">+#define X86_FEATURE_DTHERM	(14*32+ 0) /* Digital Thermal Sensor */</span>
<span class="p_add">+#define X86_FEATURE_IDA		(14*32+ 1) /* Intel Dynamic Acceleration */</span>
<span class="p_add">+#define X86_FEATURE_ARAT	(14*32+ 2) /* Always Running APIC Timer */</span>
<span class="p_add">+#define X86_FEATURE_PLN		(14*32+ 4) /* Intel Power Limit Notification */</span>
<span class="p_add">+#define X86_FEATURE_PTS		(14*32+ 6) /* Intel Package Thermal Status */</span>
<span class="p_add">+#define X86_FEATURE_HWP		(14*32+ 7) /* Intel Hardware P-states */</span>
<span class="p_add">+#define X86_FEATURE_HWP_NOTIFY	(14*32+ 8) /* HWP Notification */</span>
<span class="p_add">+#define X86_FEATURE_HWP_ACT_WINDOW (14*32+ 9) /* HWP Activity Window */</span>
<span class="p_add">+#define X86_FEATURE_HWP_EPP	(14*32+10) /* HWP Energy Perf. Preference */</span>
<span class="p_add">+#define X86_FEATURE_HWP_PKG_REQ (14*32+11) /* HWP Package Level Request */</span>
<span class="p_add">+</span>
<span class="p_add">+/* AMD SVM Feature Identification, CPUID level 0x8000000a (edx), word 15 */</span>
<span class="p_add">+#define X86_FEATURE_NPT		(15*32+ 0) /* Nested Page Table support */</span>
<span class="p_add">+#define X86_FEATURE_LBRV	(15*32+ 1) /* LBR Virtualization support */</span>
<span class="p_add">+#define X86_FEATURE_SVML	(15*32+ 2) /* &quot;svm_lock&quot; SVM locking MSR */</span>
<span class="p_add">+#define X86_FEATURE_NRIPS	(15*32+ 3) /* &quot;nrip_save&quot; SVM next_rip save */</span>
<span class="p_add">+#define X86_FEATURE_TSCRATEMSR  (15*32+ 4) /* &quot;tsc_scale&quot; TSC scaling support */</span>
<span class="p_add">+#define X86_FEATURE_VMCBCLEAN   (15*32+ 5) /* &quot;vmcb_clean&quot; VMCB clean bits support */</span>
<span class="p_add">+#define X86_FEATURE_FLUSHBYASID (15*32+ 6) /* flush-by-ASID support */</span>
<span class="p_add">+#define X86_FEATURE_DECODEASSISTS (15*32+ 7) /* Decode Assists support */</span>
<span class="p_add">+#define X86_FEATURE_PAUSEFILTER (15*32+10) /* filtered pause intercept */</span>
<span class="p_add">+#define X86_FEATURE_PFTHRESHOLD (15*32+12) /* pause filter threshold */</span>
<span class="p_add">+</span>
 /*
  * BUG word(s)
  */
<span class="p_chunk">@@ -278,6 +288,26 @@</span> <span class="p_context"></span>
 #include &lt;asm/asm.h&gt;
 #include &lt;linux/bitops.h&gt;
 
<span class="p_add">+enum cpuid_leafs</span>
<span class="p_add">+{</span>
<span class="p_add">+	CPUID_1_EDX		= 0,</span>
<span class="p_add">+	CPUID_8000_0001_EDX,</span>
<span class="p_add">+	CPUID_8086_0001_EDX,</span>
<span class="p_add">+	CPUID_LNX_1,</span>
<span class="p_add">+	CPUID_1_ECX,</span>
<span class="p_add">+	CPUID_C000_0001_EDX,</span>
<span class="p_add">+	CPUID_8000_0001_ECX,</span>
<span class="p_add">+	CPUID_LNX_2,</span>
<span class="p_add">+	CPUID_LNX_3,</span>
<span class="p_add">+	CPUID_7_0_EBX,</span>
<span class="p_add">+	CPUID_D_1_EAX,</span>
<span class="p_add">+	CPUID_F_0_EDX,</span>
<span class="p_add">+	CPUID_F_1_EDX,</span>
<span class="p_add">+	CPUID_8000_0008_EBX,</span>
<span class="p_add">+	CPUID_6_EAX,</span>
<span class="p_add">+	CPUID_8000_000A_EDX,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 #ifdef CONFIG_X86_FEATURE_NAMES
 extern const char * const x86_cap_flags[NCAPINTS*32];
 extern const char * const x86_power_flags[32];
<span class="p_chunk">@@ -355,60 +385,31 @@</span> <span class="p_context"> extern const char * const x86_bug_flags[NBUGINTS*32];</span>
 } while (0)
 
 #define cpu_has_fpu		boot_cpu_has(X86_FEATURE_FPU)
<span class="p_del">-#define cpu_has_de		boot_cpu_has(X86_FEATURE_DE)</span>
 #define cpu_has_pse		boot_cpu_has(X86_FEATURE_PSE)
 #define cpu_has_tsc		boot_cpu_has(X86_FEATURE_TSC)
 #define cpu_has_pge		boot_cpu_has(X86_FEATURE_PGE)
 #define cpu_has_apic		boot_cpu_has(X86_FEATURE_APIC)
<span class="p_del">-#define cpu_has_sep		boot_cpu_has(X86_FEATURE_SEP)</span>
<span class="p_del">-#define cpu_has_mtrr		boot_cpu_has(X86_FEATURE_MTRR)</span>
<span class="p_del">-#define cpu_has_mmx		boot_cpu_has(X86_FEATURE_MMX)</span>
 #define cpu_has_fxsr		boot_cpu_has(X86_FEATURE_FXSR)
 #define cpu_has_xmm		boot_cpu_has(X86_FEATURE_XMM)
 #define cpu_has_xmm2		boot_cpu_has(X86_FEATURE_XMM2)
<span class="p_del">-#define cpu_has_xmm3		boot_cpu_has(X86_FEATURE_XMM3)</span>
<span class="p_del">-#define cpu_has_ssse3		boot_cpu_has(X86_FEATURE_SSSE3)</span>
 #define cpu_has_aes		boot_cpu_has(X86_FEATURE_AES)
 #define cpu_has_avx		boot_cpu_has(X86_FEATURE_AVX)
 #define cpu_has_avx2		boot_cpu_has(X86_FEATURE_AVX2)
<span class="p_del">-#define cpu_has_ht		boot_cpu_has(X86_FEATURE_HT)</span>
<span class="p_del">-#define cpu_has_nx		boot_cpu_has(X86_FEATURE_NX)</span>
<span class="p_del">-#define cpu_has_xstore		boot_cpu_has(X86_FEATURE_XSTORE)</span>
<span class="p_del">-#define cpu_has_xstore_enabled	boot_cpu_has(X86_FEATURE_XSTORE_EN)</span>
<span class="p_del">-#define cpu_has_xcrypt		boot_cpu_has(X86_FEATURE_XCRYPT)</span>
<span class="p_del">-#define cpu_has_xcrypt_enabled	boot_cpu_has(X86_FEATURE_XCRYPT_EN)</span>
<span class="p_del">-#define cpu_has_ace2		boot_cpu_has(X86_FEATURE_ACE2)</span>
<span class="p_del">-#define cpu_has_ace2_enabled	boot_cpu_has(X86_FEATURE_ACE2_EN)</span>
<span class="p_del">-#define cpu_has_phe		boot_cpu_has(X86_FEATURE_PHE)</span>
<span class="p_del">-#define cpu_has_phe_enabled	boot_cpu_has(X86_FEATURE_PHE_EN)</span>
<span class="p_del">-#define cpu_has_pmm		boot_cpu_has(X86_FEATURE_PMM)</span>
<span class="p_del">-#define cpu_has_pmm_enabled	boot_cpu_has(X86_FEATURE_PMM_EN)</span>
<span class="p_del">-#define cpu_has_ds		boot_cpu_has(X86_FEATURE_DS)</span>
<span class="p_del">-#define cpu_has_pebs		boot_cpu_has(X86_FEATURE_PEBS)</span>
 #define cpu_has_clflush		boot_cpu_has(X86_FEATURE_CLFLUSH)
<span class="p_del">-#define cpu_has_bts		boot_cpu_has(X86_FEATURE_BTS)</span>
 #define cpu_has_gbpages		boot_cpu_has(X86_FEATURE_GBPAGES)
 #define cpu_has_arch_perfmon	boot_cpu_has(X86_FEATURE_ARCH_PERFMON)
 #define cpu_has_pat		boot_cpu_has(X86_FEATURE_PAT)
<span class="p_del">-#define cpu_has_xmm4_1		boot_cpu_has(X86_FEATURE_XMM4_1)</span>
<span class="p_del">-#define cpu_has_xmm4_2		boot_cpu_has(X86_FEATURE_XMM4_2)</span>
 #define cpu_has_x2apic		boot_cpu_has(X86_FEATURE_X2APIC)
 #define cpu_has_xsave		boot_cpu_has(X86_FEATURE_XSAVE)
<span class="p_del">-#define cpu_has_xsaveopt	boot_cpu_has(X86_FEATURE_XSAVEOPT)</span>
 #define cpu_has_xsaves		boot_cpu_has(X86_FEATURE_XSAVES)
 #define cpu_has_osxsave		boot_cpu_has(X86_FEATURE_OSXSAVE)
 #define cpu_has_hypervisor	boot_cpu_has(X86_FEATURE_HYPERVISOR)
<span class="p_del">-#define cpu_has_pclmulqdq	boot_cpu_has(X86_FEATURE_PCLMULQDQ)</span>
<span class="p_del">-#define cpu_has_perfctr_core	boot_cpu_has(X86_FEATURE_PERFCTR_CORE)</span>
<span class="p_del">-#define cpu_has_perfctr_nb	boot_cpu_has(X86_FEATURE_PERFCTR_NB)</span>
<span class="p_del">-#define cpu_has_perfctr_l2	boot_cpu_has(X86_FEATURE_PERFCTR_L2)</span>
<span class="p_del">-#define cpu_has_cx8		boot_cpu_has(X86_FEATURE_CX8)</span>
<span class="p_del">-#define cpu_has_cx16		boot_cpu_has(X86_FEATURE_CX16)</span>
<span class="p_del">-#define cpu_has_eager_fpu	boot_cpu_has(X86_FEATURE_EAGER_FPU)</span>
<span class="p_del">-#define cpu_has_topoext		boot_cpu_has(X86_FEATURE_TOPOEXT)</span>
<span class="p_del">-#define cpu_has_bpext		boot_cpu_has(X86_FEATURE_BPEXT)</span>
<span class="p_del">-</span>
<span class="p_del">-#if __GNUC__ &gt;= 4</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Do not add any more of those clumsy macros - use static_cpu_has_safe() for</span>
<span class="p_add">+ * fast paths and boot_cpu_has() otherwise!</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#if __GNUC__ &gt;= 4 &amp;&amp; defined(CONFIG_X86_FAST_FEATURE_TESTS)</span>
 extern void warn_pre_alternatives(void);
 extern bool __static_cpu_has_safe(u16 bit);
 
<span class="p_header">diff --git a/arch/x86/include/asm/page_types.h b/arch/x86/include/asm/page_types.h</span>
<span class="p_header">index cc071c6f7d4d..7bd0099384ca 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/page_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/page_types.h</span>
<span class="p_chunk">@@ -5,9 +5,9 @@</span> <span class="p_context"></span>
 #include &lt;linux/types.h&gt;
 
 /* PAGE_SHIFT determines the page size */
<span class="p_del">-#define PAGE_SHIFT	12</span>
<span class="p_del">-#define PAGE_SIZE	(_AC(1,UL) &lt;&lt; PAGE_SHIFT)</span>
<span class="p_del">-#define PAGE_MASK	(~(PAGE_SIZE-1))</span>
<span class="p_add">+#define PAGE_SHIFT		12</span>
<span class="p_add">+#define PAGE_SIZE		(_AC(1,UL) &lt;&lt; PAGE_SHIFT)</span>
<span class="p_add">+#define PAGE_MASK		(~(PAGE_SIZE-1))</span>
 
 #define PMD_PAGE_SIZE		(_AC(1, UL) &lt;&lt; PMD_SHIFT)
 #define PMD_PAGE_MASK		(~(PMD_PAGE_SIZE-1))
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt.h b/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">index 10d0596433f8..cbbf41c0a328 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt.h</span>
<span class="p_chunk">@@ -285,15 +285,6 @@</span> <span class="p_context"> static inline void slow_down_io(void)</span>
 #endif
 }
 
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-static inline void startup_ipi_hook(int phys_apicid, unsigned long start_eip,</span>
<span class="p_del">-				    unsigned long start_esp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_apic_ops.startup_ipi_hook,</span>
<span class="p_del">-		    phys_apicid, start_eip, start_esp);</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 static inline void paravirt_activate_mm(struct mm_struct *prev,
 					struct mm_struct *next)
 {
<span class="p_chunk">@@ -375,23 +366,6 @@</span> <span class="p_context"> static inline void pte_update(struct mm_struct *mm, unsigned long addr,</span>
 {
 	PVOP_VCALL3(pv_mmu_ops.pte_update, mm, addr, ptep);
 }
<span class="p_del">-static inline void pmd_update(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			      pmd_t *pmdp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_mmu_ops.pmd_update, mm, addr, pmdp);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pte_update_defer(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-				    pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_mmu_ops.pte_update_defer, mm, addr, ptep);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pmd_update_defer(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-				    pmd_t *pmdp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_mmu_ops.pmd_update_defer, mm, addr, pmdp);</span>
<span class="p_del">-}</span>
 
 static inline pte_t __pte(pteval_t val)
 {
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_types.h b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">index 31247b5bff7c..0451503e1716 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_chunk">@@ -215,14 +215,6 @@</span> <span class="p_context"> struct pv_irq_ops {</span>
 #endif
 };
 
<span class="p_del">-struct pv_apic_ops {</span>
<span class="p_del">-#ifdef CONFIG_X86_LOCAL_APIC</span>
<span class="p_del">-	void (*startup_ipi_hook)(int phys_apicid,</span>
<span class="p_del">-				 unsigned long start_eip,</span>
<span class="p_del">-				 unsigned long start_esp);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 struct pv_mmu_ops {
 	unsigned long (*read_cr2)(void);
 	void (*write_cr2)(unsigned long);
<span class="p_chunk">@@ -274,12 +266,6 @@</span> <span class="p_context"> struct pv_mmu_ops {</span>
 			   pmd_t *pmdp, pmd_t pmdval);
 	void (*pte_update)(struct mm_struct *mm, unsigned long addr,
 			   pte_t *ptep);
<span class="p_del">-	void (*pte_update_defer)(struct mm_struct *mm,</span>
<span class="p_del">-				 unsigned long addr, pte_t *ptep);</span>
<span class="p_del">-	void (*pmd_update)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			   pmd_t *pmdp);</span>
<span class="p_del">-	void (*pmd_update_defer)(struct mm_struct *mm,</span>
<span class="p_del">-				 unsigned long addr, pmd_t *pmdp);</span>
 
 	pte_t (*ptep_modify_prot_start)(struct mm_struct *mm, unsigned long addr,
 					pte_t *ptep);
<span class="p_chunk">@@ -354,7 +340,6 @@</span> <span class="p_context"> struct paravirt_patch_template {</span>
 	struct pv_time_ops pv_time_ops;
 	struct pv_cpu_ops pv_cpu_ops;
 	struct pv_irq_ops pv_irq_ops;
<span class="p_del">-	struct pv_apic_ops pv_apic_ops;</span>
 	struct pv_mmu_ops pv_mmu_ops;
 	struct pv_lock_ops pv_lock_ops;
 };
<span class="p_chunk">@@ -364,7 +349,6 @@</span> <span class="p_context"> extern struct pv_init_ops pv_init_ops;</span>
 extern struct pv_time_ops pv_time_ops;
 extern struct pv_cpu_ops pv_cpu_ops;
 extern struct pv_irq_ops pv_irq_ops;
<span class="p_del">-extern struct pv_apic_ops pv_apic_ops;</span>
 extern struct pv_mmu_ops pv_mmu_ops;
 extern struct pv_lock_ops pv_lock_ops;
 
<span class="p_chunk">@@ -402,10 +386,8 @@</span> <span class="p_context"> extern struct pv_lock_ops pv_lock_ops;</span>
 	__visible extern const char start_##ops##_##name[], end_##ops##_##name[];	\
 	asm(NATIVE_LABEL(&quot;start_&quot;, ops, name) code NATIVE_LABEL(&quot;end_&quot;, ops, name))
 
<span class="p_del">-unsigned paravirt_patch_nop(void);</span>
 unsigned paravirt_patch_ident_32(void *insnbuf, unsigned len);
 unsigned paravirt_patch_ident_64(void *insnbuf, unsigned len);
<span class="p_del">-unsigned paravirt_patch_ignore(unsigned len);</span>
 unsigned paravirt_patch_call(void *insnbuf,
 			     const void *target, u16 tgt_clobbers,
 			     unsigned long addr, u16 site_clobbers,
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index 6ec0c8b2e9df..d3eee663c41f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -69,9 +69,6 @@</span> <span class="p_context"> extern struct mm_struct *pgd_page_get_mm(struct page *page);</span>
 #define pmd_clear(pmd)			native_pmd_clear(pmd)
 
 #define pte_update(mm, addr, ptep)              do { } while (0)
<span class="p_del">-#define pte_update_defer(mm, addr, ptep)        do { } while (0)</span>
<span class="p_del">-#define pmd_update(mm, addr, ptep)              do { } while (0)</span>
<span class="p_del">-#define pmd_update_defer(mm, addr, ptep)        do { } while (0)</span>
 
 #define pgd_val(x)	native_pgd_val(x)
 #define __pgd(x)	native_make_pgd(x)
<span class="p_chunk">@@ -731,14 +728,9 @@</span> <span class="p_context"> static inline void native_set_pmd_at(struct mm_struct *mm, unsigned long addr,</span>
  * updates should either be sets, clears, or set_pte_atomic for P-&gt;P
  * transitions, which means this hook should only be called for user PTEs.
  * This hook implies a P-&gt;P protection or access change has taken place, which
<span class="p_del">- * requires a subsequent TLB flush.  The notification can optionally be delayed</span>
<span class="p_del">- * until the TLB flush event by using the pte_update_defer form of the</span>
<span class="p_del">- * interface, but care must be taken to assure that the flush happens while</span>
<span class="p_del">- * still holding the same page table lock so that the shadow and primary pages</span>
<span class="p_del">- * do not become out of sync on SMP.</span>
<span class="p_add">+ * requires a subsequent TLB flush.</span>
  */
 #define pte_update(mm, addr, ptep)		do { } while (0)
<span class="p_del">-#define pte_update_defer(mm, addr, ptep)	do { } while (0)</span>
 #endif
 
 /*
<span class="p_chunk">@@ -830,9 +822,7 @@</span> <span class="p_context"> static inline int pmd_write(pmd_t pmd)</span>
 static inline pmd_t pmdp_huge_get_and_clear(struct mm_struct *mm, unsigned long addr,
 				       pmd_t *pmdp)
 {
<span class="p_del">-	pmd_t pmd = native_pmdp_get_and_clear(pmdp);</span>
<span class="p_del">-	pmd_update(mm, addr, pmdp);</span>
<span class="p_del">-	return pmd;</span>
<span class="p_add">+	return native_pmdp_get_and_clear(pmdp);</span>
 }
 
 #define __HAVE_ARCH_PMDP_SET_WRPROTECT
<span class="p_chunk">@@ -840,7 +830,6 @@</span> <span class="p_context"> static inline void pmdp_set_wrprotect(struct mm_struct *mm,</span>
 				      unsigned long addr, pmd_t *pmdp)
 {
 	clear_bit(_PAGE_BIT_RW, (unsigned long *)pmdp);
<span class="p_del">-	pmd_update(mm, addr, pmdp);</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h</span>
<span class="p_header">index 222a6a3ca2b5..dfcf0727623b 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/smp.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/smp.h</span>
<span class="p_chunk">@@ -21,15 +21,6 @@</span> <span class="p_context"></span>
 extern int smp_num_siblings;
 extern unsigned int num_processors;
 
<span class="p_del">-static inline bool cpu_has_ht_siblings(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool has_siblings = false;</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	has_siblings = cpu_has_ht &amp;&amp; smp_num_siblings &gt; 1;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	return has_siblings;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
 DECLARE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_core_map);
 /* cpus sharing the last level cache: */
<span class="p_chunk">@@ -74,9 +65,6 @@</span> <span class="p_context"> struct smp_ops {</span>
 extern void set_cpu_sibling_map(int cpu);
 
 #ifdef CONFIG_SMP
<span class="p_del">-#ifndef CONFIG_PARAVIRT</span>
<span class="p_del">-#define startup_ipi_hook(phys_apicid, start_eip, start_esp) do { } while (0)</span>
<span class="p_del">-#endif</span>
 extern struct smp_ops smp_ops;
 
 static inline void smp_send_stop(void)
<span class="p_header">diff --git a/arch/x86/include/asm/x86_init.h b/arch/x86/include/asm/x86_init.h</span>
<span class="p_header">index cd0fc0cc78bc..1ae89a2721d6 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/x86_init.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/x86_init.h</span>
<span class="p_chunk">@@ -82,13 +82,11 @@</span> <span class="p_context"> struct x86_init_paging {</span>
  * struct x86_init_timers - platform specific timer setup
  * @setup_perpcu_clockev:	set up the per cpu clock event device for the
  *				boot cpu
<span class="p_del">- * @tsc_pre_init:		platform function called before TSC init</span>
  * @timer_init:			initialize the platform timer (default PIT/HPET)
  * @wallclock_init:		init the wallclock device
  */
 struct x86_init_timers {
 	void (*setup_percpu_clockev)(void);
<span class="p_del">-	void (*tsc_pre_init)(void);</span>
 	void (*timer_init)(void);
 	void (*wallclock_init)(void);
 };
<span class="p_header">diff --git a/arch/x86/include/asm/xor_32.h b/arch/x86/include/asm/xor_32.h</span>
<span class="p_header">index 5a08bc8bff33..c54beb44c4c1 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/xor_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/xor_32.h</span>
<span class="p_chunk">@@ -553,7 +553,7 @@</span> <span class="p_context"> do {							\</span>
 	if (cpu_has_xmm) {				\
 		xor_speed(&amp;xor_block_pIII_sse);		\
 		xor_speed(&amp;xor_block_sse_pf64);		\
<span class="p_del">-	} else if (cpu_has_mmx) {			\</span>
<span class="p_add">+	} else if (boot_cpu_has(X86_FEATURE_MMX)) {	\</span>
 		xor_speed(&amp;xor_block_pII_mmx);		\
 		xor_speed(&amp;xor_block_p5_mmx);		\
 	} else {					\
<span class="p_header">diff --git a/arch/x86/kernel/cpu/amd.c b/arch/x86/kernel/cpu/amd.c</span>
<span class="p_header">index a8816b325162..34c3ad608dd4 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/amd.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/amd.c</span>
<span class="p_chunk">@@ -304,7 +304,7 @@</span> <span class="p_context"> static void amd_get_topology(struct cpuinfo_x86 *c)</span>
 	int cpu = smp_processor_id();
 
 	/* get information required for multi-node processors */
<span class="p_del">-	if (cpu_has_topoext) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {</span>
 		u32 eax, ebx, ecx, edx;
 
 		cpuid(0x8000001e, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);
<span class="p_chunk">@@ -922,7 +922,7 @@</span> <span class="p_context"> static bool cpu_has_amd_erratum(struct cpuinfo_x86 *cpu, const int *erratum)</span>
 
 void set_dr_addr_mask(unsigned long mask, int dr)
 {
<span class="p_del">-	if (!cpu_has_bpext)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_BPEXT))</span>
 		return;
 
 	switch (dr) {
<span class="p_header">diff --git a/arch/x86/kernel/cpu/centaur.c b/arch/x86/kernel/cpu/centaur.c</span>
<span class="p_header">index d8fba5c15fbd..ae20be6e483c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/centaur.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/centaur.c</span>
<span class="p_chunk">@@ -43,7 +43,7 @@</span> <span class="p_context"> static void init_c3(struct cpuinfo_x86 *c)</span>
 		/* store Centaur Extended Feature Flags as
 		 * word 5 of the CPU capability bit array
 		 */
<span class="p_del">-		c-&gt;x86_capability[5] = cpuid_edx(0xC0000001);</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_C000_0001_EDX] = cpuid_edx(0xC0000001);</span>
 	}
 #ifdef CONFIG_X86_32
 	/* Cyrix III family needs CX8 &amp; PGE explicitly enabled. */
<span class="p_header">diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">index c2b7522cbf35..4d5279c95d5f 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -599,50 +599,47 @@</span> <span class="p_context"> void cpu_detect(struct cpuinfo_x86 *c)</span>
 
 void get_cpu_cap(struct cpuinfo_x86 *c)
 {
<span class="p_del">-	u32 tfms, xlvl;</span>
<span class="p_del">-	u32 ebx;</span>
<span class="p_add">+	u32 eax, ebx, ecx, edx;</span>
 
 	/* Intel-defined flags: level 0x00000001 */
 	if (c-&gt;cpuid_level &gt;= 0x00000001) {
<span class="p_del">-		u32 capability, excap;</span>
<span class="p_add">+		cpuid(0x00000001, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);</span>
 
<span class="p_del">-		cpuid(0x00000001, &amp;tfms, &amp;ebx, &amp;excap, &amp;capability);</span>
<span class="p_del">-		c-&gt;x86_capability[0] = capability;</span>
<span class="p_del">-		c-&gt;x86_capability[4] = excap;</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_1_ECX] = ecx;</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_1_EDX] = edx;</span>
 	}
 
 	/* Additional Intel-defined flags: level 0x00000007 */
 	if (c-&gt;cpuid_level &gt;= 0x00000007) {
<span class="p_del">-		u32 eax, ebx, ecx, edx;</span>
<span class="p_del">-</span>
 		cpuid_count(0x00000007, 0, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);
 
<span class="p_del">-		c-&gt;x86_capability[9] = ebx;</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_7_0_EBX] = ebx;</span>
<span class="p_add">+</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_6_EAX] = cpuid_eax(0x00000006);</span>
 	}
 
 	/* Extended state features: level 0x0000000d */
 	if (c-&gt;cpuid_level &gt;= 0x0000000d) {
<span class="p_del">-		u32 eax, ebx, ecx, edx;</span>
<span class="p_del">-</span>
 		cpuid_count(0x0000000d, 1, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);
 
<span class="p_del">-		c-&gt;x86_capability[10] = eax;</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_D_1_EAX] = eax;</span>
 	}
 
 	/* Additional Intel-defined flags: level 0x0000000F */
 	if (c-&gt;cpuid_level &gt;= 0x0000000F) {
<span class="p_del">-		u32 eax, ebx, ecx, edx;</span>
 
 		/* QoS sub-leaf, EAX=0Fh, ECX=0 */
 		cpuid_count(0x0000000F, 0, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);
<span class="p_del">-		c-&gt;x86_capability[11] = edx;</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_F_0_EDX] = edx;</span>
<span class="p_add">+</span>
 		if (cpu_has(c, X86_FEATURE_CQM_LLC)) {
 			/* will be overridden if occupancy monitoring exists */
 			c-&gt;x86_cache_max_rmid = ebx;
 
 			/* QoS sub-leaf, EAX=0Fh, ECX=1 */
 			cpuid_count(0x0000000F, 1, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);
<span class="p_del">-			c-&gt;x86_capability[12] = edx;</span>
<span class="p_add">+			c-&gt;x86_capability[CPUID_F_1_EDX] = edx;</span>
<span class="p_add">+</span>
 			if (cpu_has(c, X86_FEATURE_CQM_OCCUP_LLC)) {
 				c-&gt;x86_cache_max_rmid = ecx;
 				c-&gt;x86_cache_occ_scale = ebx;
<span class="p_chunk">@@ -654,22 +651,24 @@</span> <span class="p_context"> void get_cpu_cap(struct cpuinfo_x86 *c)</span>
 	}
 
 	/* AMD-defined flags: level 0x80000001 */
<span class="p_del">-	xlvl = cpuid_eax(0x80000000);</span>
<span class="p_del">-	c-&gt;extended_cpuid_level = xlvl;</span>
<span class="p_add">+	eax = cpuid_eax(0x80000000);</span>
<span class="p_add">+	c-&gt;extended_cpuid_level = eax;</span>
 
<span class="p_del">-	if ((xlvl &amp; 0xffff0000) == 0x80000000) {</span>
<span class="p_del">-		if (xlvl &gt;= 0x80000001) {</span>
<span class="p_del">-			c-&gt;x86_capability[1] = cpuid_edx(0x80000001);</span>
<span class="p_del">-			c-&gt;x86_capability[6] = cpuid_ecx(0x80000001);</span>
<span class="p_add">+	if ((eax &amp; 0xffff0000) == 0x80000000) {</span>
<span class="p_add">+		if (eax &gt;= 0x80000001) {</span>
<span class="p_add">+			cpuid(0x80000001, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);</span>
<span class="p_add">+</span>
<span class="p_add">+			c-&gt;x86_capability[CPUID_8000_0001_ECX] = ecx;</span>
<span class="p_add">+			c-&gt;x86_capability[CPUID_8000_0001_EDX] = edx;</span>
 		}
 	}
 
 	if (c-&gt;extended_cpuid_level &gt;= 0x80000008) {
<span class="p_del">-		u32 eax = cpuid_eax(0x80000008);</span>
<span class="p_add">+		cpuid(0x80000008, &amp;eax, &amp;ebx, &amp;ecx, &amp;edx);</span>
 
 		c-&gt;x86_virt_bits = (eax &gt;&gt; 8) &amp; 0xff;
 		c-&gt;x86_phys_bits = eax &amp; 0xff;
<span class="p_del">-		c-&gt;x86_capability[13] = cpuid_ebx(0x80000008);</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_8000_0008_EBX] = ebx;</span>
 	}
 #ifdef CONFIG_X86_32
 	else if (cpu_has(c, X86_FEATURE_PAE) || cpu_has(c, X86_FEATURE_PSE36))
<span class="p_chunk">@@ -679,6 +678,9 @@</span> <span class="p_context"> void get_cpu_cap(struct cpuinfo_x86 *c)</span>
 	if (c-&gt;extended_cpuid_level &gt;= 0x80000007)
 		c-&gt;x86_power = cpuid_edx(0x80000007);
 
<span class="p_add">+	if (c-&gt;extended_cpuid_level &gt;= 0x8000000a)</span>
<span class="p_add">+		c-&gt;x86_capability[CPUID_8000_000A_EDX] = cpuid_edx(0x8000000a);</span>
<span class="p_add">+</span>
 	init_scattered_cpuid_features(c);
 }
 
<span class="p_chunk">@@ -1443,7 +1445,9 @@</span> <span class="p_context"> void cpu_init(void)</span>
 
 	printk(KERN_INFO &quot;Initializing CPU#%d\n&quot;, cpu);
 
<span class="p_del">-	if (cpu_feature_enabled(X86_FEATURE_VME) || cpu_has_tsc || cpu_has_de)</span>
<span class="p_add">+	if (cpu_feature_enabled(X86_FEATURE_VME) ||</span>
<span class="p_add">+	    cpu_has_tsc ||</span>
<span class="p_add">+	    boot_cpu_has(X86_FEATURE_DE))</span>
 		cr4_clear_bits(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);
 
 	load_current_idt();
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">index 209ac1e7d1f0..565648bc1a0a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_chunk">@@ -445,7 +445,8 @@</span> <span class="p_context"> static void init_intel(struct cpuinfo_x86 *c)</span>
 
 	if (cpu_has_xmm2)
 		set_cpu_cap(c, X86_FEATURE_LFENCE_RDTSC);
<span class="p_del">-	if (cpu_has_ds) {</span>
<span class="p_add">+</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_DS)) {</span>
 		unsigned int l1;
 		rdmsr(MSR_IA32_MISC_ENABLE, l1, l2);
 		if (!(l1 &amp; (1&lt;&lt;11)))
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel_cacheinfo.c b/arch/x86/kernel/cpu/intel_cacheinfo.c</span>
<span class="p_header">index e38d338a6447..0b6c52388cf4 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel_cacheinfo.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel_cacheinfo.c</span>
<span class="p_chunk">@@ -591,7 +591,7 @@</span> <span class="p_context"> cpuid4_cache_lookup_regs(int index, struct _cpuid4_info_regs *this_leaf)</span>
 	unsigned		edx;
 
 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
<span class="p_del">-		if (cpu_has_topoext)</span>
<span class="p_add">+		if (boot_cpu_has(X86_FEATURE_TOPOEXT))</span>
 			cpuid_count(0x8000001d, index, &amp;eax.full,
 				    &amp;ebx.full, &amp;ecx.full, &amp;edx);
 		else
<span class="p_chunk">@@ -637,7 +637,7 @@</span> <span class="p_context"> static int find_num_cache_leaves(struct cpuinfo_x86 *c)</span>
 void init_amd_cacheinfo(struct cpuinfo_x86 *c)
 {
 
<span class="p_del">-	if (cpu_has_topoext) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {</span>
 		num_cache_leaves = find_num_cache_leaves(c);
 	} else if (c-&gt;extended_cpuid_level &gt;= 0x80000006) {
 		if (cpuid_edx(0x80000006) &amp; 0xf000)
<span class="p_chunk">@@ -809,7 +809,7 @@</span> <span class="p_context"> static int __cache_amd_cpumap_setup(unsigned int cpu, int index,</span>
 	struct cacheinfo *this_leaf;
 	int i, sibling;
 
<span class="p_del">-	if (cpu_has_topoext) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {</span>
 		unsigned int apicid, nshared, first, last;
 
 		this_leaf = this_cpu_ci-&gt;info_list + index;
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mtrr/generic.c b/arch/x86/kernel/cpu/mtrr/generic.c</span>
<span class="p_header">index 3b533cf37c74..c870af161008 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mtrr/generic.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mtrr/generic.c</span>
<span class="p_chunk">@@ -349,7 +349,7 @@</span> <span class="p_context"> static void get_fixed_ranges(mtrr_type *frs)</span>
 
 void mtrr_save_fixed_ranges(void *info)
 {
<span class="p_del">-	if (cpu_has_mtrr)</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_MTRR))</span>
 		get_fixed_ranges(mtrr_state.fixed_ranges);
 }
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mtrr/main.c b/arch/x86/kernel/cpu/mtrr/main.c</span>
<span class="p_header">index f891b4750f04..5c3d149ee91c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mtrr/main.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mtrr/main.c</span>
<span class="p_chunk">@@ -682,7 +682,7 @@</span> <span class="p_context"> void __init mtrr_bp_init(void)</span>
 
 	phys_addr = 32;
 
<span class="p_del">-	if (cpu_has_mtrr) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_MTRR)) {</span>
 		mtrr_if = &amp;generic_mtrr_ops;
 		size_or_mask = SIZE_OR_MASK_BITS(36);
 		size_and_mask = 0x00f00000;
<span class="p_header">diff --git a/arch/x86/kernel/cpu/perf_event_amd.c b/arch/x86/kernel/cpu/perf_event_amd.c</span>
<span class="p_header">index 1cee5d2d7ece..3ea177cb7366 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/perf_event_amd.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/perf_event_amd.c</span>
<span class="p_chunk">@@ -160,7 +160,7 @@</span> <span class="p_context"> static inline int amd_pmu_addr_offset(int index, bool eventsel)</span>
 	if (offset)
 		return offset;
 
<span class="p_del">-	if (!cpu_has_perfctr_core)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_PERFCTR_CORE))</span>
 		offset = index;
 	else
 		offset = index &lt;&lt; 1;
<span class="p_chunk">@@ -652,7 +652,7 @@</span> <span class="p_context"> static __initconst const struct x86_pmu amd_pmu = {</span>
 
 static int __init amd_core_pmu_init(void)
 {
<span class="p_del">-	if (!cpu_has_perfctr_core)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_PERFCTR_CORE))</span>
 		return 0;
 
 	switch (boot_cpu_data.x86) {
<span class="p_header">diff --git a/arch/x86/kernel/cpu/perf_event_amd_uncore.c b/arch/x86/kernel/cpu/perf_event_amd_uncore.c</span>
<span class="p_header">index cc6cedb8f25d..49742746a6c9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/perf_event_amd_uncore.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/perf_event_amd_uncore.c</span>
<span class="p_chunk">@@ -523,10 +523,10 @@</span> <span class="p_context"> static int __init amd_uncore_init(void)</span>
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
 		goto fail_nodev;
 
<span class="p_del">-	if (!cpu_has_topoext)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_TOPOEXT))</span>
 		goto fail_nodev;
 
<span class="p_del">-	if (cpu_has_perfctr_nb) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PERFCTR_NB)) {</span>
 		amd_uncore_nb = alloc_percpu(struct amd_uncore *);
 		if (!amd_uncore_nb) {
 			ret = -ENOMEM;
<span class="p_chunk">@@ -540,7 +540,7 @@</span> <span class="p_context"> static int __init amd_uncore_init(void)</span>
 		ret = 0;
 	}
 
<span class="p_del">-	if (cpu_has_perfctr_l2) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PERFCTR_L2)) {</span>
 		amd_uncore_l2 = alloc_percpu(struct amd_uncore *);
 		if (!amd_uncore_l2) {
 			ret = -ENOMEM;
<span class="p_chunk">@@ -583,10 +583,11 @@</span> <span class="p_context"> static int __init amd_uncore_init(void)</span>
 
 	/* amd_uncore_nb/l2 should have been freed by cleanup_cpu_online */
 	amd_uncore_nb = amd_uncore_l2 = NULL;
<span class="p_del">-	if (cpu_has_perfctr_l2)</span>
<span class="p_add">+</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PERFCTR_L2))</span>
 		perf_pmu_unregister(&amp;amd_l2_pmu);
 fail_l2:
<span class="p_del">-	if (cpu_has_perfctr_nb)</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PERFCTR_NB))</span>
 		perf_pmu_unregister(&amp;amd_nb_pmu);
 	if (amd_uncore_l2)
 		free_percpu(amd_uncore_l2);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.c</span>
<span class="p_header">index 608fb26c7254..8cb57df9398d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/scattered.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/scattered.c</span>
<span class="p_chunk">@@ -31,32 +31,12 @@</span> <span class="p_context"> void init_scattered_cpuid_features(struct cpuinfo_x86 *c)</span>
 	const struct cpuid_bit *cb;
 
 	static const struct cpuid_bit cpuid_bits[] = {
<span class="p_del">-		{ X86_FEATURE_DTHERM,		CR_EAX, 0, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_IDA,		CR_EAX, 1, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_ARAT,		CR_EAX, 2, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_PLN,		CR_EAX, 4, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_PTS,		CR_EAX, 6, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_HWP,		CR_EAX, 7, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_HWP_NOTIFY,	CR_EAX, 8, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_HWP_ACT_WINDOW,	CR_EAX, 9, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_HWP_EPP,		CR_EAX,10, 0x00000006, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_HWP_PKG_REQ,	CR_EAX,11, 0x00000006, 0 },</span>
 		{ X86_FEATURE_INTEL_PT,		CR_EBX,25, 0x00000007, 0 },
 		{ X86_FEATURE_APERFMPERF,	CR_ECX, 0, 0x00000006, 0 },
 		{ X86_FEATURE_EPB,		CR_ECX, 3, 0x00000006, 0 },
 		{ X86_FEATURE_HW_PSTATE,	CR_EDX, 7, 0x80000007, 0 },
 		{ X86_FEATURE_CPB,		CR_EDX, 9, 0x80000007, 0 },
 		{ X86_FEATURE_PROC_FEEDBACK,	CR_EDX,11, 0x80000007, 0 },
<span class="p_del">-		{ X86_FEATURE_NPT,		CR_EDX, 0, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_LBRV,		CR_EDX, 1, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_SVML,		CR_EDX, 2, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_NRIPS,		CR_EDX, 3, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_TSCRATEMSR,	CR_EDX, 4, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_VMCBCLEAN,	CR_EDX, 5, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_FLUSHBYASID,	CR_EDX, 6, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_DECODEASSISTS,	CR_EDX, 7, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_PAUSEFILTER,	CR_EDX,10, 0x8000000a, 0 },</span>
<span class="p_del">-		{ X86_FEATURE_PFTHRESHOLD,	CR_EDX,12, 0x8000000a, 0 },</span>
 		{ 0, 0, 0, 0, 0 }
 	};
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/transmeta.c b/arch/x86/kernel/cpu/transmeta.c</span>
<span class="p_header">index 3fa0e5ad86b4..252da7aceca6 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/transmeta.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/transmeta.c</span>
<span class="p_chunk">@@ -12,7 +12,7 @@</span> <span class="p_context"> static void early_init_transmeta(struct cpuinfo_x86 *c)</span>
 	xlvl = cpuid_eax(0x80860000);
 	if ((xlvl &amp; 0xffff0000) == 0x80860000) {
 		if (xlvl &gt;= 0x80860001)
<span class="p_del">-			c-&gt;x86_capability[2] = cpuid_edx(0x80860001);</span>
<span class="p_add">+			c-&gt;x86_capability[CPUID_8086_0001_EDX] = cpuid_edx(0x80860001);</span>
 	}
 }
 
<span class="p_chunk">@@ -82,7 +82,7 @@</span> <span class="p_context"> static void init_transmeta(struct cpuinfo_x86 *c)</span>
 	/* Unhide possibly hidden capability flags */
 	rdmsr(0x80860004, cap_mask, uk);
 	wrmsr(0x80860004, ~0, uk);
<span class="p_del">-	c-&gt;x86_capability[0] = cpuid_edx(0x00000001);</span>
<span class="p_add">+	c-&gt;x86_capability[CPUID_1_EDX] = cpuid_edx(0x00000001);</span>
 	wrmsr(0x80860004, cap_mask, uk);
 
 	/* All Transmeta CPUs have a constant TSC */
<span class="p_header">diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c</span>
<span class="p_header">index be39b5fde4b9..22abea04731e 100644</span>
<span class="p_header">--- a/arch/x86/kernel/fpu/init.c</span>
<span class="p_header">+++ b/arch/x86/kernel/fpu/init.c</span>
<span class="p_chunk">@@ -12,7 +12,7 @@</span> <span class="p_context"></span>
  */
 static void fpu__init_cpu_ctx_switch(void)
 {
<span class="p_del">-	if (!cpu_has_eager_fpu)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_EAGER_FPU))</span>
 		stts();
 	else
 		clts();
<span class="p_chunk">@@ -287,7 +287,7 @@</span> <span class="p_context"> static void __init fpu__init_system_ctx_switch(void)</span>
 	current_thread_info()-&gt;status = 0;
 
 	/* Auto enable eagerfpu for xsaveopt */
<span class="p_del">-	if (cpu_has_xsaveopt &amp;&amp; eagerfpu != DISABLE)</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_XSAVEOPT) &amp;&amp; eagerfpu != DISABLE)</span>
 		eagerfpu = ENABLE;
 
 	if (xfeatures_mask &amp; XFEATURE_MASK_EAGER) {
<span class="p_header">diff --git a/arch/x86/kernel/hw_breakpoint.c b/arch/x86/kernel/hw_breakpoint.c</span>
<span class="p_header">index 50a3fad5b89f..2bcfb5f2bc44 100644</span>
<span class="p_header">--- a/arch/x86/kernel/hw_breakpoint.c</span>
<span class="p_header">+++ b/arch/x86/kernel/hw_breakpoint.c</span>
<span class="p_chunk">@@ -300,6 +300,10 @@</span> <span class="p_context"> static int arch_build_bp_info(struct perf_event *bp)</span>
 			return -EINVAL;
 		if (bp-&gt;attr.bp_addr &amp; (bp-&gt;attr.bp_len - 1))
 			return -EINVAL;
<span class="p_add">+</span>
<span class="p_add">+		if (!boot_cpu_has(X86_FEATURE_BPEXT))</span>
<span class="p_add">+			return -EOPNOTSUPP;</span>
<span class="p_add">+</span>
 		/*
 		 * It&#39;s impossible to use a range breakpoint to fake out
 		 * user vs kernel detection because bp_len - 1 can&#39;t
<span class="p_chunk">@@ -307,8 +311,6 @@</span> <span class="p_context"> static int arch_build_bp_info(struct perf_event *bp)</span>
 		 * breakpoints, then we&#39;ll have to check for kprobe-blacklisted
 		 * addresses anywhere in the range.
 		 */
<span class="p_del">-		if (!cpu_has_bpext)</span>
<span class="p_del">-			return -EOPNOTSUPP;</span>
 		info-&gt;mask = bp-&gt;attr.bp_len - 1;
 		info-&gt;len = X86_BREAKPOINT_LEN_1;
 	}
<span class="p_header">diff --git a/arch/x86/kernel/paravirt.c b/arch/x86/kernel/paravirt.c</span>
<span class="p_header">index c2130aef3f9d..3265ea0fceeb 100644</span>
<span class="p_header">--- a/arch/x86/kernel/paravirt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/paravirt.c</span>
<span class="p_chunk">@@ -74,16 +74,6 @@</span> <span class="p_context"> void __init default_banner(void)</span>
 /* Undefined instruction for dealing with missing ops pointers. */
 static const unsigned char ud2a[] = { 0x0f, 0x0b };
 
<span class="p_del">-unsigned paravirt_patch_nop(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-unsigned paravirt_patch_ignore(unsigned len)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return len;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 struct branch {
 	unsigned char opcode;
 	u32 delta;
<span class="p_chunk">@@ -133,7 +123,6 @@</span> <span class="p_context"> static void *get_call_destination(u8 type)</span>
 		.pv_time_ops = pv_time_ops,
 		.pv_cpu_ops = pv_cpu_ops,
 		.pv_irq_ops = pv_irq_ops,
<span class="p_del">-		.pv_apic_ops = pv_apic_ops,</span>
 		.pv_mmu_ops = pv_mmu_ops,
 #ifdef CONFIG_PARAVIRT_SPINLOCKS
 		.pv_lock_ops = pv_lock_ops,
<span class="p_chunk">@@ -152,8 +141,7 @@</span> <span class="p_context"> unsigned paravirt_patch_default(u8 type, u16 clobbers, void *insnbuf,</span>
 		/* If there&#39;s no function, patch it with a ud2a (BUG) */
 		ret = paravirt_patch_insns(insnbuf, len, ud2a, ud2a+sizeof(ud2a));
 	else if (opfunc == _paravirt_nop)
<span class="p_del">-		/* If the operation is a nop, then nop the callsite */</span>
<span class="p_del">-		ret = paravirt_patch_nop();</span>
<span class="p_add">+		ret = 0;</span>
 
 	/* identity functions just return their single argument */
 	else if (opfunc == _paravirt_ident_32)
<span class="p_chunk">@@ -403,12 +391,6 @@</span> <span class="p_context"> NOKPROBE_SYMBOL(native_get_debugreg);</span>
 NOKPROBE_SYMBOL(native_set_debugreg);
 NOKPROBE_SYMBOL(native_load_idt);
 
<span class="p_del">-struct pv_apic_ops pv_apic_ops = {</span>
<span class="p_del">-#ifdef CONFIG_X86_LOCAL_APIC</span>
<span class="p_del">-	.startup_ipi_hook = paravirt_nop,</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 #if defined(CONFIG_X86_32) &amp;&amp; !defined(CONFIG_X86_PAE)
 /* 32-bit pagetable entries */
 #define PTE_IDENT	__PV_IS_CALLEE_SAVE(_paravirt_ident_32)
<span class="p_chunk">@@ -444,9 +426,6 @@</span> <span class="p_context"> struct pv_mmu_ops pv_mmu_ops = {</span>
 	.set_pmd = native_set_pmd,
 	.set_pmd_at = native_set_pmd_at,
 	.pte_update = paravirt_nop,
<span class="p_del">-	.pte_update_defer = paravirt_nop,</span>
<span class="p_del">-	.pmd_update = paravirt_nop,</span>
<span class="p_del">-	.pmd_update_defer = paravirt_nop,</span>
 
 	.ptep_modify_prot_start = __ptep_modify_prot_start,
 	.ptep_modify_prot_commit = __ptep_modify_prot_commit,
<span class="p_chunk">@@ -492,6 +471,5 @@</span> <span class="p_context"> struct pv_mmu_ops pv_mmu_ops = {</span>
 EXPORT_SYMBOL_GPL(pv_time_ops);
 EXPORT_SYMBOL    (pv_cpu_ops);
 EXPORT_SYMBOL    (pv_mmu_ops);
<span class="p_del">-EXPORT_SYMBOL_GPL(pv_apic_ops);</span>
 EXPORT_SYMBOL_GPL(pv_info);
 EXPORT_SYMBOL    (pv_irq_ops);
<span class="p_header">diff --git a/arch/x86/kernel/ptrace.c b/arch/x86/kernel/ptrace.c</span>
<span class="p_header">index 558f50edebca..32e9d9cbb884 100644</span>
<span class="p_header">--- a/arch/x86/kernel/ptrace.c</span>
<span class="p_header">+++ b/arch/x86/kernel/ptrace.c</span>
<span class="p_chunk">@@ -124,21 +124,6 @@</span> <span class="p_context"> const char *regs_query_register_name(unsigned int offset)</span>
 	return NULL;
 }
 
<span class="p_del">-static const int arg_offs_table[] = {</span>
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-	[0] = offsetof(struct pt_regs, ax),</span>
<span class="p_del">-	[1] = offsetof(struct pt_regs, dx),</span>
<span class="p_del">-	[2] = offsetof(struct pt_regs, cx)</span>
<span class="p_del">-#else /* CONFIG_X86_64 */</span>
<span class="p_del">-	[0] = offsetof(struct pt_regs, di),</span>
<span class="p_del">-	[1] = offsetof(struct pt_regs, si),</span>
<span class="p_del">-	[2] = offsetof(struct pt_regs, dx),</span>
<span class="p_del">-	[3] = offsetof(struct pt_regs, cx),</span>
<span class="p_del">-	[4] = offsetof(struct pt_regs, r8),</span>
<span class="p_del">-	[5] = offsetof(struct pt_regs, r9)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 /*
  * does not yet catch signals sent when the child dies.
  * in exit.c or in signal.c.
<span class="p_header">diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c</span>
<span class="p_header">index fbabe4fcc7fb..24d57f77b3c1 100644</span>
<span class="p_header">--- a/arch/x86/kernel/smpboot.c</span>
<span class="p_header">+++ b/arch/x86/kernel/smpboot.c</span>
<span class="p_chunk">@@ -304,7 +304,7 @@</span> <span class="p_context"> do {									\</span>
 
 static bool match_smt(struct cpuinfo_x86 *c, struct cpuinfo_x86 *o)
 {
<span class="p_del">-	if (cpu_has_topoext) {</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {</span>
 		int cpu1 = c-&gt;cpu_index, cpu2 = o-&gt;cpu_index;
 
 		if (c-&gt;phys_proc_id == o-&gt;phys_proc_id &amp;&amp;
<span class="p_chunk">@@ -630,13 +630,6 @@</span> <span class="p_context"> wakeup_secondary_cpu_via_init(int phys_apicid, unsigned long start_eip)</span>
 		num_starts = 0;
 
 	/*
<span class="p_del">-	 * Paravirt / VMI wants a startup IPI hook here to set up the</span>
<span class="p_del">-	 * target processor state.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	startup_ipi_hook(phys_apicid, (unsigned long) start_secondary,</span>
<span class="p_del">-			 stack_start);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
 	 * Run STARTUP IPI loop.
 	 */
 	pr_debug(&quot;#startup loops: %d\n&quot;, num_starts);
<span class="p_header">diff --git a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c</span>
<span class="p_header">index c7c4d9c51e99..3d743da828d3 100644</span>
<span class="p_header">--- a/arch/x86/kernel/tsc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/tsc.c</span>
<span class="p_chunk">@@ -1185,8 +1185,6 @@</span> <span class="p_context"> void __init tsc_init(void)</span>
 	u64 lpj;
 	int cpu;
 
<span class="p_del">-	x86_init.timers.tsc_pre_init();</span>
<span class="p_del">-</span>
 	if (!cpu_has_tsc) {
 		setup_clear_cpu_cap(X86_FEATURE_TSC_DEADLINE_TIMER);
 		return;
<span class="p_header">diff --git a/arch/x86/kernel/vm86_32.c b/arch/x86/kernel/vm86_32.c</span>
<span class="p_header">index 524619351961..483231ebbb0b 100644</span>
<span class="p_header">--- a/arch/x86/kernel/vm86_32.c</span>
<span class="p_header">+++ b/arch/x86/kernel/vm86_32.c</span>
<span class="p_chunk">@@ -357,8 +357,10 @@</span> <span class="p_context"> static long do_sys_vm86(struct vm86plus_struct __user *user_vm86, bool plus)</span>
 	tss = &amp;per_cpu(cpu_tss, get_cpu());
 	/* make room for real-mode segments */
 	tsk-&gt;thread.sp0 += 16;
<span class="p_del">-	if (cpu_has_sep)</span>
<span class="p_add">+</span>
<span class="p_add">+	if (static_cpu_has_safe(X86_FEATURE_SEP))</span>
 		tsk-&gt;thread.sysenter_cs = 0;
<span class="p_add">+</span>
 	load_sp0(tss, &amp;tsk-&gt;thread);
 	put_cpu();
 
<span class="p_header">diff --git a/arch/x86/kernel/x86_init.c b/arch/x86/kernel/x86_init.c</span>
<span class="p_header">index 3839628d962e..dad5fe9633a3 100644</span>
<span class="p_header">--- a/arch/x86/kernel/x86_init.c</span>
<span class="p_header">+++ b/arch/x86/kernel/x86_init.c</span>
<span class="p_chunk">@@ -68,7 +68,6 @@</span> <span class="p_context"> struct x86_init_ops x86_init __initdata = {</span>
 
 	.timers = {
 		.setup_percpu_clockev	= setup_boot_APIC_clock,
<span class="p_del">-		.tsc_pre_init		= x86_init_noop,</span>
 		.timer_init		= hpet_time_init,
 		.wallclock_init		= x86_init_noop,
 	},
<span class="p_header">diff --git a/arch/x86/lguest/boot.c b/arch/x86/lguest/boot.c</span>
<span class="p_header">index a0d09f6c6533..a1900d4682c0 100644</span>
<span class="p_header">--- a/arch/x86/lguest/boot.c</span>
<span class="p_header">+++ b/arch/x86/lguest/boot.c</span>
<span class="p_chunk">@@ -1472,7 +1472,6 @@</span> <span class="p_context"> __init void lguest_init(void)</span>
 	pv_mmu_ops.lazy_mode.leave = lguest_leave_lazy_mmu_mode;
 	pv_mmu_ops.lazy_mode.flush = paravirt_flush_lazy_mmu;
 	pv_mmu_ops.pte_update = lguest_pte_update;
<span class="p_del">-	pv_mmu_ops.pte_update_defer = lguest_pte_update;</span>
 
 #ifdef CONFIG_X86_LOCAL_APIC
 	/* APIC read/write intercepts */
<span class="p_header">diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c</span>
<span class="p_header">index fb0a9dd1d6e4..ee9c2e3a7199 100644</span>
<span class="p_header">--- a/arch/x86/mm/pgtable.c</span>
<span class="p_header">+++ b/arch/x86/mm/pgtable.c</span>
<span class="p_chunk">@@ -414,7 +414,7 @@</span> <span class="p_context"> int ptep_set_access_flags(struct vm_area_struct *vma,</span>
 
 	if (changed &amp;&amp; dirty) {
 		*ptep = entry;
<span class="p_del">-		pte_update_defer(vma-&gt;vm_mm, address, ptep);</span>
<span class="p_add">+		pte_update(vma-&gt;vm_mm, address, ptep);</span>
 	}
 
 	return changed;
<span class="p_chunk">@@ -431,7 +431,6 @@</span> <span class="p_context"> int pmdp_set_access_flags(struct vm_area_struct *vma,</span>
 
 	if (changed &amp;&amp; dirty) {
 		*pmdp = entry;
<span class="p_del">-		pmd_update_defer(vma-&gt;vm_mm, address, pmdp);</span>
 		/*
 		 * We had a write-protection fault here and changed the pmd
 		 * to to more permissive. No need to flush the TLB for that,
<span class="p_chunk">@@ -469,9 +468,6 @@</span> <span class="p_context"> int pmdp_test_and_clear_young(struct vm_area_struct *vma,</span>
 		ret = test_and_clear_bit(_PAGE_BIT_ACCESSED,
 					 (unsigned long *)pmdp);
 
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		pmd_update(vma-&gt;vm_mm, addr, pmdp);</span>
<span class="p_del">-</span>
 	return ret;
 }
 #endif
<span class="p_chunk">@@ -518,7 +514,6 @@</span> <span class="p_context"> void pmdp_splitting_flush(struct vm_area_struct *vma,</span>
 	set = !test_and_set_bit(_PAGE_BIT_SPLITTING,
 				(unsigned long *)pmdp);
 	if (set) {
<span class="p_del">-		pmd_update(vma-&gt;vm_mm, address, pmdp);</span>
 		/* need tlb flush only to serialize against gup-fast */
 		flush_tlb_range(vma, address, address + HPAGE_PMD_SIZE);
 	}
<span class="p_header">diff --git a/arch/x86/mm/setup_nx.c b/arch/x86/mm/setup_nx.c</span>
<span class="p_header">index 90555bf60aa4..92e2eacb3321 100644</span>
<span class="p_header">--- a/arch/x86/mm/setup_nx.c</span>
<span class="p_header">+++ b/arch/x86/mm/setup_nx.c</span>
<span class="p_chunk">@@ -31,7 +31,7 @@</span> <span class="p_context"> early_param(&quot;noexec&quot;, noexec_setup);</span>
 
 void x86_configure_nx(void)
 {
<span class="p_del">-	if (cpu_has_nx &amp;&amp; !disable_nx)</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_NX) &amp;&amp; !disable_nx)</span>
 		__supported_pte_mask |= _PAGE_NX;
 	else
 		__supported_pte_mask &amp;= ~_PAGE_NX;
<span class="p_chunk">@@ -39,7 +39,7 @@</span> <span class="p_context"> void x86_configure_nx(void)</span>
 
 void __init x86_report_nx(void)
 {
<span class="p_del">-	if (!cpu_has_nx) {</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_NX)) {</span>
 		printk(KERN_NOTICE &quot;Notice: NX (Execute Disable) protection &quot;
 		       &quot;missing in CPU!\n&quot;);
 	} else {
<span class="p_header">diff --git a/arch/x86/xen/enlighten.c b/arch/x86/xen/enlighten.c</span>
<span class="p_header">index 5774800ff583..4334e511cfc8 100644</span>
<span class="p_header">--- a/arch/x86/xen/enlighten.c</span>
<span class="p_header">+++ b/arch/x86/xen/enlighten.c</span>
<span class="p_chunk">@@ -1265,12 +1265,6 @@</span> <span class="p_context"> static const struct pv_cpu_ops xen_cpu_ops __initconst = {</span>
 	.end_context_switch = xen_end_context_switch,
 };
 
<span class="p_del">-static const struct pv_apic_ops xen_apic_ops __initconst = {</span>
<span class="p_del">-#ifdef CONFIG_X86_LOCAL_APIC</span>
<span class="p_del">-	.startup_ipi_hook = paravirt_nop,</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 static void xen_reboot(int reason)
 {
 	struct sched_shutdown r = { .reason = reason };
<span class="p_chunk">@@ -1536,7 +1530,6 @@</span> <span class="p_context"> asmlinkage __visible void __init xen_start_kernel(void)</span>
 	/* Install Xen paravirt ops */
 	pv_info = xen_info;
 	pv_init_ops = xen_init_ops;
<span class="p_del">-	pv_apic_ops = xen_apic_ops;</span>
 	if (!xen_pvh_domain()) {
 		pv_cpu_ops = xen_cpu_ops;
 
<span class="p_header">diff --git a/arch/x86/xen/mmu.c b/arch/x86/xen/mmu.c</span>
<span class="p_header">index cb5e266a8bf7..c913ca4f6958 100644</span>
<span class="p_header">--- a/arch/x86/xen/mmu.c</span>
<span class="p_header">+++ b/arch/x86/xen/mmu.c</span>
<span class="p_chunk">@@ -2436,7 +2436,6 @@</span> <span class="p_context"> static const struct pv_mmu_ops xen_mmu_ops __initconst = {</span>
 	.flush_tlb_others = xen_flush_tlb_others,
 
 	.pte_update = paravirt_nop,
<span class="p_del">-	.pte_update_defer = paravirt_nop,</span>
 
 	.pgd_alloc = xen_pgd_alloc,
 	.pgd_free = xen_pgd_free,
<span class="p_header">diff --git a/drivers/char/hw_random/via-rng.c b/drivers/char/hw_random/via-rng.c</span>
<span class="p_header">index 0c98a9d51a24..44ce80606944 100644</span>
<span class="p_header">--- a/drivers/char/hw_random/via-rng.c</span>
<span class="p_header">+++ b/drivers/char/hw_random/via-rng.c</span>
<span class="p_chunk">@@ -140,7 +140,7 @@</span> <span class="p_context"> static int via_rng_init(struct hwrng *rng)</span>
 	 * RNG configuration like it used to be the case in this
 	 * register */
 	if ((c-&gt;x86 == 6) &amp;&amp; (c-&gt;x86_model &gt;= 0x0f)) {
<span class="p_del">-		if (!cpu_has_xstore_enabled) {</span>
<span class="p_add">+		if (!boot_cpu_has(X86_FEATURE_XSTORE_EN)) {</span>
 			pr_err(PFX &quot;can&#39;t enable hardware RNG &quot;
 				&quot;if XSTORE is not enabled\n&quot;);
 			return -ENODEV;
<span class="p_chunk">@@ -200,8 +200,9 @@</span> <span class="p_context"> static int __init mod_init(void)</span>
 {
 	int err;
 
<span class="p_del">-	if (!cpu_has_xstore)</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_XSTORE))</span>
 		return -ENODEV;
<span class="p_add">+</span>
 	pr_info(&quot;VIA RNG detected\n&quot;);
 	err = hwrng_register(&amp;via_rng);
 	if (err) {
<span class="p_header">diff --git a/drivers/crypto/padlock-aes.c b/drivers/crypto/padlock-aes.c</span>
<span class="p_header">index da2d6777bd09..97a364694bfc 100644</span>
<span class="p_header">--- a/drivers/crypto/padlock-aes.c</span>
<span class="p_header">+++ b/drivers/crypto/padlock-aes.c</span>
<span class="p_chunk">@@ -515,7 +515,7 @@</span> <span class="p_context"> static int __init padlock_init(void)</span>
 	if (!x86_match_cpu(padlock_cpu_id))
 		return -ENODEV;
 
<span class="p_del">-	if (!cpu_has_xcrypt_enabled) {</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_XCRYPT_EN)) {</span>
 		printk(KERN_NOTICE PFX &quot;VIA PadLock detected, but not enabled. Hmm, strange...\n&quot;);
 		return -ENODEV;
 	}
<span class="p_header">diff --git a/drivers/crypto/padlock-sha.c b/drivers/crypto/padlock-sha.c</span>
<span class="p_header">index 4e154c9b9206..8c5f90647b7a 100644</span>
<span class="p_header">--- a/drivers/crypto/padlock-sha.c</span>
<span class="p_header">+++ b/drivers/crypto/padlock-sha.c</span>
<span class="p_chunk">@@ -540,7 +540,7 @@</span> <span class="p_context"> static int __init padlock_init(void)</span>
 	struct shash_alg *sha1;
 	struct shash_alg *sha256;
 
<span class="p_del">-	if (!x86_match_cpu(padlock_sha_ids) || !cpu_has_phe_enabled)</span>
<span class="p_add">+	if (!x86_match_cpu(padlock_sha_ids) || !boot_cpu_has(X86_FEATURE_PHE_EN))</span>
 		return -ENODEV;
 
 	/* Register the newly added algorithm module if on *
<span class="p_header">diff --git a/drivers/iommu/intel_irq_remapping.c b/drivers/iommu/intel_irq_remapping.c</span>
<span class="p_header">index 1fae1881648c..c12ba4516df2 100644</span>
<span class="p_header">--- a/drivers/iommu/intel_irq_remapping.c</span>
<span class="p_header">+++ b/drivers/iommu/intel_irq_remapping.c</span>
<span class="p_chunk">@@ -753,7 +753,7 @@</span> <span class="p_context"> static inline void set_irq_posting_cap(void)</span>
 		 * should have X86_FEATURE_CX16 support, this has been confirmed
 		 * with Intel hardware guys.
 		 */
<span class="p_del">-		if ( cpu_has_cx16 )</span>
<span class="p_add">+		if (boot_cpu_has(X86_FEATURE_CX16))</span>
 			intel_irq_remap_ops.capability |= 1 &lt;&lt; IRQ_POSTING_CAP;
 
 		for_each_iommu(iommu, drhd)
<span class="p_header">diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c</span>
<span class="p_header">index 974be09e7556..42a378a4eefb 100644</span>
<span class="p_header">--- a/fs/btrfs/disk-io.c</span>
<span class="p_header">+++ b/fs/btrfs/disk-io.c</span>
<span class="p_chunk">@@ -923,7 +923,7 @@</span> <span class="p_context"> static int check_async_write(struct inode *inode, unsigned long bio_flags)</span>
 	if (bio_flags &amp; EXTENT_BIO_TREE_LOG)
 		return 0;
 #ifdef CONFIG_X86
<span class="p_del">-	if (cpu_has_xmm4_2)</span>
<span class="p_add">+	if (static_cpu_has_safe(X86_FEATURE_XMM4_2))</span>
 		return 0;
 #endif
 	return 1;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



