
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[2/2] swiotlb: Add swiotlb=nobounce debug option - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [2/2] swiotlb: Add swiotlb=nobounce debug option</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=94301">Geert Uytterhoeven</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 31, 2016, 3:45 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1477928704-10611-3-git-send-email-geert+renesas@glider.be&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9405729/mbox/"
   >mbox</a>
|
   <a href="/patch/9405729/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9405729/">/patch/9405729/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	BF96D60721 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 31 Oct 2016 15:45:19 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B66B129330
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 31 Oct 2016 15:45:19 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id AB17B29332; Mon, 31 Oct 2016 15:45:19 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6342529331
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 31 Oct 2016 15:45:18 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S944313AbcJaPpL (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 31 Oct 2016 11:45:11 -0400
Received: from laurent.telenet-ops.be ([195.130.137.89]:55297 &quot;EHLO
	laurent.telenet-ops.be&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S944161AbcJaPpG (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 31 Oct 2016 11:45:06 -0400
Received: from ayla.of.borg ([84.193.137.253])
	by laurent.telenet-ops.be with bizsmtp
	id 2Fl41u00H5UCtCs01Fl4c0; Mon, 31 Oct 2016 16:45:04 +0100
Received: from ramsan.of.borg ([192.168.97.29] helo=ramsan)
	by ayla.of.borg with esmtp (Exim 4.82)
	(envelope-from &lt;geert@linux-m68k.org&gt;)
	id 1c1Elk-0005Am-6W; Mon, 31 Oct 2016 16:45:04 +0100
Received: from geert by ramsan with local (Exim 4.82)
	(envelope-from &lt;geert@linux-m68k.org&gt;)
	id 1c1Elq-0002lv-OP; Mon, 31 Oct 2016 16:45:10 +0100
From: Geert Uytterhoeven &lt;geert+renesas@glider.be&gt;
To: Konrad Rzeszutek Wilk &lt;konrad.wilk@oracle.com&gt;,
	Jonathan Corbet &lt;corbet@lwn.net&gt;
Cc: Magnus Damm &lt;magnus.damm@gmail.com&gt;, linux-kernel@vger.kernel.org,
	linux-doc@vger.kernel.org, iommu@lists.linux-foundation.org,
	linux-renesas-soc@vger.kernel.org,
	Geert Uytterhoeven &lt;geert+renesas@glider.be&gt;
Subject: [PATCH 2/2] swiotlb: Add swiotlb=nobounce debug option
Date: Mon, 31 Oct 2016 16:45:04 +0100
Message-Id: &lt;1477928704-10611-3-git-send-email-geert+renesas@glider.be&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1477928704-10611-1-git-send-email-geert+renesas@glider.be&gt;
References: &lt;1477928704-10611-1-git-send-email-geert+renesas@glider.be&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=94301">Geert Uytterhoeven</a> - Oct. 31, 2016, 3:45 p.m.</div>
<pre class="content">
On architectures like arm64, swiotlb is tied intimately to the core
architecture DMA support. In addition, ZONE_DMA cannot be disabled.

To aid debugging and catch devices not supporting DMA to memory outside
the 32-bit address space, add a kernel command line option
&quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.
If specified, trying to map memory that cannot be used with DMA will
fail, and a warning will be printed (rate-limited).

Note that io_tlb_nslabs is set to 1, which is the minimal supported
value.
<span class="signed-off-by">
Signed-off-by: Geert Uytterhoeven &lt;geert+renesas@glider.be&gt;</span>
---
 Documentation/kernel-parameters.txt |  3 ++-
 lib/swiotlb.c                       | 19 +++++++++++++++++--
 2 files changed, 19 insertions(+), 3 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77581">Robin Murphy</a> - Oct. 31, 2016, 5:41 p.m.</div>
<pre class="content">
Hi Geert,

On 31/10/16 15:45, Geert Uytterhoeven wrote:
<span class="quote">&gt; On architectures like arm64, swiotlb is tied intimately to the core</span>
<span class="quote">&gt; architecture DMA support. In addition, ZONE_DMA cannot be disabled.</span>

To be fair, that only takes a single-character change in
arch/arm64/Kconfig - in fact, I&#39;m amused to see my stupid patch to fix
the build if you do just that (86a5906e4d1d) has just had its birthday ;)
<span class="quote">
&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt; fail, and a warning will be printed (rate-limited).</span>

This rationale seems questionable - how useful is non-deterministic
behaviour for debugging really? What you end up with is DMA sometimes
working or sometimes not depending on whether allocations happen to
naturally fall below 4GB or not. In my experience, that in itself can be
a pain in the arse to debug.

Most of the things you might then do to make things more deterministic
again (like making the default DMA mask tiny or hacking out all the
system&#39;s 32-bit addressable RAM) are also generally sufficient to make
DMA fail earlier and make this option moot anyway. What&#39;s the specific
use case motivating this?

Robin.
<span class="quote">
&gt; Note that io_tlb_nslabs is set to 1, which is the minimal supported</span>
<span class="quote">&gt; value.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Geert Uytterhoeven &lt;geert+renesas@glider.be&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  Documentation/kernel-parameters.txt |  3 ++-</span>
<span class="quote">&gt;  lib/swiotlb.c                       | 19 +++++++++++++++++--</span>
<span class="quote">&gt;  2 files changed, 19 insertions(+), 3 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/kernel-parameters.txt b/Documentation/kernel-parameters.txt</span>
<span class="quote">&gt; index 37babf91f2cb6de2..38556cdceabaf087 100644</span>
<span class="quote">&gt; --- a/Documentation/kernel-parameters.txt</span>
<span class="quote">&gt; +++ b/Documentation/kernel-parameters.txt</span>
<span class="quote">&gt; @@ -3998,10 +3998,11 @@ bytes respectively. Such letter suffixes can also be entirely omitted.</span>
<span class="quote">&gt;  			it if 0 is given (See Documentation/cgroup-v1/memory.txt)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	swiotlb=	[ARM,IA-64,PPC,MIPS,X86]</span>
<span class="quote">&gt; -			Format: { &lt;int&gt; | force }</span>
<span class="quote">&gt; +			Format: { &lt;int&gt; | force | nobounce }</span>
<span class="quote">&gt;  			&lt;int&gt; -- Number of I/O TLB slabs</span>
<span class="quote">&gt;  			force -- force using of bounce buffers even if they</span>
<span class="quote">&gt;  			         wouldn&#39;t be automatically used by the kernel</span>
<span class="quote">&gt; +			nobounce -- Never use bounce buffers (for debugging)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	switches=	[HW,M68k]</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt; index 6ce764410ae475cc..4550e6b516c2a4c0 100644</span>
<span class="quote">&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt; @@ -54,6 +54,7 @@</span>
<span class="quote">&gt;  #define IO_TLB_MIN_SLABS ((1&lt;&lt;20) &gt;&gt; IO_TLB_SHIFT)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int swiotlb_force;</span>
<span class="quote">&gt; +static int swiotlb_nobounce;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Used to do a quick range check in swiotlb_tbl_unmap_single and</span>
<span class="quote">&gt; @@ -106,8 +107,12 @@</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (*str == &#39;,&#39;)</span>
<span class="quote">&gt;  		++str;</span>
<span class="quote">&gt; -	if (!strcmp(str, &quot;force&quot;))</span>
<span class="quote">&gt; +	if (!strcmp(str, &quot;force&quot;)) {</span>
<span class="quote">&gt;  		swiotlb_force = 1;</span>
<span class="quote">&gt; +	} else if (!strcmp(str, &quot;nobounce&quot;)) {</span>
<span class="quote">&gt; +		swiotlb_nobounce = 1;</span>
<span class="quote">&gt; +		io_tlb_nslabs = 1;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -541,8 +546,15 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,</span>
<span class="quote">&gt;  map_single(struct device *hwdev, phys_addr_t phys, size_t size,</span>
<span class="quote">&gt;  	   enum dma_data_direction dir)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	dma_addr_t start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="quote">&gt; +	dma_addr_t start_dma_addr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (swiotlb_nobounce) {</span>
<span class="quote">&gt; +		dev_warn_ratelimited(hwdev, &quot;Cannot do DMA to address %pa\n&quot;,</span>
<span class="quote">&gt; +				     &amp;phys);</span>
<span class="quote">&gt; +		return SWIOTLB_MAP_ERROR;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="quote">&gt;  	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -707,6 +719,9 @@ void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,</span>
<span class="quote">&gt;  swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt;  	     int do_panic)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +	if (swiotlb_nobounce)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Ran out of IOMMU space for this operation. This is very bad.</span>
<span class="quote">&gt;  	 * Unfortunately the drivers cannot handle this operation properly.</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - Oct. 31, 2016, 5:52 p.m.</div>
<pre class="content">
On Mon, Oct 31, 2016 at 04:45:04PM +0100, Geert Uytterhoeven wrote:
<span class="quote">&gt; On architectures like arm64, swiotlb is tied intimately to the core</span>
<span class="quote">&gt; architecture DMA support. In addition, ZONE_DMA cannot be disabled.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt; fail, and a warning will be printed (rate-limited).</span>

I would make the &#39;swiotlb_force&#39; an enum. And then instead of this
being &#39;nobounce&#39; just do the inverse of &#39;force&#39;, that is the
&#39;noforce&#39; would trigger this no bounce effect.

So:

enum {
	NORMAL,		/* Default - depending on the hardware DMA mask and such. */
	FORCE,		/* swiotlb=force */
	NO_FORCE,	/* swiotlb=noforce */
}
<span class="quote">&gt; </span>
<span class="quote">&gt; Note that io_tlb_nslabs is set to 1, which is the minimal supported</span>
<span class="quote">&gt; value.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Geert Uytterhoeven &lt;geert+renesas@glider.be&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  Documentation/kernel-parameters.txt |  3 ++-</span>
<span class="quote">&gt;  lib/swiotlb.c                       | 19 +++++++++++++++++--</span>
<span class="quote">&gt;  2 files changed, 19 insertions(+), 3 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/kernel-parameters.txt b/Documentation/kernel-parameters.txt</span>
<span class="quote">&gt; index 37babf91f2cb6de2..38556cdceabaf087 100644</span>
<span class="quote">&gt; --- a/Documentation/kernel-parameters.txt</span>
<span class="quote">&gt; +++ b/Documentation/kernel-parameters.txt</span>
<span class="quote">&gt; @@ -3998,10 +3998,11 @@ bytes respectively. Such letter suffixes can also be entirely omitted.</span>
<span class="quote">&gt;  			it if 0 is given (See Documentation/cgroup-v1/memory.txt)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	swiotlb=	[ARM,IA-64,PPC,MIPS,X86]</span>
<span class="quote">&gt; -			Format: { &lt;int&gt; | force }</span>
<span class="quote">&gt; +			Format: { &lt;int&gt; | force | nobounce }</span>
<span class="quote">&gt;  			&lt;int&gt; -- Number of I/O TLB slabs</span>
<span class="quote">&gt;  			force -- force using of bounce buffers even if they</span>
<span class="quote">&gt;  			         wouldn&#39;t be automatically used by the kernel</span>
<span class="quote">&gt; +			nobounce -- Never use bounce buffers (for debugging)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	switches=	[HW,M68k]</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt; index 6ce764410ae475cc..4550e6b516c2a4c0 100644</span>
<span class="quote">&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt; @@ -54,6 +54,7 @@</span>
<span class="quote">&gt;  #define IO_TLB_MIN_SLABS ((1&lt;&lt;20) &gt;&gt; IO_TLB_SHIFT)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int swiotlb_force;</span>
<span class="quote">&gt; +static int swiotlb_nobounce;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Used to do a quick range check in swiotlb_tbl_unmap_single and</span>
<span class="quote">&gt; @@ -106,8 +107,12 @@</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (*str == &#39;,&#39;)</span>
<span class="quote">&gt;  		++str;</span>
<span class="quote">&gt; -	if (!strcmp(str, &quot;force&quot;))</span>
<span class="quote">&gt; +	if (!strcmp(str, &quot;force&quot;)) {</span>
<span class="quote">&gt;  		swiotlb_force = 1;</span>
<span class="quote">&gt; +	} else if (!strcmp(str, &quot;nobounce&quot;)) {</span>
<span class="quote">&gt; +		swiotlb_nobounce = 1;</span>
<span class="quote">&gt; +		io_tlb_nslabs = 1;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -541,8 +546,15 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,</span>
<span class="quote">&gt;  map_single(struct device *hwdev, phys_addr_t phys, size_t size,</span>
<span class="quote">&gt;  	   enum dma_data_direction dir)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	dma_addr_t start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="quote">&gt; +	dma_addr_t start_dma_addr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (swiotlb_nobounce) {</span>
<span class="quote">&gt; +		dev_warn_ratelimited(hwdev, &quot;Cannot do DMA to address %pa\n&quot;,</span>
<span class="quote">&gt; +				     &amp;phys);</span>
<span class="quote">&gt; +		return SWIOTLB_MAP_ERROR;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="quote">&gt;  	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -707,6 +719,9 @@ void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,</span>
<span class="quote">&gt;  swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt;  	     int do_panic)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +	if (swiotlb_nobounce)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Ran out of IOMMU space for this operation. This is very bad.</span>
<span class="quote">&gt;  	 * Unfortunately the drivers cannot handle this operation properly.</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 1.9.1</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=70">Geert Uytterhoeven</a> - Oct. 31, 2016, 6:20 p.m.</div>
<pre class="content">
Hi Robin,

On Mon, Oct 31, 2016 at 6:41 PM, Robin Murphy &lt;robin.murphy@arm.com&gt; wrote:
<span class="quote">&gt; On 31/10/16 15:45, Geert Uytterhoeven wrote:</span>
<span class="quote">&gt;&gt; On architectures like arm64, swiotlb is tied intimately to the core</span>
<span class="quote">&gt;&gt; architecture DMA support. In addition, ZONE_DMA cannot be disabled.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; To be fair, that only takes a single-character change in</span>
<span class="quote">&gt; arch/arm64/Kconfig - in fact, I&#39;m amused to see my stupid patch to fix</span>
<span class="quote">&gt; the build if you do just that (86a5906e4d1d) has just had its birthday ;)</span>

Unfortunately it&#39;s not that simple. Using a small patch (based on Mark Salter&#39;s
&quot;arm64: make CONFIG_ZONE_DMA user settable&quot;), it appears to work. However:
  - With CONFIG_ZONE_DMA=n and memory present over 4G, swiotlb_init() is
    not called.
    This will lead to a NULL pointer dereference later, when
    dma_map_single() calls into an unitialized SWIOTLB subsystem through
    swiotlb_tbl_map_single().
  - With CONFIG_ZONE_DMA=n and no memory present over 4G, swiotlb_init()
    is also not called, but RAVB works fine.
Disabling CONFIG_SWIOTLB is non-trivial, as the arm64 DMA core always
uses swiotlb_dma_ops, and its operations depend a lot on SWIOTLB
helpers.

So that&#39;s why I went for this option.
<span class="quote">
&gt;&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt;&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt;&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt;&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt;&gt; fail, and a warning will be printed (rate-limited).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This rationale seems questionable - how useful is non-deterministic</span>
<span class="quote">&gt; behaviour for debugging really? What you end up with is DMA sometimes</span>
<span class="quote">&gt; working or sometimes not depending on whether allocations happen to</span>
<span class="quote">&gt; naturally fall below 4GB or not. In my experience, that in itself can be</span>
<span class="quote">&gt; a pain in the arse to debug.</span>

It immediately triggered for me, though:

    rcar-dmac e7300000.dma-controller: Cannot do DMA to address
0x000000067a9b7000
    ravb e6800000.ethernet: Cannot do DMA to address 0x000000067aa07780
<span class="quote">
&gt; Most of the things you might then do to make things more deterministic</span>
<span class="quote">&gt; again (like making the default DMA mask tiny or hacking out all the</span>
<span class="quote">&gt; system&#39;s 32-bit addressable RAM) are also generally sufficient to make</span>
<span class="quote">&gt; DMA fail earlier and make this option moot anyway. What&#39;s the specific</span>
<span class="quote">&gt; use case motivating this?</span>

My use case is finding which drivers and DMA engines do not support 64-bit
memory. There&#39;s more info in my series &quot;[PATCH/RFC 0/5] arm64: r8a7796: 64-bit
Memory and Ethernet Prototype&quot;
(https://www.mail-archive.com/linux-renesas-soc@vger.kernel.org/msg08393.html)

Gr{oetje,eeting}s,

                        Geert

--
Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org

In personal conversations with technical people, I call myself a hacker. But
when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.
                                -- Linus Torvalds
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77581">Robin Murphy</a> - Nov. 1, 2016, 11:46 a.m.</div>
<pre class="content">
On 31/10/16 18:20, Geert Uytterhoeven wrote:
<span class="quote">&gt; Hi Robin,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Mon, Oct 31, 2016 at 6:41 PM, Robin Murphy &lt;robin.murphy@arm.com&gt; wrote:</span>
<span class="quote">&gt;&gt; On 31/10/16 15:45, Geert Uytterhoeven wrote:</span>
<span class="quote">&gt;&gt;&gt; On architectures like arm64, swiotlb is tied intimately to the core</span>
<span class="quote">&gt;&gt;&gt; architecture DMA support. In addition, ZONE_DMA cannot be disabled.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; To be fair, that only takes a single-character change in</span>
<span class="quote">&gt;&gt; arch/arm64/Kconfig - in fact, I&#39;m amused to see my stupid patch to fix</span>
<span class="quote">&gt;&gt; the build if you do just that (86a5906e4d1d) has just had its birthday ;)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Unfortunately it&#39;s not that simple. Using a small patch (based on Mark Salter&#39;s</span>
<span class="quote">&gt; &quot;arm64: make CONFIG_ZONE_DMA user settable&quot;), it appears to work. However:</span>
<span class="quote">&gt;   - With CONFIG_ZONE_DMA=n and memory present over 4G, swiotlb_init() is</span>
<span class="quote">&gt;     not called.</span>
<span class="quote">&gt;     This will lead to a NULL pointer dereference later, when</span>
<span class="quote">&gt;     dma_map_single() calls into an unitialized SWIOTLB subsystem through</span>
<span class="quote">&gt;     swiotlb_tbl_map_single().</span>
<span class="quote">&gt;   - With CONFIG_ZONE_DMA=n and no memory present over 4G, swiotlb_init()</span>
<span class="quote">&gt;     is also not called, but RAVB works fine.</span>
<span class="quote">&gt; Disabling CONFIG_SWIOTLB is non-trivial, as the arm64 DMA core always</span>
<span class="quote">&gt; uses swiotlb_dma_ops, and its operations depend a lot on SWIOTLB</span>
<span class="quote">&gt; helpers.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So that&#39;s why I went for this option.</span>

OK, that&#39;s new to me - I guess this behaviour was introduced by
b67a8b29df7e (&quot;arm64: mm: only initialize swiotlb when necessary&quot;).
Regardless of this patch, that check probably wants fixing to still do
the appropriate thing if arm64_dma_phys_limit is above 4GB (or just
depend on ZONE_DMA). Disabling ZONE_DMA for development doesn&#39;t seem
that unreasonable a thing to do, especially if there are ready-made
patches floating around already, so having it crash the kernel in ways
it didn&#39;t before isn&#39;t ideal.
<span class="quote">
&gt;&gt;&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt;&gt;&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt;&gt;&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt;&gt;&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt;&gt;&gt; fail, and a warning will be printed (rate-limited).</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This rationale seems questionable - how useful is non-deterministic</span>
<span class="quote">&gt;&gt; behaviour for debugging really? What you end up with is DMA sometimes</span>
<span class="quote">&gt;&gt; working or sometimes not depending on whether allocations happen to</span>
<span class="quote">&gt;&gt; naturally fall below 4GB or not. In my experience, that in itself can be</span>
<span class="quote">&gt;&gt; a pain in the arse to debug.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It immediately triggered for me, though:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     rcar-dmac e7300000.dma-controller: Cannot do DMA to address</span>
<span class="quote">&gt; 0x000000067a9b7000</span>
<span class="quote">&gt;     ravb e6800000.ethernet: Cannot do DMA to address 0x000000067aa07780</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; Most of the things you might then do to make things more deterministic</span>
<span class="quote">&gt;&gt; again (like making the default DMA mask tiny or hacking out all the</span>
<span class="quote">&gt;&gt; system&#39;s 32-bit addressable RAM) are also generally sufficient to make</span>
<span class="quote">&gt;&gt; DMA fail earlier and make this option moot anyway. What&#39;s the specific</span>
<span class="quote">&gt;&gt; use case motivating this?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; My use case is finding which drivers and DMA engines do not support 64-bit</span>
<span class="quote">&gt; memory. There&#39;s more info in my series &quot;[PATCH/RFC 0/5] arm64: r8a7796: 64-bit</span>
<span class="quote">&gt; Memory and Ethernet Prototype&quot;</span>
<span class="quote">&gt; (https://www.mail-archive.com/linux-renesas-soc@vger.kernel.org/msg08393.html)</span>

Thanks for the context. I&#39;ve done very similar things in the past, and
my first instinct would be to change the default DMA mask in
of_dma_configure() to something which can&#39;t reach RAM (e.g. &lt;30 bits),
then instrument dma_set_mask() to catch cleverer drivers. That&#39;s a
straightforward way to get 100% coverage - the problem with simply
disabling bounce buffering is that whilst statistically it almost
certainly will catch &gt;95% of cases, there will always be some that it
won&#39;t; if some driver only ever does a single dma_alloc_coherent() early
enough that allocations are still fairly deterministic, and always
happens to get a 32-bit address on that platform, it&#39;s likely to slip
through the net.

I&#39;m not against the idea of SWIOTLB growing a runtime-disable option,
I&#39;m just not sure what situation it&#39;s actually the best solution for.

Robin.
<span class="quote">
&gt; </span>
<span class="quote">&gt; Gr{oetje,eeting}s,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                         Geert</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; In personal conversations with technical people, I call myself a hacker. But</span>
<span class="quote">&gt; when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.</span>
<span class="quote">&gt;                                 -- Linus Torvalds</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=70">Geert Uytterhoeven</a> - Nov. 7, 2016, 3:41 p.m.</div>
<pre class="content">
Hi Robin,

On Tue, Nov 1, 2016 at 12:46 PM, Robin Murphy &lt;robin.murphy@arm.com&gt; wrote:
<span class="quote">&gt;&gt;&gt;&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt;&gt;&gt;&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt;&gt;&gt;&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt;&gt;&gt;&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt;&gt;&gt;&gt; fail, and a warning will be printed (rate-limited).</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This rationale seems questionable - how useful is non-deterministic</span>
<span class="quote">&gt;&gt;&gt; behaviour for debugging really? What you end up with is DMA sometimes</span>
<span class="quote">&gt;&gt;&gt; working or sometimes not depending on whether allocations happen to</span>
<span class="quote">&gt;&gt;&gt; naturally fall below 4GB or not. In my experience, that in itself can be</span>
<span class="quote">&gt;&gt;&gt; a pain in the arse to debug.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; It immediately triggered for me, though:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;     rcar-dmac e7300000.dma-controller: Cannot do DMA to address</span>
<span class="quote">&gt;&gt; 0x000000067a9b7000</span>
<span class="quote">&gt;&gt;     ravb e6800000.ethernet: Cannot do DMA to address 0x000000067aa07780</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Most of the things you might then do to make things more deterministic</span>
<span class="quote">&gt;&gt;&gt; again (like making the default DMA mask tiny or hacking out all the</span>
<span class="quote">&gt;&gt;&gt; system&#39;s 32-bit addressable RAM) are also generally sufficient to make</span>
<span class="quote">&gt;&gt;&gt; DMA fail earlier and make this option moot anyway. What&#39;s the specific</span>
<span class="quote">&gt;&gt;&gt; use case motivating this?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; My use case is finding which drivers and DMA engines do not support 64-bit</span>
<span class="quote">&gt;&gt; memory. There&#39;s more info in my series &quot;[PATCH/RFC 0/5] arm64: r8a7796: 64-bit</span>
<span class="quote">&gt;&gt; Memory and Ethernet Prototype&quot;</span>
<span class="quote">&gt;&gt; (https://www.mail-archive.com/linux-renesas-soc@vger.kernel.org/msg08393.html)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Thanks for the context. I&#39;ve done very similar things in the past, and</span>
<span class="quote">&gt; my first instinct would be to change the default DMA mask in</span>
<span class="quote">&gt; of_dma_configure() to something which can&#39;t reach RAM (e.g. &lt;30 bits),</span>
<span class="quote">&gt; then instrument dma_set_mask() to catch cleverer drivers. That&#39;s a</span>
<span class="quote">&gt; straightforward way to get 100% coverage - the problem with simply</span>
<span class="quote">&gt; disabling bounce buffering is that whilst statistically it almost</span>
<span class="quote">&gt; certainly will catch &gt;95% of cases, there will always be some that it</span>
<span class="quote">&gt; won&#39;t; if some driver only ever does a single dma_alloc_coherent() early</span>
<span class="quote">&gt; enough that allocations are still fairly deterministic, and always</span>
<span class="quote">&gt; happens to get a 32-bit address on that platform, it&#39;s likely to slip</span>
<span class="quote">&gt; through the net.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I&#39;m not against the idea of SWIOTLB growing a runtime-disable option,</span>
<span class="quote">&gt; I&#39;m just not sure what situation it&#39;s actually the best solution for.</span>

If I set the DMA mask to a small value, DMA is never used, and SWIOTLB
always falls back to bounce buffers (and DMAing from the small pool)?

That&#39;s the inverse of what I want to achieve: I want to avoid using the
bounce feature, to make sure the DMA engine is always used with whatever
kind of memory.

Gr{oetje,eeting}s,

                        Geert

--
Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org

In personal conversations with technical people, I call myself a hacker. But
when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.
                                -- Linus Torvalds
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77581">Robin Murphy</a> - Nov. 7, 2016, 5:18 p.m.</div>
<pre class="content">
Hi Geert,

On 07/11/16 15:41, Geert Uytterhoeven wrote:
<span class="quote">&gt; Hi Robin,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Tue, Nov 1, 2016 at 12:46 PM, Robin Murphy &lt;robin.murphy@arm.com&gt; wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; fail, and a warning will be printed (rate-limited).</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; This rationale seems questionable - how useful is non-deterministic</span>
<span class="quote">&gt;&gt;&gt;&gt; behaviour for debugging really? What you end up with is DMA sometimes</span>
<span class="quote">&gt;&gt;&gt;&gt; working or sometimes not depending on whether allocations happen to</span>
<span class="quote">&gt;&gt;&gt;&gt; naturally fall below 4GB or not. In my experience, that in itself can be</span>
<span class="quote">&gt;&gt;&gt;&gt; a pain in the arse to debug.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; It immediately triggered for me, though:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;     rcar-dmac e7300000.dma-controller: Cannot do DMA to address</span>
<span class="quote">&gt;&gt;&gt; 0x000000067a9b7000</span>
<span class="quote">&gt;&gt;&gt;     ravb e6800000.ethernet: Cannot do DMA to address 0x000000067aa07780</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Most of the things you might then do to make things more deterministic</span>
<span class="quote">&gt;&gt;&gt;&gt; again (like making the default DMA mask tiny or hacking out all the</span>
<span class="quote">&gt;&gt;&gt;&gt; system&#39;s 32-bit addressable RAM) are also generally sufficient to make</span>
<span class="quote">&gt;&gt;&gt;&gt; DMA fail earlier and make this option moot anyway. What&#39;s the specific</span>
<span class="quote">&gt;&gt;&gt;&gt; use case motivating this?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; My use case is finding which drivers and DMA engines do not support 64-bit</span>
<span class="quote">&gt;&gt;&gt; memory. There&#39;s more info in my series &quot;[PATCH/RFC 0/5] arm64: r8a7796: 64-bit</span>
<span class="quote">&gt;&gt;&gt; Memory and Ethernet Prototype&quot;</span>
<span class="quote">&gt;&gt;&gt; (https://www.mail-archive.com/linux-renesas-soc@vger.kernel.org/msg08393.html)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Thanks for the context. I&#39;ve done very similar things in the past, and</span>
<span class="quote">&gt;&gt; my first instinct would be to change the default DMA mask in</span>
<span class="quote">&gt;&gt; of_dma_configure() to something which can&#39;t reach RAM (e.g. &lt;30 bits),</span>
<span class="quote">&gt;&gt; then instrument dma_set_mask() to catch cleverer drivers. That&#39;s a</span>
<span class="quote">&gt;&gt; straightforward way to get 100% coverage - the problem with simply</span>
<span class="quote">&gt;&gt; disabling bounce buffering is that whilst statistically it almost</span>
<span class="quote">&gt;&gt; certainly will catch &gt;95% of cases, there will always be some that it</span>
<span class="quote">&gt;&gt; won&#39;t; if some driver only ever does a single dma_alloc_coherent() early</span>
<span class="quote">&gt;&gt; enough that allocations are still fairly deterministic, and always</span>
<span class="quote">&gt;&gt; happens to get a 32-bit address on that platform, it&#39;s likely to slip</span>
<span class="quote">&gt;&gt; through the net.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I&#39;m not against the idea of SWIOTLB growing a runtime-disable option,</span>
<span class="quote">&gt;&gt; I&#39;m just not sure what situation it&#39;s actually the best solution for.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If I set the DMA mask to a small value, DMA is never used, and SWIOTLB</span>
<span class="quote">&gt; always falls back to bounce buffers (and DMAing from the small pool)?</span>

Not quite - I meant setting the default mask to a value small enough
that any attempt to allocate or map within it (whether bounced or
otherwise) cannot possibly succeed. Of course, if you have RAM right
down to address 0 this becomes trickier - I&#39;m not entirely certain that
going to extremes (DMA_BIT_MASK(1), say) wouldn&#39;t end up going wrong
somewhere for misleadingly unrelated reasons - but I got the impression
from the mainline DT that RAM on your platform starts at 0x40000000,
hence the 30-bit suggestion.

At that point, you can instantly tell for certain that any driver for
which DMA starts failing is relying on the default mask and definitely
needs looking at for 64-bit support, and anything that doesn&#39;t just
needs a simple check of what it&#39;s passing to dma_set_*mask*().

Alternatively, the really bulletproof option is to get the firmware to
load the kernel into the &gt;4GB area(s) of RAM (or hack dram_base in
handle_kernel_image() in arch/arm64/kernel/efi-stub.c) and simply remove
any 32-bit-addressable areas from the DT entirely (assuming the EFI
memory map isn&#39;t hard-coded). Then SWIOTLB becomes moot as there&#39;s
nowhere it can even allocate a usable bounce buffer.
<span class="quote">
&gt; That&#39;s the inverse of what I want to achieve: I want to avoid using the</span>
<span class="quote">&gt; bounce feature, to make sure the DMA engine is always used with whatever</span>
<span class="quote">&gt; kind of memory.</span>

As I said, it&#39;s that &quot;always&quot; that&#39;s the problem - there is already a
no-op path through the SWIOTLB code if the buffer happens to lie within
the device&#39;s DMA mask to start with, so just making SWIOTLB a no-op does
nothing to reveal anything sufficiently lucky to always hit that path on
current platforms.

Robin.
<span class="quote">
&gt; </span>
<span class="quote">&gt; Gr{oetje,eeting}s,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                         Geert</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; In personal conversations with technical people, I call myself a hacker. But</span>
<span class="quote">&gt; when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.</span>
<span class="quote">&gt;                                 -- Linus Torvalds</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=70">Geert Uytterhoeven</a> - Nov. 7, 2016, 6:57 p.m.</div>
<pre class="content">
Hi Konrad,

On Mon, Oct 31, 2016 at 6:52 PM, Konrad Rzeszutek Wilk
&lt;konrad.wilk@oracle.com&gt; wrote:
<span class="quote">&gt; On Mon, Oct 31, 2016 at 04:45:04PM +0100, Geert Uytterhoeven wrote:</span>
<span class="quote">&gt;&gt; On architectures like arm64, swiotlb is tied intimately to the core</span>
<span class="quote">&gt;&gt; architecture DMA support. In addition, ZONE_DMA cannot be disabled.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt;&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt;&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt;&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt;&gt; fail, and a warning will be printed (rate-limited).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I would make the &#39;swiotlb_force&#39; an enum. And then instead of this</span>
<span class="quote">&gt; being &#39;nobounce&#39; just do the inverse of &#39;force&#39;, that is the</span>
<span class="quote">&gt; &#39;noforce&#39; would trigger this no bounce effect.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; enum {</span>
<span class="quote">&gt;         NORMAL,         /* Default - depending on the hardware DMA mask and such. */</span>
<span class="quote">&gt;         FORCE,          /* swiotlb=force */</span>
<span class="quote">&gt;         NO_FORCE,       /* swiotlb=noforce */</span>

Fine for me, but swiotlb_force is exported to platform code. Hence all users
should be updated?

Gr{oetje,eeting}s,

                        Geert

--
Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org

In personal conversations with technical people, I call myself a hacker. But
when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.
                                -- Linus Torvalds
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - Nov. 7, 2016, 7:20 p.m.</div>
<pre class="content">
On Mon, Nov 07, 2016 at 07:57:11PM +0100, Geert Uytterhoeven wrote:
<span class="quote">&gt; Hi Konrad,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Mon, Oct 31, 2016 at 6:52 PM, Konrad Rzeszutek Wilk</span>
<span class="quote">&gt; &lt;konrad.wilk@oracle.com&gt; wrote:</span>
<span class="quote">&gt; &gt; On Mon, Oct 31, 2016 at 04:45:04PM +0100, Geert Uytterhoeven wrote:</span>
<span class="quote">&gt; &gt;&gt; On architectures like arm64, swiotlb is tied intimately to the core</span>
<span class="quote">&gt; &gt;&gt; architecture DMA support. In addition, ZONE_DMA cannot be disabled.</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; To aid debugging and catch devices not supporting DMA to memory outside</span>
<span class="quote">&gt; &gt;&gt; the 32-bit address space, add a kernel command line option</span>
<span class="quote">&gt; &gt;&gt; &quot;swiotlb=nobounce&quot;, which disables the use of bounce buffers.</span>
<span class="quote">&gt; &gt;&gt; If specified, trying to map memory that cannot be used with DMA will</span>
<span class="quote">&gt; &gt;&gt; fail, and a warning will be printed (rate-limited).</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; I would make the &#39;swiotlb_force&#39; an enum. And then instead of this</span>
<span class="quote">&gt; &gt; being &#39;nobounce&#39; just do the inverse of &#39;force&#39;, that is the</span>
<span class="quote">&gt; &gt; &#39;noforce&#39; would trigger this no bounce effect.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; So:</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; enum {</span>
<span class="quote">&gt; &gt;         NORMAL,         /* Default - depending on the hardware DMA mask and such. */</span>
<span class="quote">&gt; &gt;         FORCE,          /* swiotlb=force */</span>
<span class="quote">&gt; &gt;         NO_FORCE,       /* swiotlb=noforce */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Fine for me, but swiotlb_force is exported to platform code. Hence all users</span>
<span class="quote">&gt; should be updated?</span>

Yeah it would have to be moved to the swiotlb.h (the enum).

Thanks!
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/kernel-parameters.txt b/Documentation/kernel-parameters.txt</span>
<span class="p_header">index 37babf91f2cb6de2..38556cdceabaf087 100644</span>
<span class="p_header">--- a/Documentation/kernel-parameters.txt</span>
<span class="p_header">+++ b/Documentation/kernel-parameters.txt</span>
<span class="p_chunk">@@ -3998,10 +3998,11 @@</span> <span class="p_context"> bytes respectively. Such letter suffixes can also be entirely omitted.</span>
 			it if 0 is given (See Documentation/cgroup-v1/memory.txt)
 
 	swiotlb=	[ARM,IA-64,PPC,MIPS,X86]
<span class="p_del">-			Format: { &lt;int&gt; | force }</span>
<span class="p_add">+			Format: { &lt;int&gt; | force | nobounce }</span>
 			&lt;int&gt; -- Number of I/O TLB slabs
 			force -- force using of bounce buffers even if they
 			         wouldn&#39;t be automatically used by the kernel
<span class="p_add">+			nobounce -- Never use bounce buffers (for debugging)</span>
 
 	switches=	[HW,M68k]
 
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 6ce764410ae475cc..4550e6b516c2a4c0 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -54,6 +54,7 @@</span> <span class="p_context"></span>
 #define IO_TLB_MIN_SLABS ((1&lt;&lt;20) &gt;&gt; IO_TLB_SHIFT)
 
 int swiotlb_force;
<span class="p_add">+static int swiotlb_nobounce;</span>
 
 /*
  * Used to do a quick range check in swiotlb_tbl_unmap_single and
<span class="p_chunk">@@ -106,8 +107,12 @@</span> <span class="p_context"></span>
 	}
 	if (*str == &#39;,&#39;)
 		++str;
<span class="p_del">-	if (!strcmp(str, &quot;force&quot;))</span>
<span class="p_add">+	if (!strcmp(str, &quot;force&quot;)) {</span>
 		swiotlb_force = 1;
<span class="p_add">+	} else if (!strcmp(str, &quot;nobounce&quot;)) {</span>
<span class="p_add">+		swiotlb_nobounce = 1;</span>
<span class="p_add">+		io_tlb_nslabs = 1;</span>
<span class="p_add">+	}</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -541,8 +546,15 @@</span> <span class="p_context"> phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,</span>
 map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 	   enum dma_data_direction dir)
 {
<span class="p_del">-	dma_addr_t start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="p_add">+	dma_addr_t start_dma_addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (swiotlb_nobounce) {</span>
<span class="p_add">+		dev_warn_ratelimited(hwdev, &quot;Cannot do DMA to address %pa\n&quot;,</span>
<span class="p_add">+				     &amp;phys);</span>
<span class="p_add">+		return SWIOTLB_MAP_ERROR;</span>
<span class="p_add">+	}</span>
 
<span class="p_add">+	start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
 	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);
 }
 
<span class="p_chunk">@@ -707,6 +719,9 @@</span> <span class="p_context"> void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,</span>
 swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,
 	     int do_panic)
 {
<span class="p_add">+	if (swiotlb_nobounce)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	/*
 	 * Ran out of IOMMU space for this operation. This is very bad.
 	 * Unfortunately the drivers cannot handle this operation properly.

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



